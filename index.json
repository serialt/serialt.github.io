[{"categories":["DevOps"],"content":"Terraform Registry ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:0:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"一、Registry 协议 文档地址：https://developer.hashicorp.com/terraform/internals/provider-registry-protocol # list可用的provider curl 'https://registry.terraform.io/v1/providers/hashicorp/random/versions' { \"versions\": [ { \"version\": \"2.0.0\", \"protocols\": [\"4.0\", \"5.1\"], \"platforms\": [ {\"os\": \"darwin\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"arm\"}, {\"os\": \"windows\", \"arch\": \"amd64\"} ] }, { \"version\": \"2.0.1\", \"protocols\": [\"5.2\"], \"platforms\": [ {\"os\": \"darwin\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"arm\"}, {\"os\": \"windows\", \"arch\": \"amd64\"} ] } ] } # find provider package curl 'https://registry.terraform.io/v1/providers/hashicorp/random/2.0.0/download/linux/amd64' { \"protocols\": [\"4.0\", \"5.1\"], \"os\": \"linux\", \"arch\": \"amd64\", \"filename\": \"terraform-provider-random_2.0.0_linux_amd64.zip\", \"download_url\": \"https://releases.hashicorp.com/terraform-provider-random/2.0.0/terraform-provider-random_2.0.0_linux_amd64.zip\", \"shasums_url\": \"https://releases.hashicorp.com/terraform-provider-random/2.0.0/terraform-provider-random_2.0.0_SHA256SUMS\", \"shasums_signature_url\": \"https://releases.hashicorp.com/terraform-provider-random/2.0.0/terraform-provider-random_2.0.0_SHA256SUMS.sig\", \"shasum\": \"5f9c7aa76b7c34d722fc9123208e26b22d60440cb47150dd04733b9b94f4541a\", \"signing_keys\": { \"gpg_public_keys\": [ { \"key_id\": \"51852D87348FFC4C\", \"ascii_armor\": \"-----BEGIN PGP PUBLIC KEY BLOCK-----\\nVersion: GnuPG v1\\n\\nmQENBFMORM0BCADBRyKO1MhCirazOSVwcfTr1xUxjPvfxD3hjUwHtjsOy/bT6p9f\\nW2mRPfwnq2JB5As+paL3UGDsSRDnK9KAxQb0NNF4+eVhr/EJ18s3wwXXDMjpIifq\\nfIm2WyH3G+aRLTLPIpscUNKDyxFOUbsmgXAmJ46Re1fn8uKxKRHbfa39aeuEYWFA\\n3drdL1WoUngvED7f+RnKBK2G6ZEpO+LDovQk19xGjiMTtPJrjMjZJ3QXqPvx5wca\\nKSZLr4lMTuoTI/ZXyZy5bD4tShiZz6KcyX27cD70q2iRcEZ0poLKHyEIDAi3TM5k\\nSwbbWBFd5RNPOR0qzrb/0p9ksKK48IIfH2FvABEBAAG0K0hhc2hpQ29ycCBTZWN1\\ncml0eSA8c2VjdXJpdHlAaGFzaGljb3JwLmNvbT6JATgEEwECACIFAlMORM0CGwMG\\nCwkIBwMCBhUIAgkKCwQWAgMBAh4BAheAAAoJEFGFLYc0j/xMyWIIAIPhcVqiQ59n\\nJc07gjUX0SWBJAxEG1lKxfzS4Xp+57h2xxTpdotGQ1fZwsihaIqow337YHQI3q0i\\nSqV534Ms+j/tU7X8sq11xFJIeEVG8PASRCwmryUwghFKPlHETQ8jJ+Y8+1asRydi\\npsP3B/5Mjhqv/uOK+Vy3zAyIpyDOMtIpOVfjSpCplVRdtSTFWBu9Em7j5I2HMn1w\\nsJZnJgXKpybpibGiiTtmnFLOwibmprSu04rsnP4ncdC2XRD4wIjoyA+4PKgX3sCO\\nklEzKryWYBmLkJOMDdo52LttP3279s7XrkLEE7ia0fXa2c12EQ0f0DQ1tGUvyVEW\\nWmJVccm5bq25AQ0EUw5EzQEIANaPUY04/g7AmYkOMjaCZ6iTp9hB5Rsj/4ee/ln9\\nwArzRO9+3eejLWh53FoN1rO+su7tiXJA5YAzVy6tuolrqjM8DBztPxdLBbEi4V+j\\n2tK0dATdBQBHEh3OJApO2UBtcjaZBT31zrG9K55D+CrcgIVEHAKY8Cb4kLBkb5wM\\nskn+DrASKU0BNIV1qRsxfiUdQHZfSqtp004nrql1lbFMLFEuiY8FZrkkQ9qduixo\\nmTT6f34/oiY+Jam3zCK7RDN/OjuWheIPGj/Qbx9JuNiwgX6yRj7OE1tjUx6d8g9y\\n0H1fmLJbb3WZZbuuGFnK6qrE3bGeY8+AWaJAZ37wpWh1p0cAEQEAAYkBHwQYAQIA\\nCQUCUw5EzQIbDAAKCRBRhS2HNI/8TJntCAClU7TOO/X053eKF1jqNW4A1qpxctVc\\nz8eTcY8Om5O4f6a/rfxfNFKn9Qyja/OG1xWNobETy7MiMXYjaa8uUx5iFy6kMVaP\\n0BXJ59NLZjMARGw6lVTYDTIvzqqqwLxgliSDfSnqUhubGwvykANPO+93BBx89MRG\\nunNoYGXtPlhNFrAsB1VR8+EyKLv2HQtGCPSFBhrjuzH3gxGibNDDdFQLxxuJWepJ\\nEK1UbTS4ms0NgZ2Uknqn1WRU1Ki7rE4sTy68iZtWpKQXZEJa0IGnuI2sSINGcXCJ\\noEIgXTMyCILo34Fa/C6VCm2WBgz9zZO8/rHIiQm1J5zqz0DrDwKBUM9C\\n=LYpS\\n-----END PGP PUBLIC KEY BLOCK-----\", \"trust_signature\": \"\", \"source\": \"HashiCorp\", \"source_url\": \"https://www.hashicorp.com/security.html\" } ] } } ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:1:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"二、Cache Terraform Registry ​ 在执行terraform init 的时候，terraform cli 会从官方的Registry查找和下载对应的provider，小的provider几M，大的可能几百M，而且如果当执行plan或apply出现问题需要重新执行init，可能需要多次请求registry，这对网络的速度和稳定性要求比较高。因此，基于官方的 Provider Registry Protocol 和 Remote Service，可以开发一个简单的cli缓存和提供Registry服务。 ​ ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:2:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"1、terraform下载provider原理 ​ 当执行terraform init 后，terraform cli 会根据 tf文件中定义的provider去向 registry.terraform.io 发起GET请求，例如：tf文件中有使用hashicorp/random，terraform cli 会发出Get请求 https://registry.terraform.io/v1/providers/hashicorp/random/versions，请求到数据后再跟tf文件中定义的版本判断一致后获取要下载的provider package 包的信息，例如：https://registry.terraform.io/v1/providers/hashicorp/random/2.0.0/download/linux/amd64，返回的数据中有provider的下载地址、provide的hash值和用于验证provider签名的公钥，由hashicorp维护的provider package会存放在releases.hashicorp.com中，而由第三方开发者维护的只能使用github托管，要求代码必须是开源的，且repo的命名格式符合 terraform-provider-ssh。 ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:2:1","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"2、缓存加速原理 ~/.terraformrc文件中可以可以配置镜像，例如： host \"registry.terraform.io\" { services = { \"modules.v1\" = \"http://127.0.0.1:9090/pub/v1/modules/\", \"providers.v1\" = \"http://127.0.0.1:9090/v1/providers/\" } } 当执行terraform init的时候，访问 registry.terraform.io/v1/providers/ 会被替换为http://127.0.0.1:9090/v1/providers/ ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:2:2","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"三、基于nexus存储provider ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:3:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"1、下载数据并同步到nexus 配置文件格式 storage: type: nexus nexus: url: http://nexus.local.com repo: terraform tf: providerLast: 2 provider: - \"hashicorp/random\" - \"hashicorp/aws\" - \"hashicorp/tls\" - \"hashicorp/dns\" providerOS: - linux - darwin providerArch: - amd64 - arm64 providerVersion: hashicorp/random: - \"3.6.0\" - \"3.3.2\" loafoe/ssh: - \"2.5.0\" # 获取provider的版本，把这个文件上传到nexus，路径: hashicorp/random/versions curl 'https://registry.terraform.io/v1/providers/hashicorp/random/versions' # 获取到版本信息后请求下载的provider package 信息 ,下载里面的文件，并把对应的链接信修改为nexus中的地址 curl https://registry.terraform.io/v1/providers/hashicorp/random/2.0.0/download/linux/amd64' # 下载上一步获取到的原始 provider pcakge 链接中的文件，把文件上传到nexus ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:3:1","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"2、实现Provider Registry Protocol 根据 Provider Registry Protocol实现一个私有的registry，根据请求来的信息去请求nexus上的对应数据，把数据返回给terraform cli , terraform cli 会自己从接收到的数据去从nexus下载对应版本的provider。 ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:3:2","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"Vault 参考链接：https://thiscute.world/posts/experience-of-vault/#%E4%B8%80vault-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5 介绍 Vault 是 hashicorp 推出的 secrets 管理、加密即服务与权限管理工具。它的功能简介如下： 1）secrets 管理：支持保存各种自定义信息、自动生成各类密钥，vault 自动生成的密钥还能自动轮转(rotate) 2）认证方式：支持接入各大云厂商的账号体系（比如阿里云RAM子账号体系）或者 LDAP 等进行身份验证，不需要创建额外的账号体系。 3）权限管理：通过 policy，可以设定非常细致的 ACL 权限。 4）密钥引擎：也支持接管各大云厂商的账号体系（比如阿里云RAM子账号体系），实现 API Key 的自动轮转。 5）支持接入 kubernetes rbac 认证体系，通过 serviceaccount+role 为每个 Pod 单独配置认证角色。 6）支持通过 sidecar/init-container 将 secrets 注入到 pod 中，或者通过 k8s operator 将 vault 数据同步到 k8s secrets 中 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:0:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"一、Vault 基础概念 ​ 几乎所有的 Vault 组件都被统称为「屏障（Barrier）」。Vault 可以简单地被划分为存储后端（Storage Backend）、屏障（Barrier）和 HTTP/S API 三个部分。 ​ Vault，翻译成中文就是金库。类比银行金库，「屏障」就是用于保护金库的合金大门和钢筋混凝土，存储后端和客户端之间的所有数据流动都需要经过它。「屏障」确保只有加密数据会被写入存储后端，加密数据在经过「屏障」被读出的过程中被验证与解密。和银行金库的大门非常类似，「屏障」也必须先解封，才能解密存储后端中的数据。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、数据存储及加密解密 存储后端（Storage Backend）: Vault 自身不存储数据，因此需要为它配置一个存储后端。 存储后端是不受信任的，只用于存储加密数据。 初始化（Initialization）: Vault 在首次启动时需要初始化，这一步生成一个加密密钥（Encryption Key）用于加密数据，加密完成的数据才能被保存到存储后端。 解封（Unseal）: Vault 启动后，因为不知道加密密钥所以无法解密数据，这种状态被形象得称作已封印（Sealed）。在解封前 Vault 无法进行任何操作。 加密密钥被主密钥（Master Key）保护，我们必须提供主密钥才能解密出 Vault 的加密密钥，从而完成解封操作。 默认情况下，Vault 使用沙米尔密钥分割算法 将主密钥分割成五个分割密钥（Key Shares），必须要提供其中任意三个分割密钥才能重建出主密钥，完成解封操作。 分割密钥的总数，以及重建主密钥最少需要的分割密钥数量，都是可以调整的。 沙米尔密钥分割算法也可以关闭，这样主密钥将被直接提供给管理员，管理员可直接使用它进行解封操作。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2. 认证系统及权限系统 在解封完成后，Vault 就可以开始处理请求了。 HTTP 请求进入后的整个处理流程都由 vault core 管理，core 会强制进行 ACL 检查，并确保审计日志(audit logging)完成记录。 客户端首次连接 vault 时，需要先完成身份认证，vault 的 auth methods 模块有很多身份认证方法可选： 1）用户友好的认证方法，适合管理员使用：username/password、云服务商、ldap，在创建 user 的时候，需要为 user 绑定 policy，给予合适的权限。 2）应用友好的方法，适合应用程序使用：public/private keys、tokens、kubernetes、jwt身份验证请求流经 core 并进入 auth methods，auth methods 确定请求是否有效并返回「关联策略(policies)」的列表。 ACL 策略由 policy store 负责管理与存储，由 core 进行 ACL 检查。 ACL 的默认行为是拒绝，这意味着除非明确配置 policy 允许某项操作，否则该操作将被拒绝。在通过 auth methods 完成了身份认证，并且返回的关联策略也没毛病之后，token store 将会生成并管理一个新的凭证（token）， 这个 token 会被返回给客户端，用于进行后续请求。类似 web 网站的 cookie，token 也都存在一个租期（lease）或者说有效期，这加强了安全性。token 关联了相关的策略 policies，这些策略将被用于验证请求的权限。 请求经过验证后，将被路由到 secret engine。如果 secret engine 返回了一个 secret（由 vault 自动生成的 secret）， core 会将其注册到 expiration manager，并给它附加一个 lease ID。lease ID 被客户端用于更新(renew)或吊销(revoke)它得到的 secret. 如果客户端允许租约(lease)到期，expiration manager 将自动吊销这个 secret. core 还负责处理审核代理 audit broker的请求及响应日志，将请求发送到所有已配置的审核设备 audit devices. 不过默认情况下这个功能貌似是关闭的。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"3. Secret Engine Secret Engine 是保存、生成或者加密数据的组件，它非常灵活。 有的 Secret Engines 只是单纯地存储与读取数据，比如 kv 就可以看作一个加密的 Redis。 而其他的 Secret Engines 则连接到其他的服务并按需生成动态凭证。 还有些 Secret Engines 提供「加密即服务(encryption as a service)」的能力，如 transit、证书管理等。 常用的 engine 举例： 1）AliCloud Secrets Engine: 基于 RAM 策略动态生成 AliCloud Access Token，或基于 RAM 角色动态生成 AliCloud STS 凭据，Access Token 会自动更新(Renew)，而 STS 凭据是临时使用的，过期后就失效了。 2）kv: 键值存储，可用于存储一些静态的配置。它一定程度上能替代掉携程的 Apollo 配置中心。 3）Transit Secrets Engine: 提供加密即服务的功能，它只负责加密和解密，不负责存储。主要应用场景是帮 app 加解密数据，但是数据仍旧存储在 MySQL 等数据库中。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:3","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"二、部署 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、docker-compose version: '3.3' services: vault: image: vault:1.12.3 container_name: vault ports: - \"8200:8200\" restart: always volumes: - ./logs:/vault/logs - ./file:/vault/date - ./config.hcl:/vault/config/config.hcl #- ./certs:/certs # vault 需要锁定内存以防止敏感值信息被交换(swapped)到磁盘中 # 为此需要添加如下 capability cap_add: - IPC_LOCK entrypoint: vault server -config /vault/config/config.hcl config.hcl 内容如下： # 单机版 ui = true listener \"tcp\" { tls_disable = 1 address = \"[::]:8200\" cluster_address = \"[::]:8201\" } storage \"file\" { path = \"/vault/data\" } ui = true // 使用文件做数据存储（单节点） storage \"raft\" { path = \"/vault/date\" node_id = \"node1\" } listener \"tcp\" { address = \"[::]:8200\" tls_disable = \"true\" } api_addr = \"http://0.0.0.0/8200\" // ha 访问入口，不能写0.0.0.0 cluster_addr = \"http://172.16.78.161:8201\" ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2、初始化 # 设置vault地址 [root@sugar vault]# export VAULT_ADDR='http://127.0.0.1:8200' # 复制命令到宿主机 [root@sugar vault]# docker cp vault:/bin/vault /usr/local/bin/vault [root@sugar vault]# chmod +x /usr/local/bin/vault [root@sugar vault]# vault operator init vault operator init Unseal Key 1: aTpDcs5FQ1GzklifRwYCKdLPHpCUvNm9EGhZ0NH8Ut0p Unseal Key 2: 33V89ljeUr23AQpBgDANgFRzft+8f7E5KRXPDjsFpOG2 Unseal Key 3: OwfbdEA481baX8TZ0/kT49dBFg6ArXboVapBAd1y0fqk Unseal Key 4: DD1Lp86WGqVq+18LwUdGPxb6cquTjSz/yAIc9fkYNzF9 Unseal Key 5: FrqRqQSlhb/sjj7h9Pcau5eqrB/rxtkFBbBJSfuv48IM Initial Root Token: hvs.FTcALTSfrVuw9On8B2g2JQIl Vault initialized with 5 key shares and a key threshold of 3. Please securely distribute the key shares printed above. When the Vault is re-sealed, restarted, or stopped, you must supply at least 3 of these keys to unseal it before it can start servicing requests. Vault does not store the generated root key. Without at least 3 keys to reconstruct the root key, Vault will remain permanently sealed! It is possible to generate new unseal keys, provided you have a quorum of ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"3、解封 [root@sugar vault]# vault operator unseal aTpDcs5FQ1GzklifRwYCKdLPHpCUvNm9EGhZ0NH8Ut0p Key Value --- ----- Seal Type shamir Initialized true Sealed true Total Shares 5 Threshold 3 Unseal Progress 1/3 Unseal Nonce 8d5a33c3-bff5-e407-eb13-15c1457bdb63 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft HA Enabled true [root@sugar vault]# vault operator unseal OwfbdEA481baX8TZ0/kT49dBFg6ArXboVapBAd1y0fqk Key Value --- ----- Seal Type shamir Initialized true Sealed true Total Shares 5 Threshold 3 Unseal Progress 2/3 Unseal Nonce 8d5a33c3-bff5-e407-eb13-15c1457bdb63 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft HA Enabled true [root@sugar vault]# vault operator unseal 'FrqRqQSlhb/sjj7h9Pcau5eqrB/rxtkFBbBJSfuv48IM' Key Value --- ----- Seal Type shamir Initialized true Sealed false Total Shares 5 Threshold 3 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft Cluster Name vault-cluster-8257ffed Cluster ID 2eccf238-400e-1ba5-f491-321c1388c826 HA Enabled true HA Cluster n/a HA Mode standby Active Node Address \u003cnone\u003e Raft Committed Index 31 Raft Applied Index 31 [root@sugar vault]# vault status Key Value --- ----- Seal Type shamir Initialized true Sealed false Total Shares 5 Threshold 3 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft Cluster Name vault-cluster-8257ffed Cluster ID 2eccf238-400e-1ba5-f491-321c1388c826 HA Enabled true HA Cluster https://192.168.10.161:8201 HA Mode active Active Since 2023-03-07T12:11:38.884017872Z Raft Committed Index 36 Raft Applied Index 36 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:3","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"4、登录测试 # export VAULT_TOKEN='hvs.FTcALTSfrVuw9On8B2g2JQIl' [root@jenkins116 vault]# vault login Token (will be hidden): WARNING! The VAULT_TOKEN environment variable is set! The value of this variable will take precedence; if this is unwanted please unset VAULT_TOKEN or update its value accordingly. Success! You are now authenticated. The token information displayed below is already stored in the token helper. You do NOT need to run \"vault login\" again. Future Vault requests will automatically use this token. Key Value --- ----- token hvs.FTcALTSfrVuw9On8B2g2JQIl token_accessor vkDaIsiPx3w9JEpUWv9NRnQm token_duration ∞ token_renewable false token_policies [\"root\"] identity_policies [] policies [\"root\"] ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:4","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"三、策略与授权 参考链接：https://zhuanlan.zhihu.com/p/370343645 ​ Vault模拟了一个文件系统，Vault中所有的信息，包括机密、配置等，都是依照各自的路径来使用的。使用Vault策略，我们可以使用声明式的语法来赋予或者禁止对特定路径的特定操作。Vault的策略默认情况下是拒绝一切访问的，所以一个空的策略不会赋予对系统的任何访问权限。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、策略语法 策略使用HCL或是JSON语法编写，描述了一个人类用户或是应用程序允许访问Vault中哪些路径。 一个简单的例子，赋予对secret/foo路径的读权限： path \"secret/foo\" { capabilities = [\"read\"] } 当这个策略被附加到一个令牌后，该令牌可以读取secret/foo，然而无法修改或删除secret/foo，因为没有授予其相关能力（Capability）。由于策略系统是默认拒绝的，所以令牌在Vault中没有其他权限。 另一个更加丰富的策略，包含注释： # This section grants all access on \"secret/*\". Further restrictions can be # applied to this broad policy, as shown below. path \"secret/*\" { capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\"] } # Even though we allowed secret/*, this line explicitly denies # secret/super-secret. This takes precedence. path \"secret/super-secret\" { capabilities = [\"deny\"] } # Policies can also specify allowed, disallowed, and required parameters. Here # the key \"secret/restricted\" can only contain \"foo\" (any value) and \"bar\" (one # of \"zip\" or \"zap\"). path \"secret/restricted\" { capabilities = [\"create\"] allowed_parameters = { \"foo\" = [] \"bar\" = [\"zip\", \"zap\"] } } 策略基于路径匹配来验证一个请求所需要的能力。一个策略路径可以精准匹配一个确切的路径，或者可以使用*模式指定前缀匹配： # Permit reading only \"secret/foo\". An attached token cannot read \"secret/food\" # or \"secret/foo/bar\". path \"secret/foo\" { capabilities = [\"read\"] } # Permit reading everything under \"secret/bar\". An attached token could read # \"secret/bar/zip\", \"secret/bar/zip/zap\", but not \"secret/bars/zip\". path \"secret/bar/*\" { capabilities = [\"read\"] } # Permit reading everything prefixed with \"zip-\". An attached token could read # \"secret/zip-zap\" or \"secret/zip-zap/zong\", but not \"secret/zip/zap path \"secret/zip-*\" { capabilities = [\"read\"] } 另外，路径当中可以使用+代表路径中一个段内任意长度的字符（从Vault 1.1开始支持）： # Permit reading the \"teamb\" path under any top-level path under secret/ path \"secret/+/teamb\" { capabilities = [\"read\"] } # Permit reading secret/foo/bar/teamb, secret/bar/foo/teamb, etc. path \"secret/+/+/teamb\" { capabilities = [\"read\"] } Vault模拟了一个文件系统，所有的操作都对应了一个路径，以及对应的能力，即使是Vault内部的核心配置信息也挂载于sys/路径下。策略可以定义一个令牌对这些路径和能力的访问权限。 Vault采用一组具有优先级的判定规则来决定最为具体的路径匹配。如果一个匹配模式被多个策略使用并能匹配上给定路径，Vault会取其能力的并集。如果一个路径能被多个策略定义的不同的匹配模式所匹配，那么只有最高优先级的匹配会被采用。 假设对给定路径P，存在两条策略都能够匹配，它们的路径匹配模式分别是P1和P2，Vault采用如下优先级规则： 1）如果P1中第一个+或是*出现的位置早于P2，那么采用P2 2）如果P1以*结尾，而P2不是，那么采用P2 3）如果P1包含更多的+段，那么采用P2 4）如果P1更短，那么采用P2 5）如果P1得到的字典序更小，那么采用P2 举个例子，给定两个路径：secret/*和secret/+/+/foo/*，由于第一个通配符的位置相同（都在secret/之后），并且都以*结尾，而后者拥有更多的通配符段（多了两个+/段），所以结果是使用secret/*路径模式的策略。 需要注意的是，*与正则表达式中的同符号并不同义，Vault仅允许*出现在模式的末尾。 如果赋予了list能力，需要注意的是因为list操作总是作用于一个路径前缀上，所以策略定义的路径匹配模式必须使用前缀匹配（即以*结尾）。 能力（Capabilites） 除了路径匹配模式以外，每条规则都必须指定一个或多个能力来定义细颗粒度的允许-禁止规则。能力永远以一个字符串列表的形式定义，哪怕只有一个能力。 需要注意的是，我们在下面列出能力的同时，也会给出该能力相对应的HTTP动词。当编写策略时，可以先查阅相关HTTP API文档了解路径信息以及相关HTTP动词，然后映射到策略定义中的能力。虽然映射关系并不是严格的1:1，但它们通常非常相似地匹配。 create(POST/PUT)——允许在指定路径创建数据。只有很少的Vault部件会区分create和update，所以大多数操作同时需要create以及update能力。需要区分二者的部分会在相关文档中说明。 read(GET)——允许读取指定路径的数据 update(POST/PUT)——允许修改指定路径的数据。对多数Vault部件来说，这隐含了在指定位置创建初始值的能力 delete(DELETE)——允许删除指定路径的数据 list(LIST)——允许罗列指定路径的所有值。要注意的是，经由list操作返回的键是未经策略过滤的。请勿在键名中编码敏感信息。不是所有后端都支持list操作 下面的能力并无对应的HTTP动词： sudo——允许访问需要根权限保护的路径。除非拥有sudo能力，否则令牌被禁止与这些路径交互（对这种路径的操作可能同时需要其他能力，例如read或delete） 例如，修改审计日志后端配置就需要令牌具有sudo特权。 deny——不允许访问。该定义总是优先于其他能力定义，包括sudo，只要能力中存在deny，就不允许执行任何操作 需要注意的是，上述的能力映射到的是HTTP动词而非实际底层执行的操作，这通常会使人感到困惑。举个例子，通过Vault的数据库机密引擎创建一个数据库用户名密码，底层实际执行的操作是创建，但对应的HTTP动词却是GET，所以要在对应路径上配置read能力。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2、细颗粒度控制 除却以上标准的能力，Vault还提供了对指定路径的更细颗粒度的权限控制。与路径相关联的功能优先于对参数的控制。 1）参数限制 需要首先说明，Version 2的kv机密引擎不支持参数限制，所以以下例子均假设secret/路径挂载的是Version 1的kv机密引擎。 Vault中的数据以键值对的形式表达：key=value。Vault策略可以进一步限制对指定路径下特定键和值的访问。这些可选的细颗粒度控制项有： required_parameters——一组必须指定的参数： # This requires the user to create \"secret/foo\" with a parameter named # \"bar\" and \"baz\". path \"secret/foo\" { capabilities = [\"create\"] required_parameters = [\"bar\", \"baz\"] } 上述例子中，用户想要在secret/foo下创建数据，必须包含名为bar和baz的参数。 allowed_parameters——针对指定路径允许操作的键值对的白名单。值为空白列表则代表允许使用任意值： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". It cannot contain any other parameters, but \"bar\" can contain # any value. path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [] } } 上述例子允许在secret/foo下创建键为bar，值为任意值的数据。 给定非空列表值则意味着只能使用列表中限定的值： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". It cannot contain any other parameters, and \"bar\" can only # contain the values \"zip\" or \"zap\". path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"zip\", \"zap\"] } } 上述例子允许在secret/foo下创建键为bar，值为zip或zap的数据。 如果指定了任意的键，那么所有未被指定的键都会被拒绝，除非同时指定了*参数为空列表，这就允许修改其他任意键数据。被指定的键仍然受到给定的值列表的限制： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". The parameter \"bar\" can only contain the values \"zip\" or \"zap\", # but any other parameters may be created with any value. path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"zip\", \"zap\"] \"*\" = [] } } 上述例子中，只限制对bar的值必须是zip或zap，对其他键的值则没有任何限制，可以创建任意键。 重要的一点是，使用*可能会造成意外的后果： # This allows the user to create or update \"secret/foo\" with a parameter # named \"bar\". The values passed to parameter \"bar\" must start with \"baz/\" # so values like \"baz/quux\" are fine. However, values like # \"baz/quux,wibble,wobble,wubble\" would also be accepted. The API that # underlies \"secret/foo\" might allow comma delimited values for the \"bar\" # parameter, and if it did, specifying a value like # \"baz/quux,wibble,wobble,wubble\" would result in 4 different values getting # passed along. Seeing values like \"wibble\" or \"wobble\" getting passed to # \"secret/foo\" might surprise someone that expected the allowed_parameters # constraint to only allow values starting with \"baz/\". path \"secret/foo\" { capabilities = [\"create\", \"update\"] allowed_parameters = { \"bar\" = [\"baz/*\"] } } 在上面的例子中，我们限制对secret/foo只能写入键为bar的数据，并且值必须以baz/为前缀。比如bar=baz/quux这样的数据就是合法的。问题是，我们也可以把值设置成baz/quux,wibble,wobble,wubble，Vault会接纳这种带有分隔符的值，而这样的值可能会被应用程序解析为长度为4的列表，这样的话我们可能会惊讶地发现即使我们限制了bar的值必须以baz/为前缀，仍然读取到了诸如wibble这样的值。 denied_parameters——键值对的黑名单，优先级高于allowed_parameters。 设置值为空列表会导致拒绝对对应键的任意修改。 # This allows the user to create \"secret/foo\" with any parameters not # named \"bar\". path \"secret/foo\" { capabilities = [\"create\"] denied_parameters = { \"bar\" = [] } } 上面的例子禁止在secret/foo下创建键为bar的任意键值对。 如果对denied_parameters赋值一个非空列表，会导致禁止参数的值包含列表中的任意元素： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". It can contain any other parameters, but \"bar\" cannot contain # the values \"zip\" or \"zap\". path \"secret/foo\" { capabilities = [\"create\"] denied_parameters = { \"bar\" = [\"zip\", \"zap\"] } } 上述例子禁止设置secret/foo的bar的值为zip或是zap。 设置denied_parameters的键为*，则禁止操作任意键： # This allows the user to create \"secret/foo\", but it cannot have any # parameters. path \"secret/foo\" { capabilities = [\"create\"] denied_parameters = { \"*\" = [] } } 如果denied_parameters配置了任意键，那么默认所有未被指定的键都是允许操作的，除非另有显式的allowed_parameters配置。 参数限制中的值也支持前缀与后缀表示： path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"foo-*\"] } } 上面的例子规定对secret/foo，只能创建键为bar，值以foo-为前缀的键值对。 path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"*-foo\"] } } 而上面的例子则是限制值必须以-foo为后缀。 2）限制响应封装的有效期 Vault可以设置响应封装机制。我们可以在策略中使用相关参数限制客户端可以申请的响应封装的有效期时限，精确到秒。我们可以通过s、m或是h后缀来代表秒、分钟和小时。 在实践中，为特定路径指定值为一秒的min_wrapping_ttl可以达到强制必须以响应封装的形式返回相应路径数据的目的。 min_wrapping_ttl——客户端可以指定的响应封装有效期的最小值，如果设置该值，则强制必须以响应封装的形式返回相应路径的数据 max_wrapping_ttl——允","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"3、内建策略 Vault有两个内建策略：default和root。本节来讨论下这两个内建策略。 1）Default策略 default策略是一个无法删除的Vault内建策略。默认情况下，它被附加到所有令牌上，但可以通过使用身份验证方式创建令牌时显式排除之。 该策略包含了基础的功能，例如准许令牌查询有关自身的数据以及使用**Cubbyhole数据**。然而，Vault并不限制该策略的内容，你可以根据需要修改它。Vault永远不会覆盖你的设置。如果你想把default策略同步到最新的Vault版本的默认值，只要用新版Vault执行vault server -dev启动一个测试服务，读取它的default策略内容，然后写回到原来的Vault服务的default策略即可： $ vault read sys/policy/default Key Value --- ----- name default rules # Allow tokens to look up their own properties path \"auth/token/lookup-self\" { capabilities = [\"read\"] } # Allow tokens to renew themselves path \"auth/token/renew-self\" { capabilities = [\"update\"] } # Allow tokens to revoke themselves path \"auth/token/revoke-self\" { capabilities = [\"update\"] } # Allow a token to look up its own capabilities on a path path \"sys/capabilities-self\" { capabilities = [\"update\"] } # Allow a token to look up its own entity by id or name path \"identity/entity/id/{{identity.entity.id}}\" { capabilities = [\"read\"] } path \"identity/entity/name/{{identity.entity.name}}\" { capabilities = [\"read\"] } # Allow a token to look up its resultant ACL from all policies. This is useful # for UIs. It is an internal path because the format may change at any time # based on how the internal ACL features and capabilities change. path \"sys/internal/ui/resultant-acl\" { capabilities = [\"read\"] } # Allow a token to renew a lease via lease_id in the request body; old path for # old clients, new path for newer path \"sys/renew\" { capabilities = [\"update\"] } path \"sys/leases/renew\" { capabilities = [\"update\"] } # Allow looking up lease properties. This requires knowing the lease ID ahead # of time and does not divulge any sensitive information. path \"sys/leases/lookup\" { capabilities = [\"update\"] } # Allow a token to manage its own cubbyhole path \"cubbyhole/*\" { capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\"] } # Allow a token to wrap arbitrary values in a response-wrapping token path \"sys/wrapping/wrap\" { capabilities = [\"update\"] } # Allow a token to look up the creation time and TTL of a given # response-wrapping token path \"sys/wrapping/lookup\" { capabilities = [\"update\"] } # Allow a token to unwrap a response-wrapping token. This is a convenience to # avoid client token swapping since this is also part of the response wrapping # policy. path \"sys/wrapping/unwrap\" { capabilities = [\"update\"] } # Allow general purpose tools path \"sys/tools/hash\" { capabilities = [\"update\"] } path \"sys/tools/hash/*\" { capabilities = [\"update\"] } # Allow checking the status of a Control Group request if the user has the # accessor path \"sys/control-group/request\" { capabilities = [\"update\"] } 创建令牌时排除default策略： $ vault token create -no-default-policy 或是调用API： $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"no_default_policy\": \"true\"}' \\ https://vault.hashicorp.rocks/v1/auth/token/create 根策略 root策略是一个无法删除也无法修改的Vault内建策略。任何关联了该策略的用户都将是根用户。根用户可以在Vault内执行任意操作，强烈建议在生产环境中使用Vault前首先吊销所有的根令牌。 每当Vault服务被首次初始化时，都会创建一个根用户。这个根用户是用来执行Vault的初始化配置的。配置完成后，应创建并使用由细颗粒度策略约束的用户并启用身份认证方式，然后吊销根令牌。 要吊销根令牌可以使用命令行： $ vault token revoke \"\u003ctoken\u003e\" 或是通过HTTP API： $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"token\": \"\u003ctoken\u003e\"}' \\ https://vault.hashicorp.rocks/v1/auth/token/revoke ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:3","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"四、vault cli使用 显示所有策略 $ vault read sys/policy 上传并创建策略 $ vault policy write policy-name policy-file.hcl # http $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"policy\":\"path \\\"...\\\" {...} \"}' \\ https://vault.hashicorp.rocks/v1/sys/policy/policy-name # 这两个例子里，策略的名称都是 policy-name。你可以把策略名理解成指向策略规则的指针。令牌通过策略名关联相关策略规则。 更新策略 $ vault write my-existing-policy updated-policy.json # http $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"policy\":\"path \\\"...\\\" {...} \"}' \\ https://vault.hashicorp.rocks/v1/sys/policy/my-existing-policy 删除策略 $ vault delete sys/policy/policy-name # http $ curl \\ --request DELETE \\ --header \"X-Vault-Token: ...\" \\ https://vault.hashicorp.rocks/v1/sys/policy/policy-name # 删除是一个幂等操作。删除一个不存在的策略不会导致Vault返回错误。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:4:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"五、用户权限管理 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:5:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、关联策略 Vault可以通过身份认证方式登录时自动在令牌上关联一组策略，相关配置随具体的身份认证方式类型而不同。简单起见，我们演示一下Vault内建的userpass认证方式。 Vault管理员或是安全团队成员可以用如下命令行创建一个关联了一组策略的用户： # 开启用户登录 vault auth enable userpass # http 方式开启 $ curl \\ --request DELETE \\ --header \"X-Vault-Token: ...\" \\ https://vault.hashicorp.rocks/v1/sys/policy/policy-name curl -XPOST -s -H \"X-Vault-Token: xxxxx\" \"http://vault.local.com/v1/sys/auth/userpass\" -d'{\"type\": \"userpass\"}' # 创建sethvargo用户，并设置密码和策略 $ vault write auth/userpass/users/sethvargo \\ password=\"s3cr3t!\" \\ policies=\"dev-readonly,logs\" 用户可以用命令行执行身份认证，获取令牌： $ vault login -method=\"userpass\" username=\"sethvargo\" Password (will be hidden): ... 如果用户名密码正确，Vault会创建一个令牌，将预设的策略附加在令牌上，然后返回给用户。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:5:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2、创建令牌时附加策略 可以在通过命令行创建令牌时关联策略： $ vault token create -policy=dev-readonly -policy=logs 子令牌可以关联一组父令牌拥有的策略的子集。根用户可以分派任意策略。 一旦令牌被签发，其关联的策略无法再被修改。必须吊销旧令牌并申请新令牌才能得到更新后的关联策略。 然而，令牌关联的策略内容是实时解析的，也就是说，如果更新了策略内容，附加此策略的令牌下次的请求就会按照新策略内容进行权限检查。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:5:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"六、terraform 管理 terraform { required_providers { vault = { source = \"hashicorp/vault\" } } } provider \"vault\" { address = var.vault-init.url token = var.vault-init.token } resource \"vault_mount\" \"secret_path\" { for_each = var.vault-init.secret_path path = each.value.path type = each.value.type description = each.value.description options = { version = \"1\" } } resource \"vault_policy\" \"policy\" { for_each = var.vault-init.policy name = each.key policy = each.value.policy } resource \"vault_auth_backend\" \"userpass\" { type = \"userpass\" } resource \"vault_generic_endpoint\" \"create_user\" { for_each = var.vault-init.userlist path = \"auth/userpass/users/${each.key}\" ignore_absent_fields = true data_json = jsonencode(each.value) depends_on = [ vault_auth_backend.userpass, vault_policy.policy ] } resource \"vault_generic_secret\" \"secret_value\" { for_each = var.vault-init.secret_value path = \"${each.value.path}/${each.key}\" data_json = jsonencode(each.value.data) depends_on = [ vault_mount.secret_path, vault_policy.policy ] } variable \"vault-init\" { type = any default = { url = null token = null secret_path = {} userlist = {} policy = {} secret_value = {} } } tfvars vault-init = { url = \"http://127.0.0.1:8200\" token = \"cccccccccc\" secret_path = { p2 = { path = \"Monitor\" type = \"kv\" description = \"Metrics/Tracing/Logs\" }, p5 = { path = \"APP\" type = \"kv\" description = \"Gitea/Gitlab\" } } policy = { admin = { policy = \u003c\u003cEOT path \"cubbyhole/*\" { capabilities = [\"deny\"] } path \"sys/auth\" { capabilities = [\"read\"] } path \"auth/userpass/users/*\" { capabilities = [\"list\", \"read\", \"update\"] } path \"Monitor/+\" { capabilities = [\"read\", \"list\"] } path \"APP/+\" { capabilities = [\"read\", \"list\", \"update\", \"patch\"] } path \"APP/+/+\" { capabilities = [\"read\", \"list\"] } EOT }, user = { policy = \u003c\u003cEOT path \"cubbyhole/*\" { capabilities = [\"deny\"] } path \"Hardware/+\" { capabilities = [\"deny\"] } path \"Monitor/+\" { capabilities = [\"read\", \"list\"] } path \"DBMiddleware/+\" { capabilities = [\"list\"] } path \"DBMiddleware/+/+\" { capabilities = [\"read\", \"list\"] } path \"Management/+\" { capabilities = [\"read\", \"list\"] } path \"Management/Admin/*\" { capabilities = [\"deny\"] } EOT } } userlist = { user = { username = \"user\", password = \"hello_world\", policies = [\"user\"] }, admin = { username = \"admin\", password = \"hello_world\", policies = [\"admin\"] } } secret_value = { Grafana = { path = \"Monitor\" data = { \"External Address\"= \"http://grafana.local.com\", \"Password\"= \"CvcTKkm4xxxxxxxxx\", \"Username\"= \"admin\" } } } } ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:6:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["Database"],"content":"SQL Server docker run -e \"ACCEPT_EULA=Y\" -e \"SA_PASSWORD=Y.sa123456\" -p 1433:1433 --name mssql2022 -d mcr.microsoft.com/mssql/server:2022-latest 其中 sa123456 为 SQL Server sa 用户的密码，SA_PASSWORD=Y.sa123456 为密码，要求是最少8位的强密码，要有大写字母，小写字母，数字以及特殊符号， ","date":"2023-12-27","objectID":"/posts/2023-12-27-mssql/:0:0","tags":["db","sqlserver","mssql"],"title":"SQL Server","uri":"/posts/2023-12-27-mssql/"},{"categories":["DevOps"],"content":"k3s 参考链接： https://www.escapelife.site/posts/754ba85c.html ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:0:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"一、简介 K3s 是一个轻量级的 Kubernetes 发行版，它针对边缘计算、物联网等场景进行了高度优化。 CNCF 认证的 Kubernetes 发行版 支持 X86_64, ARM64, ARMv7 平台 单一进程包含 Kubernetes master，kubelet 和 containerd K3s 有以下增强功能： 打包为单个二进制文件 把 K8S 相关的组件，比如 kube-api/ kube-manager 都打包到同一个二进制文件里面，这样的话，只需要启动这个文件就可以快速的启动对应的组件。 使用基于 sqlite3 的默认存储机制 同时支持使用 etcd3、MySQL 和 PostgreSQL 作为存储机制。 默认情况下是安全的 在 K3s 中有一个默认的证书管理机制(默认一年有效期)，也有一个可以轮转证书的功能(就是在小于九十天之内重启 K3s 的话，就会自动续一年)。 功能强大的 batteries-included 功能 就是虽然有些服务本身这个二进制文件并没有提供，但是可以通过内置的服务，将配置文件放到指定的目录下面，就可以在启动的时候一并将该服务启动或替换默认组件。 所有 K8S control-plane 组件都封装在单个二进制文件和进程中 因为封装在二进制文件中，所以启动的时候只有一个进程。好处在于只需要管理这个单一进程就可以了，同时也具备操作复杂集群的能力。 最大程度减轻了外部依赖性 即稍新一点的 Linux 内核就可以了(需要 kernel 和 cgroup 挂载)。 之所以叫做 K3S 是因为希望安装的 K8S 在内存占用方面只是一半的大小，而一半大的东西就是一个 5 个字母的单词，简写为 K3S。 生命周期 同时支持 3 个 K8s 版本，支持的生命周期与 K8s 相同 可以参考: Kubernetes 版本及版本偏差支持策略 进行学习 更新周期 当 K8s 更新新版本后，一般 K3s 在一周内同步更新 可以通过 这个链接 获取 latest/stable/testing 版本 我们默认安装的是 stable 版本，可以运行通过命令进行查看 命名规范 v1.20.4+k3s1: v1.20.4 为 K8s 版本，k3s1 为补丁版本 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:1:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"二、单机部署 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:2:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"1、在线部署 curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_SELINUX_WARN=false INSTALL_K3S_MIRROR=cn INSTALL_K3S_EXEC=\"--write-kubeconfig ~/.kube/config --write-kubeconfig-mode 644 \" sh - # token存放在/var/lib/rancher/k3s/server/node-token # cat /var/lib/rancher/k3s/server/node-token curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://172.16.1.5:6443 K3S_TOKEN=K102fa20edba4cd43952970c2bce3d40e771da0382b595e70e108cf637dcf79a653::server:d0f4dec273e0e9d0b74f72b2f24a1c59 sh - ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:2:1","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"2、离线部署 1）下载k3s二进制包、镜像和安装脚本 二进制包：https://github.com/rancher/k3s/releases 镜像：https://github.com/k3s-io/k3s/releases 部署脚本：https://github.com/k3s-io/k3s/blob/master/install.sh RHEL系列需要安装selinux：https://github.com/k3s-io/k3s-selinux/releases 一下以 Rocky 9 arm64 为示例 # download wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-arm64 wget https://github.com/k3s-io/k3s-selinux/releases/download/v1.4.stable.1/k3s-selinux-1.4-1.el9.noarch.rpm wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-airgap-images-arm64.tar.gz # wget https://get.k3s.io -o ./install.sh # wget http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh wget https://raw.githubusercontent.com/k3s-io/k3s/master/install.sh # set k3s cp ./k3s /usr/local/bin/ chmod 755 /usr/local/bin/k3s # set images tar -xf k3s-airgap-images-$ARCH.tar.gz mkdir -p /var/lib/rancher/k3s/agent/images/ cp ./k3s-airgap-images-$ARCH.tar /var/lib/rancher/k3s/agent/images/ # install selinux and set system yum -y localinstall k3s-selinux-.rpm systemctl stop firewalld systemctl disable firewalld setenforce 0 sed -ri '/^SELINUX=/cSELINUX=disabled' /etc/selinux/config # install k3s INSTALL_K3S_SKIP_DOWNLOAD=true INSTALL_K3S_MIRROR=cn INSTALL_K3S_SELINUX_WARN=true INSTALL_K3S_SKIP_SELINUX_RPM=true INSTALL_K3S_EXEC=\"--write-kubeconfig ~/.kube/config --write-kubeconfig-mode 644 \" ./install.sh # 其他节点加入 # token存放在/var/lib/rancher/k3s/server/node-token # cat /var/lib/rancher/k3s/server/node-token INSTALL_K3S_SKIP_DOWNLOAD=true INSTALL_K3S_MIRROR=cn INSTALL_K3S_SELINUX_WARN=false K3S_URL=https://172.16.1.5:6443 K3S_TOKEN=K101e11731af882398bc6757080f0d8e4b46f8cdb2a17a2edfce54d7971cb3411d1::server:81ee583304cc2b38bf15190298403d34 ./install.sh ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:2:2","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"二、高级配置 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"1、设置节点hostname 集群中不能有共同的主机名，如果hostname有相同，则需要在加入集群时设置一下主机名 # 为每个节点指定主机名 curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ K3S_NODE_NAME=\"k3s2\" INSTALL_K3S_MIRROR=cn \\ K3S_URL=https://192.168.64.3:6443 K3S_TOKEN=xxx sh - # 为每个节点指定主机名 curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn K3S_URL=https://192.168.64.3:6443 \\ K3S_TOKEN=xxx sh -s - --node-name k3s2 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:1","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"2、可用环境变量 Environment Variable Description INSTALL_K3S_SKIP_DOWNLOAD 如果设置为 “true “将不会下载 K3s 的哈希值或二进制。 INSTALL_K3S_SYMLINK 默认情况下，如果路径中不存在命令，将为 kubectl、crictl 和 ctr 二进制文件创建符号链接。如果设置为’skip’将不会创建符号链接，而’force’将覆盖。 INSTALL_K3S_SKIP_ENABLE 如果设置为 “true”，将不启用或启动 K3s 服务。 INSTALL_K3S_SKIP_START 如果设置为 “true “将不会启动 K3s 服务。 INSTALL_K3S_VERSION 从 Github 下载 K3s 的版本。如果没有指定，将尝试从\"stable\"频道下载。 INSTALL_K3S_BIN_DIR 安装 K3s 二进制文件、链接和卸载脚本的目录，或者使用/usr/local/bin作为默认目录。 INSTALL_K3S_BIN_DIR_READ_ONLY 如果设置为 true 将不会把文件写入INSTALL_K3S_BIN_DIR，强制设置INSTALL_K3S_SKIP_DOWNLOAD=true。 INSTALL_K3S_SYSTEMD_DIR 安装 systemd 服务和环境文件的目录，或者使用/etc/systemd/system作为默认目录。 INSTALL_K3S_EXEC 带有标志的命令，用于在服务中启动 K3s。如果未指定命令，并且设置了K3S_URL，它将默认为“agent”。如果未设置K3S_URL，它将默认为“server”。要获得帮助，请参考此示例。 INSTALL_K3S_NAME 要创建的 systemd 服务名称，如果以服务器方式运行 k3s，则默认为’k3s’；如果以 agent 方式运行 k3s，则默认为’k3s-agent’。如果指定了服务名，则服务名将以’k3s-‘为前缀。 INSTALL_K3S_TYPE 要创建的 systemd 服务类型，如果没有指定，将默认使用 K3s exec 命令。 INSTALL_K3S_SELINUX_WARN 如果设置为 true，则在没有找到 k3s-selinux 策略的情况下将继续。 INSTALL_K3S_SKIP_SELINUX_RPM 如果设置为 “true “将跳过 k3s RPM 的自动安装。 INSTALL_K3S_CHANNEL_URL 用于获取 K3s 下载网址的频道 URL。默认为 https://update.k3s.io/v1-release/channels 。 INSTALL_K3S_CHANNEL 用于获取 K3s 下载 URL 的通道。默认值为 “stable”。选项包括：stable, latest, testing。 K3S_CONFIG_FILE 指定配置文件的位置。默认目录为/etc/rancher/k3s/config.yaml。 K3S_TOKEN 用于将 server 或 agent 加入集群的共享 secret。 K3S_TOKEN_FILE 指定 cluster-secret,token 的文件目录。 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:2","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"3、k3s安装参数设置 # 使用docker作为容器运行时 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--docker\" sh - # 指定运行时工具 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--container-runtime-endpoint containerd\" \\ sh - # 设置私有镜像仓库配置文件 # 默认配置文件: /etc/rancher/k3s/registries.yaml $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--private-registry xxx\" \\ sh - # 针对多网卡主机安装K3s集群 # 默认多网卡会使用默认网关的那个卡 $ rout -n # K3s server $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--node-ip=192.168.100.100\" \\ sh - # K3s agent $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ K3S_URL=https://192.168.99.211:6443 K3S_TOKEN=xxx \\ INSTALL_K3S_EXEC=\"--node-ip=192.168.100.100\" \\ sh - # --tls-san # 在TLS证书中添加其他主机名或IP作为主机备用名称 # 即在公网环境下允许通过公网IP访问控制、操作远程集群 # 或者部署多个Server并使用LB进行负责，就需要保留公网地址 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--tls-san 1.1.1.1\" \\ sh - # 获取配置 $ kubectl get secret k3s-serving -n kube-system -o yaml # 然后本机复制公网主节点对应的yaml文件即可本地操作了 $ scp ci@1.1.1.1:/etc/rancher/k3s/k3s.yaml ~/.kube/config # 修改启动的服务对应配置(调整节点的启动的最大Pod数量) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--kubelet-arg=max-pods=200' \\ sh - # 修改启动的服务对应配置(使用ipvs作为服务调度工具) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--kube-proxy-arg=proxy-mode=ipvs' \\ sh - # 修改启动的服务对应配置(调整服务启动的端口范围) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--kube-apiserver-arg=service-node-port-range=40000-50000' \\ sh - # kubelet-arg --kubelet-arg # kube-apiserver --kube-apiserver-arg # kube-proxy-arg --kube-proxy-arg # kube-proxy-arg --kube-proxy-arg=proxy-mode=ipvs # --data-dir # 修改K3s数据存储目录 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--data-dir=/opt/k3s-data' \\ sh - # 禁用组件 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--disable traefik' \\ sh - # 自己加自己需要的服务 $ ls /var/lib/rancher/k3s/server/manifests $ kubectl get pods -A | grep traefik # 添加label和taint标识 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--node-label foo=bar,hello=world \\ --node-taint key1=value1:NoExecute' sh - # 查看一下 $ kubectl describe nodes K3s Server/Agent - 数据库选项 # 指定数据源名称 # 标志位: --datastore-endpoint\u0026nbsp;value # 环境变量: K3S_DATASTORE_ENDPOINT $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--datastore-endpoint\u0026nbsp;etcd' \\ sh - # cron规范中的快照间隔时间 # --etcd-snapshot-schedule-cron\u0026nbsp;value $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--etcd-snapshot-schedule-cron *\u0026nbsp;*/5\u0026nbsp;*\u0026nbsp;*\u0026nbsp;*' \\ sh - ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:3","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"4、网络选项配置 默认情况下，K3s 将以 flannel 作为 CNI 运行，使用 VXLAN 作为默认后端，CNI 和默认后端都可以通过参数修改。要启用加密，请使用下面的 IPSec 或 WireGuard 选项。 # 默认安装K3s之后的网络配置 $ sudo cat /var/lib/rancher/k3s/agent/etc/flannel/net-conf.json { \"Network\": \"10.42.0.0/16\", \"EnableIPv6\": false, \"EnableIPv4\": true, \"IPv6Network\": \"::/0\", \"Backend\": { \"Type\": \"vxlan\" } } CLI Flag 和 Value 描述 --flannel-backend=vxlan 使用 VXLAN 后端(默认) --flannel-backend=host-gw 使用 host-gw 后端 --flannel-backend=ipsec 使用 IPSEC 后端；对网络流量进行加密 --flannel-backend=wireguard 使用 WireGuard 后端；对网络流量进行加密 1）配置 Flannel 选项 这样，我就可以在安装 K3s 或者之后修改对应配置文件，来修改 Flannel 默认的后端网络配置选项(重启会覆盖不生效)了。下面，我们演示下，如何修改为 host-gw 模式。 # 主节点 # flannel-backend使用host-gw # 该模式会把对端主机的IP当做默认网管(多Server情况) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--flannel-backend=host-gw' \\ sh - # 工作节点 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn K3S_URL=https://192.168.100.100:6443 \\ K3S_TOKEN=xxx sh - # 默认的路由信息 $ route -n 0.0.0.0 172.16.64.1 0.0.0.0 UG 100 0 0 enp0s2 10.42.1.0 172.16.64.9 255.255.255.0 UG 0 0 0 enp0s2 # 查看配置之后的网络配置 $ sudo cat /var/lib/rancher/k3s/agent/etc/flannel/net-conf.json { \"Network\": \"10.42.0.0/16\", \"Backend\": { \"Type\": \"host-gw\" } } ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:4","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"5、镜像仓库设置 K3s 默认使用 containerd 作为容器运行时，所以在 docker 上配置镜像仓库是不生效的。K3s 镜像仓库配置文件由两大部分组成：mirrors 和 configs。 Mirrors 是一个用于定义专用镜像仓库的名称和 endpoint 的指令 Configs 部分定义了每个 mirror 的 TLS 和证书配置 对于每个 mirror，你可以定义 auth 和 / 或 tls K3s registry 配置目录为： /etc/rancher/k3s/registries.yaml。K3s 启动时会检查 /etc/rancher/k3s/ 中是否存在 registries.yaml 文件，并指示 containerd 使用文件中定义的镜像仓库。如果你想使用一个私有的镜像仓库，那么你需要在每个使用镜像仓库的节点上以 root 身份创建这个文件。 请注意，server 节点默认是可以调度的。如果你没有在 server 节点上设置污点，那么将在它们上运行工作负载，请确保在每个 server 节点上创建 registries.yaml 文件。 containerd 使用了类似 K8S 中 svc 与 endpoint 的概念，svc 可以理解为访问名称，这个名称会解析到对应的 endpoint 上。也可以理解 mirror 配置就是一个反向代理，它把客户端的请求代理到 endpoint 配置的后端镜像仓库。mirror 名称可以随意填写，但是必须符合 IP 或域名的定义规则。并且可以配置多个 endpoint，默认解析到第一个 endpoint，如果第一个 endpoint 没有返回数据，则自动切换到第二个 endpoint，以此类推。 # /etc/rancher/k3s/registries.yaml # 同时可以设置多个mirrors地址 # 可以对mirrors设置权限和证书 mirrors: \"172.31.6.200:5000\": endpoint: - \"http://172.31.6.200:5000\" - \"http://x.x.x.x:5000\" - \"http://y.y.y.y:5000\" \"rancher.ksd.top:5000\": endpoint: - \"http://172.31.6.200:5000\" \"docker.io\": endpoint: - \"https://fogjl973.mirror.aliyuncs.com\" - \"https://registry-1.docker.io\" configs: \"172.31.6.200:5000\": auth: username: admin password: Harbor@12345 tls: cert_file: /home/ubuntu/harbor2.escapelife.site.cert key_file: /home/ubuntu/harbor2.escapelife.site.key ca_file: /home/ubuntu/ca.crt # 镜像都是从同一个仓库获取到的 $ sudo systemctl restart k3s.service $ sudo crictl pull 172.31.6.200:5000/library/alpine $ sudo crictl pull rancher.ksd.top:5000/library/alpine 这里我们介绍下，如何使用 TLS 配置。 # 证书颁发机构颁发的证书 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: \"harbor.escapelife.site\": endpoint: - \"https://harbor.escapelife.site\" configs: \"harbor.escapelife.site\": auth: username: admin password: Harbor@12345 EOF $ sudo systemctl restart k3s # 自签名证书 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: \"harbor2.escapelife.site\": endpoint: - \"https://harbor2.escapelife.site\" configs: \"harbor2.escapelife.site\": auth: username: admin password: Harbor@12345 tls: cert_file: /home/ubuntu/harbor2.escapelife.site.cert key_file: /home/ubuntu/harbor2.escapelife.site.key ca_file: /home/ubuntu/ca.crt EOF $ sudo systemctl restart k3s # 不使用TLS证书 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: \"docker.io\": endpoint: - \"https://fogjl973.mirror.aliyuncs.com\" - \"https://registry-1.docker.io\" EOF $ sudo systemctl restart k3s K3s 将会在 /var/lib/rancher/k3s/agent/etc/containerd/config.toml 中为 containerd 生成 config.toml。如果要对这个文件进行高级设置，你可以在同一目录中创建另一个名为 config.toml.tmpl 的文件，此文件将会代替默认设置。 # 可用示例 # mkdir -p /etc/rancher/k3s cat \u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: docker.io: endpoint: - \"https://docker.mirrors.sjtug.sjtu.edu.cn\" - \"https://docker.nju.edu.cn\" quay.io: endpoint: - \"https://quay.nju.edu.cn\" gcr.io: endpoint: - \"https://gcr.nju.edu.cn\" ghcr.io: endpoint: - \"https://ghcr.nju.edu.cn\" nvcr.io: endpoint: - \"https://ngc.nju.edu.cn\" EOF systemctl restart k3s # 完整示例 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml mirrors: \"harbor.escapelife.site\": endpoint: - \"https://harbor.escapelife.site\" \"harbor2.escapelife.site\": endpoint: - \"https://harbor2.escapelife.site\" \"172.31.19.227:5000\": endpoint: - \"http://172.31.19.227:5000\" \"docker.io\": endpoint: - \"https://fogjl973.mirror.aliyuncs.com\" - \"https://registry-1.docker.io\" configs: \"harbor.escapelife.site\": auth: username: admin password: Harbor@12345 \"harbor2.escapelife.site\": auth: username: admin password: Harbor@12345 tls: cert_file: /home/ubuntu/harbor2.escapelife.site.cert key_file: /home/ubuntu/harbor2.escapelife.site.key ca_file: /home/ubuntu/ca.crt ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:5","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"6、证书管理 参考链接：https://blog.starudream.cn/2023/07/21/k3s-client-cert-extend/ 默认情况下，K3s 的证书在 12 个月内过期。如果证书已经过期或剩余的时间不足 90 天，则在 K3s 重启时轮换证书。 # 查询K3s证书过期时间 $ for i in `ls /var/lib/rancher/k3s/server/tls/*.crt`; \\ do \\ echo $i;\\ openssl x509 -enddate -noout -in $i; \\ done # 修改系统时间为证书过期前90天或证书过期后 $ timedatectl set-ntp no $ date -s 20220807 # 重启K3s服务 $ service k3s restart k3s 默认的根证书签发 十年，客户端证书签发 一年。 经常需要重新签发客户端证书，可以通过修改 k3s 的环境变量来延长客户端证书的有效期。 新增 /etc/default/k3s 文件，并添加以下内容： CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=\"3650\" 该变量在 k3s server 重新签发证书时有效，或者在安装之前设置。 # 轮换证书 k3s certificate rotate # 启动 K3s systemctl start k3s ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:6","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"三、多master高可用生产级别部署—在线版 https://kube-vip.io/docs/usage/k3s/ https://zhuanlan.zhihu.com/p/651292552 HA + kube-vip ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:4:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"1、配置内核参数 [root@k8s-m1 ~]# cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf # https://github.com/moby/moby/issues/31208 # ipvsadm -l --timout # 修复ipvs模式下长连接timeout问题 小于900即可 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.ip_forward = 1 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 # 要求iptables不对bridge的数据进行处理 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.netfilter.nf_conntrack_max = 2310720 fs.inotify.max_user_watches=89100 fs.may_detach_mounts = 1 fs.file-max = 52706963 fs.nr_open = 52706963 vm.swappiness = 0 vm.overcommit_memory=1 vm.panic_on_oom=0 EOF 加载内核参数 [root@k8s-m1 ~]# sysctl -p ipvs配置 [root@k8s-m1 ~]# yum install ipset ipvsadm -y [root@k8s-m1 ~]# cat \u003e/etc/modules-load.d/ipvs.conf\u003c\u003cEOF ip_vs # 负载均衡调度算法-最少连接 ip_vs_lc # 负载均衡调度算法-加权最少连接 ip_vs_wlc # 负载均衡调度算法-轮询 ip_vs_rr # 负载均衡调度算法-加权轮询 ip_vs_wrr # 源地址散列调度算法 ip_vs_sh nf_conntrack br_netfilter EOF [root@k8s-m1 ~]# systemctl restart systemd-modules-load.service 查看加载情况 [root@k8s-m1 ~]# lsmod | grep -e ip_vs -e nf_conntrack -e br_netfilter systemctl stop firewalld systemctl disable firewalld setenforce 0 sed -ri '/^SELINUX=/cSELINUX=disabled' /etc/selinux/config 换源 sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/rocky|g' \\ -i.bak \\ /etc/yum.repos.d/rocky-extras.repo \\ /etc/yum.repos.d/rocky.repo 自签名ca [可选] mkdir -p /var/lib/rancher/k3s/server/tls cd /var/lib/rancher/k3s/server/tls openssl genrsa -out client-ca.key 2048 openssl genrsa -out server-ca.key 2048 openssl genrsa -out request-header-ca.key 2048 openssl req -x509 -new -nodes -key client-ca.key -sha256 -days 3650 -out client-ca.crt -addext keyUsage=critical,digitalSignature,keyEncipherment,keyCertSign -subj '/CN=k3s-client-ca' openssl req -x509 -new -nodes -key server-ca.key -sha256 -days 3650 -out server-ca.crt -addext keyUsage=critical,digitalSignature,keyEncipherment,keyCertSign -subj '/CN=k3s-server-ca' openssl req -x509 -new -nodes -key request-header-ca.key -sha256 -days 3650 -out request-header-ca.crt -addext keyUsage=critical,digitalSignature,keyEncipherment,keyCertSign -subj '/CN=k3s-request-header-ca' 设置k3s续签的证书有效期 echo \"CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=3650\" \u003e /etc/default/k3s # 或者 #echo \"CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=3650\" \u003e /etc/sysconfig/k3s ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:4:1","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"2、安装kube-vip 操作过程：首先生成一个用于部署在 K3s 集群中的 kube-vip Manifest，然后再启动一个高可用的 K3s 集群，启动 K3s 集群时会自动部署 kube-vip 的 Manifest 文件，从而通过 kube-vip 实现控制平面的高可用。 # 创建manifests目录 mkdir -p /var/lib/rancher/k3s/server/manifests/ # 获取 kube-vip RBAC 清单 # kube-vip 在 K3s 下作为 DaemonSet 运行，我们需要 RBAC 资源来确保 ServiceAccount 存在并进行绑定，来确保它具有与 API 服务器通信所需的权限。 curl https://kube-vip.io/manifests/rbac.yaml \u003e /var/lib/rancher/k3s/server/manifests/kube-vip-rbac.yaml 生成kube-vip DaemonSet Manifest export VIP=172.16.1.222 # 设置虚拟 IP 用于访问控制平面的地址 export INTERFACE=ens160 # 设置控制平面所在主机的网卡名称 KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r \".[0].name\") # 获取 kube-vip 版本 alias kube-vip=\"docker run --network host --rm ghcr.io/kube-vip/kube-vip:$KVVERSION\" # 针对 docker 环境设置别名 # 创建 kube-vip 清单 kube-vip manifest daemonset \\ --interface $INTERFACE \\ --address $VIP \\ --inCluster \\ --taint \\ --controlplane \\ --services \\ --arp \\ --leaderElection \u003e /var/lib/rancher/k3s/server/manifests/kube-vip.yaml 文件内容 apiVersion: v1 kind: ServiceAccount metadata: name: kube-vip namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" name: system:kube-vip-role rules: - apiGroups: [\"\"] resources: [\"services\", \"services/status\", \"nodes\", \"endpoints\"] verbs: [\"list\",\"get\",\"watch\", \"update\"] - apiGroups: [\"coordination.k8s.io\"] resources: [\"leases\"] verbs: [\"list\", \"get\", \"watch\", \"update\", \"create\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: system:kube-vip-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-vip-role subjects: - kind: ServiceAccount name: kube-vip namespace: kube-system --- apiVersion: apps/v1 kind: DaemonSet metadata: creationTimestamp: null name: kube-vip-ds namespace: kube-system spec: selector: matchLabels: name: kube-vip-ds template: metadata: creationTimestamp: null labels: name: kube-vip-ds spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node-role.kubernetes.io/master operator: Exists - matchExpressions: - key: node-role.kubernetes.io/control-plane operator: Exists containers: - args: - manager env: - name: vip_arp value: \"true\" - name: port value: \"6443\" - name: vip_interface value: ens160 - name: vip_cidr value: \"32\" - name: cp_enable value: \"true\" - name: cp_namespace value: kube-system - name: vip_ddns value: \"false\" - name: svc_enable value: \"true\" - name: vip_leaderelection value: \"true\" - name: vip_leaseduration value: \"5\" - name: vip_renewdeadline value: \"3\" - name: vip_retryperiod value: \"1\" - name: address value: 172.16.1.222 # image: ghcr.io/kube-vip/kube-vip:v0.6.0 image: ghcr.nju.edu.cn/kube-vip/kube-vip:v0.6.0 imagePullPolicy: Always name: kube-vip resources: {} securityContext: capabilities: add: - NET_ADMIN - NET_RAW - SYS_TIME hostNetwork: true serviceAccountName: kube-vip tolerations: - effect: NoSchedule operator: Exists - effect: NoExecute operator: Exists updateStrategy: {} status: currentNumberScheduled: 0 desiredNumberScheduled: 0 numberMisscheduled: 0 numberReady: 0 3、安装HA K3s集群 K3s 支持多种 HA 安装方式，本次示例采用嵌入式 ETCD 的方式搭建高可用的 K3s 集群，这样集群中就存在了 3 个控制平面，然后通过 kube-vip 实现这些控制平面的高可用。 安装 K3s 时需要指定 --tls-san 参数，这样 K3s 就会使用 kube-vip 虚拟 IP 地址生成 API 服务器证书。 master节点上 第一个server curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn INSTALL_K3S_EXEC=\" --cluster-init --tls-san 172.16.1.222 --disable=traefik --disable servicelb --kube-proxy-arg proxy-mode=ipvs --write-kubeconfig ~/.kube/config --write-kubeconfig-mode 644 \" sh - # 查看token cat /var/lib/rancher/k3s/server/token 其他server curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_TOKEN=K107f47359a4c5125056975c2bb8e4bee90a099366efa61e207092782f19f209abd::server:83a5baabf15d41e9cdf1de4a84b5367f INSTALL_K3S_EXEC=\" --server https://172.16.1.164:6443 --tls-san 172.16.1.2","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:4:2","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"四、多master高可用生产级别部署—离线版 # download wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-arm64 wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-airgap-images-arm64.tar.gz # 下载rpm包 wget https://github.com/k3s-io/k3s-selinux/releases/download/v1.4.stable.1/k3s-selinux-1.4-1.el9.noarch.rpm yum -y localinstall k3s-selinux-1.4-1.el9.noarch.rpm --downloadonly --downloaddir=./k3s-rpm yum -y install ipvsadm ipset --downloadonly --downloaddir=./k3s-rpm # 下载安装脚本 # wget https://get.k3s.io -o ./install.sh # wget http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh wget https://raw.githubusercontent.com/k3s-io/k3s/master/install.sh #分发到所有节点 # set k3s cp ./k3s /usr/local/bin/ chmod 755 /usr/local/bin/k3s # set images tar -xf k3s-airgap-images-$ARCH.tar.gz mkdir -p /var/lib/rancher/k3s/agent/images/ cp ./k3s-airgap-images-$ARCH.tar /var/lib/rancher/k3s/agent/images/ systemctl stop firewalld systemctl disable firewalld setenforce 0 sed -ri '/^SELINUX=/cSELINUX=disabled' /etc/selinux/config # 内核参数设置 cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf # https://github.com/moby/moby/issues/31208 # ipvsadm -l --timout # 修复ipvs模式下长连接timeout问题 小于900即可 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.ip_forward = 1 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 # 要求iptables不对bridge的数据进行处理 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.netfilter.nf_conntrack_max = 2310720 fs.inotify.max_user_watches=89100 fs.may_detach_mounts = 1 fs.file-max = 52706963 fs.nr_open = 52706963 vm.swappiness = 0 vm.overcommit_memory=1 vm.panic_on_oom=0 EOF sysctl -p cat \u003e/etc/modules-load.d/ipvs.conf\u003c\u003cEOF ip_vs # 负载均衡调度算法-最少连接 ip_vs_lc # 负载均衡调度算法-加权最少连接 ip_vs_wlc # 负载均衡调度算法-轮询 ip_vs_rr # 负载均衡调度算法-加权轮询 ip_vs_wrr # 源地址散列调度算法 ip_vs_sh nf_conntrack br_netfilter EOF systemctl restart systemd-modules-load.service lsmod | grep -e ip_vs -e nf_conntrack -e br_netfilter # 设置续签时间 echo \"CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=3650\" \u003e /etc/default/k3s # 设置镜像加速 mkdir -p /etc/rancher/k3s cat \u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: docker.io: endpoint: - \"https://docker.mirrors.sjtug.sjtu.edu.cn\" - \"https://docker.nju.edu.cn\" quay.io: endpoint: - \"https://quay.nju.edu.cn\" gcr.io: endpoint: - \"https://gcr.nju.edu.cn\" ghcr.io: endpoint: - \"https://ghcr.nju.edu.cn\" nvcr.io: endpoint: - \"https://ngc.nju.edu.cn\" EOF 第一个server # 配置kube-vip mkdir -p /var/lib/rancher/k3s/server/manifests/ cat \u003e kube-vip.yaml \u003c\u003cEOF apiVersion: v1 kind: ServiceAccount metadata: name: kube-vip namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" name: system:kube-vip-role rules: - apiGroups: [\"\"] resources: [\"services\", \"services/status\", \"nodes\", \"endpoints\"] verbs: [\"list\",\"get\",\"watch\", \"update\"] - apiGroups: [\"coordination.k8s.io\"] resources: [\"leases\"] verbs: [\"list\", \"get\", \"watch\", \"update\", \"create\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: system:kube-vip-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-vip-role subjects: - kind: ServiceAccount name: kube-vip namespace: kube-system --- apiVersion: apps/v1 kind: DaemonSet metadata: creationTimestamp: null name: kube-vip-ds namespace: kube-system spec: selector: matchLabels: name: kube-vip-ds template: metadata: creationTimestamp: null labels: name: kube-vip-ds spec: affinity: nodeAffinity: requ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:5:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"Ansible handbook ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:0:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"一、ansible配置 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:1:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"1、ansible.cfg https://ansible-tran.readthedocs.io/en/latest/docs/intro_configuration.html * ANSIBLE_CONFIG (一个环境变量) * ansible.cfg (位于当前目录中) * .ansible.cfg (位于家目录中) * /etc/ansible/ansible.cfg 生成ansible的配置文件 $ ansible-config init --disabled \u003e ~/.ansible.cfg 使用环境变量关闭Key验证提示 $ export ANSIBLE_HOST_KEY_CHECKING=False 可使用的模板 [defaults] interpreter_python = auto #interpreter_python = /usr/bin/python3 host_key_checking=False #inventory=~/.ansible/hosts private_key_file=/path/to/file.pem remote_user = root sudo_user=root ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:1:1","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"2、hosts 写法一 node1.ansible.com node2.ansible.com 192.168.1.1 写法二 [webserver] 192.168.10.1 192.168.10.2 [dbserver] 192.168.20.1 192.168.20.2 注意：如果主机建未做ssh互信，则可以按以下写法 # 连续IP [test1] name1 ansible_ssh_host=192.168.1.[20:50] ansible_ssh_user=\"root\" ansible_ssh_pass=\"1234\" ansible_ssh_port=22 ansible_ssh_private_key_file=~/.ssh/id_rsa # 带参数 [test1] name1 ansible_ssh_host=192.168.1.[20:50] [test1:vars] ansible_ssh_user=root ansible_ssh_pass=\"1234\" testvar=\"test\" host文件常用变量 ansible_ssh_host #用于指定被管理的主机的真实IP ansible_ssh_port #用于指定连接到被管理主机的ssh端口号，默认是22 ansible_ssh_user #ssh连接时默认使用的用户名 ansible_ssh_pass #ssh连接时的密码 ansible_sudo_pass #使用sudo连接用户时的密码 ansible_sudo_exec #如果sudo命令不在默认路径，需要指定sudo命令路径 ansible_ssh_private_key_file #秘钥文件路径，秘钥文件如果不想使用ssh-agent管理时可以使用此选项 ansible_shell_type #目标系统的shell的类型，默认sh ansible_connection #SSH 连接的类型： local , ssh , paramiko，在 ansible 1.2 之前默认是 paramiko ，后来智能选择，优先使用基于 ControlPersist 的 ssh （支持的前提） ansible_python_interpreter #用来指定python解释器的路径，默认为/usr/bin/python 同样可以指定ruby 、perl 的路径 ansible_*_interpreter #其他解释器路径，用法与ansible_python_interpreter类似，这里\"*\"可以是ruby或才perl等 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:1:2","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"二、playbook示例 - hosts: rocky become: yes become_user: root roles: #- role: serialt.centos_init - role: repo vars: elrepo_install: False - role: serialt.os_init vars: login_info: \" Welcome to local OPS\" fail2ban_ignore_ip: \"\" ssh_key_message: \"t@local.com\" - role: python - role: serialt.docker vars: docker_insecure_registries: [\"repo.local.com\"] # - role: serialt.chrony #- role: serialt.kernel # - role: zabbix-server 补充 # 本地执行 - name: check | 发布文件是否存在。 shell: \"ls {{ deploy_file }}\" connection: local # 判断 - name: Create software directory. file: path: \"{{ software_files_path }}\" state: directory connection: local when: not go_file_result.stat.exists # 串行执行 - hosts: server1 become: yes gather_facts: yes serial: 1 tasks: - YOUR TASKS HERE - hosts: serialt become: yes become_user: root vars: go_version: \"1.20.2\" tasks: - name: check | 发布文件是否存在。 shell: \"ls {{ deploy_file }}\" connection: local ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:2:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"三、公钥受信 ad hoc ansible add-public-key -m authorized_key -a \"user=root state=present key='{{ lookup('file', '/home/root/.ssh/id_rsa.pub') }}'\" playbook - hosts: add-public-key gather_facts: false tasks: - name: Add local public key to remote hosts. authorized_key: user: sugar key: \"{{ lookup('file', '/Users/serialt/.ssh/id_rsa.pub') }}\" state: present hosts [add-public-key] 172.16.78.53 ansible_connection=ssh ansible_ssh_user=\"sugar\" ansible_ssh_pass=\"ubuntu\" ; 172.25.70.2 ansible_connection=ssh ansible_ssh_user=\"root\" ansible_ssh_pass=\"redhat\" ; 172.25.70.3 ansible_connection=ssh ansible_ssh_user=\"sugar\" ansible_ssh_pass=\"redhat\" ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:2:1","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"四、模块简介 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"ping 检测被管理端是否在线 ad-hoc [root@localhost test]# ansible k8s -m ping 192.168.122.100 | SUCCESS =\u003e { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } playbook # ping模块没有参数 [root@localhost test]# cat ping.yaml - hosts: k8s user: root gather_facts: false tasks: - name: test ping ping: ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:1","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"shell 在被管理端执行命令，支持重定向和管道 ad-hoc [root@localhost test]# ansible k8s -m shell -a \" uptime\" 192.168.122.100 | CHANGED | rc=0 \u003e\u003e 11:11:05 up 25 days, 1:14, 2 users, load average: 0.31, 0.44, 0.39 # 参数 chdir=\u003cDirectory\u003e playbook [root@localhost test]# cat shell.yaml - hosts: k8s user: root gather_facts: false tasks: - name: test shell shell: date \u0026\u0026 pwd args: chdir: /tmp/ - name: Run expect to wait for a successful PXE boot via out-of-band CIMC shell: | set timeout 300 spawn ssh admin@{{ cimc_host }} expect \"password:\" send \"{{ cimc_password }}\\n\" expect \"\\n{{ cimc_name }}\" send \"connect host\\n\" expect \"pxeboot.n12\" send \"\\n\" exit 0 args: executable: /usr/bin/expect delegate_to: localhost ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:2","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"copy 拷贝ansible管理端的文件到远程主机的指定位置 常见参数： 参数 取值 默认值 说明 dest string null 指明拷贝文件的目标目录位置，使用绝对路径，如果源是目录，则目标也要是目录,如果目标文件已存在，会覆盖原有内容 src string null 指明本地路径下的某个文件，可以使用相对路径和绝对路径，支持直接指定目录，如果源是目录，则目标也要是目录 mode 权限位 无 指明复制时，目标文件的权限 owner string null 指明复制时，目标文件的属主 group string null 指明复制时，目标文件的属组 content string null 指明复制到目标主机上的内容，不能与src一起使用，相当于复制content指明的数据，到目标文件中 [root@localhost test]# ansible k8s -m copy -a \"src=/etc/hosts dest=/tmp/\" 192.168.122.100 | CHANGED =\u003e { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": true, \"checksum\": \"42d592f8ed1579880187c900197e1edd09688992\", \"dest\": \"/tmp/hosts\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"f4c82671111086eb6fa6d869e80e1128\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 803, \"src\": \"/root/.ansible/tmp/ansible-tmp-1608693775.8-22394-277593855767937/source\", \"state\": \"file\", \"uid\": 0 } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:3","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"fetch 从远程主机拉取文件到本地（ 一般情况下，只会从一个远程节点拉取数据） 常见参数： 参数 取值 默认值 说明 dest string null 从远程主机上拉取的文件存放在本地的位置，一般只能是目录 src string null 指明远程主机上要拉取的文件，只能是文件，不能是目录 [root@master ~]# ansible test -m fetch -a 'src=/etc/passwd dest=/tmp' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"checksum\": \"974b44c114ecbd71bdee11e09a9bc14c9b0395bd\", \"dest\": \"/tmp/192.168.100.102/etc/passwd\", \"md5sum\": \"01d72332a8d9737631212995fe1494f4\", \"remote_checksum\": \"974b44c114ecbd71bdee11e09a9bc14c9b0395bd\", \"remote_md5sum\": null } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:4","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"cron 管理计划任务 常见参数 参数 取值 默认值0 说明 minute 0-59, * , * / 2 * 指明计划任务的分钟 hour 0-23, * , * / 2 * day 1-31 * month 1-12 * weekday 0-6 * reboot yes | no null 指明计划任务执行的时间为每次重启之后 name string null 给该计划任务取个名称,必须要给明。每个任务的名称不能一样 job string null 执行的任务是什么，当state=present时才有意义 state present | absent present 表示这个任务是创建还是删除，present表示创建，absent表示删除，默认是present [root@master ~]# ansible test -m cron -a 'minute=*/5 name=Ajob job=\"/usr/sbin/ntpdate 172.16.8.100 \u0026\u003e /dev/null\" state=present' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"envs\": [], \"jobs\": [ \"Ajob\" ] } [root@master ~]# ansible test -m shell -a 'crontab -l' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e #Ansible: Ajob */5 * * * * /usr/sbin/ntpdate 172.16.8.100 \u0026\u003e /dev/null [root@master ~]# ansible test -m cron -a 'minute=*/5 name=Ajob job=\"/usr/sbin/ntpdate 172.16.8.100 \u0026\u003e /dev/null\" state=absent' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"envs\": [], \"jobs\": [] } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:5","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"file 用于设定远程主机上的文件属性 常见参数: 参数 取值 默认值 说明 path string null 指明对哪个文件修改其属性 src string null 指明path=指明的文件是软链接文件，其对应的源文件是谁，必须要在state=link时才有用 state directory | link| absent null 表示创建的文件是目录还是软链接 owner string null 指明文件的属主 mode 权限位 无 指明文件的权限 使用示例： 创建软链接的用法： src= path= state=link 修改文件属性的用法： path= owner= mode= group= 创建目录的用法： path= state=directory 删除文件： path= state=absent [root@ansible etc]# ansible testsrv -m file -a \"path=/tmp/1.txt mode=600 owner=root group=nobody\" [root@ansible ~]# ansible testsrv -m file -a \"path=/tmp/bb mode=777 recurse=yes\" 创建软链接 [root@master ~]# ansible test -m file -a 'src=/etc/passwd path=/tmp/passwd.link state=link' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"dest\": \"/tmp/passwd.link\", \"gid\": 0, \"group\": \"root\", \"mode\": \"0777\", \"owner\": \"root\", \"size\": 11, \"src\": \"/etc/passwd\", \"state\": \"link\", \"uid\": 0 } 删除文件 [root@master ~]# ansible test -m file -a 'path=/tmp/cc.txt state=absent' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"path\": \"/tmp/cc.txt\", \"state\": \"absent\" } 修改文件属性 [root@master ~]# ansible test -m file -a 'path=/tmp/bb.txt mode=700 owner=root group=nobody' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"gid\": 99, \"group\": \"nobody\", \"mode\": \"0700\", \"owner\": \"root\", \"path\": \"/tmp/bb.txt\", \"size\": 14, \"state\": \"file\", \"uid\": 0 } [root@master ~]# ansible test -m shell -a 'ls -l /tmp/bb.txt' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e -rwx------ 1 root nobody 14 Dec 2 2016 /tmp/bb.txt 创建目录 [root@master ~]# ansible test -m file -a 'path=/tmp/bj state=directory' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"gid\": 0, \"group\": \"root\", \"mode\": \"0755\", \"owner\": \"root\", \"path\": \"/tmp/bj\", \"size\": 4096, \"state\": \"directory\", \"uid\": 0 } 删除目录 [root@master ~]# ansible test -m file -a 'path=/tmp/bj state=absent' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"path\": \"/tmp/bj\", \"state\": \"absent\" } [root@master ~]# ansible test -m shell -a 'ls -l /tmp' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e total 16 -rw-r--r-- 1 root root 0 Dec 2 2016 aa.txt drwx------ 2 root root 4096 Dec 2 13:41 ansible_twMJYb -rwx------ 1 root nobody 14 Dec 2 2016 bb.txt -rw-r--r-- 1 root root 158 Dec 2 2016 hosts -rw------- 1 nobody nobody 947 Dec 2 2016 passwd lrwxrwxrwx 1 root root 11 Dec 2 13:35 passwd.link -\u003e /etc/passwd -rw------- 1 root root 0 Dec 2 00:58 yum.log ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:6","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"hostsname 管理远程主机的主机名 参数： name= 指明主机名 [root@master ~]# ansible test -m shell -a 'hostname' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e node1.ansible.com [root@master ~]# ansible test -m hostname -a 'name=node2.ansible.com' 192.168.100.102 | SUCCESS =\u003e { \"ansible_facts\": { \"ansible_domain\": \"ansible.com\", \"ansible_fqdn\": \"node2.ansible.com\", \"ansible_hostname\": \"node2\", \"ansible_nodename\": \"node2.ansible.com\" }, \"changed\": true, \"name\": \"node2.ansible.com\" } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:7","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"yum 基于yum机制，对远程主机管理程序包 常用参数： 参数 取值 默认值 说明 name string null 指明程序包的名称，可以带上版本号，不指明版本，就是默认最新版本 state present|lastest|absent null 指明对程序包执行的操作，present表示安装程序包，latest表示安装最新版本的程序包，absent表示卸载程序包 disablerepo yes|no null 在用yum安装时，临时禁用某个仓库，仓库的ID enablerepo yes|no null 在用yum安装时，临时启用某个仓库,仓库的ID conf_file= string null 指明yum运行时采用哪个配置文件，而不是使用默认的配置文件 disable_gpg_check yes|no null 是否启用gpg-check # 卸载软件包: [root@master ~]# ansible test -m yum -a 'name=httpd state=absent' [root@master ~]# ansible test -m shell -a 'rpm -q httpd' # 安装软件包: [root@master ~]# ansible test -m yum -a 'name=httpd state=present' [root@ansible ~]# ansible 192.168.122.102 -m yum -a \"name=ftp state=present disablerepo=zabbix\" [root@ansible_server ~]# ansible test_server -m yum -a \"name=zabbix-agent state=present enablerepo=zabbix3.2 disablerepo=zabbix\" # 更新软件 [root@ansible_server ~]# ansible test_server -m yum -a \"name=zabbix-agent state=latest\" palybook - hosts: all tasks: - name: yum yum: name: \"{{ item }}\" state: present with_items: - git - httpd - mysql ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:8","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"yum_repository 管理远程主机上的 yum 仓库 常用参数： 参数 取值 默认值 说明 name string null 必须参数，用于指定要操作的唯一的仓库ID，也就是”.repo”配置文件中每个仓库对应的”中括号”内的仓库ID baseurl string null 用于设置 yum 仓库的 baseurl description string null 用于设置仓库的注释信息，也就是”.repo”配置文件中每个仓库对应的”name字段”对应的内容 file string null 用于设置仓库的配置文件名称，即设置”.repo”配置文件的文件名前缀，在不使用此参数的情况下，默认以 name 参数的仓库ID作为”.repo”配置文件的文件名前缀，同一个”.repo” 配置文件中可以存在多个 yum 源 enabled string yes 用于设置是否激活对应的 yum 源，此参数默认值为 yes，表示启用对应的 yum 源，设置为 no 表示不启用对应的 yum 源 gpgcheck string no 用于设置是否开启 rpm 包验证功能，默认值为 no，表示不启用包验证，设置为 yes 表示开启包验证功能 gpgcakey string null 当 gpgcheck 参数设置为 yes 时，需要使用此参数指定验证包所需的公钥 state present present 当值设置为 absent 时，表示删除对应的 yum 源 [root@ansible-manager ~]# ansible ansible-demo3 -m yum_repository -a 'name=aliEpel description=\"alibaba EPEL\" baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/' ansible-demo3 | SUCCESS =\u003e { \"changed\": true, \"repo\": \"aliEpel\", \"state\": \"present\" } 配置postgresql 清华源 [root@localhost test]# cat yum_repo.yaml - hosts: 127.0.0.1 user: root gather_facts: false tasks: - name: config postgresql with tsinghua yum_repository: file: postgresql-10 name: postgresql description: postgresql-10 tsinghua baseurl: https://mirrors.tuna.tsinghua.edu.cn/postgresql/repos/yum/10/redhat/rhel-7-x86_64/ enabled: yes gpgcheck: no [root@localhost yum.repos.d]# cat postgresql-10.repo [postgresql] baseurl = https://mirrors.tuna.tsinghua.edu.cn/postgresql/repos/yum/10/redhat/rhel-7-x86_64/ enabled = 1 gpgcheck = 0 name = postgresql-10 tsinghua ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:9","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"service 管理远程主机上的服务的模块 常用参数： 参数 取值 默认值 说明 name string null 被管理的服务名称(/etc/init.d) state started|stopped|restarted started 启动或关闭或重起 enabled yes|no no 设定该服务开机自启动 [root@master ~]# ansible test -m service -a 'name=nginx state=started' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"name\": \"nginx\", \"state\": \"started\" } [root@master ~]# ansible test -m shell -a 'service nginx status' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e nginx (pid 4054) is running... [root@master ~]# [root@master ~]# ansible test -m service -a 'name=nginx state=stopped' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"name\": \"nginx\", \"state\": \"stopped\" } [root@master ~]# ansible test -m shell -a 'service nginx status' 192.168.100.102 | FAILED | rc=3 \u003e\u003e nginx is stopped [root@master ~]# ansible test -m service -a 'name=nginx state=started enabled=yes runlevel=2345' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"enabled\": true, \"name\": \"nginx\", \"state\": \"started\" } [root@master ~]# ansible test -m shell -a 'chkconfig --list nginx' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e nginx 0:off 1:off 2:on 3:on 4:on 5:on 6:off ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:10","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"systemd 管理被控制主机的systemd服务 常见参数： 参数 取值 默认值 说明 daemon_reload yes|no 无 重启守护进程，与其他systemd参数排斥 name string null 被管理的服务名 enabled yes|no null 服务设置为开机自启 state reloaded|restarted|started|stopped null 服务状态 [root@localhost test]# cat daemon_reload.yaml - hosts: 127.0.0.1 user: root gather_facts: false tasks: - name: daemon reload systemd: daemon_reload: yes [root@localhost test]# cat nginx.yaml - hosts: 127.0.0.1 user: root gather_facts: false tasks: - name: daemon reload systemd: name: nginx enabled: yes state: restarted ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:11","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"git 管理git服务模块 常见参数： 参数 取值 默认值 说明 bare yes|no no 建立裸仓库，用于服务器端git仓库存储 clone yes|no yes 本地镜像仓库不存在则clone depth 数字 null clone时克隆的commit深度，1表示只克隆最新一次提交，默认null dest string null clone出的仓库存储的路径，仅当clone=no时不用设置 force yes|no no 强制 remote string null 远程仓库的名称，默认是origin repo string null 远程仓库的地址 version string null checkout的版本，支持分支、tag、hash archive string null clone后的压缩文件存储文件，支持格式zip、tar.gz、tar、tgz - hosts: 127.0.0.1 user: root gather_facts: false vars: - GIT_REPO: git@serialt.io:sugars/sugars_backend.git - SRC_HASH: 4949e0b60be3f6a80826d3e02exxxxxxxxxxxx tasks: - name: clone a git repo git: repo: \"{{ item.repo }}\" version: \"{{ item.hash }}\" dest: /tmp/serialt_backend with_items: - {repo: \"{{ GIT_REPO }}\",hash: \"{{ SRC_HASH }}\" } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:12","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"supervisorctl 管理supervisorctl服务 常见参数： 参数 取值 默认值 说明 config string null supervisor配置文件路径 name string null supervisord program的名字，支持program和program组 state string nul 可选present, started, stopped, restarted, absent, signalled supervisorctl_path string null supervisorctl命令的路径 EXAMPLES: # Manage the state of program to be in 'started' state. - supervisorctl: name: my_app state: started # Manage the state of program group to be in 'started' state. - supervisorctl: name: 'my_apps:' state: started # Restart my_app, reading supervisorctl configuration from a specified file. - supervisorctl: name: my_app state: restarted config: /var/opt/my_project/supervisord.conf # Restart my_app, connecting to supervisord with credentials and server URL. - supervisorctl: name: my_app state: restarted username: test password: testpass server_url: http://localhost:9001 # Send a signal to my_app via supervisorctl - supervisorctl: name: my_app state: signalled signal: USR1 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:13","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"pip 管理python库依赖模块 常见参数： 参数 取值 默认值 说明 chdir string null 执行时的路径 name string null pip安装的包名 requirements string null 安装依赖的包文件 executable string null 安装依赖包时使用的python路径 state string present 依赖包的状态，absent, forcereinstall, latest, present，默认present virtualenv string null 所使用的虚拟环境目录 virtualenv_command string null 创建虚拟环境的命令 virtualenv_python string null 虚拟环境的python版本 extra_args= string null 附加参数，可以用来指定所使用的安装源 [root@localhost test]# cat pip.yaml - hosts: 192.168.100.105 user: root gather_facts: false tasks: - name: install python venv pip: requirements: /tmp/requirements.txt state: present virtualenv: /tmp/serialt_venv/ ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:14","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"archive 压缩文件模块 常用参数： 参数 取值 默认值 说明 dest string null 文件归档后的压缩包文件名，当 path中有多个文件或目录时，需提供 dest 参数 exclude_path string null 排除的path format string gz 支持bz2, gz, tar, xz, zip，默认gz path string null 要压缩的路径 remove bool False 删除源文件 EXAMPLES: - name: Compress directory /path/to/foo/ into /path/to/foo.tgz archive: path: /path/to/foo dest: /path/to/foo.tgz - name: Compress regular file /path/to/foo into /path/to/foo.gz and remove it archive: path: /path/to/foo remove: yes - name: Create a zip archive of /path/to/foo archive: path: /path/to/foo format: zip - name: Create a bz2 archive of multiple files, rooted at /path archive: path: - /path/to/foo - /path/wong/foo dest: /path/file.tar.bz2 format: bz2 - name: Create a bz2 archive of a globbed path, while excluding specific dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/bar - /path/to/foo/baz format: bz2 - name: Create a bz2 archive of a globbed path, while excluding a glob of dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/ba* format: bz2 - name: Use gzip to compress a single archive (i.e don't archive it first with tar) archive: path: /path/to/foo/single.file dest: /path/file.gz format: gz - name: Create a tar.gz archive of a single file. archive: path: /path/to/foo/single.file dest: /path/file.tar.gz format: gz force_archive: true RETURN VALUES: - name: Create a zip archive of /path/to/foo archive: path: /path/to/foo format: zip - name: Create a bz2 archive of multiple files, rooted at /path archive: path: - /path/to/foo - /path/wong/foo dest: /path/file.tar.bz2 format: bz2 - name: Create a bz2 archive of a globbed path, while excluding specific dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/bar - /path/to/foo/baz format: bz2 - name: Create a bz2 archive of a globbed path, while excluding a glob of dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/ba* format: bz2 - name: Use gzip to compress a single archive (i.e don't archive it first with tar) archive: path: /path/to/foo/single.file dest: /path/file.gz format: gz - name: Create a tar.gz archive of a single file. archive: path: /path/to/foo/single.file dest: /path/file.tar.gz format: gz force_archive: true ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:15","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"unarchive 参数 取值 默认值 说明 creates string null 文件名，当它已经存在时，这个步骤将不会被运行 copy yes / no yes 拷贝的文件从ansible主机复制到远程主机，no在远程主机上寻找src源文件解压 src string null tar源路径，可以是ansible主机上的路径，也可以是远程主机上的路径，如果是远程主机上的路径，则需设置copy=no dest string null 远程主机上的目标绝对路径 mode 数字 无 设置解压缩后的文件权限 exec 无 无 列出需要排除的目录和文件 owner string 无 解压后文件或目录的属主 group srting 无 解压后的目录或文件的属组 EXAMPLES: - name: Extract foo.tgz into /var/lib/foo unarchive: src: foo.tgz dest: /var/lib/foo - name: Unarchive a file that is already on the remote machine unarchive: src: /tmp/foo.zip dest: /usr/local/bin remote_src: yes - name: Unarchive a file that needs to be downloaded (added in 2.0) unarchive: src: https://example.com/example.zip dest: /usr/local/bin remote_src: yes - name: Unarchive a file with extra options unarchive: src: /tmp/foo.zip dest: /usr/local/bin extra_opts: - --transform - s/^xxx/yyy/ ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:16","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"uri 用于请求某个网页 常见参数： 参数 取值 默认值 说明 body raw null 当body_format设置为json时的键值对 body_format string raw 数据格式，form-urlencoded, json, raw method string GET 指明请求的方法，如GET、POST, PUT, DELETE, HEAD dest string null 下载文件的路径 force bool False force_basic_auth headers method 指明请求的方法，如GET、POST, PUT, DELETE, HEAD return_content bool False url string null url_password 如果请求的url需要认证，则填写认证的密码 url_username 如果请求的url需要认证，则填写用户名 [root@master ~]# ansible test -m url -a 'url=http://192.168.100.102/index.html' 192.168.100.102 | SUCCESS =\u003e { \"accept_ranges\": \"bytes\", \"changed\": false, \"connection\": \"close\", \"content_length\": \"612\", \"content_type\": \"text/html\", \"date\": \"Fri, 02 Dec 2016 06:31:58 GMT\", \"etag\": \"\\\"571f8501-264\\\"\", \"last_modified\": \"Tue, 26 Apr 2016 15:10:57 GMT\", \"msg\": \"OK (612 bytes)\", \"redirected\": false, \"server\": \"nginx/1.10.0\", \"status\": 200, \"url\": \"http://192.168.100.102/index.html\" } [root@master ~]# EXAMPLES: - name: Check that you can connect (GET) to a page and it returns a status 200 uri: url: http://www.example.com - name: Check that a page returns a status 200 and fail if the word AWESOME is not in the page contents uri: url: http://www.example.com return_content: yes register: this failed_when: \"'AWESOME' not in this.content\" - name: Create a JIRA issue uri: url: https://your.jira.example.com/rest/api/2/issue/ user: your_username password: your_pass method: POST body: \"{{ lookup('file','issue.json') }}\" force_basic_auth: yes status_code: 201 body_format: json - name: Login to a form based webpage, then use the returned cookie to access the app in later tasks uri: url: https://your.form.based.auth.example.com/index.php method: POST body_format: form-urlencoded body: name: your_username password: your_password enter: Sign in status_code: 302 register: login - name: Login to a form based webpage using a list of tuples uri: url: https://your.form.based.auth.example.com/index.php method: POST body_format: form-urlencoded body: - [ name, your_username ] - [ password, your_password ] - [ enter, Sign in ] status_code: 302 register: login - name: Connect to website using a previously stored cookie uri: url: https://your.form.based.auth.example.com/dashboard.php method: GET return_content: yes headers: Cookie: \"{{ login.set_cookie }}\" - name: Queue build of a project in Jenkins uri: url: http://{{ jenkins.host }}/job/{{ jenkins.job }}/build?token={{ jenkins.token }} user: \"{{ jenkins.user }}\" password: \"{{ jenkins.password }}\" method: GET force_basic_auth: yes status_code: 201 - name: POST from contents of local file uri: url: https://httpbin.org/post method: POST src: file.json - name: POST from contents of remote file uri: url: https://httpbin.org/post method: POST src: /path/to/my/file.json remote_src: yes - name: Pause play until a URL is reachable from this host uri: url: \"http://192.0.2.1/some/test\" follow_redirects: none method: GET register: _result until: _result.status == 200 retries: 720 # 720 * 5 seconds = 1hour (60*60/5) delay: 5 # Every 5 seconds # There are issues in a supporting Python library that is discussed in # https://github.com/ansible/ansible/issues/52705 where a proxy is defined # but you want to bypass proxy use on CIDR masks by using no_proxy - name: Work around a python issue that doesn't support no_proxy envvar uri: follow_redirects: none validate_certs: false timeout: 5 url: \"http://{{ ip_address }}:{{ port | default(80) }}\" register: uri_data failed_when: false changed_when: false vars: ip_address: 192.0.2.1 environment: | { {% for no_proxy in (lookup('env', 'no_proxy') | regex_replace('\\s*,\\s*', ' ') ).split() %} {% if no_proxy | regex_search('\\/') and no_proxy | ipaddr('net') != '' and no_proxy | ipaddr('net') != false and ip_address | ipaddr(no_proxy) is not none and ip_address | ipaddr(no_proxy) != false %} 'no_proxy': '{{ ip_address }}' {% elif no_proxy | regex_search(':') != '' and no_proxy | regex_search(':') != false and no_proxy == ip_address + ':' + (port | default(80)) %} 'no_proxy': '{{ ip_address }","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:17","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"group 用来添加或删除远端主机的用户组 常见参数： 参数 取值 默认值 说明 name string null state string present gid int null GID system bool False 创建系统用户 [root@master ~]# ansible test -m group -a 'name=hr gid=2000 state=present' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"gid\": 2000, \"name\": \"hr\", \"state\": \"present\", \"system\": false } [root@master ~]# ansible test -m shell -a 'tail -1 /etc/group' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e hr❌2000: ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:18","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"user 管理远程主机上的用户的账号 常见参数： 参数 取值 默认值 说明 name string null 指明要管理的账号名称 state string present 指明是创建账号还是删除账号，present表示创建，absent表示删除 system bool False 指定系统用户 uid int null 用户的uid shell string null shell类型 home string null 家目录位置 group string null 指明用户的基本组 groups string null 指明用户的附加组 move_home bool False 当home设定了家目录，如果要创建的家目录已存在，是否将已存在的家目录进行移动 password string null 指明用户的密码，最好使用加密好的字符串 comment string null 指明用户的注释信息 remove bool null 当state=absent时，也就是删除用户时，是否要删除用户的而家目录 [root@master ~]# ansible test -m user -a 'name=martin group=hr groups=shichang uid=500 shell=/bin/bash home=/home/martin comment=\"martin user\"' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"comment\": \"martin user\", \"createhome\": true, \"group\": 2000, \"groups\": \"shichang\", \"home\": \"/home/martin\", \"name\": \"martin\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 500 } [root@master ~]# ansible test -m shell -a 'grep \"martin:\" /etc/passwd' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e martin❌500:2000:martin user:/home/martin:/bin/bash [root@master ~]# ansible test -m user -a 'name=martin state=absent remove=yes' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"force\": false, \"name\": \"martin\", \"remove\": true, \"state\": \"absent\" } EXAMPLES: - name: Add the user 'johnd' with a specific uid and a primary group of 'admin' user: name: johnd comment: John Doe uid: 1040 group: admin - name: Add the user 'james' with a bash shell, appending the group 'admins' and 'developers' to the user's gro user: name: james shell: /bin/bash groups: admins,developers append: yes - name: Remove the user 'johnd' user: name: johnd state: absent remove: yes - name: Create a 2048-bit SSH key for user jsmith in ~jsmith/.ssh/id_rsa user: name: jsmith generate_ssh_key: yes ssh_key_bits: 2048 ssh_key_file: .ssh/id_rsa - name: Added a consultant whose account you want to expire user: name: james18 shell: /bin/zsh groups: developers expires: 1422403387 - name: Starting at Ansible 2.6, modify user, remove expiry time user: name: james18 expires: -1 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:19","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"script 将管理端的某个脚本，移动到远端主机(不需要指明传递到远端主机的哪个路径下，系统会自动移动，然后执行)， 一般是自动移动到远端主机的/root/.ansible/tmp目录下，然后自动给予其权限，然后再开个子shell然后运行脚本，运行完成后删除脚本 [root@master ~]# ansible test -m script -a '/root/1.sh' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"rc\": 0, \"stderr\": \"\", \"stdout\": \"\", \"stdout_lines\": [] } [root@master ~]# ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:20","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"setup 可收集远程主机的facts变量的信息，相当于收集了目标主机的相关信息(如内核版本、操作系统信息、cpu、…)，保存在ansible的内置变量中，之后我们有需要用到时，直接调用变量即可 [root@master ~]# ansible test -m setup 192.168.100.102 | SUCCESS =\u003e { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ \"192.168.100.102\" ], \"ansible_all_ipv6_addresses\": [ \"fe80::20c:29ff:fe0c:5ab9\" ], \"ansible_architecture\": \"x86_64\", \"ansible_bios_date\": \"05/20/2014\", \"ansible_bios_version\": \"6.00\", ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:21","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"template 基于模板方式，生成一个模板文件，复制到远程主机，让远程主机基于模板，生成符合远程主机自身的文件 注意：此模块不能在命令行使用，只能用在playbook中 常见参数： src= 指明管理端本地的模板文件的目录 dest= 指明将模板文件拷贝到远程主机的哪个目录下 owner= 指明拷贝到远程主机的文件的属主 group= 指明拷贝到远程主机的文件的属组 mode= 指明拷贝到远程主机的文件的权限 [root@master ~]# cat temp.txt this is {{ ansible_hostname }} [root@master ~]# cat test.yml - hosts: 192.168.10.202 remote_user: root tasks: - name: test template template: src=/root/temp.txt dest=/tmp [root@master ~]# ansible-playbook test.yml PLAY [192.168.10.202] ********************************************************** TASK [setup] ******************************************************************* ok: [192.168.10.202] TASK [test template module] **************************************************** changed: [192.168.10.202] PLAY RECAP ********************************************************************* 192.168.10.202 : ok=2 changed=1 unreachable=0 failed=0 [root@master ~]# ansible 192.168.10.202 -m shell -a 'cat /tmp/temp.txt' 192.168.10.202 | SUCCESS | rc=0 \u003e\u003e this is agent202 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:22","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"script script 模块可以在远程主机上执行 ansible 管理主机上的脚本，也就是说，脚本一直存在于 ansible 管理主机本地，不需要手动拷贝到远程主机后再执行。 常用参数： chdir：执行脚本时所在的目录 creates：使用此参数指定一个远程主机中的文件，当指定的文件存在时，就不执行对应脚本 removes：使用此参数指定一个远程主机中的文件，当指定的文件不存在时，就不执行对应脚本 示例： - name: Run a script with arguments (free form) script: /some/local/script.sh ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:23","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"lineinfile 参数 取值 默认值 说明 path string null 操作的文件 line string null 替换的内容 regexp string null 匹配表达式 state present|absent present insertafter string 无 插入到匹配行后 insertbefore string 无 插入匹配行前 backup yes|no 无 改变前备份 示例：开启selinux - name: Ensure SELinux is set to enforcing mode lineinfile: path: /etc/selinux/config regexp: '^SELINUX=' line: SELINUX=enforcing - name: Make sure group wheel is not in the sudoers configuration lineinfile: path: /etc/sudoers state: absent regexp: '^%wheel' - name: Replace a localhost entry with our own lineinfile: path: /etc/hosts regexp: '^127\\.0\\.0\\.1' line: 127.0.0.1 localhost owner: root group: root mode: '0644' ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:24","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"fail 参数 取值 默认值 说明 msg string null 满足条件执行时输出的信息 - fail: msg: The system may not be provisioned according to the CMDB status. when: cmdb_status != \"to-be-staged\" ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:25","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"stat 检查文件或文件系统的状态，对于Windows目标，则使用win_stat模块 参数 取值 默认值 说明 path string null 文件或目录的路径，必选参数 checksum_algorithm string sha1 计算文件的算法，可选md5, sha1, sha224, sha256, sha384, sha512 stat模块的返回值 返回值 取值 exists bool path str mode str isdir bool islnk bool uid int gid int size int inode int lnk_source str md5 str 使用示例 - stat: path: /etc/foo.conf register: st - fail: msg: \"Whoops! file ownership has changed\" when: st.stat.pw_name != 'root' - stat: path: /path/to/something register: sym - debug: msg: \"islnk isn't defined (path doesn't exist)\" when: sym.stat.islnk is not defined - debug: msg: \"islnk is defined (path must exist)\" when: sym.stat.islnk is defined - debug: msg: \"Path exists and is a symlink\" when: sym.stat.islnk is defined and sym.stat.islnk - debug: msg: \"Path exists and isn't a symlink\" when: sym.stat.islnk is defined and sym.stat.islnk == False - stat: path: /path/to/something register: p - debug: msg: \"Path exists and is a directory\" when: p.stat.isdir is defined and p.stat.isdir # Don't do checksum - stat: path: /path/to/myhugefile get_checksum: no # Use sha256 to calculate checksum - stat: path: /path/to/something checksum_algorithm: sha256 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:26","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"pause 暂停一段时间等待终端输入 参数 取值 默认值 说明 echo bool yes 是否输出键盘的输入值 minutes string null 暂停多少分钟 prompt string null 打印一串信息提示用户操作 seconds string null 暂停多少秒 pause模块的返回值 返回值 取值 delta string echo bool start string stdout string stop string user_input string 使用示例 - name: Pause for 5 minutes to build app cache pause: minutes: 5 - name: Pause until you can verify updates to an application were successful pause: - name: A helpful reminder of what to look out for post-update pause: prompt: \"Make sure org.foo.FooOverload exception is not present\" - name: Did you Backup DB pause: prompt=\"Did you commit it? Enter to continue or CTRL-C to quit.\" - name: Pause to get some sensitive input pause: prompt: \"Enter a secret\" echo: no ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:27","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"Gitlab ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:0:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"版本介绍 gitlab分社区版和企业版，与其他企业版软件不同的是，社区版和企业版都不收费，都可以免费使用 官方文档：https://docs.gitlab.com/ ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:1:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"授权模式 GitLab基于开源核心模型 (open core model)。即以为着Gitlab有两个版本：社区版Community Edition 和 企业版Enterprise Edition。 GitLab 社区版是MIT许可的open source。 GitLab 企业版基于社区版：使用了同样的内核，但是添加了额外的功能、特性。 这是在所有权授权下。 对于所有的版本：Gitlab 所有的 javascript 源码 都是 open source 的。Gtilab 开发的所有的 javascript code 都是 MIT 授权许可。 企业版虽然是免费使用，但免费但功能跟社区版一致。 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:1:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"一、部署 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:2:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"1、包部署 1）下载安装包 清华源：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce 南京大学镜像：https://mirrors.nju.edu.cn/gitlab-ce/ gitlab安装包比较大，建议先下载到本地再安装 [root@gitlab3 ~]# ls anaconda-ks.cfg gitlab-ce-12.9.7-ce.0.el7.x86_64.rpm [root@gitlab3 ~]# yum -y localinstall gitlab-ce-12.9.7-ce.0.el7.x86_64.rpm 2）配置gitlab gitlab使用chef进行安装，配置文件为/etc/gitlab/gitlab.rb # 配置访问地址 [root@gitlab3 ~]# vim /etc/gitlab/gitlab.rb 29 external_url 'http://gitlab.example.com' # 配置通知邮箱 # 官方邮箱配置示例：https://docs.gitlab.com/omnibus/settings/smtp.html [root@gitlab1 ~]# vim /etc/gitlab/gitlab.rb gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = \"smtphz.qiye.163.com\" gitlab_rails['smtp_port'] = 994 gitlab_rails['smtp_user_name'] = \"cccccc@163.com\" gitlab_rails['smtp_password'] = \"xxxxxxxxxx\" gitlab_rails['smtp_domain'] = \"qiye.163.com\" gitlab_rails['smtp_authentication'] = \"login\" gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['smtp_tls'] = true user['git_user_email'] = \"cccc@163.com\" gitlab_rails['gitlab_email_from'] = 'cccc@163.com' gitlab_rails['gitlab_email_reply_to'] = 'cccc@163.com' # 配置重启服务 [root@gitlab1 ~]# gitlab-ctl stop [root@gitlab1 ~]# gitlab-ctl reconfigure [root@gitlab1 ~]# gitlab-ctl restart # 测试邮件发送 [root@gitlab1 ~]# gitlab-rails console Notify.test_email('t@local.com','gitlab','this is test').deliver_now 邮箱 主题 内容 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:2:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"2、docker部署 使用docker部署时建议先修改ssh端口，预留22给gitlab docker run \\ -p 443:443 -p 80:80 -p 22:22 \\ --name gitlab \\ --volume /data/gitlab/config:/etc/gitlab \\ --volume /data/gitlab/logs:/var/log/gitlab \\ --volume /data/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:13.12.9-ce.0 docker-compose version: '3' services: gitlab: image: gitlab/gitlab-ce:13.12.9-ce.0 container_name: gitlab restart: always privileged: true environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url = \"http://git.local.com\" ports: - '80:80' - '443:443' - '2222:22' volumes: - '/dataDisk/gitlab/config:/etc/gitlab' - '/dataDisk/gitlab/logs:/var/log/gitlab' - '/dataDisk/gitlab/data:/var/opt/gitlab' ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:2:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"二、配置 1、gitlab修改url （如果是迁移或者重新配置） 1）修改gitlab的配置文件 [root@gitlab1 ~]# vim /etc/gitlab/gitlab.rb 30 external_url 'http://192.168.100.103' #修改为域名或者IP 2）修改git clone的路径 查看gitlab.yml软连接的路径 [root@gitlab1 ~]# cd /opt/gitlab/embedded/service/gitlab-rails/config lrwxrwxrwx 1 root root 43 Jun 19 15:23 gitlab.yml -\u003e /var/opt/gitlab/gitlab-rails/etc/gitlab.yml [root@gitlab1 config]# vim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml 10 ## GitLab settings 11 gitlab: 12 ## Web server settings (note: host is the FQDN, do not include http://) 13 host: 192.168.100.103 #gitlab登陆后访问的路径 14 port: 80 15 https: false ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:3:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"三、gitlab-runner ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"1、包安装 1）下载和安装 [root@gitlab1 ~]# yum -y install https://mirror.nju.edu.cn/gitlab-runner/yum/el8-x86_64/gitlab-runner-14.8.3-1.x86_64.rpm [root@gitlab1 ~]# yum -y install git 2）注册gitlab-runner [root@gitlab1 ~]# gitlab-runner register \\ --non-interactive \\ --executor \"shell\" \\ --url \"http://192.168.23.100/\" \\ --registration-token \"JRzzw2j1Ji6aBjwvkxAv\" \\ --description \"xxxxx-devops-runner\" \\ --tag-list \"build,deploy,runner-shell,runner\" \\ --run-untagged=\"true\" \\ --locked=\"false\" \\ --access-level=\"not_protected\" 会要求输入gitlab的url和Token. 查找过程如下： 进入仓库-\u003esettings-\u003eCI/CD，找到Runner Settings这一项，点击Expend,即可在Setup a specific Runner manually这项中找到。 注册完后查看runner状态 进入仓库-\u003esettings-\u003eCI/CD，找到Runner Settings这一项，点击Expend,即可看到Gitlab-Runenr的运行状态 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"2、docker安装 version: \"3\" services: gitrunner: image: 'gitlab/gitlab-runner:ubuntu-v15.8.3' container_name: \"gitlab-runner\" restart: always command: \"run --user=root --working-directory=/home/gitlab-runner\" volumes: - '/data/gitlab-runner/config:/etc/gitlab-runner' - '/data/gitlab-runner/cache:/tmp/cache' # - '/data/gitlab-runner/ssl:/etc/gitlab-runner/certs/' - '/usr/bin/docker:/usr/bin/docker' - '/var/run/docker.sock:/var/run/docker.sock' 注册 docker exec -it gitlab-runner gitlab-runner register --non-interactive --executor \"shell\" --url \"http://local.com\" --registration-token \"XmWa6cccc-ccccccc\" --description \"runner\" --tag-list \"docker-runner,gitlab-runner-shell,runner\" --run-untagged=\"true\" --locked=\"false\" --access-level=\"not_protected\" runner in docker docker exec -it gitlab-runner gitlab-runner register --non-interactive --executor \"docker\" --docker-image=debian:11 --url \"http://local.com\" --registration-token \"XmWa6cccc-ccccccc\" --description \"docker-runner\" --tag-list \"docker-runner,gitlab-runner-docker\" --run-untagged=\"true\" --locked=\"false\" --access-level=\"not_protected\" ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"3、.gitlab-ci.yml 模版 default: image: 'centos:7' before_script: - echo Hello World after_script: - echo end tags: gitlab-runner-shell # 指定gitlab runner 的tag cache: paths: [vendor/] DEPLOY_VARIABLE: \"default-deploy\" variables: IMAGE: name/${CI_PROJECT_NAMESPACE}-${CI_PROJECT_NAME} workflow: rules: - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH variables: DEPLOY_VARIABLE: \"deploy-production\" # Override globally-defined DEPLOY_VARIABLE - if: $CI_COMMIT_REF_NAME =~ /feature/ variables: IS_A_FEATURE: \"true\" # Define a new variable. - when: always stages: - test - build - package - deploy - cleanup test_all: image: \"pymicro\" pull_policy: if-not-present stage: test services: - name: my-postgres:11.7 alias: db-postgres pull_policy: if-not-present entrypoint: [\"/usr/local/bin/db-postgres\"] command: [\"start\"] veriables: MYSQL_DATABASE: db MYSQL_ROOT_PASSWORD: password allow_failure: true # job 允许失败 before_script: - 'command -v ssh-agent \u003e/dev/null || ( apt-get update -y \u0026\u0026 apt-get install openssh-client -y )' - eval $(ssh-agent -s) - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add - - mkdir -p ~/.ssh - chmod 700 ~/.ssh - echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" \u003e ~/.ssh/config' script: - flake8 app - pytest tests after_script: - execute this after my script # 执行命令 build_image: image: name docker:17.11 pull_policy: always # if-not-present #entrypoint: [\"echo hellow-world\"] #覆盖 entrypoint命令 # command: [\"start\"] 覆盖command命令 stage: build services: - name: my-postgres:11.7 alias: db-postgres entrypoint: [\"/usr/local/bin/db-postgres\"] command: [\"start\"] variables: DOCKER_HOST: tcp://dockerd:2375 # 缓存 binaries 中以 .apk 和 .config 文件结尾的所有文件： cache: key: binaries-cache paths: - binaries/*.apk - .config only: - master tags: - build script: - | docker build -t ${IMAGE_TAG} -f Dockerfile . docker push ${IMAGE_TAG} package_app: stage: build rules: - if: $CI_COMMIT_MESSAGE =~ /build-app-a/ variables: GITLAB_app_NAME: gitea-drone - if: $CI_COMMIT_MESSAGE =~ /build-app-b/ variables: GITLAB_app_NAME: gitea-drone-b - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"' changes: - Dockerfile when: manual allow_failure: true - if: $CI_PIPELINE_SOURCE == \"merge_request_event\" changes: paths: - Dockerfile - exists: - Dockerfile before_script: - hello script: - echo \"${GITLAB_app_NAME}\" after_script: - echo \"world\" allow_failure: exit_codes: - 137 - 255 # 当Gemfile.lock有变化时候，重新生成缓存 cache: key: files: - Gemfile.lock - package.json paths: - vendor/ruby - node_modules last-job: stage: .post script: - echo \"This job runs in the .post stage, after all other stages.\" deploy_production: stage: deploy variables: GIT_STRATEGY: none needs: - job: test-job2 optional: true - job: test-job1 # only/except only: # - master - main - /^issue-.*$/ - merge_requests - tags variables: - $RELEASE == \"staging\" refs: - branches changes: - Dockerfile - docker/scripts/ allow_failure: true when: manual tags: - deploy-production script: - kubectl set image deploy/myproject \"app=${IMAGE_TAG}\" --record cache: untracked: true # 来缓存 Git 仓库中所有未跟踪的文件 paths: - binaries/ cleanup_job: stage: cleanup script: - cleanup after jobs when: always 内置变量，参考地址：https://docs.gitlab.cn/jh/ci/variables/predefined_variables.html 变量 GitLab Runner 描述 CHAT_CHANNEL 10.6 all 触发 ChatOps 命令的源聊天频道。 CHAT_INPUT 10.6 all 使用 ChatOps 命令传递的附加参数。 CHAT_USER_ID 14.4 all 触发 ChatOps 命令的用户的聊天服务用户 ID。 CI all 0.4 适用于在 CI/CD 中执行的所有作业。可用时为 true。 CI_API_V4_URL 11.7 all GitLab API v4 根 URL。 CI_BUILDS_DIR all 11.10 执行构建的顶级目录。 CI_COMMIT_AUTHOR 13.11 all Name \u003cemail\u003e 格式的提交作者。 CI_COMMIT_BEFORE_SHA 11.2 all 出现在分支或标签上的上一个最新提交。在合并请求的流水线中总是 0000000000000000000000000000000000000000。 CI_COMMIT_BRANCH 12.6 0.5 提交分支名称。在分支流水线中可用，包括默认分支的流水线。在合并请求流水线或标签流水线中不可用。 CI_COMMIT_DESCRIPTION 10.8 all 提交的描述。如果标题短于 100 个字符，则消息没有第一行。 CI_COMMIT_MESSAGE 10.8 all 完整的提交消息。 CI_COMMIT_REF_NAME 9.0 all 为其构建项目的分支或标签名称。 CI_COMMIT_REF_PROTECTED 11.11 all 如果作业正在运行以获取受保护的 ref 为 true 。 CI_COMMIT_REF_SLUG 9.0 all CI_COMMIT_REF_NAME 小写，缩短为 63 字节，除了 0-9 和 a-z 之外的所有内容都替换为 -。没有前","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:3","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"四、备份与恢复 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:5:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"1、备份 [root@gitlab1 ~]# gitlab-rake gitlab:backup:create 使用以上命令会在/var/opt/gitlab/backups目录下创建一个名称类似为1530156812_2018_06_28_10.8.4_gitlab_backup.tar的压缩包, 这个压缩包就是Gitlab整个的完整部分, 其中开头的1530156812_2018_06_28_10.8.4是备份创建的日期 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:5:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"2、数据恢复 [root@gitlab1 ~]# gitlab-ctl stop unicorn [root@gitlab1 ~]# gitlab-ctl stop sidekiq 备份文件增加777权限，并且文件需要存放在/var/opt/gitlab/backups里 [root@gitlab1 ~]# gitlab-rake gitlab:backup:restore BACKUP=1530156812_2018_06_28_10.8.4 # 输入两次yes 启动服务 [root@gitlab1 ~]# gitlab-ctl restart ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:5:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"五、升级 gitlab的跨版本升级需要升级中间多个小版本，为了方便升级，可以基于docker升级。 version: '3' services: gitlab: image: gitlab/gitlab-ce:12.9.7-ce.0 container_name: gitlab restart: always privileged: true environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url = \"http://git.local.com\" ports: - '80:80' - '443:443' - '2222:22' volumes: - '/dataDisk/gitlab/config:/etc/gitlab' - '/dataDisk/gitlab/logs:/var/log/gitlab' - '/dataDisk/gitlab/data:/var/opt/gitlab' networks: - gitlab networks: gitlab: ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"数据备份 # 备份产生目录 /var/opt/gitlab/backups/ gitlab-rake gitlab:backup:create # 容器备份 sudo docker exec -t gitlab gitlab-rake gitlab:backup:create ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"迁移 ### 配置文件说明 # 原本： /etc/gitlab/gitlab.rb # 容器： /data/gitlab/config/gitlab.rb # 授权备份文件 scp 1586766848_2020_04_13_10.3.3_gitlab_backup.tar root@10.0.0.2:/var/opt/gitlab/backups/ chown 777 /var/opt/gitlab/backups/1586766848_2020_04_13_10.3.3_gitlab_backup.tar # 加载备份路径 默认 /var/opt/gitlab/backups vim /data/gitlab/config/gitlab.rb gitlab_rails['backup_path'] = \"/var/opt/gitlab/backups\" gitlab_rails['backup_archive_permissions'] = 0644 gitlab_rails['backup_keep_time'] = 864000 # 重载配置 docker exec -t gitlab gitlab-ctl reconfigure # 停止数据库进程 docker exec -t gitlab gitlab-ctl status docker exec -t gitlab gitlab-ctl stop puma docker exec -t gitlab gitlab-ctl stop sidekiq docker exec -t gitlab gitlab-ctl status # 恢复备份文件 （输入两次yes） docker exec -ti gitlab bash docker exec -t gitlab gitlab-rake gitlab:backup:restore BACKUP=1586766848_2020_04_13_10.3.3 gitlab-backup restore BACKUP=11493107454_2018_04_25_10.6.4-ce # 重启与检测 docker exec -t gitlab gitlab-ctl restart docker exec -t gitlab gitlab-rake gitlab:check SANITIZE=true ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"可能出现的问题： 公钥不受信任，要么按提示需要输入yes，要么把config也进行迁移 ssh -T git@local.com ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:3","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"Dev terraform provider 基于新框架tpf开发 main.go func main() { var debug bool flag.BoolVar(\u0026debug, \"debug\", false, \"debug terraform provider\") flag.Parse() opts := providerserver.ServeOpts{ Address: \"hashicorp.com/edu/hashicups\", Debug: debug, } err := providerserver.Serve(context.Background(), provider.New(version), opts) if err != nil { log.Fatal(err.Error()) } } provider.go package provider import ( \"context\" \"github.com/hashicorp/terraform-plugin-framework/datasource\" \"github.com/hashicorp/terraform-plugin-framework/provider\" \"github.com/hashicorp/terraform-plugin-framework/provider/schema\" \"github.com/hashicorp/terraform-plugin-framework/resource\" ) var ( _ provider.Provider = \u0026hashicupsProvider{} ) func New(version string) func() provider.Provider { return func() provider.Provider { return \u0026hashicupsProvider{ version: version, } } } type hashicupsProvider struct { version string } // Metadata returns the provider type name. func (p *hashicupsProvider) Metadata(_ context.Context, _ provider.MetadataRequest, resp *provider.MetadataResponse) { resp.TypeName = \"hashicups\" resp.Version = p.version } // Schema defines the provider-level schema for configuration data. func (p *hashicupsProvider) Schema(_ context.Context, _ provider.SchemaRequest, resp *provider.SchemaResponse) { resp.Schema = schema.Schema{} } // Configure prepares a HashiCups API client for data sources and resources. func (p *hashicupsProvider) Configure(ctx context.Context, req provider.ConfigureRequest, resp *provider.ConfigureResponse) { } // DataSources defines the data sources implemented in the provider. func (p *hashicupsProvider) DataSources(_ context.Context) []func() datasource.DataSource { return nil } // Resources defines the resources implemented in the provider. func (p *hashicupsProvider) Resources(_ context.Context) []func() resource.Resource { return nil } data_source.go package provider import ( \"context\" \"github.com/hashicorp/terraform-plugin-framework/datasource\" \"github.com/hashicorp/terraform-plugin-framework/datasource/schema\" ) // Ensure the implementation satisfies the expected interfaces. var ( _ datasource.DataSource = \u0026coffeesDataSource{} ) // NewCoffeesDataSource is a helper function to simplify the provider implementation. func NewCoffeesDataSource() datasource.DataSource { return \u0026coffeesDataSource{} } // coffeesDataSource is the data source implementation. type coffeesDataSource struct{} // Metadata returns the data source type name. func (d *coffeesDataSource) Metadata(_ context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) { resp.TypeName = req.ProviderTypeName + \"_coffees\" } // Schema defines the schema for the data source. func (d *coffeesDataSource) Schema(_ context.Context, _ datasource.SchemaRequest, resp *datasource.SchemaResponse) { resp.Schema = schema.Schema{} } // Read refreshes the Terraform state with the latest data. func (d *coffeesDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) { } ","date":"2023-12-04","objectID":"/posts/2023-12-7-dev-terraform-provider/:0:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-7-dev-terraform-provider/"},{"categories":["Go基础"],"content":"通道 channel ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:0:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"介绍 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"概括 Go语言设计团队的首任负责人Rob Pike对并发编程的一个建议是不要让计算通过共享内存来通讯，而应该让它们通过通讯来共享内存。 通道机制就是这种哲学的一个设计结果。（在Go编程中，我们可以认为一个计算就是一个协程。） 通过共享内存来通讯和通过通讯来共享内存是并发编程中的两种编程风格。 当通过共享内存来通讯的时候，我们需要一些传统的并发同步技术（比如互斥锁）来避免数据竞争。 Go提供了一种独特的并发同步技术来实现通过通讯来共享内存。此技术即为通道。 我们可以把一个通道看作是在一个程序内部的一个先进先出（FIFO：first in first out）数据队列。 一些协程可以向此通道发送数据，另外一些协程可以从此通道接收数据。 随着一个数据值的传递（发送和接收），一些数据值的所有权从一个协程转移到了另一个协程。 当一个协程发送一个值到一个通道，我们可以认为此协程释放了（通过此发送值可以访问到的）一些值的所有权。 当一个协程从一个通道接收到一个值，我们可以认为此协程获取了（通过此接受值可以访问到的）一些值的所有权。 当然，在通过通道传递数据的时候，也可能没有任何所有权发生转移。 所有权发生转移的值常常被传递的值所引用着，但有时候也并非如此。 在Go中，数据所有权的转移并非体现在语法上，而是体现在逻辑上。 Go通道可以帮助程序员轻松地避免数据竞争，但不会防止程序员因为犯错而写出错误的并发代码的情况发生。 尽管Go也支持几种传统的数据同步技术，但是只有通道为一等公民。 通道是Go中的一种类型，所以我们可以无需引进任何代码包就可以使用通道。 几种传统的数据同步技术提供在sync和sync/atomic标准库包中。 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:1","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"通道类型和值 和数组、切片以及映射类型一样，每个通道类型也有一个元素类型。 一个通道只能传送它的（通道类型的）元素类型的值。 通道可以是双向的，也可以是单向的。 字面形式chan T表示一个元素类型为T的双向通道类型。 编译器允许从此类型的值中接收和向此类型的值中发送数据。 字面形式chan\u003c- T表示一个元素类型为T的单向发送通道类型。 编译器不允许从此类型的值中接收数据。 字面形式\u003c-chan T表示一个元素类型为T的单向接收通道类型。 编译器不允许向此类型的值中发送数据。 双向通道chan T的值可以被隐式转换为单向通道类型chan\u003c- T和\u003c-chan T，但反之不行（即使显式也不行）。 类型chan\u003c- T和\u003c-chan T的值也不能相互转换。 通道类型的零值也使用预声明的nil来表示。 一个非零通道值必须通过内置的make函数来创建。 比如make(chan int, 10)将创建一个元素类型为int的通道值。 第二个参数指定了欲创建的通道的容量。此第二个实参是可选的，它的默认值为0。 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:2","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"通道操作 // 定义一个 channel var ch = make(chan struct{}) // 关闭 channel close(ch) // 传入数据 ch \u003c- struct{}{} // 接受数据 \u003c-ch msg \u003c-ch // 查询 channel容量 cap(ch) // 查询 channel 长度 len(ch) ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:3","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"操作 channel channel有三类： 零值（nil）通道； 非零值但已关闭的通道； 非零值并且尚未关闭的通道。 下表简单地描述了三种通道操作施加到三类通道的结果。 操作 一个零值nil通道 一个非零值但已关闭的通道 一个非零值且尚未关闭的通道 关闭 产生恐慌 产生恐慌 成功关闭(C) 发送数据 永久阻塞 产生恐慌 阻塞或者成功发送(B) 接收数据 永久阻塞 永不阻塞(D) 阻塞或者成功接收(A) 对于上表中的五种未打上标的情形，规则很简单： 关闭一个nil通道或者一个已经关闭的通道将产生一个恐慌。 向一个已关闭的通道发送数据也将导致一个恐慌。 向一个nil通道发送数据或者从一个nil通道接收数据将使当前协程永久阻塞。 示例： package main import ( \"fmt\" \"time\" ) func main() { c := make(chan int) // 一个非缓冲通道 go func(ch chan\u003c- int, x int) { time.Sleep(time.Second) // \u003c-ch // 此操作编译不通过 ch \u003c- x*x // 阻塞在此，直到发送的值被接收 }(c, 3) done := make(chan struct{}) go func(ch \u003c-chan int) { n := \u003c-ch // 阻塞在此，直到有值发送到c fmt.Println(n) // 9 // ch \u003c- 123 // 此操作编译不通过 time.Sleep(time.Second) done \u003c- struct{}{} }(c) \u003c-done // 阻塞在此，直到有值发送到done fmt.Println(\"bye\") } 一场永不休场的足球比赛： package main import ( \"fmt\" \"time\" ) func main() { var ball = make(chan string) kickBall := func(playerName string) { for { fmt.Print(\u003c-ball, \"传球\", \"\\n\") time.Sleep(time.Second) ball \u003c- playerName } } go kickBall(\"张三\") go kickBall(\"李四\") go kickBall(\"王二麻子\") go kickBall(\"刘大\") ball \u003c- \"裁判\" // 开球 var c chan bool // 一个零值nil通道 \u003c-c // 永久阻塞在此 } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:4","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"通道遍历 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:2:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"for-range for-range循环控制流程也适用于通道。 此循环将不断地尝试从一个通道接收数据，直到此通道关闭并且它的缓冲队列为空为止。 和应用于数组/切片/映射的for-range语法不同，应用于通道的for-range语法中最多只能出现一个循环变量，此循环变量用来存储接收到的值。 for v := range aChannel { // 使用v } // 等价于 for { v, ok = \u003c-aChannel if !ok { break } // 使用v } for x := range c { time.Sleep(time.Second) fmt.Println(x) } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:2:1","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"select-case Go中有一个专门为通道设计的select-case分支流程控制语法。 此语法和switch-case分支流程控制语法很相似。 比如，select-case流程控制代码块中也可以有若干case分支和最多一个default分支。 但是，这两种流程控制也有很多不同点。在一个select-case流程控制中， select关键字和{之间不允许存在任何表达式和语句。 fallthrough语句不能被使用. 每个case关键字后必须跟随一个通道接收数据操作或者一个通道发送数据操作。 通道接收数据操作可以做为源值出现在一条简单赋值语句中。 以后，一个case关键字后跟随的通道操作将被称为一个case操作。 所有的非阻塞case操作中将有一个被随机选择执行（而不是按照从上到下的顺序），然后执行此操作对应的case分支代码块。 在所有的case操作均为阻塞的情况下，如果default分支存在，则default分支代码块将得到执行； 否则，当前协程将被推入所有阻塞操作中相关的通道的发送数据协程队列或者接收数据协程队列中，并进入阻塞状态。 按照上述规则，一个不含任何分支的select-case代码块select{}将使当前协程处于永久阻塞状态。 // default分支将铁定得到执行，因为两个case分支后的操作均为阻塞的。 package main import \"fmt\" func main() { var c chan struct{} // nil select { case \u003c-c: // 阻塞操作 case c \u003c- struct{}{}: // 阻塞操作 default: fmt.Println(\"Go here.\") } } 下面这个例子中实现了尝试发送（try-send）和尝试接收（try-receive）。 它们都是用含有一个case分支和一个default分支的select-case代码块来实现的。 package main import \"fmt\" func main() { c := make(chan string, 2) trySend := func(v string) { select { case c \u003c- v: default: // 如果c的缓冲已满，则执行默认分支。 } } tryReceive := func() string { select { case v := \u003c-c: return v default: return \"-\" // 如果c的缓冲为空，则执行默认分支。 } } trySend(\"Hello!\") // 发送成功 trySend(\"Hi!\") // 发送成功 trySend(\"Bye!\") // 发送失败，但不会阻塞。 // 下面这两行将接收成功。 fmt.Println(tryReceive()) // Hello! fmt.Println(tryReceive()) // Hi! // 下面这行将接收失败。 fmt.Println(tryReceive()) // - } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:2:2","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"使用示例： ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:3:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"使用通道实现通知 向一个通道发送一个值来实现单对单通知 package main import ( \"crypto/rand\" \"fmt\" \"os\" \"sort\" ) func main() { values := make([]byte, 32 * 1024 * 1024) if _, err := rand.Read(values); err != nil { fmt.Println(err) os.Exit(1) } done := make(chan struct{}) // 也可以是缓冲的 // 排序协程 go func() { sort.Slice(values, func(i, j int) bool { return values[i] \u003c values[j] }) done \u003c- struct{}{} // 通知排序已完成 }() // 并发地做一些其它事情... \u003c- done // 等待通知 fmt.Println(values[0], values[len(values)-1]) } 从一个通道接收一个值来实现单对单通 package main import ( \"fmt\" \"time\" ) func main() { done := make(chan struct{}) // 此信号通道也可以缓冲为1。如果这样，则在下面 // 这个协程创建之前，我们必须向其中写入一个值。 go func() { fmt.Print(\"Hello\") // 模拟一个工作负载。 time.Sleep(time.Second * 2) // 使用一个接收操作来通知主协程。 \u003c- done }() done \u003c- struct{}{} // 阻塞在此，等待通知 fmt.Println(\" world!\") } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:3:1","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"使当前协程永久阻塞 可以用一个无分支的select流程控制代码块使当前协程永久处于阻塞状态。 这是select流程控制的最简单的应用。 事实上，上面很多例子中的for {time.Sleep(time.Second)}都可以换为select{}。 package main import \"runtime\" func DoSomething() { for { // 做点什么... runtime.Gosched() // 防止本协程霸占CPU不放 } } func main() { go DoSomething() go DoSomething() select{} } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:3:2","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["DevOps"],"content":"Gorm gen 参考链接： https://nickxu.me/2023/03/29/GORM%E7%9A%84GEN%E6%A8%A1%E5%BC%8F%E5%88%9D%E4%B8%8A%E6%89%8B/ https://www.liwenzhou.com/posts/Go/gen/ 示例代码： https://github.com/serialt/genc Gen是一个基于GORM的安全ORM框架，其主要通过代码生成方式实现GORM代码封装。使用Gen框架能够自动生成Model结构体和类型安全的CRUD代码，极大提升CRUD效率。 ","date":"2023-11-28","objectID":"/posts/2023-11-28-gorm-gen/:0:0","tags":["gorm","gorm-gen"],"title":"Gorm gen","uri":"/posts/2023-11-28-gorm-gen/"},{"categories":["DevOps"],"content":"Gen介绍 Gen是由字节跳动无恒实验室与GORM作者联合研发的一个基于GORM的安全ORM框架，主要通过代码生成方式实现GORM代码封装。 Gen框架在GORM框架的基础上提供了以下能力： 基于原始SQL语句生成可重用的CRUD API 生成不使用interface{}的100%安全的DAO API 依据数据库生成遵循GORM约定的结构体Model 支持GORM的所有特性 简单来说，使用Gen框架后我们无需手动定义结构体Model，同时Gen框架也能帮我们生成类型安全的CRUD代码。 更多详细介绍请查看Gen官方文档。 此外，Facebook开源的ent也是社区中常用的类似框架，大家可按需选择使用。 ","date":"2023-11-28","objectID":"/posts/2023-11-28-gorm-gen/:1:0","tags":["gorm","gorm-gen"],"title":"Gorm gen","uri":"/posts/2023-11-28-gorm-gen/"},{"categories":["DevOps"],"content":"Gen 使用 go get grom.io/gen 在项目根目录新建 model文件夹，然后创建 model.go package model type Student struct { Id int Name string TeacherID int } type Teacher struct { Id int Name string // has many Student []Student } 然后使用go 生成代码 创建cmd/gen/generate.go package main import ( \"github.com/root/genc/model\" \"gorm.io/gen\" ) //// Dynamic SQL //type Querier interface { // // SELECT * FROM @@table WHERE name = @name{{if role !=\"\"}} AND role = @role{{end}} // FilterWithNameAndRole(name, role string) ([]gen.T, error) //} func main() { g := gen.NewGenerator(gen.Config{ OutPath: \"../../query\", Mode: gen.WithoutContext | gen.WithDefaultQuery | gen.WithQueryInterface, // generate mode }) // gormdb, _ := gorm.Open(mysql.Open(\"root:@(127.0.0.1:3306)/demo?charset=utf8mb4\u0026parseTime=True\u0026loc=Local\")) //g.UseDB(gormdb) // reuse your gorm db // Generate basic type-safe DAO API for struct `model.User` following conventions g.ApplyBasic(model.Student{}, model.Teacher{}) // Generate Type Safe API with Dynamic SQL defined on Querier interface for `model.User` and `model.Company` //g.ApplyInterface(func(Querier) {}, model.User{}, model.Company{}) // Generate the code g.Execute() } 运行命令 go run cmd/gen/generate.go [root@Sugar genc]🐳 go run cmd/gen/generate.go 2023/11/28 01:10:21 Start generating code. 2023/11/28 01:10:21 generate query file: /Users/root/github/genc/query/students.gen.go 2023/11/28 01:10:21 generate query file: /Users/root/github/genc/query/teachers.gen.go 2023/11/28 01:10:21 generate query file: /Users/root/github/genc/query/gen.go 2023/11/28 01:10:21 Generate code done. server main文件 cmd/sugar/sugar.go package main import ( \"fmt\" \"github.com/glebarez/sqlite\" \"github.com/root/genc/model\" \"github.com/root/genc/query\" \"gorm.io/gorm\" \"gorm.io/gorm/schema\" ) func main() { // dsn := \"root:12345678@tcp(127.0.0.1:3306)/gorm_learning?charset=utf8mb4\u0026parseTime=True\u0026loc=Local\" db, err := gorm.Open(sqlite.Open(\"test.db\"), \u0026gorm.Config{ DisableForeignKeyConstraintWhenMigrating: true, NamingStrategy: schema.NamingStrategy{ SingularTable: true, // 设置创建表名时不使用复数 }, }) if err != nil { panic(err) } err = db.AutoMigrate(\u0026model.Student{}, \u0026model.Teacher{}) if err != nil { panic(err) } query.SetDefault(db) // 增 student1 := model.Student{Name: \"student1\"} student2 := model.Student{Name: \"student2\"} student3 := model.Student{Name: \"student3\"} _ = query.Student.Create(\u0026student1, \u0026student2, \u0026student3) teacher1 := model.Teacher{Name: \"teacher1\"} _ = query.Teacher.Create(\u0026teacher1) // 删 _, _ = query.Student.Where(query.Student.Id.Eq(3)).Delete() // 改 _, _ = query.Student.Where(query.Student.Id.Eq(2)).Update(query.Student.Name, \"student2_new\") // 查 student, _ := query.Student.Where(query.Student.Id.Eq(1)).Take() teacher, _ := query.Teacher.Where(query.Teacher.Id.Eq(1)).Take() fmt.Println(student) // {1 student1 0} fmt.Println(teacher) // {1 teacher1 []} // 关联 _ = query.Teacher.Student.Model(\u0026teacher1).Append(\u0026student1, \u0026student2) teacher, _ = query.Teacher.Preload(query.Teacher.Student).Where(query.Teacher.Id.Eq(1)).Take() fmt.Println(teacher) // {1 teacher1 [{1 student1 1} {2 student2_new 1}]} fmt.Println(query.Student.TableName()) fmt.Println(query.Teacher.TableName()) } 运行主服务 [root@Sugar genc]🐳 go run cmd/sugar/main.go \u0026{1 student1 1} \u0026{1 teacher1 []} \u0026{1 teacher1 [{1 student1 1} {2 student2_new 1}]} student teacher 更新字段使用对比 GLOBAL_DB.Model(\u0026Student{}).Where(\"ID = ?\", 2).Update(\"Name\", \"student2_new\") query.Student.Where(query.Student.Id.Eq(2)).Update(query.Student.Name, \"student2_new\") ","date":"2023-11-28","objectID":"/posts/2023-11-28-gorm-gen/:2:0","tags":["gorm","gorm-gen"],"title":"Gorm gen","uri":"/posts/2023-11-28-gorm-gen/"},{"categories":["DevOps"],"content":"Shell handbok ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:0:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"一、特殊符号 参考链接: https://blog.csdn.net/jiezi2016/article/details/79649382 https://blog.csdn.net/wangzhaotongalex/article/details/73321766 介绍下Shell中的${}、##和%%使用范例，本文给出了不同情况下得到的结果。 假设定义了一个变量为： 代码如下: file=/dir1/dir2/dir3/my.file.txt 可以用${ }分别替换得到不同的值： ${file#*/}：删掉第一个 / 及其左边的字符串：dir1/dir2/dir3/my.file.txt ${file##*/}：删掉最后一个 / 及其左边的字符串：my.file.txt ${file#*.}：删掉第一个 . 及其左边的字符串：file.txt ${file##*.}：删掉最后一个 . 及其左边的字符串：txt ${file%/*}：删掉最后一个 / 及其右边的字符串：/dir1/dir2/dir3 ${file%%/*}：删掉第一个 / 及其右边的字符串：(空值) ${file%.*}：删掉最后一个 . 及其右边的字符串：/dir1/dir2/dir3/my.file ${file%%.*}：删掉第一个 . 及其右边的字符串：/dir1/dir2/dir3/my 记忆的方法为： # 是 去掉左边（键盘上#在 $ 的左边） %是去掉右边（键盘上% 在$ 的右边） 单一符号是最小匹配；两个符号是最大匹配 ${file:0:5}：提取最左边的 5 个字节：/dir1 ${file:5:5}：提取第 5 个字节右边的连续5个字节：/dir2 也可以对变量值里的字符串作替换： ${file/dir/path}：将第一个dir 替换为path：/path1/dir2/dir3/my.file.txt ${file//dir/path}：将全部dir 替换为 path：/path1/path2/path3/my.file.txt $*与$@ $*和$@都表示传递给函数或脚本的所有参数，不被双引号“”包含时，都以$1 $2 …$n的形式输出所有参数。 当它们被双引号“”包含时，“$*”会将所有的参数作为一个整体，以“$1 $2 …$n”的形式输出所有参数；“$@”会将各个参数分开，以“$1” “$2”…”$n”的形式输出所有参数。 ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:1:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"二、重定向与变量 cat \u003e\u003etest.txt \u003c\u003c EOF 1、安装kvm 2、卸载kvm 3、安装python EOF $0 shell脚本的名字 $n 第n个参数 $# 获取参数的个数 $* 所有参数 $@ 所有参数 两者区别： \"$*\"会把所有位置参数当成一个整体（或者说当成一个单词），如果没有位置参数，则\"$*\"为空，如果有两个位置参数并且IFS为空格时，\"$*\"相当于\"$1 $2\" \"$@\" 会把所有位置参数当成一个单独的字段，如果没有位置参数（$#为0），则\"$@\"展开为空（不是空字符串，而是空列表），如果存在一个位置参数，则\"$@\"相当于\"$1\"，如果有两个参数，则\"$@\"相当于\"$1\" \"$2\"等等 $? 用于记录上一条命令的执行状态 0---255 0：执行成功 $$ 获取当前执行Shell脚本的进程号（PID） $! 获取上一个在后台工作的进程的进程号 $_ 获取在此之前执行的命令或脚本的最后一个参数 特殊扩展变量 可以man bash 命令，然后搜索\"Parameter Expansion\"来查找相关的内容帮助 ${parameter:-word} 如果parameter的变量值为空或没赋值，则返回word字符串并代替变量的值（变量没定义，返回备用的值，防止变量为空或没定义报错） ${parameter:=word} 如果parameter的变量值为空或没赋值，。。。同上，（变量没定义为防止出错，找的备胎变量） ${parameter:?word} 如果parameter的变量值为空或者没赋值，word字符串就作为标准错误输出，否则出书变量的值（捕捉由于变量未定义导致的错误，并退出） ${parameter:+word} 若果parameter的变量值为空或者未赋值，则什么都不做，否则word字符串将代替变量的值。 ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:2:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"三、判断 条件判断 -z 判断字符串是否为空串 -n 字符段长度是否非零的 如果结果为真值 返回值为0 如果结果为假值 -eq 等于 -gt 大于 -lt 小于 -ge 大于等于 -le 小于等于 -ne 不等于 根据文件类型判断 -d 文件存在且必须是目录 -e 文件存在，不判断文件类型 -f 文件存在且是标准普通文件 -h 文件存在且是软连接，同 -L -r 文件存在且可读 -w 文件存在且可写 -x 文件存在且可执行 -s 文件存在且至少有一个字符 双目表达式 单目表达式， 所有的单目表达式都可以使用!表示取反 [ ! -f file_name ] if标准写法 if 条件; then 操作语句 操作语句 .... else 操作语句 操作语句 fi [ file1 -ef file2 ] 两个文件有相同的设备编号和inode编号 (判断硬链接) if [ 'a' != 'b'];then echo 'a' fi 以上可以简写为: [ 'a' != 'b' ] \u0026\u0026 echo 'a' case 语法 read -p \"Enter string: \" str_01 case $str_01 in linux|Linux) echo \"CentOS\" ;; windows|Windows) echo \"Microsoft\" ;; *) echo \"Other\" ;; esac for 循环 # 普通循环 sum=0 for i in `seq 100`; do let sum=$sum+$i done echo $sum # 类C写法 for ((i=1;i\u003c8;i++));do cmd1 done while循环 while 条件; do 操作语句 操作语句 存在一条可以改变条件真假的语句 done until循环 当条件为假时才循环 until 条件测试 ;do cmd1 done 数组与循环 # ca.crt /etc/openvpn/easy-rsa/pki # server.crt /etc/openvpn/easy-rsa/pki/issued # user.crt /etc/openvpn/easy-rsa/pki/issued # user.key /etc/openvpn/easy-rsa/pki/private # ca.key /etc/openvpn/easy-rsa/pki/private # ta.key /etc/openvpn/easy-rsa # 定义用户 accounts=( client2,用户2 client3,用户3 client4,用户4 ) OPENVPN_DIR=\"/etc/openvpn\" EASY_RSA_DIR=\"/etc/openvpn/easy-rsa\" # 分配好的证书 OVPN_DIR=\"/tmp/openvpn\" # 创建key # $1 用户证书名 create_key(){ [[ ! -f ${EASY_RSA_DIR}/easyrsa ]] \u0026\u0026 exit 55 cd ${EASY_RSA_DIR}/ \u0026\u0026 ./easyrsa build-client-full $1 nopass } # $1 用户名 create_ovpn(){ [[ ! -f ${OVPN_DIR} ]] \u0026\u0026 mkdir -p ${OVPN_DIR} cat \u003e ${OVPN_DIR}/$1.ovpn \u003c\u003c EOF client dev tun proto tcp remote vpn.local.com 50000 resolv-retry infinite nobind persist-key persist-tun remote-cert-tls server cipher AES-256-CBC comp-lzo verb 3 EOF } # $1 用户名 insert_file(){ ca=`cat ${EASY_RSA_DIR}/pki/ca.crt` user_crt=`cat ${EASY_RSA_DIR}/pki/issued/$1.crt` user_key=`cat ${EASY_RSA_DIR}/pki/private/$1.key` ta=`cat ${EASY_RSA_DIR}/ta.key` cat \u003e\u003e ${OVPN_DIR}/$1.ovpn \u003c\u003c EOF \u003cca\u003e ${ca} \u003c/ca\u003e \u003ccert\u003e ${user_crt} \u003c/cert\u003e \u003ckey\u003e ${user_key} \u003c/key\u003e key-direction 1 \u003ctls-auth\u003e ${ta} \u003c/tls-auth\u003e EOF } ## main for aobj in ${accounts[@]} do arr=(${aobj//,/ }) actName=${arr[0]} chineseName=${arr[1]} create_ovpn ${actName} create_key ${actName} insert_file ${actName} done ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:3:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"四、高级语法 可选参数 while getopts \"🅰️b:c:\" opt do case $opt in a) echo \"参数a的值$OPTARG\" ;; b) echo \"参数b的值$OPTARG\" ;; c) echo \"参数c的值$OPTARG\" ;; ?) echo \"未知参数\" exit 1;; esac done ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:4:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"sed d 删除符合条件的行 # sed '1,2d' /etc/inittab 删除文件中包含oot的行 # sed '/oot/d' /etc/fstab 删除第1行及其后2行 # sed '1,+2d' /etc/fstab 删除第1行 # sed '1d' /etc/fstab 删除以/开头的行 # sed '/^\\//d' /etc/fstab a \\string 在符合条件的行后追加新行，string为追加的内容 在以/开头的行后面追加# hello world # sed '/^\\//a \\# hello world' /etc/fstab 在以/开头的行后面追加两行内容，分别为# hello worl # hello linux # sed '/^\\//a \\# hello world\\n# hello linux' /etc/fstab i \\string 在符合条件的行前添加新行，string为追加的内容 在文件第1行添加# hello world # sed '1i \\# hello world' /etc/fstab c \\string 替换指定行的内容 将文件中最后一行内容替换为End Of File # sed '$c \\End Of File' /1.txt # sed '7c \\SELINUX=disabled' /etc/sysconfig/selinux ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:4:1","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"awk # awk -F: '/^r/{print $1}' /etc/passwd ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:4:2","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"switch-case语法 shell 语法 case 变量 in 取值1) 操作语句 操作语句 ;; 取值2) 操作语句 操作语句 ;; 取值3) 操作语句 操作语句 ;; *) 操作语句 操作语句 ;; esac # example read -p \"Enter string: \" str_01 case $str_01 in linux|Linux) echo \"CentOS\" ;; windows|Windows) echo \"Microsoft\" ;; *) echo \"Other\" ;; esac go func testSwitch3() { switch n := 7; n { case 1, 3, 5, 7, 9: fmt.Println(\"奇数\") case 2, 4, 6, 8: fmt.Println(\"偶数\") default: fmt.Println(n) } } func switchDemo1() { finger := 3 switch finger { case 1: fmt.Println(\"大拇指\") case 4: fmt.Println(\"无名指\") case 5: fmt.Println(\"小拇指\") default: fmt.Println(\"无效的输入！\") } } python 3.10及以后 match term: case pattern-1: action-1 case pattern-2: action-2 case pattern-3: action-3 case _: action-default lang = input(\"What's the programming language you want to learn? \") match lang: case \"Python\": print(\"You can become a Data Scientist\") case \"go\": print(\"You can become a Blockchain developer\") case \"Java\": print(\"You can become a mobile app developer\") case _: print(\"The language doesn't matter, what matters is solving problems.\") ","date":"2023-11-24","objectID":"/posts/2023-11-24-switch-case/:0:0","tags":["switch","case","switch-case"],"title":"switch-case handbook","uri":"/posts/2023-11-24-switch-case/"},{"categories":["DevOps"],"content":"Ansible Module 参考链接：https://ansible.leops.cn/dev/modules/ 1、自定义模块开发 该模块的目的是在远程主机上将远程源文件复制到远程目标文件 #!/usr/bin/python # -*- coding: utf-8 -*- # Copyright: (c) 2020, lework # GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt) ANSIBLE_METADATA = {'metadata_version': '1.0', 'status': ['preview'], 'supported_by': 'community'} DOCUMENTATION = ''' --- module: remote_copy short_description: Copy a file on the remote host version_added: \"2.9\" description: - The remote_copy module copies a file on the remote host from a given source to a provided destination. options: source: description: - Path to a file on the source file on the remote host required: true dest: description: - Path to the destination on the remote host for the copy required: true author: - \"Lework\" ''' EXAMPLES = ''' # Example from Ansible Playbooks - name: backup a config file remote_copy: source: /tmp/foo dest: /tmp/bar ''' RETURN = ''' source: description: Path to a file on the source file on the remote host type: str returned: success sample: \"/path/to/file.name\" dest: description: Path to the destination on the remote host for the copy type: string returned: success sample: \"/path/to/destination.file\" ''' import os import shutil from ansible.module_utils.basic import AnsibleModule def main(): module_args = dict( source=dict(required=True, type='str'), dest=dict(required=True, type='str') ) result = dict( changed=False, source='', dest='' ) module = AnsibleModule( argument_spec=module_args, supports_check_mode=True ) if module.check_mode: module.exit_json(**result) if not os.path.isfile(module.params['source']): module.fail_json(msg='The '+ module.params['source'] +' file was not found', **result) try: shutil.copy(module.params['source'], module.params['dest']) except Exception as e: module.fail_json(msg=e, **result) result['source'] = module.params['source'] result['dest'] = module.params['dest'] if os.path.isfile(module.params['dest']): result['changed'] = True remote_facts = {'rc_source': module.params['source'], 'rc_dest': module.params['dest'] } result['ansible_facts'] = remote_facts module.exit_json(**result) if __name__ == '__main__': main() ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-ansible-module/:0:0","tags":["python-ansible","ansible-module"],"title":"Python ansible module","uri":"/posts/2023-11-22-python-ansible-module/"},{"categories":["DevOps"],"content":"Python 基础 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:0:0","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"一、基础语法 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:0","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"1、输出语句的使用 1）引号的使用 \u003e\u003e\u003e print ('hello world') hello world \u003e\u003e\u003e print (\"hello world\") hello world \u003e\u003e\u003e 2）三引号: 输出多行内容 \u003e\u003e\u003e print (\"\"\"abc ... cdc ... ddd ... ccc ... fff\"\"\") abc cdc ddd ccc fff 注释符：# python2与python3的区别 print语法不同，python3需要加() python2默认使用的字符集ASCII码, # encoding: utf8。python3默认使用的字符集Unicode 2）输出变量 username = \"root\" password = \"redhat\" print(username) print(\"my name is \", username, \"my password is\", password) print(\"my name is \" + username + \"my password is \" + password) #只适用于字符串 3）格式化输出 \u003e\u003e\u003e username = \"root\" \u003e\u003e\u003e password = \"redhat\" \u003e\u003e\u003e print(\"my name is %s\" % username ) my name is root \u003e\u003e\u003e print(\"my name is '%s'\" % username) my name is 'root' \u003e\u003e\u003e print(\"my name is %s, my password is %s\" % (username, password)) my name is root, my password is redhat 常用的格式化字符 %s 字符串 通用 %d 数字，整数 number_01 = 123 number_02 = \"456\" number_03 = 3.9415 print(\"It is %d\" % number_01) print(\"It is %d\" % number_03) %f 浮点数，小数 number_01 = 123 number_02 = 3.948915 number_03 = 3.9489151111111111 print(\"It is %f\" % number_01) print(\"It is %f\" % number_02) print(\"It is %f\" % number_03) print(\"It is %.2f\" % number_02) %% 输出%本身 number = 50 # This is 50% print(\"This is %d%%\" % number) username = \"root\" password = \"redhat\" sql_01 = \"select * from tb01 where username='%s' and password='%s'\" % (username, password) print(sql_01) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:1","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"2、变量定义 变量名称规范： 字母、数字、下划线_ 只能以字母、下划线_开头 不能与python关键字冲突。（print if for while else ） #交互式变量赋值 username = input(\"输入用户名： \") #注意： #返回的结果是字符串 print(\"用户名： %s\" % username) 删除变量 name = \"Martin\" print(name) del name print(name) python变量与其他语言不同之处 弱类型 地址引用类型 number_01 = 10 number_02 = 10 print(id(number_01)) print(id(number_02)) number_01 = 100 number_02 = number_01 print(id(number_01)) print(id(number_02)) 内置函数 id() 返回变量的内存地址 type() 返回变量的类型 内存使用机制 每个变量定义后，会在内存中开辟一段空间，这段空间对应存在一个引用计数器，变量被调用一次，引用计数器会自动增加；当python解释器检测到一段内存的引用计数器为0后，会自动清理该内存 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:2","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"3、变量的类型 数字 字符串 列表 元组 字典 集合 Bytes ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:3","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"4、运算 #数学运算符 \u003e\u003e\u003e a = 10 \u003e\u003e\u003e b = 4 \u003e\u003e\u003e a + b 14 \u003e\u003e\u003e a - b 6 \u003e\u003e\u003e a * b 40 \u003e\u003e\u003e a ** b 10000 \u003e\u003e\u003e \u003e\u003e\u003e a / b 2.5 \u003e\u003e\u003e a // b 2 \u003e\u003e\u003e a % b 2 \u003e\u003e\u003e a = 10 \u003e\u003e\u003e a = a + 1 \u003e\u003e\u003e a 11 \u003e\u003e\u003e a += 1 \u003e\u003e\u003e a 12 \u003e\u003e\u003e #比较运算符 ==, !=, \u003e, \u003e=, \u003c=, \u003c 逻辑运算符 and, or, not \u003e\u003e\u003e a = 10 \u003e\u003e\u003e \u003e\u003e\u003e \u003e\u003e\u003e a \u003e 20 and 1 \u003c 2 False \u003e\u003e\u003e \u003e\u003e\u003e a \u003e 20 or 1 \u003c 2 True \u003e\u003e\u003e \u003e\u003e\u003e not a \u003e 20 True \u003e\u003e\u003e 数制转换 \u003e\u003e\u003e a = 10 \u003e\u003e\u003e bin(a) '0b1010' \u003e\u003e\u003e oct(a) '0o12' \u003e\u003e\u003e hex(a) '0xa' \u003e\u003e\u003e #生成随机数的模块 \u003e\u003e\u003e import random \u003e\u003e\u003e random.randint(0, 10) 7 \u003e\u003e\u003e random.randint(0, 10) 9 \u003e\u003e\u003e random.randint(0, 10) 2 \u003e\u003e\u003e random.randint(0, 10) 3 \u003e\u003e\u003e random.randint(0, 10) 6 示例：四则运算 number_01 = int(input(\"输入第1个数字： \")) number_02 = int(input(\"输入第2个数字： \")) print(\"%s + %s = %s\" % (number_01, number_02, number_01 + number_02)) print(\"%s - %s = %s\" % (number_01, number_02, number_01 - number_02)) print(\"%s * %s = %s\" % (number_01, number_02, number_01 * number_02)) print(\"%s / %s = %s\" % (number_01, number_02, number_01 / number_02)) print(\"%s // %s = %s\" % (number_01, number_02, number_01 // number_02)) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:4","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"5、逻辑控制语句 同级代码要有相同缩进，默认4个空格 条件判断 — if if 条件: 操作语句 操作语句 if 1 \u003c 2: print(\"AAA\") print(\"BBB\") # 只要数字不等于0，条件为真 number = 10 if number: print(\"AAA\") print(\"BBB\") number = 10 if not number: print(\"AAA\") print(\"BBB\") # True, False 首字母全是大写 if True: print(\"AAA\") if …. else number = 100 if number \u003c 20: print(\"AAAA\") else: print(\"BBBB\") if … elif … elif …. else number = int(input(\"Enter number: \")) if number \u003e 10: print(\"AAA\") elif number \u003e 30: print(\"BBBB\") elif number \u003e 40: print(\"CCCC\") else: print(\"DDDD\") 嵌套if age = int(input(\"输入你的年龄： \")) if age \u003c= 18: gender = input(\"输入你的性别： \") if gender == \"M\": print(\"准备入队\") else: print(\"睡吧\") else: print(\"回家洗洗睡吧\") 循环 for while for循环： for 变量 in 取值: 操作语句 操作语句 for i in range(5): print(\"第%s次循环开始\" % i) print(\"第%s次循环结束\" % i) print(\"-----------------\") 中断循环： #break 中断整体循环 for i in range(5): print(\"第%s次循环开始\" % i) if i == 3: break print(\"第%s次循环结束\" % i) print(\"-----------------\") continue 中断本次循环 for i in range(5): print(\"第%s次循环开始\" % i) if i == 3: continue print(\"第%s次循环结束\" % i) print(\"-----------------\") 示例：斐波那契数列 length=int(input(\"input length:\")) i=0 j=1 tmp=1 for n in range(length): print( tmp,\" \",end=) tmp = i + j i = j j = tmp print() while循环 while 条件: 操作语句 操作语句 i = 1 while i \u003c= 4: print(\"第%s次循环开始\" % i) print(\"第%s次循环结束\" % i) print(\"-----------------\") i += 1 while True: 操作语句 操作语句 示例： 实现数制转换 import sys number = int(input(\"输入数字： \")) menu = \"\"\" 1、二进制 2、八进制 3、十六进制 4、退出 输入你的选择：d \"\"\" ''' 循环判断用户的选择，根据不同的选择做不同的响应 ''' while True: choice = int(input(menu)) if choice == 1: print(\"数字%s的二进制形式：%s\" % (number, bin(number))) elif choice == 2: print(\"数字%s的八进制形式：%s\" % (number, oct(number))) elif choice == 3: print(\"数字%s的十六进制形式：%s\" % (number, hex(number))) else: print(\"谢谢\") sys.exit() pass: 占位符 #!/usr/bin/python import time for i in range(5): print i if i == 1: pass ---- 代码桩 if之间不能空代码可以用pass占位 if i == 2: continue if i == 3: break print \"#\"*10 else: print \"END\" for j in range(2): print \"---\u003e\",j [root@server python]# python dic.py 0 ########## 1 ########## 2 3 ---\u003e 0 ---\u003e 1 结束执行 [root@server python]# cat dic.py #!/usr/bin/python for i in range(10): print i if i == 5: exit() [root@server python]# python dic.py 0 1 2 3 4 5 switch语句 switch语句用于编写多分支结构的程序,类似与if… elif… else语句 switch语句表达的分支结构比if… elif… else语句表达的更清晰,代码可读性更高，但是python并没有提供switch语句 python可以通过字典实现switch语句的功能 实现方法分为两步 首先：定义一个字典，其次,调用字典的get()获取相应的表达式xxxxxxxxxx [root@www python]# cat test.py #!/usr/bin/bash #coding:utf8 from __future__ import division def jia(x,y): return x+y def jian(x,y): return x-y def cheng(x,y): return x*y def chu(x,y): return x/y def operator(x,o,y): if o == \"+\": print jia(x,y) elif o == \"-\": print jian(x,y) elif o == \"*\": print cheng(x,y) elif o == \"/\": print chu(x,y) else: pass operator(2,\"/\",4) #!/usr/bin/bash #coding:utf8 from __future__ import division def jia(x,y): return x+y def jian(x,y): return x-y def cheng(x,y): return x*y def chu(x,y): return x/y operator = {\"+\":jia,\"-\":jian,\"*\":cheng,\"/\":chu} print operator [\"/\"](3,2) 示例： 写一个卖水果的菜单(有菜单),再将他转换为switch格式 menu=\"\"\" 1、apple 2、banala 3、orange \"\"\" fuirt={1:['apple',5],2:['banala',3],3:['orange',7]} print(fuirt[1]) while True: print(menu) tmp=int(input(\"请输入要查询价格的水果:\")) print(\"%s的价格是 %s 元/斤\"%(fuirt[tmp][0],fuirt[tmp][1])) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:5","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"六、函数 1、格式 未定义返回值 \u003e\u003e\u003e def fun(): ... print (\"a\") \u003e\u003e\u003e var=fun() a \u003e\u003e\u003e print (var) None 定义返回值 \u003e\u003e\u003e def fun(): ... return \"ok\" ... ... \u003e\u003e\u003e var=fun() \u003e\u003e\u003e print (var) ok 2、默认值 #!/usr/bin/python # -*- coding: UTF-8 -*- #可写函数说明 def printinfo( name, age = 35 ): \"打印任何传入的字符串\" print \"Name: \", name print \"Age \", age return #调用printinfo函数 printinfo( age=50, name=\"miki\" ) printinfo( name=\"miki\" ) 3、不定长参数 #!/usr/bin/python # -*- coding: UTF-8 -*- # 可写函数说明 def printinfo( arg1, *vartuple ): \"打印任何传入的参数\" print \"输出: \" print arg1 for var in vartuple: print var return # 调用printinfo 函数 printinfo( 10 ) printinfo( 70, 60, 50 ) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:6","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"七、模块 搜索路径是一个解释器会先进行搜索的所有目录的列表。如想要导入模块 support.py，需要把命令放在脚本的顶端： # support.py def print_func( par ): print \"Hello : \", par return # test.py #!/usr/bin/python # -*- coding: UTF-8 -*- # 导入模块 import support # 现在可以调用模块里包含的函数了 support.print_func(\"sugar\") Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下： ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:7","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"八、面向对象 定义类与实例化 class Ren: name = \"人\" def run(self): print(\"跑步\") cmd = Ren() print(cmd) 私有属性与方法 在属性或者方法前加__的，即表示该方法和属性为私有类外不可调用 #!/usr/bin/python # -*- coding: UTF-8 -*- class Employee: '所有员工的基类' empCount = 0 def __init__(self, name, salary): self.name = name self.salary = salary Employee.empCount += 1 def displayCount(self): print \"Total Employee %d\" % Employee.empCount def displayEmployee(self): print \"Name : \", self.name, \", Salary: \", self.salary 类的继承 #!/usr/bin/python # -*- coding: UTF-8 -*- class Parent: # 定义父类 parentAttr = 100 def __init__(self): print \"调用父类构造函数\" def parentMethod(self): print '调用父类方法' def setAttr(self, attr): Parent.parentAttr = attr def getAttr(self): print \"父类属性 :\", Parent.parentAttr class Child(Parent): # 定义子类 def __init__(self): print \"调用子类构造方法\" def childMethod(self): print '调用子类方法' c = Child() # 实例化子类 c.childMethod() # 调用子类的方法 c.parentMethod() # 调用父类方法 c.setAttr(200) # 再次调用父类的方法 - 设置属性值 c.getAttr() # 再次调用父类的方法 - 获取属性值 方法重写 #!/usr/bin/python # -*- coding: UTF-8 -*- class Parent: # 定义父类 def myMethod(self): print '调用父类方法' class Child(Parent): # 定义子类 def myMethod(self): print '调用子类方法' c = Child() # 子类实例 c.myMethod() # 子类调用重写方法 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:8","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"Terraform handbook 参考链接：https://blog.gmem.cc/terraform ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:0:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"一、简介 Terraform用于实现基础设施即代码（infrastructure as code）—— 通过代码（配置文件）来描述基础设施的拓扑结构，并确保云上资源和此结构完全对应。Terraform有三个版本，我们主要关注Terraform CLI。 Terraform CLI主要包含以下组件： 命令行前端 Terraform Language（以下简称TL，衍生自HashiCorp配置语言HCL）编写的、描述基础设施拓扑结构的配置文件。配置文件的组织方式是模块。本文使用术语“配置”（Configuration）来表示一整套描述基础设施的Terraform配置文件 针对各种云服务商的驱动（Provider），实现云资源的创建、更新和删除 云上资源不单单包括基础的IaaS资源，还可以是DNS条目、SaaS资源。事实上，通过开发Provider，你可以用Terraform管理任何资源。 Terraform会检查配置文件，并生成执行计划。计划描述了那些资源需要被创建、修改或删除，以及这些资源之间的依赖关系。Terraform会尽可能并行的对资源进行变更。当你更新了配置文件后，Terraform会生成增量的执行计划。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:1:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"二、命令行 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"1、安装命令行 直接到https://www.terraform.io/downloads.html下载，存放到$PATH下即可。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:1","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"2、基本特性 1）切换工作目录 使用选项 -chdir=DIR 2）Shell自动补全 使用 terraform -install-autocomplete安装自动完成脚本，使用 terraform -uninstall-autocomplete删除自动完成脚本。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:2","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"3、资源地址 很多子命令接受资源地址参数，下面是一些例子： # 资源类型.资源名 aws_instance.foo # 资源类型.资源列表名[索引] aws_instance.bar[1] # 子模块foo的子模块bar中的 module.foo.module.bar.aws_instance.baz ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:3","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"4、配置文件 配置文件的路径可以通过环境变量 TF_CLI_CONFIG_FILE设置。非Windows系统中， $HOME/.terraformrc为默认配置文件路径。配置文件语法类似于TF文件： # provider缓存目录 plugin_cache_dir = \"$HOME/.terraform.d/plugin-cache\" # disable_checkpoint = true # 存放凭证信息，包括模块仓库、支持远程操作的系统的凭证 credentials \"app.terraform.io\" { token = \"xxxxxx.atlasv1.zzzzzzzzzzzzz\" } # 改变默认安装逻辑 provider_installation { # 为example.com提供本地文件系统镜像，这样安装example.com/*/*的provider时就不会去网络上请求 # 默认路径是： # ~/.terraform.d/plugins/${host_name}/${namespace}/${type}/${version}/${target} # 例如： # ~/.terraform.d/plugins/hashicorp.com/edu/hashicups/0.3.1/linux_amd64/terraform-provider-hashicups_v0.3.1 filesystem_mirror { path = \"/usr/share/terraform/providers\" include = [\"example.com/*/*\"] } direct { exclude = [\"example.com/*/*\"] } # Terraform会在terraform init的时候，校验Provider的版本和checksum。Provider从Registry或者本地 # 目录下载Provider。当我们开发Provider的时候，常常需要方便的测试临时Provider版本，这种Provider还 # 没有关联版本号，也没有在Registry中注册Chencksum # 为了简化开发，可以配置dev_overrides，它能覆盖所有配置的安装方法 dev_overrides { \"hashicorp.com/edu/hashicups-pf\" = \"$(go env GOBIN)\" } } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:4","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"5、init 配置工作目录，为使用其它命令做好准备。 Terraform命令需要在一个编写了Terraform配置文件的目录（配置根目录）下执行，它会在此目录下存储设置、缓存插件/模块，以及（默认使用Local后端时）存储状态数据。此目录必须进行初始化。 初始化后，会生成以下额外目录/文件： .terraform目录，用于缓存provider和模块 如果使用Local后端，保存状态的terraform.tfstate文件。如果使用多工作区，则是terraform.tfstate.d目录。 对配置的某些变更，需要重新运行初始化，包括provider需求的变更、模块源/版本约束的变更、后端配置的变更。需要重新初始化时，其它命令可能会无法执行并提示你进行初始化。 命令 terraform get可以仅仅下载依赖的模块，而不执行其它init子任务。 运行 terraform init -upgrade会强制拉取最新的、匹配约束的版本并更新依赖锁文件。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:5","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"6、validate 校验配置是否合法。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:6","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"7、plan 显示执行计划，即当前配置将请求（结合state）哪些变更。Terraform的核心功能时创建、修改、删除基础设施对象，使基础设施的状态和当前配置匹配。当我们说运行Terraform时，主要是指plan/apply/destroy这几个命令。 terraform plan命令评估当前配置，确定其声明的所有资源的期望状态。然后比较此期望状态和真实基础设施的当前状态。它使用state来确定哪些真实基础设施对象和声明资源的对应关系，并且使用provider的API查询每个资源的当前状态。当确定到达期望状态需要执行哪些变更后，Terraform将其打印到控制台，它并不会执行任何实际的变更操作。 计划模式 plan命令支持两种备选的工作模式： 销毁模式：创建一个计划，其目标是销毁所有当前存在于配置中的远程对象，留下一个空白的state。对应选项 -destroy 仅刷新模式：创建一个计划，其目标仅仅是更新state和根模块的输出值，以便和从Terraform之外对基础设施对象的变更匹配。对应选项 -refresh-only 指定输入变量 使用选项 -var ‘NAME=VALUE’可以指定输入变量，该选项可以使用多次。 使用选项 -var-file=FILENAME可以从文件读取输入变量，某些文件会自动读取 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:7","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"8、apply 应用执行计划，创建、更新设施对象。 apply会做plan的任何事情，并在其基础上，直接执行变更操作。默认情况下，apply即席的执行一次plan，你也可以直接使用已保存的plan 命令格式： terraform apply [options] [plan file] 自动确认 选项 -auto-approve可以自动确认并执行所需操作，不需要人工确认。 使用已有计划 如果指定plan file参数，则读取先前保存的计划并执行。 计划模式 支持plan命令中关于计划模式的选项。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:8","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"三、TF语言 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"1、块 配置文件由若干块（Block）组成，块的语法如下： # Block header, which identifies a block \u003cBLOCK TYPE\u003e \"\u003cBLOCK LABEL\u003e\" \"\u003cBLOCK LABEL\u003e\" \"...\" { # Block body \u003cIDENTIFIER\u003e = \u003cEXPRESSION\u003e # Argument } 块是一个容器，它的作用取决于块的类型。块常常用来描述某个资源的配置。 取决于块的类型，标签的数量可以是0-N个。对于resource块，标签数量为两个。某些特殊的块，可能支持任意数量的标签。某些内嵌的块，例如network_interface，则不支持标签。 块体中可以包含若干参数（Argument），或者其它内嵌的块。参数用于将一个表达式分配到一个标识符，常常对应某个资源的一条属性。表达式可以是字面值，或者引用其它的值，正是这种引用让Terraform能够识别资源依赖关系。 直接位于配置文件最外层的块，叫做顶级块（Top-level Block），Terraform支持有限种类的顶级块。大部分Terraform特性，例如resource，基于顶级块实现。 下面是一个例子： resource \"aws_vpc\" \"main\" { cidr_block = var.base_cidr_block } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:1","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"2、数据类型 类型 说明 string Unicode字符序列，基本形式 “hello” number 数字，形式 6.02 bool true或 false list/tuple 一系列的值，形式 [“us-west-1a”, “us-west-1c”] map/object 键值对，形式 {name = “Mabel”, age = 52} ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:2","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"3、空值 空值使用 null表示。 4、字符串和模板 转义字符 \\n 换行 \\r 回车 \\t 制表 \\\" 引号 \\\\ 反斜杠 \\uNNNN Unicode字符 \\UNNNNNNNN Unicode字符 注意，在Heredoc中反斜杠不用于转义，可以使用： $${ 字符串插值标记${ %%{ 模板指令标记%{ 支持unix风格的字符串 block { value = \u003c\u003cEOT hello world EOT } block { value = \u003c\u003c-EOT hello world EOT } 要将对象转换为JSON或YAML，可以调用函数： example = jsonencode({ a = 1 b = \"hello\" }) ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:3","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"5、操作符 逻辑操作符： ! \u0026\u0026 || 算数操作符： * / % + - 比较操作符： \u003e, \u003e=, \u003c, \u003c= ==, != 条件表达式 condition ? true_val : false_val var.a != \"\" ? var.a : \"default-a\" for表达式 使用for表达式可以通过转换一种复杂类型输出，生成另一个复杂类型结果。输入中的每个元素，可以对应结果的0-1个元素。任何表达式可以用于转换，下面是使用upper函数将列表转换为大写： [for s in var.list : upper(s)] 输入类型 作为for表达式的输入的类型可以是list / set / tuple / map / object。可以为for声明两个临时符号，前一个表示index或key： [for k, v in var.map : length(k) + length(v)] 结果类型 结果的类型取决于包围for表达式的定界符： [] 表示生成的结果是元组 {} 表示生成的结果是object，你必须使用 =\u003e符号： {for s in var.list : s =\u003e upper(s)} 输入过滤 包含一个可选的if子句可以对输入元素进行过滤： [for s in var.list : upper(s) if s != \"\"] 示例： variable \"users\" { type = map(object({ is_admin = boolean })) } locals { admin_users = { for name, user in var.users : name =\u003e user if user.is_admin } } splat表达式 splat表达式提供了更简单语法，在某些情况下代替for表达式： [for o in var.list : o.id] # 等价于 var.list[*].id [for o in var.list : o.interfaces[0].name] # 等价于 var.list[*].interfaces[0].name 可选object属性 variable \"with_optional_attribute\" { type = object({ a = string # 必须属性 b = optional(string) # 可选属性 }) } 版本约束 版本约束是一个特殊的字符串值，在引用module、使用provider时，或者通过terraform块的required_version时，需要用到版本约束： # 版本范围区间 version = \"\u003e= 1.2.0, \u003c 2.0.0\" # 操作符 = 等价于无操作符，限定特定版本 != 排除特定版本 \u003e \u003e= \u003c \u003c= 限制版本范围 ~\u003e 允许最右侧的版本号片段的变化 depends_on 该元参数用于处理隐含的资源/模块依赖，这些依赖无法通过分析Terraform配置文件得到。从0.13版本开始，该元参数可用于模块。之前的版本仅仅用于资源。 depends_on的值是一个列表，其元素具必须是其它资源的引用，不支持任意表达式。 depends_on应当仅仅用作最后手段，避免滥用。 resource \"aws_iam_role\" \"example\" { name = \"example\" assume_role_policy = \"...\" } # 这个策略允许运行在EC2中的实例访问S3 API resource \"aws_iam_role_policy\" \"example\" { name = \"example\" role = aws_iam_role.example.name policy = jsonencode({ \"Statement\" = [{ \"Action\" = \"s3:*\", \"Effect\" = \"Allow\", }], }) } resource \"aws_iam_instance_profile\" \"example\" { # 这是可以自动分析出的依赖 role = aws_iam_role.example.name } resource \"aws_instance\" \"example\" { ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" # 这是可以自动分析出的依赖，包括传递性依赖 iam_instance_profile = aws_iam_instance_profile.example # 如果这个实例中的程序需要访问S3接口，我们需要用元参数显式的声明依赖 # 从而分配策略 depends_on = [ aws_iam_role_policy.example, ] } count 默认情况下，一个resource块代表单个云上基础设施对象。如果你想用一个resource块生成多个类似的资源，可以用count或for_each参数。 设置了此元参数的上下文中，可以访问名为 count的变量，它具有属性 index，为从0开始计数的资源实例索引。 示例： resource \"aws_instance\" \"server\" { # 创建4个类似的实例 count = 4 ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" tags = { # 实例的索引作为tag的一部分 Name = \"Server ${count.index}\" } } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:4","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"for_each 如果资源的规格几乎完全一致，可以用count，否则，需要使用更加灵活的for_each元参数。 for_each的值必须是一个映射或set(string)，你可以在上下文中访问 each对象， 它具有 key和 value两个属性，如果for_each的值是集合，则key和value相等。示例： resource \"azurerm_resource_group\" \"rg\" { for_each = { a_group = \"eastus\" another_group = \"westus2\" } # 对于每个键值对都会生成azurerm_resource_group资源 name = each.key location = each.value } resource \"aws_iam_user\" \"the-accounts\" { # 数组转换为集合 for_each = toset( [\"Todd\", \"James\", \"Alice\", \"Dottie\"] ) name = each.key } variable \"vpcs\" { # 这里定义了map类型的变量，并且限定了map具有的键 type = map(object({ cidr_block = string })) } # 创建多个VPC资源 resource \"aws_vpc\" \"example\" { for_each = var.vpcs cidr_block = each.value.cidr_block } # 上述资源作为下面那个for_each的值 # 创建对应数量的网关资源 resource \"aws_internet_gateway\" \"example\" { # 为每个VPC创建一个网关 # 资源作为值 for_each = aws_vpc.example # 映射的值，在这里是完整的VPC对象 vpc_id = each.value.id } # 输出所有VPC ID output \"vpc_ids\" { value = { for k, v in aws_vpc.example : k =\u003e v.id } # 显式依赖网关资源，确保网关创建后，输出才可用 depends_on = [aws_internet_gateway.example] } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:5","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"Timezone 参考链接： https://bbs.huaweicloud.com/blogs/detail/243151 http://www.timeofdate.com/timezone/abbr/all ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:0:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"一、设置时区 timedatectl set-timezone Asia/Shanghai ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:1:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"二、时区详细 ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"1、概念 ​ 在以前全球国家都处于农业社会的时候，人们通过每天观察太阳的位置来决定时间，这就使得不同经度的地方有不同的时间。当时人们旅行主要靠走和马匹，不同地方时间不一致的问题没有那么突出。但是到了十九世纪随着火车的发明，人们一天旅行的距离一下子延长了很多，到不同的地方因此迫切需要一个通用的方法把各个地方的时间统一起来。1853年8月12日，美国东部罗德岛州，两辆火车迎头相撞，14人因此死亡。事故的原因在今天看来难以置信——两车工程师的手表差了2分钟。 1863年，首次使用时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。 1870年代加拿大铁路工程师弗莱明首次提出全世界按统一标准划分时区。 1883年11月18日，美国铁路部门正式实施五个时区。 1884年华盛顿子午线国际会议正式通过采纳这种时区划分，称为世界标准时制度。因此，世界标准时区的诞生同其它全球标准一样也是有一个缓慢的发展过程。 ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:1","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"2、通用名词解释 时区 ：时区是地球上的区域使用同一个时间定义。以前，人们通过观察太阳的位置（时角）决定时间，这就使得不同经度的地方的时间有所不同（地方时）。1863年，首次使用时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。世界各个国家位于地球不同位置上，因此不同国家，特别是东西跨度大的国家日出、日落时间必定有所偏差。这些偏差就是所谓的时差。 格林尼治标准时间： GMT（Greenwich Mean Time）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义为在那里通过的经线。由于地球在它的椭圆轨道里的运动速度不均匀，地球每天的自转是有些不规则的，而且正在缓慢减速。所以，格林尼治时间已经不再被作为标准时间使用。 世界协调时间 ：UTC（Coordinated Universal Time）是经过平均太阳时(以格林威治时间GMT为准)、地轴运动修正后的新时标以及以「秒」为单位的国际原子时所综合精算而成的时间。UTC比GMT来得更加精准。对于现行表款来说，GMT与UTC的功能与精确度是没有差别的。 夏日节约时间 ：DST（Daylight Saving Time）又称日光节约时制，在英国称为夏令时间(Summer Time)。是一种为节约能源而人为规定地方时间的制度，在这一制度实行期间所采用的统一时间称为“夏令时间”。一般在天亮较早的夏季人为将时间调快一小时，可以使人早起早睡，减少照明量，以充分利用光照资源，从而节约照明用电。各个采纳夏时制的国家规定不同。 时区表示法 如果时间是以协调世界时（UTC）表示，则在时间后面直接加上一个“Z”（不加空格）。“Z”是协调世界时中0时区的标志。因此，“09:30 UTC”就写作“09:30Z”或是“0930Z”。“14:45:15 UTC”则为“14:45:15Z”或“144515Z”。UTC时间也被叫做祖鲁时间，因为在北约音标字母中用“Zulu”表示“Z”。 UTC偏移量 ：UTC偏移量是协调世界时（UTC）和特定地点的日期与时间差异，其单位为小时和分钟。它通常以 ±[hh]:[mm]、±[hh][mm]、或 ±[hh]的格式显示。所以，如果被描述的时间比UTC早一小时（例如柏林的冬季时间），UTC的偏移量将是”+01:00”、”+0100”、或简单显示为”+01”。 ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:2","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"3、linux时区存储位置 为了避免因国家或地区问题，一般时区设置是以城市为标准 [root@sugar2 Asia]# pwd /usr/share/zoneinfo/Asia [root@sugar2 Asia]# ls Aden Baku Colombo Ho_Chi_Minh Kashgar Magadan Pyongyang Singapore Ujung_Pandang Almaty Bangkok Dacca Hong_Kong Kathmandu Makassar Qatar Srednekolymsk Ulaanbaatar Amman Barnaul Damascus Hovd Katmandu Manila Qostanay Taipei Ulan_Bator Anadyr Beirut Dhaka Irkutsk Khandyga Muscat Qyzylorda Tashkent Urumqi Aqtau Bishkek Dili Istanbul Kolkata Nicosia Rangoon Tbilisi Ust-Nera Aqtobe Brunei Dubai Jakarta Krasnoyarsk Novokuznetsk Riyadh Tehran Vientiane Ashgabat Calcutta Dushanbe Jayapura Kuala_Lumpur Novosibirsk Saigon Tel_Aviv Vladivostok Ashkhabad Chita Famagusta Jerusalem Kuching Omsk Sakhalin Thimbu Yakutsk Atyrau Choibalsan Gaza Kabul Kuwait Oral Samarkand Thimphu Yangon Baghdad Chongqing Harbin Kamchatka Macao Phnom_Penh Seoul Tokyo Yekaterinburg Bahrain Chungking Hebron Karachi Macau Pontianak Shanghai Tomsk Yerevan ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:3","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"三、时区简写 UTC GMT SGT 新加坡时间 Singapore（CST时间有多个地区相同的名字） HKT 香港时间 Hongkong Asia/Hong_Kong ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:3:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["Other"],"content":"电脑一键恢复： Dell： F12 –\u003e Supportassist OS Recovery MSI：F3 Huawei: F10 Mac: 长按电源键直到Option出现（m系列mac） ","date":"2023-11-20","objectID":"/posts/2023-11-20-pc/:0:0","tags":["recovery","pc"],"title":"Recovery","uri":"/posts/2023-11-20-pc/"},{"categories":["Other"],"content":"ventoy ","date":"2023-11-20","objectID":"/posts/2023-11-20-pc/:1:0","tags":["recovery","pc"],"title":"Recovery","uri":"/posts/2023-11-20-pc/"},{"categories":["Other"],"content":"1、使用说明 ventoy下载链接： 官方：https://www.ventoy.net/cn/download.html 国内镜像：https://mirror.nju.edu.cn/github-release/ventoy/Ventoy/ 下载解压后执行Ventoy2Disk https://www.ventoy.net/cn/doc_secure.html ","date":"2023-11-20","objectID":"/posts/2023-11-20-pc/:1:1","tags":["recovery","pc"],"title":"Recovery","uri":"/posts/2023-11-20-pc/"},{"categories":["DevOps"],"content":"Git使用规范 一、commit \u003ctype\u003e(scope): \u003csubject\u003e Header \u003cBLANK LINE\u003e \u003cbody\u003e Body \u003cBALNK LINE\u003e \u003cfooter\u003e Footer commit message包含Header、Body、Footer三个部分，其中Header是必须的 Header 用于说明commit的类型 feat：新功能 fix：BUG修复 docs：对文档或说明的改变 revert：revert之前的commit ","date":"2023-11-19","objectID":"/posts/2023-11-19-git-to-use/:0:0","tags":["git-branch","branch","dev"],"title":"Git-to-use","uri":"/posts/2023-11-19-git-to-use/"},{"categories":["DevOps"],"content":"二、分支命名规范 master：长期分支，与生产环境发布的代码保持同步，每个commit就是一个发布版本 develop：长期分支，用于汇总各分支代码 release-*：短期分支，每个版本的测试阶段和发布阶段时使用的分支 hotfix-*：短期分支，用于生产环境发生问题时，用来解决问题而拉取的分支，进行修改bug feature-*：短期分支，用于开发新功能 格式为： release-6.5.0 hotfix-6.5.0 feature-6.5.0 feature-somesymbol ","date":"2023-11-19","objectID":"/posts/2023-11-19-git-to-use/:0:1","tags":["git-branch","branch","dev"],"title":"Git-to-use","uri":"/posts/2023-11-19-git-to-use/"},{"categories":["DevOps"],"content":"三、保护分支 1、master和develop为保护分支（protect branch）只有管理员有权操作。 master分支的每一个commit对应一个tag（发布的版本） 2、release-*分支时在develop合并feature分支后，拉出的新分支，release分支一定是要从develop拉出的新分支，用户测试以及pre上线，期间产生的bug都在release分支上提交，在pre上测试通过后再发布生产环境，然后再将release分支合并到develop和master分支，并在master上新建tag 3、hotfix分支是生产环境发生问题，从master的commit或tag中拉出的分支，经过测试和发布后分别合到develop和master分支。 ","date":"2023-11-19","objectID":"/posts/2023-11-19-git-to-use/:0:2","tags":["git-branch","branch","dev"],"title":"Git-to-use","uri":"/posts/2023-11-19-git-to-use/"},{"categories":["DevOps"],"content":"SVN ","date":"2023-11-18","objectID":"/posts/2023-11-18-svn/:1:0","tags":["svn","vcs","dev"],"title":"svn","uri":"/posts/2023-11-18-svn/"},{"categories":["DevOps"],"content":"介绍： 代码版本管理工具 能记住本版修改的情况 查看所有的修改记录 恢复到任何历史版本 恢复已经删除的文件 svn与git相比的优势: 使用简单、上手快 目录权限控制，企业安全必备 子目录checkout，减少不必要的文件检出 缺点： svc是集中到版本库控制，需要依赖于中央版本控制服务，git是分布式的，可以独立工作 主要应用: 开发人员代码版本管理 重要文件的存储 关系内部文件共享 windows客户端：TortoiseSVN ","date":"2023-11-18","objectID":"/posts/2023-11-18-svn/:1:1","tags":["svn","vcs","dev"],"title":"svn","uri":"/posts/2023-11-18-svn/"},{"categories":["DevOps"],"content":"安装 基于centos7 1、安装svn [root@localhost ~]# yum -y install svn 2、创建svn版本库 创建版本库目录 [root@localhost /]# mkdir -p /svn/repos [root@localhost /]# svnadmin create /svn/repos 3、配置svn [root@localhost repos]# ll total 8 drwxr-xr-x 2 root root 54 Jun 13 21:47 conf drwxr-sr-x 6 root root 233 Jun 13 21:47 db -r--r--r-- 1 root root 2 Jun 13 21:47 format drwxr-xr-x 2 root root 231 Jun 13 21:47 hooks drwxr-xr-x 2 root root 41 Jun 13 21:47 locks -rw-r--r-- 1 root root 229 Jun 13 21:47 README.txt 1）conf目录 [root@localhost conf]# ll total 12 -rw-r--r-- 1 root root 1080 Jun 13 21:47 authz -rw-r--r-- 1 root root 309 Jun 13 21:47 passwd -rw-r--r-- 1 root root 3090 Jun 13 21:47 svnserve.conf authz：负责账号权限的管理，控制账号是否读写权限 passwd：负责账号和密码的用户名单管理 svnserve.conf：svn服务器配置文件 2）authz配置文件 [root@localhost conf]# vim authz [repos:/] # / 表示根目录 ，既/svn/repos cccc = rw # rw表示seialt用户拥有读写权限 abc = rw # 组设置 [groups] # harry_and_sally = harry,sally # harry_sally_and_joe = harry,sally,\u0026joe iso = zhang,wang test = li # [/foo/bar] # harry = rw # \u0026joe = r # * = [repos:/iso] jk = rw [repos:/data] @iso = rw # [repository:/baz/fuz] # @harry_and_sally = rw # * = r [repos:/] cccc = rw abc = rw 3）passwd文件 [root@localhost conf]# vim passwd [users] # harry = harryssecret # sally = sallyssecret cccc = 123456 abc = 123 4）svnserve.conf文件 [root@localhost conf]# vim svnserve.conf [root@localhost conf]# vim svnserve.conf 19 anon-access = none 20 auth-access = write 27 password-db = passwd 34 authz-db = authz 39 realm = cccc anon-access = none：表示禁止匿名用户访问。 auth-access = write：表示授权用户拥有读写权限。 password-db = passswd：指定用户名口令文件，即 passwd 文件。 authz-db = authz：指定权限配置文件，即 authz 文件。 realm = cccc：指定认证域，即/svn/repos目录。 4、启动svn [root@localhost conf]# svnserve -d -r /svn [root@localhost conf]# ps -ef | grep svn root 10923 1 0 22:49 ? 00:00:00 svnserve -d -r /repo root 10925 1396 0 22:49 pts/0 00:00:00 grep --color=auto svn [root@localhost conf]# ss -anpl | grep svn tcp LISTEN 0 7 *:3690 *:* users:((\"svnserve\",pid=10923,fd=3)) [root@localhost conf]# 5、连接 [root@localhost conf]# svn co svn://127.0.0.1/repos Authentication realm: \u003csvn://127.0.0.1:3690\u003e /repos Password for 'root': Authentication realm: \u003csvn://127.0.0.1:3690\u003e /repos Username: cccc Password for 'cccc': ----------------------------------------------------------------------- ATTENTION! Your password for authentication realm: \u003csvn://127.0.0.1:3690\u003e /repos can only be stored to disk unencrypted! You are advised to configure your system so that Subversion can store passwords encrypted, if possible. See the documentation for details. You can avoid future appearances of this warning by setting the value of the 'store-plaintext-passwords' option to either 'yes' or 'no' in '/root/.subversion/servers'. ----------------------------------------------------------------------- Store password unencrypted (yes/no)? yes Checked out revision 0. [root@localhost conf]# 6、使用sasldb加密密码文件 说明：Linux下使用svnserve的SASL认证能解决这个问题，subversion1.5以上的版本默认装了sasl认证，解决svnserve密码文件passwd是明文的问题，生成一个sasl认证的密码文件sasldb。 1）修改conf/svnserve.conf文件 [sasl] use-sasl = true min-encryption = 128 max-encryption = 256 注释：# password-db = passwd这行保持注释掉的状态，不使用passwd文件。变量 min-encryption 和 max-encryption 控制服务器所需要的加密强度。要完全禁用加密，就将这 2 个变量的值都设为 0。要启用简单的数据校验(例如，为了防止篡改和保证数据的完整，不加密)，就将这 2 个值都设为 1。如果你想允许(但不强制)加密，将最小值设为 0，最大值设为任意位数。要强制加密，将这 2 个值设为大于 1 的数字。在前面的例子中，我们要求客户端至少进行 128 位加密，但是不大于 256 位加密。 2）新建svn.conf文件 一般放在/usr/Lib/sasl2或者/etc/sasl2，内容如下 pwcheck_method: auxprop auxprop_plugin: sasldb sasldb_path: /svn/repo/cccc/sasldb mech_list: DIGEST-MD5 注释：pwcheck_method指明检查的方法，这里是“auxprop ”，这个pwcheck_method还对应了如启动一个代理作为认证服务等方式，而现在的意思就是使用本文件说的方式去检查。然后我们指明auxprop_plugin为sasldb，也就是使用一个文件存放用户名密码，也就是/home/svn/svnjiami/sasldb,其它的认证信息存放plugin还有sql和ldapdb。而mech_list指明了认证信息传递机制。 3）重启svn 如果 svnserve 已经在运行，你需要重启服务，并确保它读取了更新后的配置参数 killall svnserve //停止svnserve服务 svnserve –d –r /svn/repos //启动svnserve服务 4）创建加密后的用户和密码 saslpasswd2 -c -f /svn/repo/cccc/sasldb -u cccc cccc # –u [svnserve.conf里面配置的realm名字] [username] -p \u003cpw //新建用户，可修改用户用","date":"2023-11-18","objectID":"/posts/2023-11-18-svn/:1:2","tags":["svn","vcs","dev"],"title":"svn","uri":"/posts/2023-11-18-svn/"},{"categories":["DevOps"],"content":"Git ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:0:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"一、git基本使用 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、commit [root@node01 project]# git add 1.txt [root@node01 project]# git commit -m \"create new 1.txt\" [master (root-commit) 3e8ce87] create new 1.txt 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 1.txt ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"2、diff文件 [root@node01 project]# git diff 1.txt diff --git a/1.txt b/1.txt index e69de29..21d56a0 100644 --- a/1.txt +++ b/1.txt @@ -0,0 +1 @@ +1111111111111111 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:2","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"3、版本回退 在进行版本回退时，使用HEAD代表当前版本，HEAD^ 代表上一个版本，HEAD^^代表上上个版本，还可以使用HEAD~10代表前10个版本 [root@node01 project]# git reset --hard HEAD^ HEAD is now at fdf9d68 add new 1111 [root@node01 project]# [root@node01 project]# cat 1.txt 1111111111111111 [root@node01 project]# 也可以使用如下命令格式: [root@node01 project] git reset --hard \u003ccommit_id\u003e [root@node01 project]# git reflog 1.txt fdf9d68 HEAD@{0}: reset: moving to HEAD^ 996cc77 HEAD@{1}: commit: add new 222 fdf9d68 HEAD@{2}: commit: add new 1111 3e8ce87 HEAD@{3}: commit (initial): create new 1.txt [root@node01 project]# [root@node01 project]# git reset --hard 996cc77 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:3","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"4、撤销更改 1）对于尚未添加到暂存区的修改，可直接通过编辑原文件或者使用git checkout -- \u003cfile\u003e的方式进行撤销 [root@node01 project]# git checkout -- 1.txt [root@node01 project]# git status # On branch master nothing to commit, working directory clean 2）对于已经添加到暂存区，但还没有git commit的修改，可使用git reset HEAD \u003cfile\u003e的方式撤销 [root@node01 project]# vim 1.txt [root@node01 project]# git add 1.txt [root@node01 project]# git status # On branch master # Changes to be committed: # (use \"git reset HEAD \u003cfile\u003e...\" to unstage) # # modified: 1.txt # [root@node01 project]# git reset HEAD 1.txt Unstaged changes after reset: M 1.txt [root@node01 project]# git status # On branch master # Changes not staged for commit: # (use \"git add \u003cfile\u003e...\" to update what will be committed) # (use \"git checkout -- \u003cfile\u003e...\" to discard changes in working directory) # # modified: 1.txt # no changes added to commit (use \"git add\" and/or \"git commit -a\") [root@node01 project]# git checkout -- 1.txt [root@node01 project]# git status # On branch master nothing to commit, working directory clean [root@node01 project]# cat 1.txt 1111111111111111 22222222222222222 3333333333333 3）对于已经添加到暂存区，并已经提交的修改可通过git reset –hard \u003ccommit_id\u003e的方式进行撤销 [root@node01 project]# vim 1.txt [root@node01 project]# git add 1.txt [root@node01 project]# git commit -m \"add new 44444444\" [master 240af53] add new 44444444 1 file changed, 1 insertion(+) [root@node01 project]# git reflog 1.txt 240af53 HEAD@{0}: commit: add new 44444444 5424335 HEAD@{1}: commit: add new 333333 996cc77 HEAD@{2}: reset: moving to 996cc77 3e8ce87 HEAD@{3}: reset: moving to 3e8ce87 996cc77 HEAD@{4}: reset: moving to 996cc77 fdf9d68 HEAD@{5}: reset: moving to HEAD^ 996cc77 HEAD@{6}: commit: add new 222 fdf9d68 HEAD@{7}: commit: add new 1111 3e8ce87 HEAD@{8}: commit (initial): create new 1.txt [root@node01 project]# [root@node01 project]# [root@node01 project]# git reset --hard 5424335 HEAD is now at 5424335 add new 333333 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:4","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"二、git配置 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、配置基本信息 [root@localhost srv]# git config --global user.name 'sugar' [root@localhost srv]# git config --global user.email 't@local.com' [root@localhost srv]# git config --global color.ui true #配置显示的颜色，方便看到更改的信息 [root@localhost srv]# git config --global core.ignorecase false # 配置大小写敏感，git默认大小写不敏感 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"2、gitconfig配置文件 [user] name = sugar email = t@local.com # signingkey = DCE96Cxxxxxxxxxxxxxxxxxxxxxxxx #[commit] # gpgsign = true # ~/github/ 目录下的项目使用~/github/.gitconfig下的gitconfig配置文件 [includeIf \"gitdir:~/github/\"] path = ~/github/.gitconfig [includeIf \"gitdir:~/my-prod/\"] path = ~/my-prod/.gitconfig [init] defaultBranch = main [color] ui = true [alias] lg = log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u003c%an\u003e%Creset' --abbrev-commit [alias] # status st = status ss = status --short --branch # stash sh = stash shp = stash pop shl = stash list shs = stash save sha = stash apply std = stash drop # branch br = branch bra = branch -a brm = branch -m co = checkout cob = checkout -b sw = switch swc = switch -c # remote ra = remote add rao = remote add origin ru = remote set-url ruo = remote set-url origin rv = remote -v # fetch fe = fetch fep = fetch -p fo = fetch origin fop = fetch origin -p # merge mr = merge mnc = merge --no-commit # msq = merge --squash # commit cm = commit -m # config user and mail user = config user.name mail = config user.email [url \"git@github.com:username\"] insteadOf = https://github.com/username # 强制https转ssh协议 [url \"ssh://git@local.com/\"] insteadOf = https://local.com/ [core] excludesfile = ~/.gitignore_global autocrlf = input quotepath = false ignorecase = false editor = vim # sshCommand = ssh -i ~/.ssh/id_rsa -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no [i18n \"commit\"] encoding = utf-8 [i18n] logoutputencoding = utf-8 [http \"https://github.com\"] proxy = socks5://127.0.0.1:8888 [http] proxy = http://127.0.0.1:8889 [https] proxy = http://127.0.0.1:8889 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:2","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"3、windows上终端打开出现乱码 cmd配置 git config --global core.quotepath false git config --global gui.encoding utf-8 git config --global i18n.commit.encoding utf-8 git config --global i18n.logoutputencoding utf-8 # bash 环境下 export LESSCHARSET=utf-8 # cmd环境下： set LESSCHARSET=utf-8 powershell配置 git config --global core.quotepath false git config --global gui.encoding utf-8 git config --global i18n.commit.encoding utf-8 git config --global i18n.logoutputencoding utf-8 $env:LESSCHARSET='utf-8' git bash sugar@sugar MINGW64 /e/Desktop/company/github (master) $ cat /etc/bash.bashrc alias ls='ls -F --color --show-control-chars' NOW_DIR=\"E:\\Desktop\" cd ${NOW_DIR} export LESSCHARSET=utf-8 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:3","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"三、分支管理 git版本库所有的操作都是运行在分支上，git仓库创建时会建立默认的分支，名称为master；所有的操作都在master分支上进行 在对版本库中的文件进行操作时，可以创建不同的分支，不同的操作运行在不同的分支上，不同分支上的操作不会相互干扰，操作进行完成后，可以合并不同分支上的操作 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:3:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、创建分支 [root@node01 project]# git checkout -b game Switched to a new branch 'game' [root@node01 project]# [root@node01 project]# git branch dev * game master 1）远程chekout到本地 [root@node01 project]# git checkout origin/develop -b develop 2）删除分支 # 删除本地分支 [root@node01 project]# git branch -d release-1.1.0 # 强制删除 [root@node01 project]# git branch -D release-1.1.0 # 删除远程分支 [root@node01 project]# git push origin --delete release-1.1.0 或者 [root@node01 project]# git push origin :release-1.1.0 3）根据hash值进行checkout git checkout d21a8c517ca3xxxxxxxxxxxxxxxxxxxxxxxxxxx 4）分支合并 切换到准备合并后的分支，合并其他分支到当前分支 [root@node01 project]# git merge dev Updating bb6fb7a..d83dae8 Fast-forward 1.txt | 2 ++ 1 file changed, 2 insertions(+) ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:3:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"四、tag管理 打标签，用于仓库某个提交打上标签，以表示其特殊性。比较有代表性的是人们会使用这个功能来标记发布结点（ v1.0 、 v2.0 等等） 1、查看本地已有标签 [root@localhost github_web]# git tag 4.101.0 4.103.0 4.103.1 列出所有标签 -l或者--list，指定某些提交信息-l \"v4.4*\" 2、创建tag Git 支持两种标签： 轻量标签（lightweight） 附注标签（annotated）。 轻量标签很像一个不会改变的分支——它只是某个特定提交的引用。 而附注标签是存储在 Git 数据库中的一个完整对象， 它们是可以被校验的，其中包含打标签者的名字、电子邮件地址、日期时间， 此外还有一个标签信息，并且可以使用 GNU Privacy Guard （GPG）签名并验证。 通常会建议创建附注标签，这样你可以拥有以上所有信息。但是如果你只是想用一个临时的标签， 或者因为某些原因不想要保存这些信息，那么也可以用轻量标签。 附属标签： git tag -a v1.4 -m \"my version 1.4\" 查看详细信息 git show v1.4 输出显示了打标签者的信息、打标签的日期时间、附注信息，然后显示具体的提交信息。 轻量标签: 另一种给提交打标签的方式是使用轻量标签。 轻量标签本质上是将提交校验和存储到一个文件中——没有保存任何其他信息。 创建轻量标签，不需要使用 -a、-s 或 -m 选项，只需要提供标签名字： $ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息： $ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u003ct@local.com\u003e Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number 后期打标签 git tag -a v1.2 9fceb02 共享标签 默认情况下，git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样——你可以运行 git push origin \u003ctagname\u003e。 $ git push origin v1.5 Counting objects: 14, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (14/14), 2.05 KiB | 0 bytes/s, done. Total 14 (delta 3), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.5 -\u003e v1.5 如果想要一次性推送很多标签，也可以使用带有 --tags 选项的 git push 命令。 这将会把所有不在远程仓库服务器上的标签全部传送到那里。 $ git push origin --tags Counting objects: 1, done. Writing objects: 100% (1/1), 160 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.4 -\u003e v1.4 * [new tag] v1.4-lw -\u003e v1.4-lw 3、删除标签 要删除掉你本地仓库上的标签，可以使用命令 git tag -d \u003ctagname\u003e。 例如，可以使用以下命令删除一个轻量标签： $ git tag -d v1.4-lw Deleted tag 'v1.4-lw' (was e7d5add) 注意上述命令并不会从任何远程仓库中移除这个标签，你必须用 git push \u003cremote\u003e :refs/tags/\u003ctagname\u003e 来更新你的远程仓库： 方法一：git push \u003cremote\u003e :refs/tags/\u003ctagname\u003e $ git push origin :refs/tags/v1.4-lw To /git@github.com:username/project.git - [deleted] v1.4-lw 上面这种操作的含义是，将冒号前面的空值推送到远程标签名，从而高效地删除它。 方法二：直接删除远程标签 $ git push origin --delete \u003ctagname\u003e 4、检出标签 检出标签为一个分支，格式为git checkout -b branch_name tag_name git checkout -b version2 v2.0.0 5、.git 目录 ├── HEAD ├── branches ├── config ├── description ├── hooks │ ├── pre-commit.sample │ ├── pre-push.sample │ └── ... ├── info │ └── exclude ├── objects │ ├── info │ └── pack └── refs ├── heads └── tags config （配置）该文件包含你的仓库配置，比如远程的 url ，你的邮箱和用户名等。每次你在控制台使用 git config… 都会对这里产生影响。 description（描述）供 gitweb ( github 的一种前身) 使用，显示仓库的描述。 hooks (钩子)这是一个有趣的特性。 Git 提供了一套脚本，可以在每个有意义的 Git 阶段自动运行。这些被称为钩子的脚本可以在提交 (commit)、变基 (rebase)、拉取 ( pull ) 操作的前后运行。脚本命预示着它的执行时机。如我们可以编写 pre-push 的作为钩子，进行推送代码前的检查。 info (信息)你可以将不想被 git 管理的文件记录到 .gitignore 文件中。排除文件的意思是不想共享这个文件。例如你不想共享你的 IDE 自定义配置，将其添加到 .gitignore 文件中即可。 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:4:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"五、cherry-pick 参考：https://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html 对于多分支的代码库，将代码从一个分支转移到另一个分支是常见需求。 这时分两种情况。一种情况是，你需要另一个分支的所有代码变动，那么就采用合并（git merge）。另一种情况是，你只需要部分代码变动（某几个提交），这时可以采用 Cherry pick。 1、基本语法 git cherry-pick命令的作用，就是将指定的提交（commit）应用于其他分支。 $ git cherry-pick \u003ccommitHash\u003e 上面命令就会将指定的提交commitHash，应用于当前分支。这会在当前分支产生一个新的提交，当然它们的哈希值会不一样。 举例来说，代码仓库有master和feature两个分支。 a - b - c - d Master \\ e - f - g Feature 现在将提交f应用到master分支。 # 切换到 master 分支 $ git checkout master # Cherry pick 操作 $ git cherry-pick f 上面的操作完成以后，代码库就变成了下面的样子。 a - b - c - d - f Master \\ e - f - g Feature 从上面可以看到，master分支的末尾增加了一个提交f。 git cherry-pick命令的参数，不一定是提交的哈希值，分支名也是可以的，表示转移该分支的最新提交。 $ git cherry-pick feature 上面代码表示将feature分支的最近一次提交，转移到当前分支。 操作示例： [sugar@centos-7 git-test]$ git log -1 commit dcf3a215fd6ba3288ad21584d2112bdab5a713b4 Author: sugar \u003ccccc@gmail.com\u003e Date: Sun Sep 12 14:29:26 2021 +0800 feat: v1 version 1s add [sugar@centos-7 git-test]$ git checkout master Switched to branch 'master' [sugar@centos-7 git-test]$ git log commit 31da420cc2d2ae6094f88e368a72f0353541d89f Author: sugar \u003ccccc@gmail.com\u003e Date: Sun Sep 12 14:25:43 2021 +0800 feat: 第一此增加 [sugar@centos-7 git-test]$ git cherry-pick dcf3a215fd6ba3288ad21584d2112bdab5a713b4 [master fa78bb0] feat: v1 version 1s add 1 file changed, 2 insertions(+), 1 deletion(-) [sugar@centos-7 git-test]$ ls cccc.txt [sugar@centos-7 git-test]$ git log -1 commit fa78bb090d3221ba2ff9cae59efa1f8691677115 Author: sugar \u003ccccc@gmail.com\u003e Date: Sun Sep 12 14:29:26 2021 +0800 feat: v1 version 1s add 2、转移多个commit Cherry pick 支持一次转移多个提交 [sugar@centos-7 git-test]$ git cherry-pick \u003cHashA\u003e \u003cHashB\u003e 连续提交多个commit # 提交A到B的commit，但不包含A；提交A必须早于提交B，否则命令将失败，但不会报错。 [sugar@centos-7 git-test]$ git cherry-pick A..B # 提交A到B的commit，包含A [sugar@centos-7 git-test]$ git cherry-pick A^..B 3、参数 git cherry-pick命令的常用配置项如下。 （1）-e，--edit 打开外部编辑器，编辑提交信息。 （2）-n，--no-commit 只更新工作区和暂存区，不产生新的提交。 （3）-x 在提交信息的末尾追加一行(cherry picked from commit ...)，方便以后查到这个提交是如何产生的。 （4）-s，--signoff 在提交信息的末尾追加一行操作者的签名，表示是谁进行了这个操作。 （5）-m parent-number，--mainline parent-number 如果原始提交是一个合并节点，来自于两个分支的合并，那么 Cherry pick 默认将失败，因为它不知道应该采用哪个分支的代码变动。 -m配置项告诉 Git，应该采用哪个分支的变动。它的参数parent-number是一个从1开始的整数，代表原始提交的父分支编号。 $ git cherry-pick -m 1 \u003ccommitHash\u003e 上面命令表示，Cherry pick 采用提交commitHash来自编号1的父分支的变动。 一般来说，1号父分支是接受变动的分支（the branch being merged into），2号父分支是作为变动来源的分支（the branch being merged from）。 4、代码冲突 如果操作过程中发生代码冲突，Cherry pick 会停下来，让用户决定如何继续操作。 1）--contine 用户解决代码冲突后，第一步将修改的文件重新加入暂存区（git add .），第二步使用下面的命令，让 Cherry pick 过程继续执行。 $ git cherry-pick --continue 2）--abort 发生代码冲突后，放弃合并，回到操作前的样子。 3）--quit 发生代码冲突后，退出 Cherry pick，但是不回到操作前的样子。 5、转移到另外一个仓库 Cherry pick 也支持转移另一个代码库的提交，方法是先将该库加为远程仓库。 # 添加一个远程仓库 $ git remote add target git://gitUrl # 将远程仓库的代码抓取到本地 $ git fetch target # 检查一下要从远程仓库转移的提交，获取它的哈希值 $ git log target/master # 使用git cherry-pick命令转移提交 $ git cherry-pick \u003ccommitHash\u003e ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:5:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"六、合并commit 在使用 Git 作为版本控制的时候，我们可能会由于各种各样的原因提交了许多临时的 commit，而这些 commit 拼接起来才是完整的任务。那么我们为了避免太多的 commit 而造成版本控制的混乱，通常我们推荐将这些 commit 合并成一个。 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、查看提交历史 $ git log commit 3ca6ec340edc66df13423f36f52919dfa3...... commit 1b4056686d1b494a5c86757f9eaed844...... commit 53f244ac8730d33b353bee3b24210b07...... commit 3a4226b4a0b6fa68783b07f1cee7b688....... ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"2、git rebase 想要合并1-3条，有两个方法 1）从HEAD版本开始往过去数3个版本 $ git rebase -i HEAD~3 2）指名要合并的版本之前的版本号 $ git rebase -i 3a4226b 请注意3a4226b这个版本是不参与合并的，只是把它当做一个坐标 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:2","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"3、选择要合并的提交 p是保留，s是合并 1）执行了rebase命令之后，会弹出一个窗口，头几行如下： pick 3ca6ec3 '注释**********' pick 1b40566 '注释*********' pick 53f244a '注释**********' 2）将pick改为squash或者s,之后保存并关闭文本编辑窗口即可。改完之后文本内容如下： pick 3ca6ec3 '注释**********' s 1b40566 '注释*********' s 53f244a '注释**********' 3）然后保存退出，Git会压缩提交历史，如果有冲突，需要修改，修改的时候要注意，保留最新的历史，不然我们的修改就丢弃了。修改以后要记得敲下面的命令： pick 3ca6ec3 '注释**********' s 1b40566 '注释*********' s 53f244a '注释**********' ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:3","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"4）冲突解决 然后保存退出，Git会压缩提交历史，如果有冲突，需要修改，修改的时候要注意，保留最新的历史 git add . # 继续合并 git rebase --continue # 放弃合并 git rebase --abort 如果没有冲突，或者冲突已经解决，则会出现如下的编辑窗口： # This is a combination of 4 commits. #The first commit’s message is: 注释...... # The 2nd commit’s message is: 注释...... # The 3rd commit’s message is: 注释...... # Please enter the commit message for your changes. Lines starting # with ‘#’ will be ignored, and an empty message aborts the commit. ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:4","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"5）检查 git log查看 commit 历史信息，查询commit的信息 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:5","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"七、Git Hook Git Hook 也分为两个端: 客户端和服务端。 客户端的 Git Hook 就是工作在我们本地机器的，服务端的 Git Hook 则是工作在我们提交到远程的服务器仓库中。 客户端 Git Hook: pre-commit: 执行git commit命令时触发，常用于检查代码风格 prepare-commit-msg: 触发于 commit message 编辑器呼起前 ,default commit message创建后,常用于生成默认的标准化的提交说明 commit-msg: 开发者编写完并确认commit message后触发，常用于校验提交说明是否标准 post-commit: 整个git commit完成后触发，常用于邮件通知、提醒 applypatch-msg: 执行git am命令时触发，常用于检查命令提取出来的提交信息是否符合特定格式 pre-applypatch: git am提取出补丁并应用于当前分支后，准备提交前触发，常用于执行测试用例或检查缓冲区代码 post-applypatch: git am提交后触发，常用于通知、或补丁邮件回复（此钩子不能停止git am过程） pre-rebase: 执行git rebase命令时触发 post-rewrite: 执行会替换commit的命令时触发，比如git rebase或git commit –amend post-checkout: 执行git checkout命令成功后触发，可用于生成特定文档，处理大二进制文件等 post-merge: 成功完成一次 merge行为后触发 pre-push: 执行git push命令时触发，可用于执行测试用例 pre-auto-gc: 执行垃圾回收前触发 服务端 Git Hook: pre-receive: 当服务端收到一个 push 操作请求时触发，可用于检测 push 的内容 update: update 脚本和 pre-receive 脚本十分类似，不同之处在于它会为每一个准备更新的分支各运行一次。 假如推送者同时向多个分支推送内容，pre-receive 只运行一次，相比之下 update 则会为每一个被推送的分支各运行一次。 post-receive: post-receive 挂钩在整个过程完结以后运行，可以用来更新其他系统服务或者通知用户。它的用途包括给某个邮件列表发信，通知持续集成（continous integration）的服务器，或者更新问题追踪系统（ticket-tracking system） —— 甚至可以通过分析提交信息来决定某个问题（ticket）是否应该被开启，修改或者关闭。 使用git hook Git Hook 本身自带有脚本，会存放在仓库 .git/hooks 文件夹中，目录一般是这样的: - YourGitRepo |- .git |- hooks |- hooks--commit-msg.sample |- hooks--post-update.sample ... 注意如果是 sample 文件，要去掉 .sample 后缀，变成前面 Git Hook 分类 中提到对应的操作来作为文件名。 比如我要做的校验 commit 的提交信息，那么使用的 Git Hook 脚本名应该为 commit-msg. 在 hooks--commit-msg.sample 里的内容为: #!/bin/sh # # An example hook script to check the commit log message. # Called by \"git commit\" with one argument, the name of the file # that has the commit message. The hook should exit with non-zero # status after issuing an appropriate message if it wants to stop the # commit. The hook is allowed to edit the commit message file. # # To enable this hook, rename this file to \"commit-msg\". # Uncomment the below to add a Signed-off-by line to the message. # Doing this in a hook is a bad idea in general, but the prepare-commit-msg # hook is more suited to it. # # SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\\(.*\u003e\\).*$/Signed-off-by: \\1/p') # grep -qs \"^$SOB\" \"$1\" || echo \"$SOB\" \u003e\u003e \"$1\" # This example catches duplicate Signed-off-by lines. test \"\" = \"$(grep '^Signed-off-by: ' \"$1\" | sort | uniq -c | sed -e '/^[ ]*1[ ]/d')\" || { echo \u003e\u00262 Duplicate Signed-off-by lines. exit 1 } 上面说明里有一些基本说明, 这里获得的 $1 参数，其实是存放 commit msg 内容的文件路径，为 .git/COMMIT_EDITMSG. 利用命令: msg=$(cat $1) 就能取到 commit 的信息，稍作修改，就能达到我说的，校验团队 commit 信息的规范的目的了。 Git Hook 不生效 如果遇到不起作用的，可能脚本没有打开执行权限，导致没办法执行。我就是这样的情况。 cd 到 .git/hooks 目录下,执行 chmod 777 命令即可,如： chmod 777 commit-msg ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:7:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"八、Git GC 清理不必要的文件并优化本地存储库 参考链接：Git - 管理 | Administration - git gc - 开发者手册 - 云+社区 - 腾讯云 (tencent.com) Git的底层并没有采用 CVS、SVN 底层所采用的那套增量式文件系统，而是采用一套自行维护的存储文件系统。当文件变动发生提交时，该文件系统存储的不是文件的差异信息，而是文件快照，即整个文件内容，并保存指向快照的索引。这种做法，提高 Git 分支的使用效率；但也容易导致代码仓库中内容重复程度过高，从而仓库体积过大。当遇到这种情况时，或者需要将仓库推送到远程主机时，就需要Git中的gc（garbage collect）功能，也就是垃圾回收功能。 大体来说，当运行 “git gc” 命令时，Git会收集所有松散对象并将它们存入 packfile，合并这些 packfile 进一个大的 packfile，然后将不被任何 commit 引用并且已存在一段时间 (数月) 的对象删除。 此外，Git还会将所有引用 (references) 并入一个单独文件。 就细节而言，Git做了这几件事： pack_refs 过程 reflog expire 过程 repack 过程 prune 过程 rerere 过程 概要： git gc [--aggressive] [--auto] [--quiet] [--prune=\u003cdate\u003e | --no-prune] [--force] 描述： 在当前存储库中运行许多内务处理任务，例如压缩文件修订（以减少磁盘空间并提高性能）并移除可能由之前git add调用创建的不可达对象。 鼓励用户在每个存储库中定期运行此任务，以保持良好的磁盘空间利用率和良好的操作性能。 一些git命令可能会自动运行git gc; --auto详细信息请参阅下面的标志。如果您知道自己在做什么，并且所有您想要的都是永久禁用此行为而无需进一步考虑，请执行以下操作： $ git config --global gc.auto 0 选项： –aggressive 通常git gc运行速度很快，同时提供良好的磁盘空间利用率和性能 此选项将导致git gc更积极地优化存储库，但花费更多时间。这种优化的效果是持久的，所以这个选项只需要偶尔使用; 每隔几百个变更集左右。 –auto 使用此选项，git gc检查是否需要进行任何清洁工作; 如果没有，它会退出而不执行任何工作。一些git命令git gc --auto在执行可能会产生许多松散对象的操作之后运行。 如果存储库中的松散对象太多或包装太多，则需要进行内务处理。如果松散对象的数量超过了gc.auto配置变量的值，则所有松散对象都将使用组合到一个包中git repack -d -l。将值设置gc.auto为0将禁用自动填充松散物体。 如果包装数量超过了价值gc.autoPackLimit，那么现有包装（标有.keep文件的包装除外）将通过使用-A选项合并到一个包装中git repack。设置gc.autoPackLimit为0将禁用自动合并包装。 –prune= 修剪比日期更旧的松散对象（默认为2周前，可由配置变量覆盖gc.pruneExpire）。–prune =不管年龄大小，都修剪松散的物体，并且如果另一个进程同时写入存储库，则会增加腐败风险; 请参阅下面的“注意事项”。–prune默认打开。 –no-prune 不要修剪任何松动的物体。 –quiet 取消所有进度报告。 –force git gc即使可能有另一个git gc实例在此存储库上运行，也强制运行。 注意： git gc尽量不要删除在存储库中任何位置引用的对象。特别是，它不仅会保存当前一组分支和标记所引用的对象，还会保留由索引引用的对象，远程跟踪分支，git filter-branchrefs / original /中保存的引用或reflogs（可引用分支中的提交后来修改或倒带）。如果您希望某些对象被删除而不是，请检查所有这些位置，并决定在您的情况下删除这些引用是否有意义。 另一方面，当git gc与另一个进程同时运行时，可能会删除另一个进程正在使用但尚未创建引用的对象。这可能会导致其他进程失败或者可能会损坏存储库，如果其他进程稍后添加对已删除对象的引用。Git有两个功能可以显着缓解这个问题： --prune保留修改时间比日期更新的任何对象以及可从其访问的所有对象。 将对象添加到数据库的大多数操作都会更新对象的修改时间（如果该对象已存在，以便应用＃1）。 然而，这些功能并不能提供完整的解决方案，因此，同时运行命令的用户必须忍受一些腐败风险（实践中似乎很低），除非他们关闭自动垃圾收集git config gc.auto 0 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:8:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"九、Git gpg签名 # 查看gpg密钥 [root@local ~]# gpg --list-key /root/.gnupg/pubring.kbx ------------------------ pub rsa4096 2021-08-23 [SC] C40EA42A60xxxxxxxxxxxxxxxxxx uid [ 绝对 ] cccc (local) \u003ct@local.com\u003e sub rsa4096 2021-08-23 [E] pub rsa4096 2021-08-23 [SC] 3CB22116355xxxxxxxxxxxxxxxxxx uid [ 绝对 ] tom (github) \u003ct@local.cc\u003e sub rsa4096 2021-08-23 [E] 配置使用gpg签名 # git 配置使用gpg签名 git config --global user.signingkey \u003cgpg-key-id\u003e # 提交是否强制 GPG，带上--global 是作用全局，局部的去除--global [root@sugar2 ~]# git config --global commit.gpgsign true # commit 提交设置GPG签名，如果没有设置强制，则需要加上-S [root@sugar2 ~]# git commit -S -m “commit message\" # 在github上签名的提交将显示包含“ Verified” 问题： [root@sugar ssl]# git commit -m \"init repo\" error: gpg 数据签名失败 fatal: 写提交对象失败 参考链接：https://zhuanlan.zhihu.com/p/97984430 解决办法：export GPG_TTY=$(tty) 在环境变量里增加一项GPG_TTY ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:9:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"Nexus 参考： https://juejin.cn/post/6844904016762109959 https://cloud.tencent.com/developer/article/1764866 官网：https://help.sonatype.com/repomanager3/ ","date":"2023-11-18","objectID":"/posts/2023-11-18-nexus/:0:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2023-11-18-nexus/"},{"categories":["DevOps"],"content":"介绍 生产环境中，一般不会允许所有服务器都能访问公网，理想的情况是有几台服务器作为访问代理，同时作为缓存服务器。当服务器中有所需包时通过内网获取，如无则通过公网获取同时在本地保存。常用搭建私有yum源的方法是createrepo生成本地仓库，其它服务器通过http访问仓库。这种方法的弊端是如果当前仓库中没有所需软件包会导致安装失败，不会去其它源获取数据。Nexus是一个强大的仓库管理器，它极大地简化了自己内部仓库的维护和外部仓库的访问。 Nexus是一个强大的Maven仓库管理器，它极大地简化了本地内部仓库的维护和外部仓库的访问。 如果使用了公共的Maven仓库服务器，可以从Maven中央仓库下载所需要的构件（Artifact），但这通常不是一个好的做法。 正常做法是在本地架设一个Maven仓库服务器，即利用Nexus可以只在一个地方就能够完全控制访问和部署在你所维护仓库中的每个Artifact。 Nexus在代理远程仓库的同时维护本地仓库，以降低中央仓库的负荷,节省外网带宽和时间，Nexus就可以满足这样的需要。 Nexus是一套“开箱即用”的系统不需要数据库，它使用文件系统加Lucene来组织数据。 Nexus使用ExtJS来开发界面，利用Restlet来提供完整的REST APIs，通过m2eclipse与Eclipse集成使用。 Nexus支持WebDAV与LDAP安全身份认证。 Nexus还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。 为什么要构建Nexus私服？ 如果没有Nexus私服，我们所需的所有构件都需要通过maven的中央仓库和第三方的Maven仓库下载到本地，而一个团队中的所有人都重复的从maven仓库下载构件无疑加大了仓库的负载和浪费了外网带宽，如果网速慢的话，还会影响项目的进程。很多情况下项目的开发都是在内网进行的，连接不到maven仓库怎么办呢？开发的公共构件怎么让其它项目使用？这个时候我们不得不为自己的团队搭建属于自己的maven私服，这样既节省了网络带宽也会加速项目搭建的进程，当然前提条件就是你的私服中拥有项目所需的所有构件。 同时Nexus支持仓库有：Apt、Bower、CocoaPods、Conda、Docker、Git LFS、Go、Maven、Npm、NuGet、PyPi、Raw、RubyGems、Yum ","date":"2023-11-18","objectID":"/posts/2023-11-18-nexus/:1:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2023-11-18-nexus/"},{"categories":["DevOps"],"content":"二、安装 二进制安装 # 下载地址 https://help.sonatype.com/repomanager3/download # 解压 tar zxf nexus-3.23.0-03-unix.tar.gz mv nexus-3.23.0-03 sonatype-work /data echo 'NEXUS_HOME=\"/data/nexus-3.23.0-03\"' \u003e\u003e ~/.bashrc echo 'run_as_user=\"root\"' \u003e\u003e /data/nexus-3.23.0-03/bin/nexus.rc # 配置systemd服务 $ vim /etc/systemd/system/nexus.service [Unit] Description=nexus service After=network.target [Service] Type=forking LimitNOFILE=65536 ExecStart=/data/nexus-3.23.0-03/bin/nexus start ExecStop=/data/nexus-3.23.0-03/bin/nexus stop User=root Restart=on-abort [Install] WantedBy=multi-user.target # 启动服务 systemctl start nexus # 此处启动后，请耐心等待，netstat -tunlp 查看端口8081监听后继续 # 查看admin用户的密码 cat /data/sonatype-work/nexus3/admin.password 基于docker安装nexus mkdir -p /data/nexus/data \u0026\u0026 chown -R 200 /data/nexus/data docker run -d -p 8081:8081 --name nexus -v /data/nexus/data:/nexus-data sonatype/nexus3 docker-compose安装 mkdir -p /data/nexus/data \u0026\u0026 chown -R 200 /data/nexus/data # docker-compose cat \u003edocker-compose.yaml \u003c\u003cEOF version: \"3\" services: nexus3: image: sonatype/nexus3 container_name: nexus3 restart: always privileged: true environment: - TZ=Asia/Shanghai ports: - '8081:8081' volumes: - /data/nexus/data:/nexus-data EOF 查看密码 管理员：admin 密码：cat /data/nexus/data/admin.passwor nginx代理设置 upstream nexus-server{ server 127.0.0.1:8081; } #server { # listen 80; # server_name mirrors.cccc.io; # location / { # return 301 https://xx.xx; # } # location ~ /.well-known { # root /tmp; # } #} server { listen 80; server_name mirrors.local.com; location / { proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; #proxy_set_header X-Forwarded-Proto \"https\"; proxy_max_temp_file_size 0; proxy_pass http://nexus-server; # This is the maximum upload size client_max_body_size 1024m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_temp_file_write_size 64k; # Required for new HTTP-based CLI #proxy_http_version 1.1; #proxy_request_buffering off; #proxy_buffering off; # Required for HTTP-based CLI to work over SSL } #ssl_certificate cert/xx.pem; #ssl_certificate_key cert/xx.key; } ","date":"2023-11-18","objectID":"/posts/2023-11-18-nexus/:2:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2023-11-18-nexus/"},{"categories":["DevOps"],"content":"二、nexus仓库 Nexus 仓库按照类型（Type）区分，主要分为以下 3 个类型： 代理仓库（proxy）：主要用于代理缓存访问外网上其他公开的仓库，将每次从代理仓库拉取的制品缓存到nexus文件系统中，下次再拉取相同版本制品时就不需再次从外网拉取，起到代理访问缓存的功能。 宿主仓库（hosted）：类型的仓库主要用于存放各个项目组产出的、用于共享、不能放到公网上、私有的制品。有两种版本策略，一种是Snapshots版本策略类型的，对于相同版本制品的上传，nexus会自动追加时间戳加以区分；一种是Release版本策略类型的，对于相同的制品，要明确版本，不能存放相同版本。可以理解为snapshots仓库存放一些内容变更频繁的制品，这样不管上传还是使用时不用频繁变更版本号就能拉取到最新版本。而release仓库存放一些内容稳定变更少的制品，使用时指定好版本就行，无需经常变动。 仓库组（group）：主要用于组合其他仓库，统一对外使用方式。可设置组仓库组合其他仓库的顺序。例如组合顺序为先拉取maven格式aliyun代理仓库中的制品，如果其中没有想要的制品，再去拉取maven格式Central代理仓库中的制品。如果还没有，就去maven格式hosted类型仓库中拉取，直到遍历完所有的组合仓库。同时，拉取使用时不需要配置那么多的仓库地址，只需要配置group仓库地址就行。 group仓库可以包含proxy和hosted类型的仓库，并对外提供统一的服务 ","date":"2023-11-18","objectID":"/posts/2023-11-18-nexus/:3:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2023-11-18-nexus/"},{"categories":["DevOps"],"content":"二、数据接入prometheus grafana模板： 155563 https://grafana.com/grafana/dashboards/16459 neuxs 官方参考地址： https://help.sonatype.com/repomanager3/nexus-repository-administration/support-features#SupportFeatures-Prometheus 配置文件模板 global: scrape_interval: 15s scrape_timeout: 10s evaluation_interval: 15s alerting: alertmanagers: - static_configs: - targets: [] scheme: http timeout: 10s scrape_configs: - job_name: nxrm scrape_interval: 15s scrape_timeout: 10s metrics_path: /service/metrics/prometheus scheme: http basic_auth: username: admin password: admin123 static_configs: - targets: - localhost:8081 ","date":"2023-11-18","objectID":"/posts/2023-11-18-nexus/:4:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2023-11-18-nexus/"},{"categories":["Database"],"content":"PostgreSQL ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:0:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"一、安装 docker 安装 # docker-compose.yaml version: \"3\" services: postgres10-5432: image: \"postgres:10-bullseye\" container_name: postgres10-5432 shm_size: \"1gb\" restart: always ports: - \"5432:5432\" volumes: - /data/postgresql:/var/lib/postgresql/data - $PWD/init.sql:/docker-entrypoint-initdb.d/init.sql environment: - POSTGRES_PASSWORD=xxxxxxxxxxx # init.sql CREATE USER db_user WITH CREATEDB ENCRYPTED PASSWORD 'xxxxxxxxxx'; alter user db_user superuser; ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:1:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"二、配置 ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:2:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"1、修改数据库时区 postgres=# show timezone; TimeZone ---------- Etc/UTC (1 row) sed -i \"s+timezone = 'Etc/UTC'+timezone = 'Asia/Shanghai\" postgresql.conf sed -i \"s+log_timezone = 'Etc/UTC'+log_timezone = 'Asia/Shanghai'\" postgresql.conf postgres=# select pg_reload_conf(); pg_reload_conf ---------------- t (1 row) postgres=# show timezone; TimeZone --------------- Asia/Shanghai (1 row) ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:2:1","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"2、sql使用 查询数据库大小： select datname, pg_size_pretty (pg_database_size(datname)) AS size from pg_database order by size; 查看表大小 --数据库中单个表的大小（不包含索引） select pg_size_pretty(pg_relation_size('表名')); --查出所有表（包含索引）并排序 SELECT table_schema || '.' || table_name AS table_full_name, pg_size_pretty(pg_total_relation_size('\"' || table_schema || '\".\"' || table_name || '\"')) AS size FROM information_schema.tables ORDER BY pg_total_relation_size('\"' || table_schema || '\".\"' || table_name || '\"') DESC limit 20; --查出表大小按大小排序并分离data与index SELECT table_name, pg_size_pretty(table_size) AS table_size, pg_size_pretty(indexes_size) AS indexes_size, pg_size_pretty(total_size) AS total_size FROM ( SELECT table_name, pg_table_size(table_name) AS table_size, pg_indexes_size(table_name) AS indexes_size, pg_total_relation_size(table_name) AS total_size FROM ( SELECT ('\"' || table_schema || '\".\"' || table_name || '\"') AS table_name FROM information_schema.tables ) AS all_tables ORDER BY total_size DESC ) AS pretty_sizes -- 修改用户密码 ALTER USER postgres with password 'hello_world'; schema 管理 -- 创建schema create schema test; -- 查看schema \\dn -- 修改schema 属主 alter schema test owner to highgo; -- 修改schema名称 alter schema test rename to testa; create schema test authorization highgo;; -- 切换schema set search_path to test_schema 修改数据库名 -- 修改数据库名 alter database src_dbname rename to dst_dbname; -- 将数据库的名称由database2改成database1 UPDATE pg_database SET datname = 'database1' WHERE datname = 'database2'; 慢查询配置 # postgresql.conf # 10s log_min_duration_statement=10000 # 热加载配置 postgres=# select pg_reload_conf(); 1 # 查看配置： postgres=# show log_min_duration_statement; log_min_duration_statement ---------------------------- 10s (1 row) # 也可以针对某个用户或者某数据库进行设置： postgres=# alter database test set log_min_duration_statement=5000; # sql 查询慢语句，超过1s postgres=# select * from pg_stat_activity where state\u003c\u003e'idle' and now()-query_start \u003e interval '1 s' order by query_start; select * from pg_stat_activity where state\u003c\u003e'idle' and now()-query_start \u003e interval '5 s' order by query_start; # 断开数据库连接 select pg_terminate_backend(pid) from (select pid from pg_stat_activity where datname = 'db_name' ) as a; # 创建一个数据库归属其他用户 create database 'db_name' OWNER db_user; # 查看数据库连接数 select count(*) from pg_stat_activity; select * from pg_stat_activity; # 查询数据库最大连接数，默认是100 postgres=\u003e show max_connections; # docker 部署到数据库修改最大连接数 # 进入容器，修改最大连接数 root@ip142:~# docker exec -ti postgres10-5433 bash root@568a83e098a5:/# sed -ri '/max_connections/c max_connections = 2000' /var/lib/postgresql/data/postgresql.conf 用户只读权限设置：https://blog.csdn.net/qq_41018743/article/details/105492884 -- 以super user创建只读用户 CREATE USER readonly WITH PASSWORD '*****'; -- 以super user设置用户默认事务只读 alter user readonly set default_transaction_read_only=on; -- 使用数据库的创建所有者去执行以下操作 -- 增加连接数据库权限 GRANT CONNECT ON DATABASE testDB to readonly; -- 切换到 testDB \\c testDB; -- 赋予用户权限访问public模式 GRANT USAGE ON SCHEMA public to readonly; -- 赋予表序列查看权限 GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO readonly; GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly; -- 新增加的表都默认增加权限 alter default privileges in schema public grant select on tables to readonly; -- 新增加的序列都默认增加权限 alter default privileges in schema public grant select on SEQUENCES to readonly; ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:2:2","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"三、从库配置 参考链接：https://help.aliyun.com/document_detail/53096.html ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:3:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"1、配置PostgreSQL主节点 1）输入以下SQL语句创建数据库账号replica，并设置密码及登录权限和备份权限。 本示例中将密码设置为replica。 CREATE ROLE replica login replication encrypted password 'replica'; CREATE ROLE replica login replication encrypted password 'rRweb9iojLxhVeWNddddddddddd'; 2）修改配置文件 data/pg_hba.conf 在IPv4 local connections段添加下面两行内容。 host all all \u003c从节点的VPC IPv4网段\u003e md5 #允许VPC网段中md5密码认证连接 host replication replica \u003c从节点的VPC IPv4网段\u003e md5 #允许用户从replication数据库进行数据同步 postgresql.conf listen_addresses = '*' #监听的IP地址 wal_level = hot_standby #启用热备模式 synchronous_commit = on #开启同步复制 max_wal_senders = 32 #同步最大的进程数量 wal_sender_timeout = 60s #流复制主机发送数据的超时时间 max_connections = 100 #最大连接数，从库的max_connections必须要大于主库的 修改完后重启服务 ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:3:1","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"2、从节点上操作 参考链接：https://blog.51cto.com/u_13482808/6875114 pg_basebackup --help 用法： pg_basebackup [选项] ... 控制输出的选项： -D, --pgdata=DIRECTORY 接收基本备份到目录，如果不存在会自动创建 -F, --format=p|t 输出格式（plain,直接拷贝数据文件，tar 配合 -z -Z 进行打包压缩） -r, --max-rate=RATE 传输数据目录的最大传输速率（以 kB/s 为单位，或使用后缀“k”或“M”） -R,--write-recovery-conf 是否输出recovery-conf文件，方便后续使用备份快速搭建出从节点 -T, --tablespace-mapping=OLDDIR=NEWDIR 将 OLDDIR 中的表空间重定位到 NEWDIR --waldir=WALDIR 预写日志目录的位置 -X, --wal-method=none|fetch|stream 包含指定方法所需的 WAL 文件 -z, --gzip 压缩 tar 输出 -Z, --compress=0-9 使用给定的压缩级别压缩 tar 输出 常规选项： -c, --checkpoint=fast|spread 设置快速或扩展检查点 -C, --create-slot 创建复制槽 -l, --label=LABEL 设置备份标签 -n, --no-clean 出错后不清理 -N, --no-sync 不等待更改安全写入磁盘 -P, --progress 显示进度信息 -S, --slot=SLOTNAME 要使用的复制槽 -v, --verbose 输出详细信息 -V, --version 输出版本信息，然后退出 --no-slot 防止创建临时复制槽 --no-verify-checksums 不验证校验和 -?, --help 显示此帮助，然后退出 连接选项： -d, --dbname 数据库名称 -h, --host 数据库服务器主机ip或套接字目录 -p, --port 数据库口号 -s, --status-interval=状态包发送到服务器的间隔时间（以秒为单位） -U, --username 连接用户，要有super权限 -w, --no-password 从不提示输入密码 1）备份数据 使用pg_basebackup基础备份工具指定备份目录。 #保持pg data目录格式 pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv # 自动创建recovery.conf pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv -R # 打包成tar文件 pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv -Ft # 打包成tar.gz文件 pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv -Ft -z 新建并修改recovery.conf配置文件。 vim /var/lib/pgsql/11/data/recovery.conf ####分别找到以下参数，并将参数修改为以下内容： standby_mode = on #声明此节点为从库 primary_conninfo = 'host=\u003c主节点IP\u003e port=5432 user=replica password=replica' #对应主库的连接信息 recovery_target_timeline = 'latest' #流复制同步到最新的数据 修改postgresql.conf文件 max_connections = 1000 # 最大连接数，从节点需设置比主节点大 hot_standby = on # 开启热备 max_standby_streaming_delay = 30s # 数据流备份的最大延迟时间 wal_receiver_status_interval = 5s # 从节点向主节点报告自身状态的最长间隔时间 hot_standby_feedback = on # 如果有错误的数据复制向主进行反馈 修改数据目录的权限 chown -R postgres.postgres /var/lib/pgsql/11/data 启动服务 ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:3:2","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"3、验证 1）在主节点中运行以下命令，查看sender进程。 ps aux |grep sender 返回结果如下，表示可成功查看到sender进程。 postgres 2916 0.0 0.3 340388 3220 ? Ss 15:38 0:00 postgres: wal sender process replica 192.168.**.**(49640) streaming 0/F01C1A8 2）在从节点中运行以下命令，查看receiver进程。 ps aux |grep receiver 返回结果如下，表示可成功查看到receiver进程。 postgres 23284 0.0 0.3 387100 3444 ? Ss 16:04 0:00 postgres: wal receiver process streaming 0/F01C1A8 3）在主节点中进入PostgreSQL交互终端，输入以下SQL语句，在主库中查看从库状态。 select * from pg_stat_replication; 返回结果如下，表示可成功查看到从库状态。 pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_location | write_locati on | flush_location | replay_location | sync_priority | sync_state ------+----------+---------+------------------+---------------+-----------------+------------- +-------------------------------+--------------+-----------+---------------+------------- ---+----------------+-----------------+---------------+------------ 2916 | 16393 | replica | walreceiver | 192.168.**.** | | 49640 | 2017-05-02 15:38:06.188988+08 | 1836 | streaming | 0/F01C0C8 | 0/F01C0C8 | 0/F01C0C8 | 0/F01C0C8 | 0 | async (1 rows) ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:3:3","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"4、查看主从延迟 如果主库没有插入或者修改的数据的sql执行，主从同步的延时会逐渐增加 select now() - pg_last_xact_replay_timestamp() AS replication_delay; ","date":"2023-11-12","objectID":"/posts/2023-11-12-postgresql/:3:4","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["安全信息"],"content":"漏洞信息 云服务商安全服务公告 云服务商 链接 cve官网 https://cve.mitre.org/ 阿里云 https://help.aliyun.com/noticelist/9213612.html?spm=a2c4g.789004748.n2.3.cddb4c07NBt9Rl 华为云 https://www.huaweicloud.com/notice.securecenter.html 腾讯云 https://cloud.tencent.com/announce?categorys=21\u0026page=1 阿里云漏洞数据库 https://avd.aliyun.com/ 国家信息漏洞库 http://www.cnnvd.org.cn/ 常用软件官方安全公告链接 名称 链接 redis https://github.com/redis/redis/security nginx http://nginx.org/en/security_advisories.html httpd https://httpd.apache.org/security ","date":"2023-11-12","objectID":"/posts/2023-11-12-security-info/:1:0","tags":["security","cve"],"title":"security-info","uri":"/posts/2023-11-12-security-info/"},{"categories":["安全信息"],"content":"安全服务推送 github: https://github.com/zema1/watchvuln version: \"3\" services: watchvuln: image: zemal/watchvuln container_name: watchvuln hostname: watchvuln restart: always environment: DINGDING_ACCESS_TOKEN: cd316d9dxxxxxxxxxxxxxxxxxxxxxxx DINGDING_SECRET: SECa87a39xxxxxxxxxxxxxxxxxxxxxxxxxxxx LARK_ACCESS_TOKEN: 1ddfb805-xxxxxxxxxxxxxxxxxxxxxxxxxxxx LARK_SECRET: GUUKIrxxxxxxxxxxxxxxxxxxxxxxxxxxxx INTERVAL: 30m volumes: - \"/etc/localtime:/etc/localtime:ro\" ","date":"2023-11-12","objectID":"/posts/2023-11-12-security-info/:2:0","tags":["security","cve"],"title":"security-info","uri":"/posts/2023-11-12-security-info/"},{"categories":["Database"],"content":"SQLite SQLite是一种开源，零配置，独立的，独立的，事务关系数据库引擎，旨在嵌入到应用程序中。 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:0:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"一、安装sqlite SQLite以其零配置而闻名，所以不需要复杂的设置或管理。 # rpm yum -y install sqlite3 # apt apt install sqlite3 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:1:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"二、sqlite命令 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:2:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"进入sqlite [sugar@MacBook-Pro ~]$ sqlite3 SQLite version 3.32.3 2020-06-18 14:16:19 Enter \".help\" for usage hints. Connected to a transient in-memory database. Use \".open FILENAME\" to reopen on a persistent database. sqlite\u003e .exit 如需获取可用的点命令的清单，可以在任何时候输入 “.help” sqlite\u003e .help .auth ON|OFF Show authorizer callbacks .backup ?DB? FILE Backup DB (default \"main\") to FILE .bail on|off Stop after hitting an error. Default OFF .binary on|off Turn binary output on or off. Default OFF .cd DIRECTORY Change the working directory to DIRECTORY .changes on|off Show number of rows changed by SQL .check GLOB Fail if output since .testcase does not match .clone NEWDB Clone data into NEWDB from the existing database .databases List names and files of attached databases .dbconfig ?op? ?val? List or change sqlite3_db_config() options .dbinfo ?DB? Show status information about the database .dump ?TABLE? Render database content as SQL .echo on|off Turn command echo on or off 上面的命令会显示各种重要的 SQLite 点命令的列表，如下所示： 命令 描述 .backup ? DB? FILE 备份 DB 数据库（默认是 “main”）到 FILE 文件。 .bail ON|OFF 发生错误后停止。默认为 OFF。 .databases 列出数据库的名称及其所依附的文件。 .dump ?TABLE? 以 SQL 文本格式转储数据库。如果指定了 TABLE 表，则只转储匹配 LIKE 模式的 TABLE 表。 .echo ON|OFF 开启或关闭 echo 命令。 .exit 退出 SQLite 提示符。 .explain ON|OFF 开启或关闭适合于 EXPLAIN 的输出模式。如果没有带参数，则为 EXPLAIN on，即开启 EXPLAIN。 .header(s) ON|OFF 开启或关闭头部显示。 .help 显示消息。 .import FILE TABLE 导入来自 FILE 文件的数据到 TABLE 表中。 .indices ?TABLE? 显示所有索引的名称。如果指定了 TABLE 表，则只显示匹配 LIKE 模式的 TABLE 表的索引。 .load FILE ?ENTRY? 加载一个扩展库。 .log FILE|off 开启或关闭日志。FILE 文件可以是 stderr（标准错误）/stdout（标准输出）。 .mode MODE 设置输出模式，MODE 可以是下列之一：csv 逗号分隔的值column 左对齐的列html HTML 的 代码insert TABLE 表的 SQL 插入（insert）语句line 每行一个值list 由 .separator 字符串分隔的值tabs 由 Tab 分隔的值tcl TCL 列表元素 .nullvalue STRING 在 NULL 值的地方输出 STRING 字符串。 .output FILENAME 发送输出到 FILENAME 文件。 .output stdout 发送输出到屏幕。 .print STRING… 逐字地输出 STRING 字符串。 .prompt MAIN CONTINUE 替换标准提示符。 .quit 退出 SQLite 提示符。 .read FILENAME 执行 FILENAME 文件中的 SQL。 .schema ?TABLE? 显示 CREATE 语句。如果指定了 TABLE 表，则只显示匹配 LIKE 模式的 TABLE 表。 .separator STRING 改变输出模式和 .import 所使用的分隔符。 .show 显示各种设置的当前值。 .stats ON|OFF 开启或关闭统计。 .tables ?PATTERN? 列出匹配 LIKE 模式的表的名称。 .timeout MS 尝试打开锁定的表 MS 毫秒。 .width NUM NUM 为 “column” 模式设置列宽度。 .timer ON|OFF 开启或关闭 CPU 定时器。 用.show命令来查看 SQLite 命令提示符的默认设置 sqlite\u003e .show echo: off eqp: off explain: auto headers: off mode: list nullvalue: \"\" output: stdout colseparator: \"|\" rowseparator: \"\\n\" stats: off width: filename: :memory: sqlite\u003e ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:2:1","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"格式化输出 .header on .mode column .timer on .changes on 这样设置只是在当前终端中设置了格式化输出，当再次打开时则需要再次设置，可以把sqlite的配置写入到~/.sqliter [sugar@localhost domain]$ cat ~/.sqliterc .header on .mode column .timer on [sugar@localhost domain]$ sqlite3 domain.db -- Loading resources from /Users/sugar/.sqliterc SQLite version 3.37.0 2021-12-09 01:34:53 Enter \".help\" for usage hints. sqlite\u003e .tables ssls sqlite\u003e select * from ssls; id created_at updated_at deleted_at status web -- -------------------------------- -------------------------------- ---------- ------ ----------------- 1 2022-10-14 23:31:24.473488+08:00 2022-10-14 23:31:24.473488+08:00 1 https://gitea.com Run Time: real 0.001 user 0.000178 sys 0.000250 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:2:2","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"三、sql操作 创建数据库 $ sqlite3 cccc.db SQLite version 3.32.3 2020-06-18 14:16:19 Enter \".help\" for usage hints. sqlite\u003e 上面的命令将在当前目录下创建一个文件 cccc.db。该文件将被 SQLite 引擎用作数据库。如果您已经注意到 sqlite3 命令在成功创建数据库文件之后，将提供一个 sqlite\u003e 提示符。 一旦数据库被创建，您就可以使用 SQLite 的 .databases 命令来检查它是否在数据库列表中，如下所示： sqlite\u003e .database main: /Users/sugar/Desktop/workspace/cccc.db sqlite\u003e 数据库备份 sqlite3 cccc.db .dump \u003e cccc.sql 恢复数据库 sqlite3 cccc.db \u003c cccc.sql 查看表详细信息 .schema 非交互式执行sql [sugar@Sugar sqlite]$ sqlite3 cccc.db \"select * from msg;\" -- Loading resources from /Users/sugar/.sqliterc age id --- ---- 19 1001 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:3:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"四、sql语法 大小写 SQLite不区分大小写。但是，有一些区分大小写的命令。例如：GLOB和glob在SQLite语句中有不同的含义。 注释： 注释用于在SQLite代码中增加代码的可读性。 注释不能嵌套。 注释以两个连续的“ - ”字符。 也可使用“/*”字符开始，并延伸至下一个“*/”字符对所包括的内容视为注释。 1、表操作 列的数据类型 NULL —该值为 NULL 值 INTEGER —有符号整数 REAL —浮点值 TEXT-文本字符串 BLOB —数据块 -- 创建表 sqlite\u003e CREATE TABLE Testing(Id INTEGER); Run Time: real 0.002 user 0.000269 sys 0.001006 changes: 0 total_changes: 0 sqlite\u003e -- 查看表结构 sqlite\u003e .schema CREATE TABLE Testing(Id INTEGER); sqlite\u003e .schema Testing CREATE TABLE Testing(Id INTEGER); sqlite\u003e -- 如果存在则不创建 CREATE TABLE IF NOT EXISTS Testing(Id INTEGER); -- 复制表 CREATE TABLE Cars2 AS SELECT * FROM Cars; -- 查看所有表 sqlite\u003e .tables Testing -- 通用语法 sqlite\u003e select * from sqlite_master; type name tbl_name rootpage sql ----- ------- -------- -------- -------------------------------- table Testing Testing 2 CREATE TABLE Testing(Id INTEGER) Run Time: real 0.001 user 0.000111 sys 0.000102 changes: 0 total_changes: 0 sqlite\u003e -- 删除表 sqlite\u003e DROP TABLE Testing; sqlite\u003e DROP TABLE IF EXISTS Testing; -- 重命名数表 sqlite\u003e CREATE TABLE Names(Id INTEGER, Name TEXT); sqlite\u003e ALTER TABLE Names RENAME TO NamesOfFriends; sqlite\u003e .schema NamesOfFriends 2、数据操作 sqlite\u003e CREATE TABLE Cars(Id INTEGER PRIMARY KEY, Name TEXT,Price INTEGER DEFAULT 'Not available'); -- 插入数据 sqlite\u003e INSERT INTO Cars(Id, Name, Price) VALUES(1, 'Audi', 52642); -- 删除数据 sqlite\u003e DELETE FROM Cars2 WHERE Id=1; -- 删除表所有数据 sqlite\u003e DELETE FROM Cars2; -- 更新数据 sqlite\u003e UPDATE Cars SET Name='Skoda Octavia' WHERE Id=3; 3、约束 # 非空 NOT NULL # 唯一 UNIQUE # 主键 PRIMARY KEY # 外键 FOREIGN KEY # 默认值 sqlite\u003e CREATE TABLE Hotels(Id INTEGER PRIMARY KEY, Name TEXT,City TEXT DEFAULT 'not available'); 所有的SQLite语句都是以关键字(如：SELECT，INSERT，UPDATE，DELETE，ALTER，DROP等)开始的。所有语句都以分号(;)结尾。 ANALYZE语句的语法： ANALYZE; -- or ANALYZE database_name; -- or ANALYZE database_name.table_name; AND/OR子句的语法： SELECT column1, column2....columnN FROM table_name WHERE CONDITION-1 {AND|OR} CONDITION-2; ALTER TABLE语句的语法 ALTER TABLE table_name ADD COLUMN column_def...; ALTER TABLE语句(Rename)语句的语法 ALTER TABLE table_name RENAME TO new_table_name; ATTACH DATABASE语句的语法： ATTACH DATABASE 'DatabaseName' As 'Alias-Name'; BEGIN TRANSACTION语句的语法： BEGIN; -- or BEGIN EXCLUSIVE TRANSACTION; BETWEEN语句的语法： SELECT column1, column2....columnN FROM table_name WHERE column_name BETWEEN val-1 AND val-2; SQLite COMMIT Statement: COMMIT; CREATE INDEX语句的语法： CREATE INDEX index_name ON table_name ( column_name COLLATE NOCASE ); CREATE UNIQUE INDEX语句的语法： CREATE UNIQUE INDEX index_name ON table_name ( column1, column2,...columnN); CREATE TABLE语句的语法： CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY( one or more columns )); CREATE TRIGGER语句的语法： CREATE TRIGGER database_name.trigger_name BEFORE INSERT ON table_name FOR EACH ROW BEGIN stmt1; stmt2; .... END; CREATE VIEW语句的语法： CREATE VIEW database_name.view_name AS SELECT statement....; CREATE VIRTUAL TABLE语句的语法： CREATE VIRTUAL TABLE database_name.table_name USING weblog( access.log ); -- or CREATE VIRTUAL TABLE database_name.table_name USING fts3( ); COMMIT TRANSACTION语句的语法： COMMIT; COUNT语句的语法： SELECT COUNT(column_name) FROM table_name WHERE CONDITION; DELETE语句的语法： DELETE FROM table_name WHERE {CONDITION}; DETACH DATABASE语句的语法： DETACH DATABASE 'Alias-Name'; DISTINCT语句的语法： SELECT DISTINCT column1, column2....columnN FROM table_name; DROP INDEX语句的语法： DROP INDEX database_name.index_name; DROP TABLE语句的语法： DROP TABLE database_name.table_name; DROP VIEW语句的语法： DROP INDEX database_name.view_name; SQLite DROP TRIGGER 语句的语法： DROP INDEX database_name.trigger_name; SQLite EXISTS语句的语法： SELECT column1, column2....columnN FROM table_name WHERE column_name EXISTS (SELECT * FROM table_name ); EXPLAIN语句的语法： EXPLAIN INSERT statement...; -- or EXPLAIN QUERY PLAN SELECT statement...; GLOB语句的语法： SELECT column1, column2....columnN FROM table_name WHERE column_name GLOB { PATTERN }; GROUP BY语句的语法： SELECT SUM(column_name) FROM table_name WHERE CONDITION GROUP BY column_name; HAVING语句的语法： SELEC","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:4:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["DevOps"],"content":"钉钉机器人 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:0:0","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"一、shell脚本 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:1:0","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"1、基于关键字或者 ip 版 发送txt格式消息 info='hello' logFile='/var/log/dingbot.log' #发送消息 sendMsg() { token='1e18ffe069052b56f5a0f8fe9b6c058373e7df7ef4xxxxxxxxxxxxxxx' result=$(curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{'msgtype': 'text','text': {'content': 'msg:\\n$*'}}\") [ $(echo $result | grep \"errmsg.*ok\") ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result msg: $*\" \u003e\u003e$logFile } sendMsg $info 发送 markdown 格式消息 logFile='/var/log/DingBot.log' token='1e18ffe069052b56f5a0f8fe9b6c058373xxxxxxxxxxxxxx' #发送消息 sendMsg() { local info=$* result=$(curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{'msgtype': 'text', 'text': { 'content': '$info' } }\") [ $(echo $result | grep \"errmsg.*ok\") ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result MessagesType: text [ text: $* ]\" \u003e\u003e$logFile } SendMsgByMD() { local info=$1 # $info markdown的标题 local infoMsg=$2 # $infoMsg 内容 # token='1e18ffe069052b56f5a0f8fe9b6c058373e7df7xxxxxxxxxxxxxx' result=$(curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{ 'msgtype': 'markdown', 'markdown': { 'title':'$info', 'text': '$infoMsg' }, 'at': { 'atMobiles': [ '156xxxx8827', '189xxxx8325' ], 'isAtAll': true } }\") [ $(echo $result | grep \"errmsg.*ok\") ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result MessagesType: markdown [ title: $info text: $infoMsg ]\" \u003e\u003e$logFile } #main() (sendMsg 'zabbix') \u0026 (SendMsgByMD 'zabbix' '# send msg') \u0026 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:1:1","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"2、签名计算版 计算签名是使用的date是linux版的，而mac上的date是unix版的，在mac上需要替换为linux版的date才能正常计算签名。 ## 钉钉机器人配置 dingbot_secret='SECa87axxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' dingbot_url='https://oapi.dingtalk.com/robot/send?access_token=cd3xxxxxxxxxxxxx' ## secret_type keywords || sign ding_secret_type='sign' ## 需要艾特的人的手机号码，以空格隔开 atMobiles=(13346123456 13346123457) ## encode url function url_encode() { t=\"${1}\" if [[ -n \"${1}\" \u0026\u0026 -n \"${2}\" ]];then if ! echo 'xX' | grep -q \"${t}\";then t='x' fi echo -n \"${2}\" | od -t d1 | awk -v a=\"${t}\" '{for (i = 2; i \u003c= NF; i++) {printf(($i\u003e=48 \u0026\u0026 $i\u003c=57) || ($i\u003e=65 \u0026\u0026$i\u003c=90) || ($i\u003e=97 \u0026\u0026 $i\u003c=122) ||$i==45 || $i==46 || $i==95 || $i==126 ?\"%c\" : \"%%%02\"a, $i)}}' else echo -e '$1 and $2 can not empty\\n$1 ==\u003e 'x' or 'X', x ==\u003e lower, X ==\u003e toupper.\\n$2 ==\u003e Strings need to url encode' fi } ## Dingbot function dingbot(){ send_strs=\"${1}\" new_url=\"${dingbot_url}\" at_who='' for i in ${atMobiles[*]} do if [ -n \"${at_who}\" ];then at_who=\"${at_who},\\\"${i}\\\"\" else at_who=\"\\\"${i}\\\"\" fi done if [ \"${ding_secret_type}\" == 'keywords' ];then curl -s -X POST -H 'Content-Type: application/json' \"${new_url}\" \\ -d \"{\\\"at\\\":{\\\"atMobiles\\\":[${at_who}]},\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"${send_strs}\\\"}}\" elif [ \"${ding_secret_type}\" == 'sign' ];then timestamp=$(date \"+%s%3N\") dingbot_sign=$(echo -ne \"${timestamp}\\n${dingbot_secret}\" | openssl dgst -sha256 -hmac \"${dingbot_secret}\" -binary | base64) dingbot_sign=$(url_encode 'X' \"${dingbot_sign}\") post_url=\"${dingbot_url}\u0026timestamp=${timestamp}\u0026sign=${dingbot_sign}\" curl -s -X POST -H 'Content-Type: application/json' \"${post_url}\" \\ -d \"{\\\"at\\\":{\\\"atMobiles\\\":[${at_who}]},\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"${send_strs}\\\"}}\" else echo \"secret_type 未知，请检查配置\" fi } dingbot \"hello\" ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:1:2","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"二、python版 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:2:0","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"1、基于关键字或者 ip #!/usr/bin/python3 # encoding: utf-8 import requests import json def dingmsg(): #钉钉机器人的url ding_url = 'https://oapi.dingtalk.com/robot/send?access_token=' #钉钉机器人的token token = 'ba9b7c169caebb1048a66845fa8344348b3e8fdaefxxxxxxxxxxx' #请求的url，webhook的地址 webhook = ding_url+token #构建请求的头部 header = { \"Content-Type\": \"application/json\", \"Charset\": \"UTF-8\" } #构建请求数据 text = \"this is first python to test dingding\" msg = { \"msgtype\": \"text\", \"text\": { \"content\": text, } } #对请求的数据进行封装 msg_json = json.dumps(msg) #发起请求 info = requests.post(url=webhook,data=msg_json,headers=header) #打印返回的结果 print(info.text) if __name__ == \"__main__\": dingmsg() ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:2:1","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"2、基于加签计算 #!/usr/bin/python3 # encoding: utf-8 import requests import json import time import hmac import hashlib import base64 import urllib.parse class dingRobot: def __init__(self): self.dingUrl = 'https://oapi.dingtalk.com/robot/send?access_token=' self.__secret = 'SECc95942d1139feaefcdef6abf33e6497eb3d0120b4ca3dxxxxxxxxxx' self.__token = 'ba9b7c169caebb1048a66845fa8344348b3e8fdaef264e6exxxxxxxxxxxdc' self.__sign = '' self.__timestamp = '' def createTimestampSign(self): self.__timestamp = str(round(time.time() * 1000)) secret_enc = self.__secret.encode('utf-8') string_to_sign = '{}\\n{}'.format(self.__timestamp, self.__secret) string_to_sign_enc = string_to_sign.encode('utf-8') hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest() self.__sign = urllib.parse.quote_plus(base64.b64encode(hmac_code)) def sendMsg(self,text): self.createTimestampSign() # 请求的url，webhook的地址 webhook = self.dingUrl + self.__token + '\u0026timestamp=' + self.__timestamp + '\u0026sign=' + self.__sign # 构建请求的头部 header = { \"Content-Type\": \"application/json\", \"Charset\": \"UTF-8\" } # 构建请求数据 # text = \"this is first python to test dingding\" msg = { \"msgtype\": \"text\", \"text\": { \"content\": text, } } # 对请求的数据进行封装 msg_json = json.dumps(msg) # 发起请求 info = requests.post(url=webhook, data=msg_json, headers=header) return info if __name__ == \"__main__\": robot = dingRobot() result = robot.sendMsg('只是用于测试') if json.loads(result.text)['errcode'] == 0: print(\"发送消息成功\") else: print(\"发送消息失败\") ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:2:2","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["linux 基础"],"content":"服务器中有关常用端口的信息在/etc/services文件中记录 [root@localhost ~]# vim /etc/services 协议 端口 说明 FTP 21 FTP服务上传和下载文件。 SSH 22 远程连接Linux弹性云服务器或者SFTP。 Telnet 23 使用Telnet协议访问网站。 HTTP 80 使用HTTP协议访问网站。 POP3 110 使用POP3协议接受邮件。 IMAP 143 使用IMAP协议接受邮件。 LDAP 389 LDAP端口 HTTPS 443 使用HTTPS协议访问网站。 LDAPS 636 LDAP over SSL SQL Server 1433 SQL Server的TCP端口，用于供SQL Server对外提供服务。 SQL Server 1434 SQL Server的TCP端口，用于返回SQLServer使用了哪个TCP/IP端口。 Oracle 1521 Oracle通信端口，弹性云服务器上部署了Oracle SQL需要放行的端口。 MySQL 3306 MySQL数据库对外提供服务的端口。 Windows Server Remote Desktop Services 3389 Windows远程桌面服务端口，通过这个端口可以连接Windows弹性云服务器。 Postgresql 5432 Postgresql数据库对外提供服务端口 Redis 6379 Redis对外提供服务端口 RabbitMQ 5672/15672 5672是rabbitmq对外提供服务端口，15672是rabbitmq management对外提供服务端口 代理 8080 8080端口常用于WWW代理服务，实现网页浏览，实现网页浏览。如果您使用8080端口，访问网站或使用代理服务器时，需要在IP地址后面加上：8080。安装Apache Tomcat服务后，默认服务端口为8080。 NetBIOS 137、138、139 NetBIOS协议常被用于Windows文件、打印机共享和Samba。·137、138:UDP端口，通过网上邻居传输文件时使用的端口。·139:通过这个端口进入的连接试图获得NetBIOS/SMB服务。 无法访问公有云某些端口 1）问题现象： 访问公有云特定端口，在部分地区部分运营商无法访问，而其它端口访问正常。 2）问题分析： 部分运营商判断如下表的端口为高危端口，默认被屏蔽。 高危端口 协议 端口 TCP 42 135 138 139 444 445 593 1025 1068 1434 3127 3128 3129 3130 UDP 135～139 1026 1027 1028 解决方案： 建议您修改敏感端口为其它非高危端口来承载业务。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-port/:0:0","tags":["port"],"title":"port","uri":"/posts/2023-11-11-port/"},{"categories":["web server"],"content":"Caddy Caddy 是一个 Go 编写的 Web 服务器，类似于 Nginx，Caddy 提供了更加强大的功能，随着 v2 版本发布 Caddy 已经可以作为中小型站点 Web 服务器的另一个选择；相较于 Nginx 来说使用 Caddy 的优势如下: 自动的 HTTPS 证书申请(ACME HTTP/DNS 挑战) 自动证书续期以及 OCSP stapling 等 更高的安全性包括但不限于 TLS 配置以及内存安全等 友好且强大的配置文件支持 支持 API 动态调整配置(有木有人可以搞个 Dashboard？) 支持 HTTP3(QUIC) 支持动态后端，例如连接 Consul、作为 k8s ingress 等 后端多种负载策略以及健康检测等 本身 Go 编写，高度模块化的系统方便扩展(CoreDNS 基于 Caddy1 开发) ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:0:0","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"一、Caddyfile ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:0","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"1、简单使用 在当前目录下新建Caddyfile文件 localhost { respond \"Hello, world!\" } localhost:2016 { respond \"Goodbye, world!\" } 服务管理 # 启动服务 caddy start # 重启服务，重启服务有两种方式 caddy reload curl localhost:2019/load \\ -X POST \\ -H \"Content-Type: text/caddyfile\" \\ --data-binary @Caddyfile # 停止服务 caddy stop ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:1","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"2、静态文件管理 显示文件列表 localhost file_server browse 文件夹作为站点根目录： localhost root * /home/me/mysite file_server ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:2","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"3、反向代理 localhost reverse_proxy 127.0.0.1:9000 ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:3","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"4、启用压缩算法 localhost encode zstd gzip file_server browse ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:4","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"5、多个站点 :8080 { respond \"I am 8080\" } :8081 { respond \"I am 8081\" } 多端口 :8080, :8081 { ... } ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:5","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"6、匹配器 对某一个api使用反向代理 localhost file_server reverse_proxy /api/* 127.0.0.1:9005 # 现在反向代理只会处理所有以/api/开始的请求。 使用环境变量 export SITE_ADDRESS=localhost:9055 {$SITE_ADDRESS} file_server root * /var/www # matcher token: * root /index.html /var/www # matcher token: /index.html root @post /var/www # matcher token: @post 占位符 简写 替换 {dir} {http.request.uri.path.dir} {file} {http.request.uri.path.file} {header.*} {http.request.header.*} {host} {http.request.host} {labels.*} {http.request.host.labels.*} {hostport} {http.request.hostport} {port} {http.request.port} {method} {http.request.method} {path} {http.request.uri.path} {path.*} {http.request.uri.path.*} {query} {http.request.uri.query} {query.*} {http.request.uri.query.*} {re.*.*} {http.regexp.*.*} {remote} {http.request.remote} {remote_host} {http.request.remote.host} {remote_port} {http.request.remote.port} {scheme} {http.request.scheme} {uri} {http.request.uri} {tls_cipher} {http.request.tls.cipher_suite} {tls_version} {http.request.tls.version} {tls_client_fingerprint} {http.request.tls.client.fingerprint} {tls_client_issuer} {http.request.tls.client.issuer} {tls_client_serial} {http.request.tls.client.serial} {tls_client_subject} {http.request.tls.client.subject} {tls_client_certificate_pem} {http.request.tls.client.certificate_pem} {tls_client_certificate_der_base64} {http.request.tls.client.certificate_der_base64} {upstream_hostport} {http.reverse_proxy.upstream.hostport} 在Caddyfile中，紧跟在指令后面的匹配器标记可以限制该指令的范围。匹配器标记可以是以下形式之一： \\* 匹配所有请求（通配符；默认）。 /path 以正斜杠开头以匹配请求路径。 @name 指定一个命名匹配器。 匹配器标记通常是可选的。如果省略匹配器标记，则它与通配符匹配器（*）相同。 命名匹配器 要匹配路径以外的任何内容，请定义一个命名匹配器并使用@name引用它： @postfoo { method POST path /foo/* } reverse_proxy @postfoo localhost:9000 @websockets { header Connection *Upgrade* header Upgrade websocket } reverse_proxy @websockets localhost:6001 file file { root \u003cpaths\u003e try_files \u003cfiles...\u003e try_policy first_exist|smallest_size|largest_size|most_recent_modified split_path \u003cdelims...\u003e } 通过文件进行匹配。 root定义在其中查找文件的目录。默认是当前工作目录，或者root变量 ({http.vars.root})对应的位置 (可以通过root指令设置)。 try_files检查其列表中与重试策略(try_policy)匹配的文件。如果try_policy是first_exist，那么列表中的最后一项可能是一个以=(比如=404)开头的数字，作为后备，将触发以这个数字作为错误码的回调; 该错误也可以使用handle_errors捕获和处理错误。 try_policy 指定如何选择文件。默认为 first_exist . first_exist检查文件是否存在。选择存在的第一个文件。 smallest_size选择大小最小的文件。 largest_size选择最大的文件。 most_recent_modified选择最近修改的文件。 split_path将导致路径在每个要尝试的文件路径中找到的列表中的第一个分隔符处拆分。对于每个拆分值，拆分的左侧（包括分隔符本身）将是尝试的文件路径。例如，/remote.php/dav/使用.php作为分隔符，将尝试文件/remote.php。每个分隔符必须出现在 URI 路径组件的末尾，才能用作拆分分隔符。这是一个小众设置，主要用于为 PHP 站点提供服务。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:6","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"7、地址 有效地址： localhost example.com :443 http://example.com localhost:8080 127.0.0.1 [::1]:2015 example.com/foo/* *.example.com http:// 注意：如果你的站点地址包含主机名或 IP 地址，则会启用自动HTTPS。然而，这种行为纯粹是隐含的，因此它永远不会覆盖任何显式配置。例如，如果站点的地址是http://example.com，则不会激活自动HTTPS，因为该方案是明确的http://。 如果找不到文件，则回退到发出404错误。 file {path}.html {path} =404 header header \u003cfield\u003e [\u003cvalue\u003e] 通过请求头字段进行匹配。 \u003cfield\u003e 是要检查的 HTTP 标头字段的名称。 如果以!为前缀，则该字段必须不存在才能匹配 (省略value参数). \u003cvalue\u003e 是字段必须匹配的值。 如果前缀是*，则执行快速后缀匹配。 如果后缀为*，则执行快速前缀匹配。 如果用*括起来，它将执行快速子字符串匹配。 否则，它是快速精确匹配。 统一集合的不同header字段是“和”的关系。每个字段的多个值之间是“或”的关系。 示例： 匹配请求Connection标头字段包含Upgrade的请求： header Connection *Upgrade* 匹配Foo标头字段包含bar或者baz的请求： @foo { header Foo bar header Foo baz } 匹配根本没有Foo标头字段的请求： @not_foo { header !Foo } ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:7","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"8、片段 可以定义称为片段的特殊块，方法是给它们一个用括号括起来的名称： (redirect) { @http { protocol http } redir @http https://{host}{uri} } 然后你可以在任何你需要的地方重复使用它： import redirect 例如： (snippet) { respond \"Yahaha! You found {args.0}!\" } a.example.com { import snippet \"Example A\" } b.example.com { import snippet \"Example B\" } ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:8","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"9、全局参数 { # General Options debug http_port \u003cport\u003e https_port \u003cport\u003e order \u003cdir1\u003e first|last|[before|after \u003cdir2\u003e] storage \u003cmodule_name\u003e { \u003coptions...\u003e } storage_clean_interval \u003cduration\u003e admin off|\u003caddr\u003e { origins \u003corigins...\u003e enforce_origin } log [name] { output \u003cwriter_module\u003e ... format \u003cencoder_module\u003e ... level \u003clevel\u003e include \u003cnamespaces...\u003e exclude \u003cnamespaces...\u003e } grace_period \u003cduration\u003e # TLS Options auto_https off|disable_redirects|ignore_loaded_certs email \u003cyours\u003e default_sni \u003cname\u003e local_certs skip_install_trust acme_ca \u003cdirectory_url\u003e acme_ca_root \u003cpem_file\u003e acme_eab \u003ckey_id\u003e \u003cmac_key\u003e acme_dns \u003cprovider\u003e ... on_demand_tls { ask \u003cendpoint\u003e interval \u003cduration\u003e burst \u003cn\u003e } key_type ed25519|p256|p384|rsa2048|rsa4096 cert_issuer \u003cname\u003e ... ocsp_stapling off preferred_chains [smallest] { root_common_name \u003ccommon_names...\u003e any_common_name \u003ccommon_names...\u003e } # Server Options servers [\u003clistener_address\u003e] { listener_wrappers { \u003clistener_wrappers...\u003e } timeouts { read_body \u003cduration\u003e read_header \u003cduration\u003e write \u003cduration\u003e idle \u003cduration\u003e } max_header_size \u003csize\u003e protocol { allow_h2c experimental_http3 strict_sni_host } } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:1:9","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"二、使用示例 1、静态文件服务器 example.com { root * /var/www file_server } 像往常一样，第一行是站点地址。该root指令指定站点根目录的路径（*匹配所有请求的方法，以便与路径匹配器消除歧义）；如果站点不是当前工作目录，则更改站点的路径。最后，我们启用静态文件服务器。 2、反向代理服务器 代理所有请求 example.com { reverse_proxy localhost:5000 } 只代理以/api/开头的请求，并为其他所有内容提供静态文件： example.com {} root * /var/www reverse_proxy /api/* localhost:5000 file_server } 3、php 在运行PHP FastCGI服务的情况下，类似这样的内容适用于大多数现代PHP应用程序 example.com root * /var/www php_fastcgi /blog/* localhost:9000 file_server 请对应地调整站点根目录和路径匹配器；此示例假定PHP仅位于/blog/子目录中——所有其他请求将作为静态文件提供。 该php_fastcgi指令实际上只是几个配置的快捷方式。 4、重定向到www.子域名 example.com { redir https://www.example.com{uri} } www.example.com { } www.example.com { redir https://example.com{uri} } example.com { } 5、通配符证书 *.example.com { tls { dns \u003cprovider_name\u003e [\u003cparams...\u003e] } @foo host foo.example.com handle @foo { respond \"Foo!\" } @bar host bar.example.com handle @bar { respond \"Bar!\" } # Fallback for otherwise unhandled domains handle { abort } } 6、web example.com { # 网站的域名信息 tls example.com.pem example.com.key # 证书和密钥的 PEM 格式的文件路径 encode zstd gzip # 启用压缩 root * ./ # 域名映射根路径 file_server # 启动文件服务 } example2.com { # 网站的域名信息 tls example2.com.pem example2.com.key # 证书和密钥的 PEM 格式的文件路径 reverse_proxy localhost:9000 # 反向代理 } ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:2:0","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["web server"],"content":"三、部署 docker-compose.yaml version: \"3.7\" services: caddy: image: caddy:\u003cversion\u003e restart: unless-stopped ports: - \"80:80\" - \"443:443\" volumes: - $PWD/Caddyfile:/etc/caddy/Caddyfile - $PWD/site:/srv - caddy_data:/data - caddy_config:/config volumes: caddy_data: caddy_config: ","date":"2023-11-11","objectID":"/posts/2023-11-11-caddy/:2:1","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2023-11-11-caddy/"},{"categories":["DevOps"],"content":"flatpak ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:0:0","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"简介 Flatpak 是一种新的通用包装格式。启用 Flatpak 将使您能够轻松安装许多 Linux 应用程序。这是在 Ubuntu 和其他 Linux 发行版中使用 Flatpak 的方法。 在 Linux 中安装应用程序就像打开软件中心、搜索和安装一样简单。App Store 中没有的应用程序可以通过 DEB 或 RPM 包安装。其中一些可通过 PPA（用于基于 Debian 的发行版）获得，如果没有，可以从源代码构建。 虽然有一些限制。App Store 通常没有最新版本的应用程序，处理依赖项可能很烦人，而且 PPA 可能并不总是安全的！而且，从源头构建需要一些终端动手操作。 对于多个 Linux 发行版和包管理系统，需要一个通用打包系统，它可以运行应用程序，而不管您使用的是什么 Linux 发行版。Canonical 想到了它并创建了Snaps。还有一个名为AppImage的独立通用软件包 ，您可以在其中下载应用程序并运行它，而无需实际安装应用程序。 除了 Snaps 和AppImage之外，还有另一个名为Flatpak的通用包系统。我们将了解如何在大多数 Linux 发行版上安装和使用 Flatpak 及其优势。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:0:1","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"什么是 Flatpak？ Flatpak基本上是 Linux 上的应用程序框架。由于不同的发行版更喜欢自己的包管理，Flatpak 旨在提供具有其他优势的跨平台解决方案。它使开发人员的工作更加轻松。几乎所有 Linux 发行版（支持 Flatpak）都可以使用单个应用程序构建，而无需对捆绑包进行任何修改。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:1:0","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"Flatpak 的主要优势 除了为不同的 Linux 发行版提供单个捆绑包之外，Flatpak 还提供与 Linux 桌面的集成，从而更容易浏览、安装和使用 Flatpak 应用程序，例如 Gnome 软件中心可用于安装 Flatpak。 Flatpak 是向前兼容的，即相同的 Flatpak 应用程序可以在发行版的下一个版本上运行而无需更改。 维护可以由应用程序使用的运行时依赖项。缺少的可以作为应用程序的一部分添加。 虽然 Flatpak 提供了应用分发的中心化服务，但它完全支持应用的去中心化分发。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:1:1","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"使用 # 查看当前的remote [root@sugar ~]# flatpak remotes # 最方便的方式添加远程仓库是使用 .flatpakrepo 文件，它包含远程仓库的信息和GPG秘钥： [root@sugar ~]# flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo # 移除远程仓库 [root@sugar ~]# flatpak remote-delete flathub # 查询软件 flatpak search gimp # 安装软件 flatpak install flathub org.gimp.GIMP 使用国内镜像 $ flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo $ flatpak remote-modify flathub --url=https://mirror.sjtu.edu.cn/flathub # 或者 $ flatpak remote-add --if-not-exists sjtu https://mirror.sjtu.edu.cn/flathub/flathub.flatpakrepo # 如果您中断了某次安装，重新下载可能会出现找不到文件的问题。您可以使用 flatpak repair 解决相关的问题。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:1:2","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"Daemon 守护进程服务 systemd supervisor launchd ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:0:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"一、supervisor ​ 是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程 supervisor官网：supervisord.org ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"安装supervisor supervisor是用python开发的，支持yum和pip安装 [root@localhost ~]# yum install supervisor [root@localhost ~]# pip3 install supervisor ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:1","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"配置文件 若没有配置文件，可以生成主配置文件模板 [root@localhost ~]# echo_supervisord_conf \u003e /etc/supervisord.conf # 参考链接 http://supervisord.org/configuration.html 配置模板 # 参数可以根据需求进行调整 [program:pock] directory=/home/sugars/pock/backend command=/home/sugars/pock/pock_venv/bin/python3 /home/sugars/pock/backend/sugars.py autostart=true autorestart=true startsecs=7 user = sugars stderr_logfile=/var/log/supervisor/pock-err.log stdout_logfile=/var/log/supervisor/pock.log redirect_stderr = true stdout_logfile_maxbytes = 50MB stdout_logfile_backups = 3 stopasgroup=true killasgroup=true 配置文件读取目录于顺序 # 配置文件明名为supervisor.comf,如果不使用`-c` 指定文件名，则自动匹配的文件路径为 1) ../etc/supervisord.conf 2) ../supervisord.conf 3) $CWD/supervisord.conf 4) $CWD/etc/supervisord.conf 5) /etc/supervisord.conf 6) /etc/supervisor/supervisord.conf systemctl start supervisord ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:2","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"supervisor命令说明 supervisorctl status 查看进程运行状态 supervisorctl start g_name 启动进程 supervisorctl stop g_name 关闭进程 supervisorctl restart g_name 重启进程 supervisorctl update 重新载入配置文件(配置文件修改后使用该命令加载新的配置) supervisorctl shutdown 关闭 supervisord supervisorctl clear g_name 清空进程日志 supervisorctl 进入到交互模式下。使用help查看所有命令。 supervisorctl start/stop/restart + all 表示启动，关闭，重启所有进程 supervisorctl reload //重新启动配置中的所有程序 新添加一个program后的操作 root@serialt:~# supervisorctl update sugar 停止sugar服务 root@serialt:~# supervisorctl stop sugar 启动sugar服务 root@serialt:~# supervisorctl start sugar 重启sugar服务 root@serialt:~# supervisorctl restart sugar ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:3","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"日志管理 在rhel中，supervisord的日志轮转管理是通过调用logrotate来实现的，其配置文件内容是 [root@serialt ~]# cat /etc/logrotate.d/supervisor /var/log/supervisor/*.log { missingok weekly notifempty nocompress } 会自动轮转/var/log/supervisor/*.log的文件，若把用supervisor管理的日志也输入到/var/log/supervisor/里会导致日志文件被轮转成带时间戳的格式 sugar.log sugar.log-20211019 sugar.log-20211026 sugar.log.1 sugar.log.2 sugar.log.3 两种解决办法： 1）修改supervisord的日志记录文件，同时修改supervisord的logrotate配置文件 2）supervisord管理的进程的日志不输出到/var/log/supervisor里 日志压缩 supervisord本身日志只能轮转，不能用于压缩，要实现日志压缩论证，需要借用logrotate [root@tc ~]# cat /etc/logrotate.d/sugar /var/log/sugar/*.log { missingok daily notifempty create 0664 nobody root #dateext #dateformat .%Y%m%d rotate 20 compress delaycompress copytruncate size 10K } ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:4","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"二、systemd 常用命令 systemctl restart foo systemctl stop foo systemctl start foo systemctl status foo systemctl cat foo systemctl daemon-reload 配置模板 [Unit] Description=Gins After=network-online.target Documentation=https://serialt.github.io/ Documentation=https://serialt.github.io on-failure always [Service] Type=simple WorkingDirectory=/usr/local/gin KillSignal=SIGTERM ExecStart=/usr/local/gins/bin/gins start ExecStop=/bin/kill -SIGTERM $MAINPID Restart=on-failure RestartSec=3 TimeoutSec=50 User=gins Group=gins [Install] WantedBy=multi-user.target systemd 236之后的版本可以直接在systemd的unit文件里面配置StandardOutput和StandardError两个参数来将相关运行日志输出到指定的文件中。 [Unit] Description=Gins After=network.target Documentation=https://serialt.github.io/ Documentation=https://serialt.github.io on-failure always [Service] Type=simple WorkingDirectory=/usr/local/gin KillSignal=SIGTERM ExecStart=/usr/local/gins/bin/gins start ExecStop=/bin/kill -SIGTERM $MAINPID # append类型可以在原有文件末尾继续追加内容，而file类型则是重新打开一个新文件 # 两者的区别类似于 echo \u003e\u003e 和 echo \u003e StandardOutput=append:/home/coredns/logs/coredns.log StandardError=append:/home/coredns/logs/coredns_error.log Restart=on-failure RestartSec=3 TimeoutSec=50 User=gins Group=gins [Install] WantedBy=multi-user.target ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:2:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"三、launchd服务 https://www.fythonfang.com/blog/2021/4/19/mac-launchd-daemons-and-agents-tutorial ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"基本概念 launchd 是 MacOS 上用于管理系统级或者用户级后台服务进程的管理工具。也是官方推荐的系统后台进程管理工具，就好像在 Linux 系统里，我们使用 systemd 去管理后台服务进程一样。 launchd 是一个程序，以系统常驻进程的形态运转，是 MacOS 系统启动后的第一个进程，在 Terminal 终端，键入命令 ps aux 可以看到，launchd 的进程ID（PID）是 1。也即这是系统的第一个进程。 与 launchd 交互的工具，叫 launchctl。可以认为是它的管理客户端程序。通过该命令，我们可以发送指令给 launchd 完成对系统服务或后台进程的管理。 launchd 的管理对象都是后台进程，这些后台进程使用一种特定格式的配置文件叫 launchd.plist 来描述被管理的对象。这种文件是 XML 格式的，根据不同的运行权限，放在不同的目录里面，请看下面的表格。 目录 说明 ~/Library/LaunchAgents 用户自己提供的用户级 Agent。 /Library/LaunchAgents 管理员提供的用户级 Agent。 /Library/LaunchDaemons 管理员提供的系统级 Daemon。 /System/Library/LaunchAgents 苹果官方提供的用户级 Agent。 /System/Library/LaunchDaemons 苹果官方提供的系统级 Daemon。 存放 launchd 配置文件的常用目录 通过 launchd 管理的进程，人为被分为了几个种类： 服务（Services）—— 在后台运行，用以支持图形界面应用（GUI App）运行的服务进程，比如响应系统全局快捷键，或者进行网络通信等； 守护进程（Daemons）—— 理论上，不属于服务的后台进程，都归为守护进程一类，不过这里特指运行在后台，且不能与用户交互图形界面产生联系的进程； 代理（Agents）—— 以用户的名义，在后台运行的进程，可以和用户图形界面产生联系，比如呼起一个软件的界面，不过官方不推荐这么用。 一般文件名都以com.domain.programName.plist格式命名，不管是 Daemons 还是 Agents 格式都是一样的，只是存放位置不同。看下面一个 hello world 的例子 ~/Library/LaunchAgents/com.example.hello.plist \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e \u003cplist version=\"1.0\"\u003e \u003cdict\u003e \u003ckey\u003eLabel\u003c/key\u003e \u003cstring\u003ecom.example.hello\u003c/string\u003e \u003ckey\u003eProgramArguments\u003c/key\u003e \u003carray\u003e \u003cstring\u003e/bin/echo\u003c/string\u003e \u003cstring\u003ehello world\u003c/string\u003e \u003c/array\u003e \u003c/dict\u003e \u003c/plist\u003e 上面定义了一个最简单的任务只使用了Label和ProgramAgruments两个键 Label这是个必须的键，指定这个任务名 ProgramArguments是带参数的可执行文件上面等同于运行/bin/echo hello world命令，如果执行的程序不带参数可以使用Program键，但一个任务中必须包含这两个中的其中一个键 还有一些常用的键名，所有的键可参考man 5 launchd.plist或者这里 Keys Description EnvironmentVariables 设置运行环境变量 StandardOutPath 标准输出到文件 StandardErrorPath 标准错误到文件 RunAtLoad 是否再加载的时候就运行 StartInterval 设置程序每隔多少秒运行一次 KeepAlive 是否设置程序是一直存活着 如果退出就重启 UserName 设置用户名只在 Daemons 可用 WorkingDirectory 设置工作目录 # 检查配置 $ plutil ~/Library/LaunchAgents/com.example.hello.plist /Users/fython/Library/LaunchAgents/com.example.hello.plist: OK # 加载配置文件 $ launchctl load ~/Library/LaunchAgents/com.example.hello.plist # 启动服务 $ launchctl start com.example.hello $ cat /tmp/hello.log hello world $ launchctl list | grep hello - 0 com.example.hello $ launchctl remove com.example.hello # remove jobs 一个任务首先需要被加载(load)，然后启动(start)正常运行完退出，所以我们查看/tmp目录下会有日志输出 ​ 1）任务一般都要手动启动(start)，如果设置了RunAtLoad或者KeepAlive则在launchctl load时就启动 ​ 2）使用launchctl list列出当前加载的任务，第一列代表进程id，因为上面的程序运行一次就退出了所以显示-，第二列是程序上次运行退出的code，0代表正常退出，如果是正数代表退出的时候是有错误的，负数代表是接收到信号被终止的 ​ 3）launchctl stop \u003cservice_name\u003e可以终止一个在运行中的任务，launchctl unload \u003cpath\u003e指定路径卸载一个任务，launchctl remove \u003cservice_name\u003e通过服务名卸载任务 ​ 4）launchctl load \u003cpath\u003e只会加载没有被disable的任务，可以加-w参数 launchctl load -w \u003cpath\u003e覆盖如果设置了disable的，下次开机启动一定会起来。launchctl unload \u003cpath\u003e只会停止和卸载这个任务，但下次启动还会加载，可以使用-w参数launchctl unload -w \u003cpath\u003e停止任务，下次启动也不会起来，也就是标记了disable ​ 5）调试一个任务可以配合使用plutil命令检查语法，设置StandardOutPath、StandardErrorPath、Debug键，也可以看看苹果自带的Console.app应用中的system.log ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:1","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"基本操作 # 罗列系统当前运行的进程清单 launchctl list # 查看特定服务的配置信息 launchctl list com.adobe.AdobeCreativeCloud # 加载特定的服务配置 launchctl load \u003cfile_path\u003e # 卸载特定的服务配置 launchctl unload -w /Library/LaunchAgents/com.adobe.AdobeCreativeCloud.plist # 特此说明，-w 参数的作用是，如果自动执行了 load 命令尝试去恢复服务注册，则让其无效 plist 文件配置 www.launchd.info ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:2","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"配置参数 1）配置job名 \u003ckey\u003eLabel\u003c/key\u003e \u003cstring\u003ecom.local.cmd\u003c/string\u003e 2）cmd启动配置 \u003ckey\u003eProgramArguments\u003c/key\u003e \u003carray\u003e \u003cstring\u003e/usr/bin/rsync\u003c/string\u003e \u003cstring\u003e--archive\u003c/string\u003e \u003cstring\u003e--compress-level=9\u003c/string\u003e \u003cstring\u003e/Volumes/Macintosh HD\u003c/string\u003e \u003cstring\u003e/Volumes/Backup\u003c/string\u003e \u003c/array\u003e 执行后命令 /usr/bin/rsync --archive --compress-level=9 \"/Volumes/Macintosh HD\" \"/Volumes/Backup\" 3）环境变量设置 \u003ckey\u003eEnvironmentVariables\u003c/key\u003e \u003cdict\u003e \u003ckey\u003ePATH\u003c/key\u003e \u003cstring\u003e/bin:/usr/bin:/usr/local/bin\u003c/string\u003e \u003c/dict\u003e 3）设置工作目录 \u003ckey\u003eWorkingDirectory\u003c/key\u003e \u003cstring\u003e/tmp\u003c/string\u003e 4）资源限制 \u003ckey\u003eHardResourceLimits\u003c/key\u003e \u003cdict\u003e \u003ckey\u003eFileSize\u003c/key\u003e \u003cinteger\u003e1048576\u003c/integer\u003e \u003c/dict\u003e \u003ckey\u003eSoftResourceLimits\u003c/key\u003e \u003cdict\u003e \u003ckey\u003eFileSize\u003c/key\u003e \u003cinteger\u003e524288\u003c/integer\u003e \u003c/dict\u003e 5）其他 RunAtLoad \u003ckey\u003eRunAtLoad\u003c/key\u003e \u003ctrue/\u003e 每隔多少秒执行 单位 秒 \u003ckey\u003eStartInterval\u003c/key\u003e \u003cinteger\u003e3600\u003c/integer\u003e 定时执行 \u003ckey\u003eStartCalendarInterval\u003c/key\u003e \u003cdict\u003e \u003ckey\u003eHour\u003c/key\u003e \u003cinteger\u003e3\u003c/integer\u003e \u003ckey\u003eMinute\u003c/key\u003e \u003cinteger\u003e0\u003c/integer\u003e \u003c/dict\u003e 可用参数 Month Integer Month of year (1..12, 1 being January) Day Integer Day of month (1..31) Weekday Integer Day of week (0..7, 0 and 7 being Sunday) Hour Integer Hour of day (0..23) Minute Integer Minute of hour (0..59) 示例1： /Library/LaunchDaemons/com.fython.clash.plist \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e \u003cplist version=\"1.0\"\u003e \u003cdict\u003e \u003ckey\u003eLabel\u003c/key\u003e \u003cstring\u003ecom.fython.clash\u003c/string\u003e \u003ckey\u003eRunAtLoad\u003c/key\u003e \u003ctrue/\u003e \u003ckey\u003eUserName\u003c/key\u003e \u003cstring\u003eroot\u003c/string\u003e \u003ckey\u003eStandardErrorPath\u003c/key\u003e \u003cstring\u003e/Users/fython/bin/clash/stderr.log\u003c/string\u003e \u003ckey\u003eStandardOutPath\u003c/key\u003e \u003cstring\u003e/Users/fython/bin/clash/stdout.log\u003c/string\u003e \u003ckey\u003eWorkingDirectory\u003c/key\u003e \u003cstring\u003e/Users/fython/bin/clash\u003c/string\u003e \u003ckey\u003eProgramArguments\u003c/key\u003e \u003carray\u003e \u003cstring\u003e/Users/fython/bin/clash/clash\u003c/string\u003e \u003cstring\u003e-f\u003c/string\u003e \u003cstring\u003econfig.yaml\u003c/string\u003e \u003cstring\u003e-d\u003c/string\u003e \u003cstring\u003e/Users/fython/bin/clash\u003c/string\u003e \u003c/array\u003e \u003ckey\u003eKeepAlive\u003c/key\u003e \u003ctrue/\u003e \u003c/dict\u003e \u003c/plist\u003e ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:3","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DNS"],"content":"CoreDNS 在内网服务中，需要部署内部的 dns，用于各种服务的 dns 解析。常见的 dns server 有 bind，dnsmasq，coredns 等。coredns 出名于用于 kubernetes 中 service 到 ip 的解析，由于是使用 go 开发的，构建的二进制很发布部署使用，同时 coredns 也兼容 bind 的域名解析配置文件。 官网：https://coredns.io/ 参考链接：https://blog.gmem.cc/coredns-study-note ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:0:0","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"一、基本使用 常用插件 bind 指定服务器监听的网络接口（IP地址）： bind ADDRESS … . { bind 127.0.0.1 ::1 } . { bind 127.0.0.1 bind ::1 } autopath 允许服务器端进行的搜索后缀（search domain）补全。如果插件发现客户端查询的名称，匹配search path的第一个元素，则自动遍历search path中的domain链，并返回第一个非NXDOMAIN结果。如果出现失败，则返回原始查询的应答。 由于autopath的应答中的名称，和原始问题不匹配，因此他会在CoreDNS中添加一个CNAME，从原始名称指向应答中的名称。 # ZONE autopath权威负责的Zone # RESOLV-CONF 包含search domain的配置文件。或者指向其它插件，例如@kubernetes，这时从其它插件读取search domain # 配置文件中必须有 search domain1 domain2 ... 这样的行 autopath [ZONE...] RESOLV-CONF cache 实现前端缓存，用于查询后端（Upstream、Database…）成本较高的场景。启用此插件后，除了Zone transfers / Metadata以外的记录会被缓存默认3600s。 # TTL 缓存有效期，单位秒，默认3600 # ZONES 哪些Zone支持缓存 cache [TTL] [ZONES...] { # 成功的DNS应答的缓存配置 success CAPACITY [TTL] [MINTTL] # Denial of existence应答的缓存配置 denial CAPACITY [TTL] [MINTTL] prefetch AMOUNT [[DURATION] [PERCENTAGE%]] } loop 能够检测简单的forwarding循环并终止服务器。 debug 能够从Panic中恢复，用于调试用途 errors 启用错误日志记录，格式： errors { # 在DURATION期间抓取匹配REGEXP的错误日志，聚合为单条日志 consolidate DURATION REGEXP } . { errors { consolidate 5m \".* i/o timeout$\" consolidate 30s \"^Failed to .+\" } } forward 将DNS请求转发给上游DNS服务器，支持DNS / TCP / DNS over TLS。该插件代替原先的proxy插件。 # FROM 匹配此后缀的DNS查询会被转发 # TO 上游服务器的端点，支持指定协议，例如tls://9.9.9.9 forward FROM TO... { # 空格分隔的，不进行转发的域名列表 except IGNORED_NAMES... # 强制基于TCP协议 force_tcp # 优先使用UDP prefer_udp # 多久后丢弃连接， expire DURATION # 判定为不健康需要的连续失败辞书 max_fails INTEGER # DNS over TLS配置 tls CERT KEY CA tls_servername NAME # 选取上游服务器的算法，默认random policy random|round_robin|sequential # 健康检查周期 health_check DURATION } 直接转发，用于兜底的示例： forward . 223.5.5.5 1.1.1.1 使用TLS的示例： forward . tls://9.9.9.9 { tls_servername dns.quad9.net health_check 5s } 强制TCP转发： svc.k8s.gmem.cc { forward . 127.0.0.1:5353 { force_tcp } } 从文件中读取上游DNS： forward . /etc/resolv.conf 如果CoreDNS运行在K8S中，则CoreDNS的Pod的/etc/resolv.conf内容的基础，取决于kubelet的–resolv-conf配置，默认值指向宿主机的/etc/resolv.conf文件。 上游健康检查 首次转发，随机选取一个上游服务器，后续一直使用，直到它不健康了。 当出现一个错误 —— 任何DNS响应都不看作错误（REFUSED, NOTIMPL, SERVFAIL … ）—— 则CoreDNS启动健康检查循环（默认0.5s一次），直到上游服务器恢复健康。 如果max_fails设置为0则不进行健康检查，总是认为上游服务器是健康的。 CoreDNS不向不健康的上游服务器转发请求，如果所有上游服务器都不健康，则随机选取一个转发。 health 启用进程级别的监控检查。示例： health :8080，你可以访问:8080/health获取健康状态。 ready 提供readiness探针。示例： ready localhost:8091 hosts 以/etc/hosts风格提供Zone数据，格式： # FILE 从文件中读取Zone数据，默认从/etc/hosts读取 # ZONES 此插件的权威Zone hosts [FILE [ZONES...]] { # 内联的HOSTS条目 [INLINE] # 修改生成的DNS记录的DNS TTL ttl SECONDS # 禁止自动生成in-addr.arpa或ip6.arpa条目 no_reverse # 重新载入文件的间隔，例如 300ms 1.5h 2h45m reload DURATION # 对于匹配的ZONES，如果此插件没有记录，则由下一个插件处理 fallthrough [ZONES...] } hosts { 172.21.0.1 kdc-1 fallthrough } import 该插件有两个用途： 导入其它配置文件到主配置文件 导入配置片段 格式： import PATTERN log 记录查询日志，格式： # NAMES 匹配的DNS查询被记录 # FORMAT 日志格式， log [NAMES...] [FORMAT] log [NAMES...] [FORMAT] { class CLASSES... } CLASSES 指定哪些RCode会被记录 取值 说明 success 记录成功的请求 denial 记录NXDOMAIN的请求、NOERROR但是没有数据的（nodata，域名存在，但是请求的记录类型没有） error 记录SERVFAIL、NOTIMP、REFUSED等等，任何提示远程服务器不愿意解析请求的应答都包含在内 all 默认，记录所有请求 rewrite 执行内部的消息重写。格式 # FIELD 请求/应答的什么字段需要被重写 # type 请求的TYPE字段 # class 消息的类型 # name 请求中的DNS名称 # answer name 应答中的DNS名称 # ttl TTL值 rewrite [continue|stop] FIELD [FROM TO|FROM TTL] 要重写DNS请求中的名称，使用格式： rewrite [continue|stop] name [exact|prefix|suffix|substring|regex] STRING STRING 示例： rewrite name substring k8s.gmem.cc k8s.gmem.site rewrite name regex (.*)\\.gmem\\.cc {1}.gmem.site rewrite name suffix .gmem.cc. .gmem.site. 要重写DNS响应中的名称，参考： rewrite stop { name regex (.*)\\.gmem\\.site {1}.gmem.site answer name (.*)\\.gmem\\.site {1}.gmem.site } template 提供一个模板，基于请求来动态的生成响应。格式 # CLASS 查询分类，IN或ANY # TYPE 查询类型，A、PTR... ANY匹配所有类型 # ZONE 此模板的Zone template CLASS TYPE [ZONE...] { # 匹配请求DNS名称的正则式 match REGEX... # DNS应答 answer RR additional RR authority RR rcode CODE # 用于解析CNAMEs的上有集群 upstream fallthrough [ZONE...] } 泛域名 使用template插件可以实现泛域名解析，下面是一个例子： template IN A mesh.gmem.cc { match .*\\.mesh\\.gmem\\.cc answer \"{{ .Name }} 60 IN A 10.0.11.11\" fallthrough } 当前版本有一个奇怪的行为： 上述配置导致hosts插件指定的10.0.11.1 mesh.gmem.cc条目失效，必须指定fallthrough才能避免此问题。 启动服务 docker run -d --restart=always --name coredns-srv -p 53:53/udp -v `pwd`/conf:/Conf coredns/c","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:1:0","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"可行的配置 参考链接：https://segmentfault.com/a/1190000022179401 Corefile .:53 { health { lameduck 5s } auto { directory ./zones reload 1m } hosts { 127.0.0.1 local.io ttl 120 reload 1m fallthrough } #chaos CoreDNS-001 info@coredns.io # prometheus 0.0.0.0:0153 log #cache 120 loop errors forward . 114.114.114.114:53 8.8.8.8:53 [2400:3200::1]:53 loadbalance } db.local.com $TTL 3600 ; 记录超时时间 $ORIGIN local.com. ; 指定 origin，下面的@符号可以作为他的别名，注意后面的. ; SOA 格式 [domain_name] IN SOA [域主服务器或主DNS服务器名] [管理员email] (时间信息) @ IN SOA ns1.local.com. admin.local.com. ( 2019071601 ; Serial 4H ; Refresh 1H ; Retry 7D ; Expire 4H ) ; Negative Cache TTL ; 配置 DNS 记录，指向 ns1.local.com @ IN NS ns1 ; 配置 ns1.local.com 的 A 记录, 指向coredns所在的机器 ns1 IN A 192.168.78.51 ; 配置 local.com 的 A 记录，指向网站或其他用途的机器 @ IN A 192.168.78.51 git IN A 192.168.78.51 drone IN A 192.168.78.51 drone-runner IN A 192.168.78.51 www IN A 192.168.78.51 ccc IN A 192.168.78.51 ; 配置泛域名，没有准确的三级子域名的域名全部指向此IPV4地址 * IN A 192.168.78.50 启动服务 docker run -tid -p 53:53/udp -v /yaml/coredns/Corefile:/Corefile -v /yaml/coredns/zones:/zones --name=coredns coredns/coredns ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:1:1","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"二、增加和编译插件 编译安装coredns： coredns官方对于插件的分类基本可以分为三种：Plugins、External Plugins和其他。其中Plugins一般都会被默认编译到coredns的预编译版本中，而External Plugins则不会。官方的文档对外部插件的定义有着明确的解释，主要要求大概是有用、高效、符合标准、文档齐全、通过测试等。 官方给出了一个详细的文档说明，编译插件基本可以分为修改源码和修改编译的配置文件这两种方式，这里我们采用简单高效的修改配置文件的方式进行测试。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:2:0","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"1、编译 下载源码：https://github.com/coredns/coredns.git 在我们前面下载的官方源码中，有一个plugin的目录，里面是各种插件的安装包，同时还有一个plugin.cfg的文件，里面列出了会编译到coredns中的插件， [root@sugar2 coredns]# tail plugin.cfg secondary:secondary etcd:etcd loop:loop forward:forward grpc:grpc erratic:erratic whoami:whoami on:github.com/coredns/caddy/onevent sign:sign git:github.com/miekg/coredns-git 添加一个git插件 git:github.com/miekg/coredns-git 对于在plugin目录下已经存在的插件，则可以直接写成plugin中的目录名，不在的则写插件的仓库，可以使用go get下载： sign:sign 下载插件： go get github.com/miekg/coredns-git 然后我们开始编译 [root@sugar2 coredns]# make ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:2:1","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"2、验证插件 可以使用-plugins输出包含的插件 [root@sugar2 coredns]# ./coredns -plugins Server types: dns Caddyfile loaders: flag default Other plugins: dns.acl dns.any dns.auto dns.autopath dns.azure dns.bind dns.bufsize dns.cache dns.cancel dns.chaos dns.clouddns dns.debug dns.dns64 dns.dnssec dns.dnstap dns.erratic dns.errors dns.etcd dns.file dns.forward dns.geoip dns.git dns.grpc dns.header dns.health dns.hosts dns.k8s_external dns.kubernetes dns.loadbalance dns.local dns.log dns.loop dns.metadata dns.minimal dns.nsid dns.pprof dns.prometheus dns.ready dns.reload dns.rewrite dns.root dns.route53 dns.secondary dns.sign dns.template dns.tls dns.trace dns.transfer dns.whoami on 1）使用git插件 建立存储zones文件的的git仓库：git@local.io:sugar/coredns_zone.git 配置文件模板 .:53 { health { lameduck 5s } auto { directory /usr/local/coredns/zones reload 1m } hosts { ttl 120 reload 1m fallthrough } #chaos CoreDNS-001 info@coredns.io prometheus 0.0.0.0:9153 log cache 300 loop errors forward . 114.114.114.114:53 8.8.8.8:53 [2400:3200::1]:53 loadbalance git git@local.io:sugar/coredns_zone.git /usr/local/coredns/zones { branch master interval 3000 # pull的时间间隔 args --depth=1 pull_args --force } } supervisord [root@ftp coredns]# cat /etc/supervisord.d/coredns.ini [program:coredns] directory=/usr/local/coredns command=/usr/local/coredns/coredns -conf /usr/local/coredns/Corefile autostart=true autorestart=true startsecs=7 user = root stderr_logfile=/var/log/coredns/coredns-err.log stdout_logfile=/var/log/coredns/coredns.log redirect_stderr = true stdout_logfile_maxbytes = 100MB stdout_logfile_backups = 4 stopasgroup=true killasgroup=true ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:2:2","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["虚拟化"],"content":"​ Multipass 是一个轻量虚拟机管理器，是由 Ubuntu 运营公司 Canonical 所推出的开源项目。运行环境支持 Linux、Windows、macOS。在不同的操作系统上，使用的是不同的虚拟化技术。在 Linux 上使用的是 KVM、Window 上使用 Hyper-V、macOS 中使用 HyperKit 以最小开销运行VM，支持在笔记本模拟小型云。Multipass唯一的遗憾是支持Linux版本只有Ubuntu。 同时，Multipass 提供了一个命令行界面来启动和管理 Linux 实例。下载一个全新的镜像需要几秒钟的时间，并且在几分钟内就可以启动并运行 VM。 github地址：https://github.com/canonical/multipass 官网：https://multipass.run/ ","date":"2023-11-11","objectID":"/posts/2023-11-11-multipass/:0:0","tags":["multipass","vm"],"title":"multipass","uri":"/posts/2023-11-11-multipass/"},{"categories":["虚拟化"],"content":"安装 Mac： # 1）brew 安装 brew install --cask multipass # 2)github或者官网下二进制安装 Linux： ubuntu官方只release了snap安装版本 sudo snap install multipass Windows： github下载安装包 ","date":"2023-11-11","objectID":"/posts/2023-11-11-multipass/:0:1","tags":["multipass","vm"],"title":"multipass","uri":"/posts/2023-11-11-multipass/"},{"categories":["虚拟化"],"content":"使用 1）查找可以下载的ubuntu镜像（multipass官方镜像只有ubuntu） [root@sugar ~]$ multipass find Image Aliases Version Description 18.04 bionic 20221014 Ubuntu 18.04 LTS 20.04 focal 20221018 Ubuntu 20.04 LTS 22.04 jammy,lts 20221101.1 Ubuntu 22.04 LTS anbox-cloud-appliance latest Anbox Cloud Appliance charm-dev latest A development and testing environment for charmers docker latest A Docker environment with Portainer and related tools jellyfin latest Jellyfin is a Free Software Media System that puts you in control of managing and streaming your media. minikube latest minikube is local Kubernetes 2）创建虚拟机 参数： -n, --name: 名称 -c, --cpus: cpu核心数, 默认: 1 -m, --mem: 内存大小, 默认: 1G -d, --disk: 硬盘大小, 默认: 5G 创建虚拟机时需要联网下载镜像 # 使用最新版LTS镜像 [root@sugar ~]$ multipass launch -n vm01 -c 1 -m 1G -d 10G # 设置使用的镜像 [root@sugar ~]$ multipass launch focal -n vm01 -c 1 -m 1G -d 10G # 设置网络 # name 网卡名 # mode dhcp方式，auto或者manual，默认auto # mac 设置mac地址 [root@sugar ~]$ multipass launch --network en0 --network name=bridge0,mode=manual 修改配置 [root@sugar ~]$ multipass set local.\u003cinstance-name\u003e.(cpus|disk|memory) xxx 3）与虚拟机交互 # 默认是以ubuntu用户进入 [root@sugar ~]$ multipass shell vm01 # 在虚拟机外执行命令 [root@sugar ~]$ multipass exec vm01 -- pwd 4）启动与关闭 [root@sugar ~]$ multipass start vm01 [root@sugar ~]$ multipass start vm01 vm02 [root@sugar ~]$ multipass start --all [root@sugar ~]$ multipass suspend vm01 [root@sugar ~]$ multipass suspend --all [root@sugar ~]$ multipass stop vm01 [root@sugar ~]$ multipass stop --all [root@sugar ~]$ multipass delete vm01 [root@sugar ~]$ multipass delete --all # 从一个删除的实例中恢复 [root@sugar ~]$ multipass recover keen-yak # 移除一个实例 [root@sugar ~]$ multipass delete keen-yak [root@sugar ~]$ multipass purge [root@sugar ~]$ multipass list No instances found. # 或者 [root@sugar ~]$$ multipass delete --purge keen-yak 5）数据共享 mount $ multipass mount $HOME keen-yak $ multipass info keen-yak … Mounts: /home/michal =\u003e /home/michal # 挂载指定路径 $ multipass mount $HOME keen-yak:/some/path # 查看信息 $ multipass info keen-yak # 卸载 $ multipass umount keen-yak 传输文件 $ multipass transfer keen-yak:/etc/crontab keen-yak:/etc/fstab /home/michal $ ls -l /home/michal/crontab /home/michal/fstab -rw-r--r-- 1 michal michal 722 Oct 18 12:13 /home/michal/crontab -rw-r--r-- 1 michal michal 82 Oct 18 12:13 /home/michal/fstab $ multipass transfer /home/michal/crontab /home/michal/fstab keen-yak: $ multipass exec keen-yak -- ls -l crontab fstab -rw-rw-r-- 1 ubuntu ubuntu 722 Oct 18 12:14 crontab -rw-rw-r-- 1 ubuntu ubuntu 82 Oct 18 12:14 fstab 6）容器自动化 为了保持开发环境和线上环境一致性 同时节省部署时间 multipass 给我们提供了 –cloud-init 选项进行容器启动初始化配置: multipass launch --name ubuntu --cloud-init config.yaml 上面 config.yaml 则是容器的初始化配置文件，例如，我们想在初始化容器的时候，自动下载安装 Node.js，内容如下： #cloud-config runcmd: - curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - - sudo apt-get install -y nodejs runcmd 可以指定容器 首次启动 时运行的命令 凡是用户自定义的cloud-init的配置文件,必须以#cloud-config开头，这是cloud-init识别它的方式。 yaml 配置文件参考链接：https://cloudinit.readthedocs.io/en/latest/topics/examples.html?highlight=lock-passwd#including-users-and-groups ","date":"2023-11-11","objectID":"/posts/2023-11-11-multipass/:0:2","tags":["multipass","vm"],"title":"multipass","uri":"/posts/2023-11-11-multipass/"},{"categories":["Go 基础"],"content":"1、变量定义 var name string var isOk bool // 隐式申明 a := 100 str := \"serialt\" // 批量声明 var ( a string b int c bool d float32 ) // 变量的初始化 var name string = \"github\" var age int = 10 var name, age = \"github\", 11 // 类型推导 var name = \"github\" var age = 11 // 常量声明 const pi = 3.1415 const e = 2.7182 const ( pi = 3.1415 e = 2.7182 ) // const同时声明多个常量时，如果省略了值则表示和上面一行的值相同。 const ( n1 = 100 n2 n3 ) // 枚举 const ( n1 = iota //0 n2 //1 n3 //2 n4 //3 ) // 使用_跳过某些值 const ( n1 = iota //0 n2 //1 _ n4 //3 ) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:1:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"2、流程控制 func ifDemo1() { score := 65 if score \u003e= 90 { fmt.Println(\"A\") } else if score \u003e 75 { fmt.Println(\"B\") } else { fmt.Println(\"C\") } } func forDemo() { for i := 0; i \u003c 10; i++ { fmt.Println(i) } } func forDemo3() { i := 0 for i \u003c 10 { fmt.Println(i) i++ } } // 无限循环 for { 循环体语句 } // switch 语法 func testSwitch3() { n := 7 switch n { case 1, 3, 5, 7, 9: fmt.Println(\"奇数\") case 2, 4, 6, 8: fmt.Println(\"偶数\") default: fmt.Println(n) } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:2:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"3、slice a := []int{1, 2, 3, 4, 5} // 从切片中删除元素 func main() { // 从切片中删除元素 a := []int{30, 31, 32, 33, 34, 35, 36, 37} // 要删除索引为2的元素 a = append(a[:2], a[3:]...) fmt.Println(a) //[30 31 33 34 35 36 37] } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:3:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"4、函数 // 匿名函数 func(x, y int) { fmt.Println(x + y) }(10, 20) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:4:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"结构体 // 嵌套匿名字段 type Address struct { Province string City string } //User 用户结构体 type User struct { Name string Gender string Address //匿名字段 } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:4:1","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"5、编译 Mac 下编译 Linux 和 Windows平台 64位 可执行程序： CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build # go 1.16+版本 CGO_ENABLED=0 GOOS=linux GOARCH=arm64 go build CGO_ENABLED=0 GOOS=windows GOARCH=arm64 go build Linux 下编译 Mac 和 Windows 平台64位可执行程序： CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build Windows下编译Mac平台64位可执行程序： SET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 go build 国内镜像设置 export GOPROXY=https://goproxy.cn,direct export GOPATH=/root/go export GO111MODULE=\"on\" export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:5:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"6、私有仓库设置 go env -w GOPRIVATE=\"github.com/private_org/private_repo\" go env -w GOPRIVATE=\"github.com/private_org\" 强制走ssh协议get私有包代码 [url \"ssh://git@github.com/\"] insteadOf = https://github.com/ # 或者 git config --global url.\"ssh://git@github.com/\".insteadOf https://github.com/ # go get/install 默认是走https的，默认go get发起请求使用的是HTTPS，如果自己的私有服务是HTTP的，则需要配置下。 go env -w GOINSECURE=git.local.com ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:6:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"7、makefile PROJECT_NAME= cli GOBASE=$(shell pwd) GOFILES=$(wildcard *.go) BRANCH := $(shell git symbolic-ref HEAD 2\u003e/dev/null | cut -d\"/\" -f 3) # BRANCH := `git fetch --tags \u0026\u0026 git tag | sort -V | tail -1` # BUILD := $(shell git rev-parse --short HEAD) BUILD_DIR := $(GOBASE)/dist VERSION = $(BRANCH) BuildTime := $(shell date -u '+%Y-%m-%d %H:%M:%S %Z') GitHash := $(shell git rev-parse HEAD) GoVersion = $(shell go version | cut -d \" \" -f 3 ) Maintainer := cccc@gmail.com KEY := wzFdVccccccccccccccc PKGFLAGS := \" -s -w -X 'main.APPVersion=$(VERSION)' -X 'main.GoVersion=$(GoVersion)' -X 'main.BuildTime=$(BuildTime)' -X 'main.GitCommit=$(GitHash)' -X 'main.AesKey=$(KEY)' \" APP_NAME = $(PROJECT_NAME) # go-pkg.v0.1.1-linux-amd64 .PHONY: clean clean: @-rm -rf dist/$(PROJECT_NAME)* .PHONY: serve serve: go run . .PHONY: build build: clean @go build -trimpath -ldflags $(PKGFLAGS) -o \"dist/$(APP_NAME)\" @echo \"\\n******************************\" @echo \" build succeed \" @echo \"******************************\\n\" @ls -la dist/$(PROJECT_NAME)* @echo .PHONY: build-linux build-linux: clean @go mod tidy @GOOS=\"linux\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-amd64\" @GOOS=\"linux\" GOARCH=\"arm64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-arm64\" @echo \"\\n******************************\" @echo \" build linux succeed \" @echo \"******************************\\n\" @ls -la dist/$(PROJECT_NAME)* @echo .PHONY: release release: clean @go mod tidy @GOOS=\"windows\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-windows-amd64.exe\" @GOOS=\"linux\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-amd64\" @GOOS=\"linux\" GOARCH=\"arm64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-arm64\" @GOOS=\"darwin\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-darwin-amd64\" @GOOS=\"darwin\" GOARCH=\"arm64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-darwin-arm64\" @echo \"\\n******************************\" @echo \" release succeed \" @echo \"******************************\\n\" @ls -la dist/$(PROJECT_NAME)* @echo ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:7:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"8、go work 参考链接：https://cloud.tencent.com/developer/article/1970405 go 1.18 新增加 workspace的开发模式， ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:8:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"Go work 使用介绍 1）创建一个workspace [root@tc ~]$ mkdir github [root@tc ~]$ cd github 2）创建包 p1 [root@tc p1]$ tree . . ├── go.mod └── p1.go 0 directories, 2 files [root@tc p1]$ cat p1.go package p1 import \"fmt\" func Hello(obj string) { fmt.Printf(\"Hello %s\\n\", obj) } 3）回到github目录，生成go.work [root@tc github]$ go work init ./p1 [root@tc github]$ cat go.work go 1.18 use ( ./p1 ) 4、创建p2，go [root@tc p2]$ tree . . ├── go.mod └── main.go 0 directories, 2 files [root@tc p2]$ cat main.go package main import ( \"github.com/serialt/p1\" ) func main() { p1.Hello(\"world\") } [root@tc p2]$ go run main.go Hello world 注意：以上操作不能build成二进制文件，因为p2 没有被添加go work里，需要把p2 添加进go work才能使用，可以直接编辑github目录下的go.work，也可使用go work use p2 把p2添加到go work里，然后再执行go build [root@tc p2]$ go build [root@tc p2]$ ls go.mod main.go p2 [root@tc p2]$ ./p2 Hello world 注意：因为此时p1 没有提交到远程git仓库，所以在执行go mod tidy 的时候是会去远程仓库下载解决依赖，可以等p1 开发完后 把p1 提交到远程仓库后再对p2 进行go mod tidy。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:8:1","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"9、依赖版本控制 go 版本依赖库管理方式主要有三种 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:9:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"方式1： v1版本go.mod module github.com/serialt/sugar v2版本go.md module github.com/serialt/sugar/v2 使用库时库名仍然是sugar.xxxx 参考地址 https://github.com/serialt/sugar ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:9:1","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"方式2: github.com/go-git/go-git/v5 使用库时候库名是git，使用库名时候会自动去掉go-，直接使用git。 参考地址： https://github.com/serialt/git-mirror/blob/master/service/github.go ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:9:2","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"方式3： gopkg.in/yaml.v3 参考地址： https://github.com/go-yaml/yaml 使用库是时候是yaml.xxxxx，会自动去掉.v3 注意，以上方式一个repo多个版本共存的基础是需要与go.md对应。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:9:3","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"10、可选参数 type Option func(*OptionSet) func New(opts ...Option){ //下面设置默认值 options:=OptionSet{ A:\"default-a\", B:\"default-b\", C:\"default-c\", } for _,fun:=range opts{ fun(\u0026options) } } //如果我们需要提供option选项,比方说设置A func WithA(a string) Option{ return func(opt *OptionSet){ opt.A=a } } // 使用的时候 a=New(WithA(\"abc\")) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:10:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"11、进程退出 // 进程持续运行 c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGTERM, syscall.SIGINT) s := \u003c-c slog.Info(\"Aborting...\", \"signal\", s) os.Exit(2) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-basic/:11:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["mac"],"content":"Mac 优化 ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:0:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["mac"],"content":"1、mac终端增加颜色，参考centos7 eval \"$(/opt/homebrew/bin/brew shellenv)\" # Setting PATH for Python 3.9 # The original version is saved in .bash_profile.pysave PATH=\"/Library/Frameworks/Python.framework/Versions/3.9/bin:${PATH}\" export PG_HOME=/opt/homebrew/Cellar/postgresql@10/10.17 export PATH export GOPROXY=https://goproxy.cn,direct export GOPATH=/Users/sugar/go export GO111MODULE=\"on\" export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN:$PG_HOME/bin # 参考RHEL console export PS1=\"[\\u@\\h \\W]\\\\$ \" export CLICOLOR=1 export LSCOLORS=ExGxFxdaCxDaDahbadeche export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:1:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["mac"],"content":"2、安装homebrew 参考：http://mirrors.ustc.edu.cn/help/brew.git.html 配置环境变量 [sugar@localhost ~]$ cat ~/.bash_profile # brew 安装其他目录下才需要设置 #eval \"$(/opt/homebrew/bin/brew shellenv)\" export HOMEBREW_BREW_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/brew.git\" export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/homebrew-core.git\" export HOMEBREW_BOTTLE_DOMAIN=\"https://mirrors.ustc.edu.cn/homebrew-bottles\" 安装 /bin/bash -c \"$(curl -fsSL https://cdn.jsdelivr.net/gh/Homebrew/install@HEAD/install.sh)\" 3、去除自动生成.DS_Store文件 .DS_Store是Mac OS保存文件夹的自定义属性的隐藏文件，如文件的图标位置或背景色，相当于Windows的desktop.ini 1）禁止.DS_Store文件的生成： defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUE 2）恢复.DS_Store文件的生成 defaults delete com.apple.desktopservices DSDontWriteNetworkStores 3）删除磁盘上的 .DS_Store,删除当前目录及其子目录下的所有.DS_Store 文件: sudo find . -name '*.DS_Store' -type f -delete 最后重启电脑即可生效！ ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:2:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["mac"],"content":"4、环境变量 eval \"$(/opt/homebrew/bin/brew shellenv)\" export HOMEBREW_BREW_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/brew.git\" export HOMEBREW_BOTTLE_DOMAIN=\"https://mirrors.ustc.edu.cn/homebrew-bottles\" export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/homebrew-core.git\" export PG_HOME=/opt/homebrew/Cellar/postgresql@10/10.17 export GOPROXY=https://goproxy.cn,direct export GOPATH=/Users/sugar/go export GO111MODULE=\"on\" export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN:$PG_HOME/bin export GOPRIVATE=\"local.com,gitee.com/cccccc\" export GOINSECURE=\"local.com\" #export CGO_ENABLED=\"0\" #export PS1='[\\u@\\h \\W]\\$ ' export PS1=\"[\\u@\\h \\W]\\\\$ \" export CLICOLOR=1 export LSCOLORS=ExGxFxdaCxDaDahbadeche export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 function k8s-local(){ unset KUBECONFIG export KUBECONFIG=~/.kube/kubeconfig-local.json kubectl cluster-info kubectl get namespace } function k8s-1(){ unset KUBECONFIG export KUBECONFIG=~/.kube/kubeconfig-1.json kubectl cluster-info kubectl get namespace } alias ll='ls -l' alias lh='ls -lh' #UserIP=$(who -u am i | cut -d\"(\" -f 2 | sed -e \"s/[()]//g\") export HISTTIMEFORMAT=\"[%F %T] [`whoami`] \" export HISTSIZE=99999 export HISTFILESIZE=550 # socket5 proxy(){ export http_proxy=\"http://127.0.0.1:5559\" export https_proxy=\"http://127.0.0.1:5559\" # 设置代理 networksetup -setwebproxy Wi-Fi 127.0.0.1 5559 networksetup -setsecurewebproxy Wi-Fi 127.0.0.1 5559 networksetup -setsocksfirewallproxy Wi-Fi 127.0.0.1 5558 # 打开系统代理 networksetup -setwebproxystate Wi-Fi on networksetup -setsecurewebproxystate Wi-Fi on networksetup -setsocksfirewallproxystate Wi-Fi on ~/Desktop/v2cc/proxy } # 取消设置的代理 noproxy(){ unset http_proxy unset https_proxy networksetup -setwebproxystate Wi-Fi off networksetup -setsecurewebproxystate Wi-Fi off networksetup -setsocksfirewallproxystate Wi-Fi off } export PATH=\"/opt/homebrew/opt/icu4c/bin:$PATH\" export PATH=\"/opt/homebrew/opt/icu4c/sbin:$PATH\" #For compilers to find icu4c you may need to set: export LDFLAGS=\"-L/opt/homebrew/opt/icu4c/lib\" export CPPFLAGS=\"-I/opt/homebrew/opt/icu4c/include\" #For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\"/opt/homebrew/opt/icu4c/lib/pkgconfig\" export PATH=\"/opt/homebrew/opt/node@14/bin:$PATH\" export LDFLAGS=\"-L/opt/homebrew/opt/node@14/lib\" export CPPFLAGS=\"-I/opt/homebrew/opt/node@14/include\" 5、使用bash-completion补全 bash-completion部分已经不兼容，需要使用v2版 brew install bash-completion@2 vim ~/.bash_profile # use bash-completion export BASH_COMPLETION_COMPAT_DIR=\"/opt/homebrew/etc/bash_completion.d\" [[ -r \"/opt/homebrew/etc/profile.d/bash_completion.sh\" ]] \u0026\u0026 . \"/opt/homebrew/etc/profile.d/bash_completion.sh\" 6、kubectl命令补齐 vim ~/.bash_profile kubectl completion bash \u003e /opt/homebrew/etc/bash_completion.d/kubectl # 设置别名 echo 'alias k=kubectl' \u003e\u003e~/.bash_profile echo 'complete -o default -F __start_kubectl k' \u003e\u003e~/.bash_profile 7、应用下载网站 http://mac-torrent-download.net/ https://www.torrentmac.net/ https://mac-torrents.io/ 8 、软件出现 【xxxxx将对您的电脑造成伤害，您应该将它移动到废纸篓】 # 切换到软件或者cmd所在的目录 codesign -f -s - --deep xxxx_app_name # 例如 codesign -f -s - --deep terraform 9、安装“Chromium”已损坏，无法打开。 您应该将它移到废纸篓。 # 因为签名不造成的，执行以下命令 sudo xattr -cr /Applications/Chromium.app 10、配置github代理 # http || https # Host github.com # User git # ProxyCommand nc -v -x 127.0.0.1:5559 %h %p Host github.com User git ProxyCommand nc -v -x 127.0.0.1:5558 %h %p ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:3:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["linux 基础"],"content":"ubuntu 基础 ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:0:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"一、apt源 修改apt源为国内源，主配置文件：/etc/apt/sources.list，配置文件目录：/etc/apt/sources.d，以1804为例。 # 修改 /etc/apt/sources.list deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 修改命令 sudo sed -i \"s@http://.*archive.ubuntu.com@http://repo.huaweicloud.com@g\" /etc/apt/sources.list sudo sed -i \"s@http://.*security.ubuntu.com@http://repo.huaweicloud.com@g\" /etc/apt/sources.list ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:1:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"apt 使用问题 1）apt-get安装中的E: Sub-process /usr/bin/dpkg returned an error code (1)问题 参考网址：https://www.cnblogs.com/orzs/p/10844869.html cd /var/lib/dpkg/ sudo mv info/ info_bak # 现将info文件夹更名 sudo mkdir info # 再新建一个新的info文件夹 sudo apt-get update # 更新 sudo apt-get -f install # 修复 sudo mv info/* info_bak/ # 执行完上一步操作后会在新的info文件夹下生成一些文件，现将这些文件全部移到info_bak文件夹下 sudo rm -rf info # 把自己新建的info文件夹删掉 sudo mv info_bak info # 把以前的info文件夹重新改回名 2）Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend) 解决办法： 第一种情况： 进程中存在与apt相关的正在运行的进程： 首先检查是否在运行apt,apt-get相关的进程 ps aux | grep -i apt 如果存在与apt相关的正在运行的进程，kill掉进程； sudo kill -9 \u003cprocess id\u003e 或者直接简单粗暴的： sudo killall apt apt-get 如果进行完上面的步骤还是无法顺利执行apt-get 操作，则属于第二种情况： 第二种情况： 进程列表中已经没有与apt,apt-get相关的进程在运行，但依然报错，在这种情况下，产生错误的根本原因是lock file。 loack file用于防止两个或多个进程使用相同的数据。 当运行apt或apt-commands时，它会在几个地方创建lock files。 当前一个apt命令未正确终止时，lock file未被删除，因此它们会阻止任何新的apt / apt-get命令实例，比如正在执行apt-get upgrade，在执行过程中直接ctrl+c取消了该操作，很有可能就会造成这种情况。 要解决此问题，首先要删除lock file。 使用lsof命令获取持有lock file的进程的进程ID,依次运行如下命令： lsof /var/lib/dpkg/lock lsof /var/lib/apt/lists/lock lsof /var/cache/apt/archives/lock 需要注意的是，以上命令执行结果如果无返回，说明没有正在运行的进程；如果返回了相应的进程，需要kill掉。 删除所有的lock file sudo rm /var/lib/apt/lists/lock sudo rm /var/cache/apt/archives/lock sudo rm /var/lib/dpkg/lock 最后重新配置一下dpkg： sudo dpkg --configure -a 如果上述命令不出任何错误，就万事大吉了。（我是到这里问题就解决了） 但是有时候，生活总是嫌你不够惨，执行配置命令时可能会出现以下错误： dpkg: error: dpkg frontend is locked by another process 这需要我们额外进行一些操作： 找出正在锁定lock file的进程： lsof /var/lib/dpkg/lock-frontend kill掉输出的进程（如果输出为空则忽略） sudo kill -9 PID 删除lock file并重新配置dpkg: sudo rm /var/lib/dpkg/lock-frontend sudo dpkg --configure -a ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:1:1","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"升级系统 ubuntu 1804 升级到2004 1）切换apt源 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 2）更新和重启系统 apt update apt upgrade reboot 3）更新系统 do-release-upgrade Reading cache Checking package manager Continue running under SSH? This session appears to be running under ssh. It is not recommended to perform a upgrade over ssh currently because in case of failure it is harder to recover. If you continue, an additional ssh daemon will be started at port '1022'. Do you want to continue? Continue [yN] y Starting additional sshd To make recovery in case of failure easier, an additional sshd will be started on port '1022'. If anything goes wrong with the running ssh you can still connect to the additional one. If you run a firewall, you may need to temporarily open this port. As this is potentially dangerous it's not done automatically. You can open the port with e.g.: 'iptables -I INPUT -p tcp --dport 1022 -j ACCEPT' ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:1:2","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"二、安装 docker ubuntu与红帽系列系统不同，在配置apt源时需要先配置要添加的密钥的证书 root@harbor:~# curl -fsSL https://mirrors.huaweicloud.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - root@harbor:~# sudo apt-get install software-properties-common root@harbor:~# add-apt-repository \"deb [arch=amd64] https://mirrors.huaweicloud.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" root@harbor:~# apt-get update root@harbor:~# apt-get install docker-ce ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:2:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"三、vim 设置 ubuntu上默认的许多文件的编辑器是nano，其使用非常不友好，可以修改为vim root@ubuntu:~# sudo select-editor Select an editor. To change later, run 'select-editor'. 1. /bin/nano \u003c---- easiest 2. /usr/bin/vim.basic 3. /usr/bin/vim.tiny 4. /bin/ed Choose 1-4 [1]: 2 # 先择vim.basic，设置好后就可以在编辑一些文件或服务时使用vim ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:3:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"四、exsi 配置 exsi 安装ubuntu2004 报错 multipathd[651]: sda: add missing path multipathd[651]: sda: failed to get udev uid: Invalid argument multipathd[651]: sda: failed to get sysfs uid: Invalid argument multipathd[651]: sda: failed to get sgio uid: No such file or directory multipathd[651]: sda: add missing path multipathd[651]: sda: failed to get udev uid: Invalid argument multipathd[651]: sda: failed to get sysfs uid: Invalid argument multipathd[651]: sda: failed to get sgio uid: No such file or directory 解决办法： https://askubuntu.com/questions/1242731/ubuntu-20-04-multipath-configuration 方法一： exsi虚拟机配置文件中增加 disk.EnableUUID = \"TRUE\" 方法二： # vim defaults { user_friendly_names yes } blacklist { device { vendor \"VMware\" product \"Virtual disk\" } } # 重启 /etc/init.d/multipath-tools restart # 或者 systemctl restart multipathd defaults { user_friendly_names yes } blacklist { devnode \"^(ram|raw|loop|fd|md|dm-|sr|scd|st|sda)[0-9]*\" } ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:4:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"五、network配置 静态IP 1、配置静态ip root@ubuntu:/etc/netplan# pwd /etc/netplan root@ubuntu:/etc/netplan# vim 50-cloud-init.yaml network: version: 2 renderer: networkd ethernets: ens160: dpch4: no addresses: - 192.168.100.17/24 gateway4: 192.168.100.1 nameservers: addresses: - 223.5.5.5 或者 network: ethernets: ens3: dhcp4: no addresses: [192.168.100.141/24] gateway4: 192.168.100.1 nameservers: addresses: [114.114.114.114,8.8.8.8] version: 2 2204开始 network: version: 2 ethernets: ens3: dhcp4: false addresses: [192.168.100.141/24] routes: - to: default via: 192.168.100.1 nameservers: addresses: [114.114.114.114,8.8.8.8] 2、加载配置 root@ubuntu:~# netplan apply #测试网络 root@ubuntu:~# ping baidu.com 3、连接wifi network: version: 2 wifis: wlan0: dhcp4: true access-points: \"sugar\": # ssid name password: \"password\" ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:5:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"六、rc.local 设置 [root@tc ~]# cat /etc/systemd/system/rc-local.service [Unit] Description=/etc/rc.local Compatibility Documentation=man:systemd-rc-local-generator(8) ConditionFileIsExecutable=/etc/rc.local After=network.target [Service] Type=forking ExecStart=/etc/rc.local TimeoutStartSec=0 TimeoutStopSec=30 RemainAfterExit=yes GuessMainPID=no [Install] WantedBy=multi-user.target [root@tc rc.d]# cat rc.local #!/bin/bash date \u003e\u003e /tmp/data.txt exit 0 ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:6:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"七、ssh 服务配置 ubuntu默认不安装openssh-server 1、安装openssl-server root@ubuntu:~# apt-get install openssh-sevrer root@ubuntu:~# systemctl start ssh root@ubuntu:~# systemctl enable ssh # 查询可安装的包所有版本 apt list -a ssh Listing... Done ssh/jammy-updates,jammy-security 1:8.9p1-3ubuntu0.6 all ssh/jammy 1:8.9p1-3 all apt install ssh=1:8.9p1-3 all 2、允许root用户远程登陆 ubuntu默认不允许root用户远程登陆 root@ubuntu:~# vim /etc/ssh/sshd_config 32 #PermitRootLogin prohibit-password 修改为 33 PermitRootLogin yes 打开密钥认证 56 #PasswordAuthentication yes 修改为 57 PasswordAuthentication yes 为root用户设置密码 root@ubuntu:~# passwd root 重启ssh服务 root@ubuntu:~# systemctl restart ssh ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:7:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"八、unsnapd ubuntu 系统卸载snap 停止开机自启 sudo systemctl disable snapd.service sudo systemctl disable snapd.socket sudo systemctl disable snapd.seeded.service 卸载snap安装的软件 # 查询当前系统上snap安装了哪些app snap list # 卸载 sudo snap remove xxxxx_app 禁止重新安装snap sudo vim /etc/apt/preferences.d/nosnap.pref Package: snapd Pin: release a=* Pin-Priority: -10 ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:8:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"九、用户管理 1、用户 Ubuntu系统中存在的是nobody和nogroup 在使用useradd命令创建用户的时候，ubuntu不会为主动为用户创建家目录，其默认的shell也不是bash 创建一个具有家目录的用户，其shell为bash root@ubuntu:~# useradd -m test3 -s /bin/bash # 若没有指定shell，可以进行修改 root@ubuntu:~# chsh -s /bin/bash test1 2、创建用户，非交互式更改密码 root@ubuntu:~# useradd tom root@ubuntu:~# echo tom:jerry | chpasswd 格式：echo username:password | chpasswd 3、sudo权限免密 root@ubuntu:~# vim /etc/sudoers ops_serialt ALL=(ALL) NOPASSWD: ALL 4、ubuntu 2004重置密码 参考链接：https://blog.51cto.com/u_15169172/2793265 1）重启服务器后按e进入grub菜单 2）在linux的一行的最后修改为rw init=/bin/bash 3）按ctrl + x启动系统 按下Ctrl+c可以撤销登录 4）查看根目录是否有写的权限：mount | grep -w / 5）重置密码 确认根目录正处于rw状态后，那就可以直接重置或破解Ubuntu 20.04任何用户的密码了。 重置root密码： passwd root 6）重启 完成重置密码或者破解密码的工作后，重启Ubuntu 20.04，执行以下命令重启服务器： exec /sbin/init ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:9:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["DevOps"],"content":"WSL2 windows上到linux(windows sub system for linux ) ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:0","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"一、安装 wsl 2 如果系统中带有 wsl，则需要升级到 wsl 2。 以管理员身份打开 PowerShell（“开始”菜单 \u003e“PowerShell”\u003e 单击右键 \u003e“以管理员身份运行”），然后输入以下命令： dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 启动虚拟化功能，然后重启windows dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 下载 linux 内核更新包 https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi 修改 wsl 2 为默认的版本 wsl --set-default-version 2 下载 linux 发行版 Ubuntu 20.04 Ubuntu 20.04 ARM Ubuntu 18.04 Ubuntu 18.04 ARM Ubuntu 16.04 Debian GNU/Linux Kali Linux SUSE Linux Enterprise Server 12 SUSE Linux Enterprise Server 15 SP2 openSUSE Leap 15.2 Fedora Remix for WSL 将获得 \u003cdistro\u003e.appx 包 导入系统 app-name 是 Linux 发行版 .appx 文件的名称。 Add-AppxPackage .\\app_name.appx ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:1","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"二、wsl 基本命令 wsl 常用命令 # 安装特定的linux发行版 wsl -d \u003cDistribution Name\u003e # 列出可用的 Linux 发行版 wsl -l -o # 列出已安装的 Linux 发行版 wsl --list --verbose # 将 WSL 版本设置为 1 或 2 wsl --set-version 2 # 设置默认 WSL 版本 wsl --set-default-version \u003cVersion\u003e wsl --set-default-version 2 # 设置默认 Linux 发行版 wsl --set-default \u003cDistribution Name\u003e # 将目录更改为主页 wsl ~ # 通过 PowerShell 或 CMD 运行特定的 Linux 发行版 wsl --distribution \u003cDistribution Name\u003e --user \u003cUser Name\u003e # 启动一个发行版 wsl -d Ubuntu-20.04 -u root 更新 WSL wsl --update 回滚wsl版本 wsl --update rollback 检查 WSL 状态 wsl --status 以特定用户的身份运行 wsl -u \u003cUsername\u003e 更改发行版的默认用户 \u003cDistributionName\u003e config --default-user \u003cUsername\u003e # ubuntu config --default-user johndoe 会将 Ubuntu 发行版的默认用户更改为“johndoe”用户。 关闭 wsl --shutdown 内存限制 .wslconfig 文件 关闭一个发行版 wsl --terminate \u003cDistribution Name\u003e 将发行版导出到 TAR 文件 wsl --export \u003cDistribution Name\u003e \u003cFileName\u003e 导入新发行版 wsl --import \u003cDistribution Name\u003e \u003cInstallLocation\u003e \u003cFileName\u003e 注销或卸载 Linux 发行版，注销后就被删除，注意！！！ wsl --unregister \u003cDistributionName\u003e 装载磁盘或设备 wsl --mount \u003cDiskPath\u003e 安装特定的linux发行版 wsl -d \u003cDistribution Name\u003e wsl 配置文件 https://docs.microsoft.com/zh-cn/windows/wsl/wsl-config ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:2","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"三、发行版维护 1、迁移工作目录 wsl 默认安装c盘里，c盘因为硬盘分区的问题，可能分配空间比较小，因此可能存在需要迁移的操作。 1）关闭运行的系统 PS C:\\Users\\serialt\u003e PS C:\\Users\\serialt\u003e wsl -l -v NAME STATE VERSION * Ubuntu-20.04 Running 2 docker-desktop Stopped 2 docker-desktop-data Stopped 2 PS C:\\Users\\serialt\u003e wsl --shutdown PS C:\\Users\\serialt\u003e wsl -l -v NAME STATE VERSION * Ubuntu-20.04 Stopped 2 docker-desktop Stopped 2 docker-desktop-data Stopped 2 PS C:\\Users\\serialt\u003e 2）导出与导入发行版 wsl --export docker-desktop-data \"E:\\wsl\\docker-data\\docker-desktop-data.tar\" wsl --unregister docker-desktop-data wsl --import docker-desktop-data D:\\docker\\desktop \"E:\\wsl\\docker-data\\docker-desktop-data.tar\" --version 2 wsl --export docker-desktop \"E:\\wsl\\docker-data\\docker-desktop.tar\" wsl --unregister docker-desktop wsl --import docker-desktop D:\\docker\\desktop \"E:\\wsl\\docker-data\\docker-desktop.tar\" --version 2 ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:3","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"四、自定义发行版 参考链接：https://docs.microsoft.com/zh-cn/windows/wsl/use-custom-distro 通过使用 tar 文件导入任何 Linux 发行版，可在适用于 Linux 的 Windows 子系统 (WSL) 中使用该发行版（即使它不在 Microsoft Store 中提供）。 本文演示了如何通过使用 Docker 容器获取 Linux 发行版 CentOS 的 tar 文件来将它导入，以便与 WSL 一起使用。 此过程可应用于导入任何 Linux 发行版。 1、获取发行版的tar文件 首先，需要获取一个 tar 文件，其中包含发行版的所有 Linux 二进制文件。 可通过多种方式获取 tar 文件，其中两种方式包括： 下载提供的 tar 文件。 可在 Alpine Linux 下载站点的“微型根文件系统”部分找到 Alpine 的示例。 查找 Linux 发行版容器，将实例导出为 tar 文件。 以下示例将使用 CentOS 容器演示此过程。 获取CentOS的tar文件 从容器中导出tar文件 [root@tc tabby]# docker pull rockylinux Using default tag: latest latest: Pulling from library/rockylinux 72a2451028f1: Pull complete Digest: sha256:5fed5497b568bcf7a90a00965987fc099edbcf44b1179a5ef6d4b47758281ca5 Status: Downloaded newer image for rockylinux:latest docker.io/library/rockylinux:latest [root@tc tabby]# docker run -tid --name=rocky rockylinux 38b201fca776cc1aadf029cbf5a1d6a1fb57ff62f5d71d4ed0416d870b407550 [root@tc tabby]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 38b201fca776 rockylinux \"/bin/bash\" 4 seconds ago Up 2 seconds rocky [root@tc tabby]# [root@tc tabby]# dockerContainerID=$(docker container ls -a | grep -i rocky | awk '{print $1}') [root@tc tabby]# docker export $dockerContainerID \u003e /mnt/e/rocky.tar [root@tc tabby]# du -sh /mnt/e/rocky.tar 202M /mnt/e/rocky.tar 2、导入到wsl中 准备好 tar 文件后，可使用以下命令导入它：wsl --import \u003cDistro\u003e \u003cInstallLocation\u003e \u003cFileName\u003e。 # 创建好存储发行版的目录 cd E:\\wsl2 mkdir E:\\wsl2\\Rocky # 导入tar文件 PS E:\\wsl2\u003e wsl --import Rocky E:\\wsl2\\Rocky ..\\rocky.tar PS E:\\wsl2\u003e wsl -l -v NAME STATE VERSION * docker-desktop-data Stopped 2 Rocky Stopped 2 docker-desktop Stopped 2 Ubuntu-20.04 Running 2 PS E:\\wsl2\u003e 3、启动 wsl -d Rocky -u root 自定义的发行版可能存在因使用system管理服务而无法使用service去管理服务 ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:4","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"五、wsl 配置文件 1、wsl.conf ​```toml [root@tc tcs]# cat /etc/wsl.conf # Automatically mount Windows drive when the distribution is launched [automount] # Set to true will automount fixed drives (C:/ or D:/) with DrvFs under the root directory set above. Set to false means drives won't be mounted automatically, but need to be mounted manually or with fstab. enabled = true # Sets the directory where fixed drives will be automatically mounted. This example changes the mount location, so your C-drive would be /c, rather than the default /mnt/c. #root = /mnt/d/serialt/ # DrvFs-specific options can be specified. options = \"metadata,uid=1003,gid=1003,umask=077,fmask=11,case=off\" # Sets the `/etc/fstab` file to be processed when a WSL distribution is launched. mountFsTab = true # Network host settings that enable the DNS server used by WSL 2. This example changes the hostname, sets generateHosts to false, preventing WSL from the default behavior of auto-generating /etc/hosts, and sets generateResolvConf to false, preventing WSL from auto-generating /etc/resolv.conf, so that you can create your own (ie. nameserver 1.1.1.1). [network] hostname = tc generateHosts = true generateResolvConf = true # Set whether WSL supports interop process like launching Windows apps and adding path variables. Setting these to false will block the launch of Windows processes and block adding $PATH environment variables. [interop] enabled = false appendWindowsPath = true # Set the user when launching a distribution with WSL. [user] default = root # Set a command to run when a new WSL instance launches. This example starts the Docker container service. [boot] command = service docker start [root@tc tcs]# ​``` ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:5","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["Go 库文档"],"content":"gopsutil 库 参考链接：https://segmentfault.com/a/1190000022281174 ","date":"2023-11-11","objectID":"/posts/2023-11-11-gopsutil/:1:0","tags":["Go","gopsutil"],"title":"Go gopsutil","uri":"/posts/2023-11-11-gopsutil/"},{"categories":["Go 库文档"],"content":"简介 gopsutil是 Python 工具库psutil 的 Golang 移植版，可以帮助我们方便地获取各种系统和硬件信息。gopsutil为我们屏蔽了各个系统之间的差异，具有非常强悍的可移植性。有了gopsutil，我们不再需要针对不同的系统使用syscall调用对应的系统方法。更棒的是gopsutil的实现中没有任何cgo的代码，使得交叉编译成为可能。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-gopsutil/:1:1","tags":["Go","gopsutil"],"title":"Go gopsutil","uri":"/posts/2023-11-11-gopsutil/"},{"categories":["Go 库文档"],"content":"快速使用 安装 go get github.com/shirou/gopsutil 使用 package main import ( \"fmt\" \"github.com/shirou/gopsutil/mem\" ) func main() { v, _ := mem.VirtualMemory() fmt.Printf(\"Total: %v, Available: %v, UsedPercent:%f%%\\n\", v.Total, v.Available, v.UsedPercent) fmt.Println(v) } gopsutil将不同的功能划分到不同的子包中： cpu：CPU 相关； disk：磁盘相关； docker：docker 相关； host：主机相关； mem：内存相关； net：网络相关； process：进程相关； winservices：Windows 服务相关。 想要使用对应的功能，要导入对应的子包。例如，上面代码中，我们要获取内存信息，导入的是mem子包。mem.VirtualMemory()方法返回内存信息结构mem.VirtualMemoryStat，该结构有丰富的字段，我们最常使用的无外乎Total（总内存）、Available（可用内存）、Used（已使用内存）和UsedPercent（内存使用百分比）。mem.VirtualMemoryStat还实现了fmt.Stringer接口，以 JSON 格式返回内存信息。语句fmt.Println(v)会自动调用v.String()，将返回信息输出。程序输出： Total: 8526921728, Available: 3768975360, UsedPercent:55.000000% {\"total\":8526921728,\"available\":3768975360,\"used\":4757946368,\"usedPercent\":55,\"free\":0,\"active\":0,\"inactive\":0,\"wired\":0,\"laundry\":0,\"buffers\":0,\"cached\":0,\"writeback\":0,\"dirty\":0,\"writebacktmp\":0,\"shared\":0,\"slab\":0,\"sreclaimable\":0,\"sunreclaim\":0,\"pagetables\":0,\"swapcached\":0,\"commitlimit\":0,\"committedas\":0,\"hightotal\":0,\"highfree\":0,\"lowtotal\":0,\"lowfree\":0,\"swaptotal\":0,\"swapfree\":0,\"mapped\":0,\"vmalloctotal\":0,\"vmallocused\":0,\"vmallocchunk\":0,\"hugepagestotal\":0,\"hugepagesfree\":0,\"hugepagesize\":0} 单位为字节，我的电脑内存 8GB，当前使用百分比为 55%，可用内存 3768975360B（即 3.51GB）。 CPU 我们知道 CPU 的核数有两种，一种是物理核数，一种是逻辑核数。物理核数就是主板上实际有多少个 CPU，一个物理 CPU 上可以有多个核心，这些核心被称为逻辑核。gopsutil中 CPU 相关功能在cpu子包中，cpu子包提供了获取物理和逻辑核数、CPU 使用率的接口： Counts(logical bool)：传入false，返回物理核数，传入true，返回逻辑核数； Percent(interval time.Duration, percpu bool)：表示获取interval时间间隔内的 CPU 使用率，percpu为false时，获取总的 CPU 使用率，percpu为true时，分别获取每个 CPU 的使用率，返回一个[]float64类型的值。 例如： func main() { physicalCnt, _ := cpu.Counts(false) logicalCnt, _ := cpu.Counts(true) fmt.Printf(\"physical count:%d logical count:%d\\n\", physicalCnt, logicalCnt) totalPercent, _ := cpu.Percent(3*time.Second, false) perPercents, _ := cpu.Percent(3*time.Second, true) fmt.Printf(\"total percent:%v per percents:%v\", totalPercent, perPercents) } 上面代码获取物理核数和逻辑核数，并获取 3s 内的总 CPU 使用率和每个 CPU 各自的使用率，程序输出（注意每次运行输出可能都不相同）： physical count:4 logical count:8 total percent:[30.729166666666668] per percents:[32.64248704663213 26.94300518134715 44.559585492227974 23.958333333333336 36.787564766839374 20.3125 38.54166666666667 28.125] 详细信息调用cpu.Info()可获取 CPU 的详细信息，返回[]cpu.InfoStat： func main() { infos, _ := cpu.Info() for _, info := range infos { data, _ := json.MarshalIndent(info, \"\", \" \") fmt.Print(string(data)) } } 为了方便查看，我使用 JSON 输出结果： { \"cpu\": 0, \"vendorId\": \"GenuineIntel\", \"family\": \"198\", \"model\": \"\", \"stepping\": 0, \"physicalId\": \"BFEBFBFF000906E9\", \"coreId\": \"\", \"cores\": 8, \"modelName\": \"Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz\", \"mhz\": 3601, \"cacheSize\": 0, \"flags\": [], \"microcode\": \"\" } 由结果可以看出，CPU 是 Intel 的 i7-7700 系列，频率 3.60GHz。上面是我在 Windows 上运行的返回结果，内部使用了github.com/StackExchange/wmi库。在 Linux 下每个逻辑 CPU 都会返回一个InfoStat结构。 时间占用 调用cpu.Times(percpu bool)可以获取从开机算起，总 CPU 和 每个单独的 CPU 时间占用情况。传入percpu=false返回总的，传入percpu=true返回单个的。每个 CPU 时间占用情况是一个TimeStat结构： // src/github.com/shirou/gopsutil/cpu/cpu.go type TimesStat struct { CPU string `json:\"cpu\"` User float64 `json:\"user\"` System float64 `json:\"system\"` Idle float64 `json:\"idle\"` Nice float64 `json:\"nice\"` Iowait float64 `json:\"iowait\"` Irq float64 `json:\"irq\"` Softirq float64 `json:\"softirq\"` Steal float64 `json:\"steal\"` Guest float64 `json:\"guest\"` GuestNice float64 `json:\"guestNice\"` } CPU：CPU 标识，如果是总的，该字段为cpu-total，否则为cpu0、cpu1…； User：用户时间占用（用户态）； System：系统时间占用（内核态）； Idle：空闲时间； … 例如： func main() { infos, _ := cpu.Times(true) for _, info := range infos { data, _ := json.MarshalIndent(info, \"\", \" \") fmt.Print(string(data)) } } 为了方便查看，我用 JSON 输出结果，下面是其中一个输出： { \"cpu\": \"cpu0\", \"user\": 674.46875, \"system\": 1184.984375, \"idle\": 7497.1875, \"nice\": 0, \"iowait\": 0, \"irq\": 75.578125, \"softirq\": 0, \"steal\": 0, \"guest\": 0, \"guestNice\": 0 } 磁盘 子包disk用于获取磁盘信息。disk可获取 IO 统计、分区和使用率信息。下面依次介绍。 IO 统计 调用disk.IOCounters()函数，返回的 IO 统计信息用map[string]IOCountersStat类型表示。每个分区一个结构，键为分区名，值为统计信息。这里摘取统计","date":"2023-11-11","objectID":"/posts/2023-11-11-gopsutil/:1:2","tags":["Go","gopsutil"],"title":"Go gopsutil","uri":"/posts/2023-11-11-gopsutil/"},{"categories":["Go 库文档"],"content":"Go 读取yaml格式配置文件 package config import ( \"fmt\" \"io/ioutil\" \"gopkg.in/yaml.v3\" ) type Service struct { Host string `json:\"host\" yaml:\"host\"` Port string `json:\"port\" yaml:\"port\"` } type MyConfig struct { Service Service `json:\"service\" yaml:\"service\"` } var Config *MyConfig func LoadConfig(filepath string) { if filepath == \"\" { return } // 读yaml文件 config, err := ioutil.ReadFile(filepath) if err != nil { fmt.Printf(\"read config failed, please check the path: %v , err: %v\", filepath, err) } err = yaml.Unmarshal(config, \u0026Config) if err != nil { fmt.Printf(\"Unmarshal to struct, err: %v\", err) } fmt.Printf(\"LoadConfig: %v\", Config) } // 写yaml文件 data, err := yaml.Marshal(SkopeoData) if err != nil { slog.Error(\"yaml marshal failed\", \"err\", err) return } err = os.WriteFile(config.AutoSyncfile, data, 0644) if err != nil { slog.Error(\"Write auto sync data to file failed\", \"err\", err) } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-yaml/:1:0","tags":["Go","yaml"],"title":"Go yaml","uri":"/posts/2023-11-11-go-yaml/"},{"categories":["Go 库文档"],"content":"Go语言内置包之strconv Go语言中strconv包实现了基本数据类型和其字符串表示的相互转换。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:0","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"strconv包 strconv包实现了基本数据类型与其字符串表示的转换，主要有以下常用函数： Atoi()、Itia()、parse系列、format系列、append系列。 更多函数请查看官方文档。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:1","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"string与int类型转换 这一组函数是我们平时编程中用的最多的。 Atoi() Atoi()函数用于将字符串类型的整数转换为int类型，函数签名如下。 func Atoi(s string) (i int, err error) 如果传入的字符串参数无法转换为int类型，就会返回错误。 s1 := \"100\" i1, err := strconv.Atoi(s1) if err != nil { fmt.Println(\"can't convert to int\") } else { fmt.Printf(\"type:%T value:%#v\\n\", i1, i1) //type:int value:100 } Itoa() Itoa()函数用于将int类型数据转换为对应的字符串表示，具体的函数签名如下。 func Itoa(i int) string 示例代码如下： i2 := 200 s2 := strconv.Itoa(i2) fmt.Printf(\"type:%T value:%#v\\n\", s2, s2) //type:string value:\"200\" a的典故 【扩展阅读】这是C语言遗留下的典故。C语言中没有string类型而是用字符数组(array)表示字符串，所以Itoa对很多C系的程序员很好理解。 Parse系列函数 Parse类函数用于转换字符串为给定类型的值：ParseBool()、ParseFloat()、ParseInt()、ParseUint()。 ParseBool() func ParseBool(str string) (value bool, err error) 返回字符串表示的bool值。它接受1、0、t、f、T、F、true、false、True、False、TRUE、FALSE；否则返回错误。 ParseInt() func ParseInt(s string, base int, bitSize int) (i int64, err error) 返回字符串表示的整数值，接受正负号。 base指定进制（2到36），如果base为0，则会从字符串前置判断，”0x”是16进制，”0”是8进制，否则是10进制； bitSize指定结果必须能无溢出赋值的整数类型，0、8、16、32、64 分别代表 int、int8、int16、int32、int64； 返回的err是*NumErr类型的，如果语法有误，err.Error = ErrSyntax；如果结果超出类型范围err.Error = ErrRange。 ParseUnit() func ParseUint(s string, base int, bitSize int) (n uint64, err error) ParseUint类似ParseInt但不接受正负号，用于无符号整型。 ParseFloat() func ParseFloat(s string, bitSize int) (f float64, err error) 解析一个表示浮点数的字符串并返回其值。 如果s合乎语法规则，函数会返回最为接近s表示值的一个浮点数（使用IEEE754规范舍入）。 bitSize指定了期望的接收类型，32是float32（返回值可以不改变精确值的赋值给float32），64是float64； 返回值err是*NumErr类型的，语法有误的，err.Error=ErrSyntax；结果超出表示范围的，返回值f为±Inf，err.Error= ErrRange。 代码示例 b, err := strconv.ParseBool(\"true\") f, err := strconv.ParseFloat(\"3.1415\", 64) i, err := strconv.ParseInt(\"-2\", 10, 64) u, err := strconv.ParseUint(\"2\", 10, 64) 这些函数都有两个返回值，第一个返回值是转换后的值，第二个返回值为转化失败的错误信息。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:2","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"Format系列函数 Format系列函数实现了将给定类型数据格式化为string类型数据的功能。 FormatBool() func FormatBool(b bool) string 根据b的值返回”true”或”false”。 FormatInt() func FormatInt(i int64, base int) string 返回i的base进制的字符串表示。base 必须在2到36之间，结果中会使用小写字母’a’到’z’表示大于10的数字。 FormatUint() func FormatUint(i uint64, base int) string 是FormatInt的无符号整数版本。 FormatFloat() func FormatFloat(f float64, fmt byte, prec, bitSize int) string 函数将浮点数表示为字符串并返回。 bitSize表示f的来源类型（32：float32、64：float64），会据此进行舍入。 fmt表示格式：’f’（-ddd.dddd）、’b’（-ddddp±ddd，指数为二进制）、’e’（-d.dddde±dd，十进制指数）、’E’（-d.ddddE±dd，十进制指数）、’g’（指数很大时用’e’格式，否则’f’格式）、’G’（指数很大时用’E’格式，否则’f’格式）。 prec控制精度（排除指数部分）：对’f’、’e’、’E’，它表示小数点后的数字个数；对’g’、’G’，它控制总的数字个数。如果prec 为-1，则代表使用最少数量的、但又必需的数字来表示f。 代码示例 s1 := strconv.FormatBool(true) s2 := strconv.FormatFloat(3.1415, 'E', -1, 64) s3 := strconv.FormatInt(-2, 16) s4 := strconv.FormatUint(2, 16) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:3","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"其他 isPrint() func IsPrint(r rune) bool 返回一个字符是否是可打印的，和unicode.IsPrint一样，r必须是：字母（广义）、数字、标点、符号、ASCII空格。 CanBackquote() func CanBackquote(s string) bool 返回字符串s是否可以不被修改的表示为一个单行的、没有空格和tab之外控制字符的反引号字符串。 其他 除上文列出的函数外，strconv包中还有Append系列、Quote系列等函数。具体用法可查看官方文档。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:4","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"Go tail库 实时读取文件内容 go get github.com/hpcloud/tail 示例： package main import ( \"fmt\" \"time\" \"github.com/hpcloud/tail\" ) func main() { fileName := \"./my.log\" config := tail.Config{ ReOpen: true, // 重新打开 Follow: true, // 是否跟随 Location: \u0026tail.SeekInfo{Offset: 0, Whence: 2}, // 从文件的哪个地方开始读 MustExist: false, // 文件不存在不报错 Poll: true, } tails, err := tail.TailFile(fileName, config) if err != nil { fmt.Println(\"tail file failed, err:\", err) return } var ( line *tail.Line ok bool ) for { line, ok = \u003c-tails.Lines if !ok { fmt.Printf(\"tail file close reopen, filename:%s\\n\", tails.Filename) time.Sleep(time.Second) continue } fmt.Println(\"line:\", line.Text) } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-tail/:1:0","tags":["Go","tail"],"title":"Go tail","uri":"/posts/2023-11-11-go-tail/"},{"categories":["Go 库文档"],"content":"Go语言标准库net包介绍 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-net/:1:0","tags":["Go","net"],"title":"Go net","uri":"/posts/2023-11-11-go-net/"},{"categories":["Go 库文档"],"content":"一、域名解析 DNS 记录是与 DNS 服务器关联的映射文件，无论每个域名与哪个 IP 地址关联，它们都能处理发送到每个域名的请求。net 包包含各种方法来查找 DNS 记录的细节。让我们运行一些示例，收集有关 DNS 服务器的信息以及目标域名的相应记录： 本文是 Go语言中文网组织的 GCTT 翻译，发布在 Go语言中文网公众号，转载请联系我们授权。 1、Go 程序查找域名的 A 记录 net.LookupIP() 函数接受一个字符串（domain-name）并返回一个包含主机的 IPv4 和 IPv6 地址的 net.IP 对象切片。 package main import ( \"fmt\" \"net\" ) func main() { iprecords, _ := net.LookupIP(\"facebook.com\") for _, ip := range iprecords { fmt.Println(ip) } } 上述程序的输出列出了以 IPv4 和 IPv6 格式返回的 facebook.com 的 A 记录。 C:\\golang\\dns\u003e Go run example1.go 2a03:2880:f12f:83:face:b00c:0:25de 31.13.79.35 2、Go 程序查找域名的 CNAME 记录 CNAME 是规范名称的缩写。CNAME 本质上是绑定路径的域名和子域名的文本别名。net.LookupCNAME() 函数接受主机域名（m.facebook.com）作为字符串，并返回给定主机的单个规范域名 package main import ( \"fmt\" \"net\" ) func main() { cname, _ := net.LookupCNAME(\"m.facebook.com\") fmt.Println(cname) } m.facebook.com 域名返回的 CNAME 记录如下所示： C:\\golang\\dns\u003e Go run example2.go star-mini.c10r.facebook.com。 3、Go 程序查找域名的 PTR 指针记录 这些记录提供从地址到名称的反向绑定。PTR 记录应与正向记录完全匹配。net.LookupAddr() 函数对地址执行反向查找，并返回映射到给定地址的名称列表。 package main import ( \"fmt\" \"net\" ) func main() { ptr, _ := net.LookupAddr(\"6.8.8.8\") for _, ptrvalue := range ptr { fmt.Println(ptrvalue) } } 对于给定的地址，上述程序返回单个反向记录，如下所示： C:\\golang\\dns\u003ego run example3.go tms_server.yuma.army.mil. 4、Go 程序查找域名的名称服务器（NS）记录 NS 记录描述了区域的授权名称服务器。NS 还将子域名委托给区域文件上的其他组织。net.LookupNS() 函数将域名（facebook.com）作为字符串，并返回 DNS-NS 记录作为 NS 结构的切片。 package main import ( \"fmt\" \"net\" ) func main() { nameserver, _ := net.LookupNS(\"facebook.com\") for _, ns := range nameserver { fmt.Println(ns) } } 支持该域名的 NS 记录如下所示： C:\\golang\\dns\u003ego run example4.go \u0026{a.ns.facebook.com.} \u0026{b.ns.facebook.com.} 5、Go 程序查找域的 MX 记录 这些记录用来记录可以交换电子邮件的服务器。net.LookupMX() 函数将域名作为字符串，并返回按首选项排序的 MX 结构切片。MX 结构由类型为字符串的 HOST 和 类型为 uint16 的 Pref 组成。 package main import ( \"fmt\" \"net\" ) func main() { mxrecords, _ := net.LookupMX(\"facebook.com\") for _, mx := range mxrecords { fmt.Println(mx.Host, mx.Pref) } } 域名（facebook.com）的输出列表 MX 记录。 C:\\golang\\dns\u003ego run example5.go msgin.vvv.facebook.com. 10 6、Go 程序查找域名的 SRV 服务记录 LookupSRV 函数尝试解析给定服务，协议和域名的 SRV 查询。第二个参数是 “tcp” 或 “udp”。返回的记录按优先级排序，并按照权重随机化。 package main import ( \"fmt\" \"net\" ) func main() { cname, srvs, err := net.LookupSRV(\"xmpp-server\", \"tcp\", \"golang.org\") if err != nil { panic(err) } fmt.Printf(\"\\ncname: %s \\n\\n\", cname) for _, srv := range srvs { fmt.Printf(\"%v:%v:%d:%d\\n\", srv.Target, srv.Port, srv.Priority, srv.Weight) } } 下面的输出演示了 CNAME 返回，后跟由冒号分隔的 SRV 记录的目标，端口，优先级和权重。 C:\\golang\\dns\u003ego run example6.go cname: _xmpp-server._tcp.golang.org. 7、Go 程序查找域名的 TXT 记录 TXT 记录存储有关 SPF 的信息，该信息可以识别授权服务器以代表您的组织发送电子邮件。net.LookupTXT() 函数将域名（facebook.com）作为字符串，并返回 DNS TXT 记录的字符串切片。 package main import ( \"fmt\" \"net\" ) func main() { txtrecords, _ := net.LookupTXT(\"facebook.com\") for _, txt := range txtrecords { fmt.Println(txt) } } gmail.com 的单个 TXT 记录如下所示。 C:\\golang\\dns\u003ego run example7.go v=spf1 redirect=_spf.facebook.com via: http://www.golangprograms.com/find-dns-records-programmatically.html 作者：golangprograms[1]译者：lovechuck[2]校对：polaris1119[3] ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-net/:1:1","tags":["Go","net"],"title":"Go net","uri":"/posts/2023-11-11-go-net/"},{"categories":["Go 库文档"],"content":"参考资料 [1]golangprograms: http://www.golangprograms.com [2]lovechuck: https://github.com/lovechuck [3]polaris1119: https://github.com/polaris1119 [4]GCTT: https://github.com/studygolang/GCTT [5]Go 中文网: https://studygolang.com/ ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-net/:1:2","tags":["Go","net"],"title":"Go net","uri":"/posts/2023-11-11-go-net/"},{"categories":["Go 库文档"],"content":"mapstructure 转换库 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:0","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"简介 mapstructure用于将通用的map[string]interface{}解码到对应的 Go 结构体中，或者执行相反的操作。很多时候，解析来自多种源头的数据流时，我们一般事先并不知道他们对应的具体类型。只有读取到一些字段之后才能做出判断。这时，我们可以先使用标准的encoding/json库将数据解码为map[string]interface{}类型，然后根据标识字段利用mapstructure库转为相应的 Go 结构体以便使用。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:1","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"快速使用 本文代码采用 Go Modules。 首先创建目录并初始化： $ mkdir mapstructure \u0026\u0026 cd mapstructure $ go mod init github.com/darjun/go-daily-lib/mapstructure 下载mapstructure库： $ go get github.com/mitchellh/mapstructure 使用： package main import ( \"encoding/json\" \"fmt\" \"log\" \"github.com/mitchellh/mapstructure\" ) type Person struct { Name string Age int Job string } type Cat struct { Name string Age int Breed string } func main() { datas := []string{` { \"type\": \"person\", \"name\":\"dj\", \"age\":18, \"job\": \"programmer\" } `, ` { \"type\": \"cat\", \"name\": \"kitty\", \"age\": 1, \"breed\": \"Ragdoll\" } `, } for _, data := range datas { var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } switch m[\"type\"].(string) { case \"person\": var p Person mapstructure.Decode(m, \u0026p) fmt.Println(\"person\", p) case \"cat\": var cat Cat mapstructure.Decode(m, \u0026cat) fmt.Println(\"cat\", cat) } } } 运行结果： $ go run main.go person {dj 18 programmer} cat {kitty 1 Ragdoll} 我们定义了两个结构体Person和Cat，他们的字段有些许不同。现在，我们约定通信的 JSON 串中有一个type字段。当type的值为person时，该 JSON 串表示的是Person类型的数据。当type的值为cat时，该 JSON 串表示的是Cat类型的数据。 上面代码中，我们先用json.Unmarshal将字节流解码为map[string]interface{}类型。然后读取里面的type字段。根据type字段的值，再使用mapstructure.Decode将该 JSON 串分别解码为Person和Cat类型的值，并输出。 实际上，Google Protobuf 通常也使用这种方式。在协议中添加消息 ID 或全限定消息名。接收方收到数据后，先读取协议 ID 或全限定消息名。然后调用 Protobuf 的解码方法将其解码为对应的Message结构。从这个角度来看，mapstructure也可以用于网络消息解码，如果你不考虑性能的话😄。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:2","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"字段标签 默认情况下，mapstructure使用结构体中字段的名称做这个映射，例如我们的结构体有一个Name字段，mapstructure解码时会在map[string]interface{}中查找键名name。注意，这里的name是大小写不敏感的！ type Person struct { Name string } 当然，我们也可以指定映射的字段名。为了做到这一点，我们需要为字段设置mapstructure标签。例如下面使用username代替上例中的name： type Person struct { Name string `mapstructure:\"username\"` } 看示例： type Person struct { Name string `mapstructure:\"username\"` Age int Job string } type Cat struct { Name string Age int Breed string } func main() { datas := []string{` { \"type\": \"person\", \"username\":\"dj\", \"age\":18, \"job\": \"programmer\" } `, ` { \"type\": \"cat\", \"name\": \"kitty\", \"Age\": 1, \"breed\": \"Ragdoll\" } `, ` { \"type\": \"cat\", \"Name\": \"rooooose\", \"age\": 2, \"breed\": \"shorthair\" } `, } for _, data := range datas { var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } switch m[\"type\"].(string) { case \"person\": var p Person mapstructure.Decode(m, \u0026p) fmt.Println(\"person\", p) case \"cat\": var cat Cat mapstructure.Decode(m, \u0026cat) fmt.Println(\"cat\", cat) } } } 上面代码中，我们使用标签mapstructure:\"username\"将Person的Name字段映射为username，在 JSON 串中我们需要设置username才能正确解析。另外，注意到，我们将第二个 JSON 串中的Age和第三个 JSON 串中的Name首字母大写了，但是并没有影响解码结果。mapstructure处理字段映射是大小写不敏感的。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:3","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"内嵌结构 结构体可以任意嵌套，嵌套的结构被认为是拥有该结构体名字的另一个字段。例如，下面两种Friend的定义方式对于mapstructure是一样的： type Person struct { Name string } // 方式一 type Friend struct { Person } // 方式二 type Friend struct { Person Person } 为了正确解码，Person结构的数据要在person键下： map[string]interface{} { \"person\": map[string]interface{}{\"name\": \"dj\"}, } 我们也可以设置mapstructure:\",squash\"将该结构体的字段提到父结构中： type Friend struct { Person `mapstructure:\",squash\"` } 这样只需要这样的 JSON 串，无效嵌套person键： map[string]interface{}{ \"name\": \"dj\", } 看示例： type Person struct { Name string } type Friend1 struct { Person } type Friend2 struct { Person `mapstructure:\",squash\"` } func main() { datas := []string{` { \"type\": \"friend1\", \"person\": { \"name\":\"dj\" } } `, ` { \"type\": \"friend2\", \"name\": \"dj2\" } `, } for _, data := range datas { var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } switch m[\"type\"].(string) { case \"friend1\": var f1 Friend1 mapstructure.Decode(m, \u0026f1) fmt.Println(\"friend1\", f1) case \"friend2\": var f2 Friend2 mapstructure.Decode(m, \u0026f2) fmt.Println(\"friend2\", f2) } } } 注意对比Friend1和Friend2使用的 JSON 串的不同。 另外需要注意一点，如果父结构体中有同名的字段，那么mapstructure会将JSON 中对应的值同时设置到这两个字段中，即这两个字段有相同的值。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:4","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"未映射的值 如果源数据中有未映射的值（即结构体中无对应的字段），mapstructure默认会忽略它。 我们可以在结构体中定义一个字段，为其设置mapstructure:\",remain\"标签。这样未映射的值就会添加到这个字段中。注意，这个字段的类型只能为map[string]interface{}或map[interface{}]interface{}。 看示例： type Person struct { Name string Age int Job string Other map[string]interface{} `mapstructure:\",remain\"` } func main() { data := ` { \"name\": \"dj\", \"age\":18, \"job\":\"programmer\", \"height\":\"1.8m\", \"handsome\": true } ` var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } var p Person mapstructure.Decode(m, \u0026p) fmt.Println(\"other\", p.Other) } 上面代码中，我们为结构体定义了一个Other字段，用于保存未映射的键值。输出结果： other map[handsome:true height:1.8m] ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:5","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"逆向转换 前面我们都是将map[string]interface{}解码到 Go 结构体中。mapstructure当然也可以将 Go 结构体反向解码为map[string]interface{}。在反向解码时，我们可以为某些字段设置mapstructure:\",omitempty\"。这样当这些字段为默认值时，就不会出现在结构的map[string]interface{}中： type Person struct { Name string Age int Job string `mapstructure:\",omitempty\"` } func main() { p := \u0026Person{ Name: \"dj\", Age: 18, } var m map[string]interface{} mapstructure.Decode(p, \u0026m) data, _ := json.Marshal(m) fmt.Println(string(data)) } 上面代码中，我们为Job字段设置了mapstructure:\",omitempty\"，且对象p的Job字段未设置。运行结果： $ go run main.go {\"Age\":18,\"Name\":\"dj\"} ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:6","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"Metadata 解码时会产生一些有用的信息，mapstructure可以使用Metadata收集这些信息。Metadata结构如下： // mapstructure.go type Metadata struct { Keys []string Unused []string } Metadata只有两个导出字段： Keys：解码成功的键名； Unused：在源数据中存在，但是目标结构中不存在的键名。 为了收集这些数据，我们需要使用DecodeMetadata来代替Decode方法： type Person struct { Name string Age int } func main() { m := map[string]interface{}{ \"name\": \"dj\", \"age\": 18, \"job\": \"programmer\", } var p Person var metadata mapstructure.Metadata mapstructure.DecodeMetadata(m, \u0026p, \u0026metadata) fmt.Printf(\"keys:%#v unused:%#v\\n\", metadata.Keys, metadata.Unused) } 先定义一个Metadata结构，传入DecodeMetadata收集解码的信息。运行结果： $ go run main.go keys:[]string{\"Name\", \"Age\"} unused:[]string{\"job\"} ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:7","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"错误处理 mapstructure执行转换的过程中不可避免地会产生错误，例如 JSON 中某个键的类型与对应 Go 结构体中的字段类型不一致。Decode/DecodeMetadata会返回这些错误： type Person struct { Name string Age int Emails []string } func main() { m := map[string]interface{}{ \"name\": 123, \"age\": \"bad value\", \"emails\": []int{1, 2, 3}, } var p Person err := mapstructure.Decode(m, \u0026p) if err != nil { fmt.Println(err.Error()) } } 上面代码中，结构体中Person中字段Name为string类型，但输入中name为int类型；字段Age为int类型，但输入中age为string类型；字段Emails为[]string类型，但输入中emails为[]int类型。故Decode返回错误。运行结果： $ go run main.go 5 error(s) decoding: * 'Age' expected type 'int', got unconvertible type 'string' * 'Emails[0]' expected type 'string', got unconvertible type 'int' * 'Emails[1]' expected type 'string', got unconvertible type 'int' * 'Emails[2]' expected type 'string', got unconvertible type 'int' * 'Name' expected type 'string', got unconvertible type 'int' 从错误信息中很容易看出哪里出错了。 弱类型输入 有时候，我们并不想对结构体字段类型和map[string]interface{}的对应键值做强类型一致的校验。这时可以使用WeakDecode/WeakDecodeMetadata方法，它们会尝试做类型转换： type Person struct { Name string Age int Emails []string } func main() { m := map[string]interface{}{ \"name\": 123, \"age\": \"18\", \"emails\": []int{1, 2, 3}, } var p Person err := mapstructure.WeakDecode(m, \u0026p) if err == nil { fmt.Println(\"person:\", p) } else { fmt.Println(err.Error()) } } 虽然键name对应的值123是int类型，但是在WeakDecode中会将其转换为string类型以匹配Person.Name字段的类型。同样的，age的值\"18\"是string类型，在WeakDecode中会将其转换为int类型以匹配Person.Age字段的类型。 需要注意一点，如果类型转换失败了，WeakDecode同样会返回错误。例如将上例中的age设置为\"bad value\"，它就不能转为int类型，故而返回错误。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:8","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"解码器 除了上面介绍的方法外，mapstructure还提供了更灵活的解码器（Decoder）。可以通过配置DecoderConfig实现上面介绍的任何功能： // mapstructure.go type DecoderConfig struct { ErrorUnused bool ZeroFields bool WeaklyTypedInput bool Metadata *Metadata Result interface{} TagName string } 各个字段含义如下： ErrorUnused：为true时，如果输入中的键值没有与之对应的字段就返回错误； ZeroFields：为true时，在Decode前清空目标map。为false时，则执行的是map的合并。用在struct到map的转换中； WeaklyTypedInput：实现WeakDecode/WeakDecodeMetadata的功能； Metadata：不为nil时，收集Metadata数据； Result：为结果对象，在map到struct的转换中，Result为struct类型。在struct到map的转换中，Result为map类型； TagName：默认使用mapstructure作为结构体的标签名，可以通过该字段设置。 看示例： type Person struct { Name string Age int } func main() { m := map[string]interface{}{ \"name\": 123, \"age\": \"18\", \"job\": \"programmer\", } var p Person var metadata mapstructure.Metadata decoder, err := mapstructure.NewDecoder(\u0026mapstructure.DecoderConfig{ WeaklyTypedInput: true, Result: \u0026p, Metadata: \u0026metadata, }) if err != nil { log.Fatal(err) } err = decoder.Decode(m) if err == nil { fmt.Println(\"person:\", p) fmt.Printf(\"keys:%#v, unused:%#v\\n\", metadata.Keys, metadata.Unused) } else { fmt.Println(err.Error()) } } 这里用Decoder的方式实现了前面弱类型输入小节中的示例代码。实际上WeakDecode内部就是通过这种方式实现的，下面是WeakDecode的源码： // mapstructure.go func WeakDecode(input, output interface{}) error { config := \u0026DecoderConfig{ Metadata: nil, Result: output, WeaklyTypedInput: true, } decoder, err := NewDecoder(config) if err != nil { return err } return decoder.Decode(input) } 再实际上，Decode/DecodeMetadata/WeakDecodeMetadata内部都是先设置DecoderConfig的对应字段，然后创建Decoder对象，最后调用其Decode方法实现的。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:9","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"Go leveldb库 github地址：https://github.com/syndtr/goleveldb 安装： go get github.com/syndtr/goleveldb/leveldb ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:0","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"简介： levelDB在区块链中比较常用，其是Google开源的持久化单机Key-Value文件数据库，其支持按照文件大小切分文件的功能。levelDB具有很高的随机写，顺序读/写性能，但是随机读的性能很一般，也就是说，levelDB很适合应用在查询较少，而写很多的场景。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:1","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"LevelDB特点 1）key和value都是任意长度的字节数组； 2）entry（即一条k-v记录）默认是按照key的字典顺序存储的，开发者也可以重写这个方法； 3）提供了基本的增删改查接口； 4）支持批量操作以原子操作进行； 5）开源创建数据全景的snapshot（快照），并允许在快照中查询； 6）开源通过向前（后）迭代器遍历数据（迭代器隐含的创建了一个snapshot）； 7）自动使用Snappy压缩数据； 8）可移植性。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:2","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"levelDB限制 1）NoSQL，不支持sql语句，也不支持索引； 2）一次只允许一个进程访问一个特定的数据库； 3）没有内置的C/S架构，开发者需要使用levelDB库自己封装一个server； ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:3","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"使用： 1）打开、创建数据库 db, err := leveldb.OpenFile(\"./block.db\", nil) 2）写入key数据 err = db.Put([]byte(\"hello\"), []byte(\"world\"), nil) 3）读取key数据 data, _ := db.Get([]byte(\"hello\"), nil) 4）遍历数据库 iter := db.NewIterator(nil, nil) for iter.Next() { logger.Debug(iter.Key() + iter.Value()) } 5）读取某个前缀的所有KEY数据 读出来的数据会被放进一个Iterator中。加入数据库现在有key-$num为头的数条数据 iter := db.NewIterator(dbUtil.BytesPrefix([]byte(\"key-\")), nil) 遍历读取这些数据 for iter.Next() { logger.Debug(string(iter.Key()) + string(iter.Value())) } 读取最后一条数据 if iter.Last() { logger.Debug(iter.Key() + iter.Value()) } 6）删除某个KEY err = db.Delete([]byte(\"key-3\"), nil) 7）批量写 batch := new(leveldb.Batch) batch.Put([]byte(\"foo\"), []byte(\"value\")) batch.Put([]byte(\"bar\"), []byte(\"another value\")) batch.Delete([]byte(\"baz\")) err = db.Write(batch, nil) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:4","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"Go ini库 参考：https://juejin.cn/post/6844904048764649479 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:0","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"简介 ini 是 Windows 上常用的配置文件格式。MySQL 的 Windows 版就是使用 ini 格式存储配置的。 go-ini是 Go 语言中用于操作 ini 文件的第三方库。 本文介绍go-ini库的使用。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:1","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"快速使用 go-ini 是第三方库，使用前需要安装： $ go get gopkg.in/ini.v1 也可以使用 GitHub 上的仓库： $ go get github.com/go-ini/ini 首先，创建一个my.ini配置文件： app_name = awesome web # possible values: DEBUG, INFO, WARNING, ERROR, FATAL log_level = DEBUG [mysql] ip = 127.0.0.1 port = 3306 user = dj password = 123456 database = awesome [redis] ip = 127.0.0.1 port = 6381 使用 go-ini 库读取： package main import ( \"fmt\" \"log\" \"gopkg.in/ini.v1\" ) func main() { cfg, err := ini.Load(\"my.ini\") if err != nil { log.Fatal(\"Fail to read file: \", err) } fmt.Println(\"App Name:\", cfg.Section(\"\").Key(\"app_name\").String()) fmt.Println(\"Log Level:\", cfg.Section(\"\").Key(\"log_level\").String()) fmt.Println(\"MySQL IP:\", cfg.Section(\"mysql\").Key(\"ip\").String()) mysqlPort, err := cfg.Section(\"mysql\").Key(\"port\").Int() if err != nil { log.Fatal(err) } fmt.Println(\"MySQL Port:\", mysqlPort) fmt.Println(\"MySQL User:\", cfg.Section(\"mysql\").Key(\"user\").String()) fmt.Println(\"MySQL Password:\", cfg.Section(\"mysql\").Key(\"password\").String()) fmt.Println(\"MySQL Database:\", cfg.Section(\"mysql\").Key(\"database\").String()) fmt.Println(\"Redis IP:\", cfg.Section(\"redis\").Key(\"ip\").String()) redisPort, err := cfg.Section(\"redis\").Key(\"port\").Int() if err != nil { log.Fatal(err) } fmt.Println(\"Redis Port:\", redisPort) } 在 ini 文件中，每个键值对占用一行，中间使用=隔开。以#开头的内容为注释。ini 文件是以分区（section）组织的。 分区以[name]开始，在下一个分区前结束。所有分区前的内容属于默认分区，如my.ini文件中的app_name和log_level。 使用go-ini读取配置文件的步骤如下： 首先调用ini.Load加载文件，得到配置对象cfg； 然后以分区名调用配置对象的Section方法得到对应的分区对象section，默认分区的名字为\"\"，也可以使用ini.DefaultSection； 以键名调用分区对象的Key方法得到对应的配置项key对象； 由于文件中读取出来的都是字符串，key对象需根据类型调用对应的方法返回具体类型的值使用，如上面的String、MustInt方法。 运行以下程序，得到输出： App Name: awesome web Log Level: DEBUG MySQL IP: 127.0.0.1 MySQL Port: 3306 MySQL User: dj MySQL Password: 123456 MySQL Database: awesome Redis IP: 127.0.0.1 Redis Port: 6381 配置文件中存储的都是字符串，所以类型为字符串的配置项不会出现类型转换失败的，故String()方法只返回一个值。 但如果类型为Int/Uint/Float64这些时，转换可能失败。所以Int()/Uint()/Float64()返回一个值和一个错误。 要留意这种不一致！如果我们将配置中 redis 端口改成非法的数字 x6381，那么运行程序将报错： 2020/01/14 22:43:13 strconv.ParseInt: parsing \"x6381\": invalid syntax 复制代码 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:2","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"Must*便捷方法 如果每次取值都需要进行错误判断，那么代码写起来会非常繁琐。为此，go-ini也提供对应的MustType（Type 为Init/Uint/Float64等）方法，这个方法只返回一个值。 同时它接受可变参数，如果类型无法转换，取参数中第一个值返回，并且该参数设置为这个配置的值，下次调用返回这个值： package main import ( \"fmt\" \"log\" \"gopkg.in/ini.v1\" ) func main() { cfg, err := ini.Load(\"my.ini\") if err != nil { log.Fatal(\"Fail to read file: \", err) } redisPort, err := cfg.Section(\"redis\").Key(\"port\").Int() if err != nil { fmt.Println(\"before must, get redis port error:\", err) } else { fmt.Println(\"before must, get redis port:\", redisPort) } fmt.Println(\"redis Port:\", cfg.Section(\"redis\").Key(\"port\").MustInt(6381)) redisPort, err = cfg.Section(\"redis\").Key(\"port\").Int() if err != nil { fmt.Println(\"after must, get redis port error:\", err) } else { fmt.Println(\"after must, get redis port:\", redisPort) } } 配置文件还是 redis 端口为非数字 x6381 时的状态，运行程序： before must, get redis port error: strconv.ParseInt: parsing \"x6381\": invalid syntax redis Port: 6381 after must, get redis port: 6381 复制代码 我们看到第一次调用Int返回错误，以 6381 为参数调用MustInt之后，再次调用Int，成功返回 6381。MustInt源码也比较简单： // gopkg.in/ini.v1/key.go func (k *Key) MustInt(defaultVal ...int) int { val, err := k.Int() if len(defaultVal) \u003e 0 \u0026\u0026 err != nil { k.value = strconv.FormatInt(int64(defaultVal[0]), 10) return defaultVal[0] } return val } 复制代码 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:3","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"分区操作 获取信息 在加载配置之后，可以通过Sections方法获取所有分区，SectionStrings()方法获取所有分区名。 sections := cfg.Sections() names := cfg.SectionStrings() fmt.Println(\"sections: \", sections) fmt.Println(\"names: \", names) 复制代码 运行输出 3 个分区： [DEFAULT mysql redis] 复制代码 调用Section(name)获取名为name的分区，如果该分区不存在，则自动创建一个分区返回： newSection := cfg.Section(\"new\") fmt.Println(\"new section: \", newSection) fmt.Println(\"names: \", cfg.SectionStrings()) 创建之后调用SectionStrings方法，新分区也会返回： names: [DEFAULT mysql redis new] 也可以手动创建一个新分区，如果分区已存在，则返回错误： err := cfg.NewSection(\"new\") 父子分区 在配置文件中，可以使用占位符%(name)s表示用之前已定义的键name的值来替换，这里的s表示值为字符串类型： NAME = ini VERSION = v1 IMPORT_PATH = gopkg.in/%(NAME)s.%(VERSION)s [package] CLONE_URL = https://%(IMPORT_PATH)s [package.sub] 上面在默认分区中设置IMPORT_PATH的值时，使用了前面定义的NAME和VERSION。 在package分区中设置CLONE_URL的值时，使用了默认分区中定义的IMPORT_PATH。 我们还可以在分区名中使用.表示两个或多个分区之间的父子关系，例如package.sub的父分区为package，package的父分区为默认分区。 如果某个键在子分区中不存在，则会在它的父分区中再次查找，直到没有父分区为止： cfg, err := ini.Load(\"parent_child.ini\") if err != nil { fmt.Println(\"Fail to read file: \", err) return } fmt.Println(\"Clone url from package.sub:\", cfg.Section(\"package.sub\").Key(\"CLONE_URL\").String()) 运行程序输出： Clone url from package.sub: https://gopkg.in/ini.v1 子分区中package.sub中没有键CLONE_URL，返回了父分区package中的值。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:4","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"保存配置 有时候，我们需要将生成的配置写到文件中。例如在写工具的时候。保存有两种类型的接口，一种直接保存到文件，另一种写入到io.Writer中： err = cfg.SaveTo(\"my.ini\") err = cfg.SaveToIndent(\"my.ini\", \"\\t\") cfg.WriteTo(writer) cfg.WriteToIndent(writer, \"\\t\") 下面我们通过程序生成前面使用的配置文件my.ini并保存： package main import ( \"fmt\" \"os\" \"gopkg.in/ini.v1\" ) func main() { cfg := ini.Empty() defaultSection := cfg.Section(\"\") defaultSection.NewKey(\"app_name\", \"awesome web\") defaultSection.NewKey(\"log_level\", \"DEBUG\") mysqlSection, err := cfg.NewSection(\"mysql\") if err != nil { fmt.Println(\"new mysql section failed:\", err) return } mysqlSection.NewKey(\"ip\", \"127.0.0.1\") mysqlSection.NewKey(\"port\", \"3306\") mysqlSection.NewKey(\"user\", \"root\") mysqlSection.NewKey(\"password\", \"123456\") mysqlSection.NewKey(\"database\", \"awesome\") redisSection, err := cfg.NewSection(\"redis\") if err != nil { fmt.Println(\"new redis section failed:\", err) return } redisSection.NewKey(\"ip\", \"127.0.0.1\") redisSection.NewKey(\"port\", \"6381\") err = cfg.SaveTo(\"my.ini\") if err != nil { fmt.Println(\"SaveTo failed: \", err) } err = cfg.SaveToIndent(\"my-pretty.ini\", \"\\t\") if err != nil { fmt.Println(\"SaveToIndent failed: \", err) } cfg.WriteTo(os.Stdout) fmt.Println() cfg.WriteToIndent(os.Stdout, \"\\t\") } 运行程序，生成两个文件my.ini和my-pretty.ini，同时控制台输出文件内容。 my.ini： app_name = awesome web log_level = DEBUG [mysql] ip = 127.0.0.1 port = 3306 user = root password = 123456 database = awesome [redis] ip = 127.0.0.1 port = 6381 my-pretty.ini： app_name = awesome web log_level = DEBUG [mysql] ip = 127.0.0.1 port = 3306 user = root password = 123456 database = awesome [redis] ip = 127.0.0.1 port = 6381 *Indent方法会对子分区下的键增加缩进，看起来美观一点。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:5","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"分区与结构体字段映射 定义结构变量，加载完配置文件后，调用MapTo将配置项赋值到结构变量的对应字段中。 package main import ( \"fmt\" \"gopkg.in/ini.v1\" ) type Config struct { AppName string `ini:\"app_name\"` LogLevel string `ini:\"log_level\"` MySQL MySQLConfig `ini:\"mysql\"` Redis RedisConfig `ini:\"redis\"` } type MySQLConfig struct { IP string `ini:\"ip\"` Port int `ini:\"port\"` User string `ini:\"user\"` Password string `ini:\"password\"` Database string `ini:\"database\"` } type RedisConfig struct { IP string `ini:\"ip\"` Port int `ini:\"port\"` } func main() { cfg, err := ini.Load(\"my.ini\") if err != nil { fmt.Println(\"load my.ini failed: \", err) } c := Config{} cfg.MapTo(\u0026c) fmt.Println(c) } MapTo内部使用了反射，所以结构体字段必须都是导出的。如果键名与字段名不相同，那么需要在结构标签中指定对应的键名。 这一点与 Go 标准库encoding/json和encoding/xml不同。标准库json/xml解析时可以将键名app_name对应到字段名AppName。 或许这是go-ini库可以优化的点？ 先加载，再映射有点繁琐，直接使用ini.MapTo将两步合并： err = ini.MapTo(\u0026c, \"my.ini\") 复制代码 也可以只映射一个分区： mysqlCfg := MySQLConfig{} err = cfg.Section(\"mysql\").MapTo(\u0026mysqlCfg) 还可以通过结构体生成配置： cfg := ini.Empty() c := Config { AppName: \"awesome web\", LogLevel: \"DEBUG\", MySQL: MySQLConfig { IP: \"127.0.0.1\", Port: 3306, User: \"root\", Password:\"123456\", Database:\"awesome\", }, Redis: RedisConfig { IP: \"127.0.0.1\", Port: 6381, }, } err := ini.ReflectFrom(cfg, \u0026c) if err != nil { fmt.Println(\"ReflectFrom failed: \", err) return } err = cfg.SaveTo(\"my-copy.ini\") if err != nil { fmt.Println(\"SaveTo failed: \", err) return } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:6","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"总结 本文介绍了go-ini库的基本用法和一些有趣的特性。示例代码已上传GitHub。 其实go-ini还有很多高级特性。官方文档非常详细，推荐去看，而且有中文哟~ 作者无闻，相信做 Go 开发的都不陌生。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:7","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"参考 go-ini GitHub 仓库 go-ini 官方文档 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:8","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"homedir家目录 GitHub地址：https://github.com/mitchellh/go-homedir 使用os/user获取用户家目录： package main import ( \"fmt\" \"log\" \"os/user\" ) func main() { u, err := user.Current() if err != nil { log.Fatal(err) } fmt.Println(\"Home dir:\", u.HomeDir) } 那么为什么还要go-homedir库？ 在 Darwin 系统上，标准库os/user的使用需要 cgo。所以，任何使用os/user的代码都不能交叉编译。 但是，大多数人使用os/user的目的仅仅只是想获取主目录。因此，go-homedir库出现了。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:0","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"快速使用 go-homedir是第三方包，使用前需要先安装： $ go get github.com/mitchellh/go-homedir 使用非常简单： package main import ( \"fmt\" \"log\" \"github.com/mitchellh/go-homedir\" ) func main() { dir, err := homedir.Dir() if err != nil { log.Fatal(err) } fmt.Println(\"Home dir:\", dir) dir = \"~/golang/src\" expandedDir, err := homedir.Expand(dir) if err != nil { log.Fatal(err) } fmt.Printf(\"Expand of %s is: %s\\n\", dir, expandedDir) } go-homedir有两个功能： Dir：获取用户主目录； Expand：将路径中的第一个~扩展成用户主目录。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:1","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"高级用法 由于Dir的调用可能涉及一些系统调用和外部执行命令，多次调用费性能。所以go-homedir提供了缓存的功能。默认情况下，缓存是开启的。 我们也可以将DisableCache设置为false来关闭它。 package main import ( \"fmt\" \"log\" \"github.com/mitchellh/go-homedir\" ) func main() { homedir.DisableCache = false dir, err := homedir.Dir() if err != nil { log.Fatal(err) } fmt.Println(\"Home dir:\", dir) } 使用缓存时，如果程序运行中修改了主目录，再次调用Dir还是返回之前的目录。如果需要获取最新的主目录，可以先调用Reset清除缓存。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:2","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"实现 go-homedir源码只有一个文件homedir.go，今天我们大概看一下Dir的实现，去掉缓存相关代码： func Dir() (string, error) { var result string var err error if runtime.GOOS == \"windows\" { result, err = dirWindows() } else { // Unix-like system, so just assume Unix result, err = dirUnix() } if err != nil { return \"\", err } return result, nil } 判断当前的系统是windows还是类 Unix，分别调用不同的方法。先看 windows 的，比较简单： func dirWindows() (string, error) { // First prefer the HOME environmental variable if home := os.Getenv(\"HOME\"); home != \"\" { return home, nil } // Prefer standard environment variable USERPROFILE if home := os.Getenv(\"USERPROFILE\"); home != \"\" { return home, nil } drive := os.Getenv(\"HOMEDRIVE\") path := os.Getenv(\"HOMEPATH\") home := drive + path if drive == \"\" || path == \"\" { return \"\", errors.New(\"HOMEDRIVE, HOMEPATH, or USERPROFILE are blank\") } return home, nil } 流程如下： 读取环境变量HOME，如果不为空，返回这个值； 读取环境变量USERPROFILE，如果不为空，返回这个值； 读取环境变量HOMEDRIVE和HOMEPATH，如果两者都不为空，拼接这两个值返回。 类 Unix 系统的实现稍微复杂一点： func dirUnix() (string, error) { homeEnv := \"HOME\" if runtime.GOOS == \"plan9\" { // On plan9, env vars are lowercase. homeEnv = \"home\" } // First prefer the HOME environmental variable if home := os.Getenv(homeEnv); home != \"\" { return home, nil } var stdout bytes.Buffer // If that fails, try OS specific commands if runtime.GOOS == \"darwin\" { cmd := exec.Command(\"sh\", \"-c\", `dscl -q . -read /Users/\"$(whoami)\" NFSHomeDirectory | sed 's/^[^ ]*: //'`) cmd.Stdout = \u0026stdout if err := cmd.Run(); err == nil { result := strings.TrimSpace(stdout.String()) if result != \"\" { return result, nil } } } else { cmd := exec.Command(\"getent\", \"passwd\", strconv.Itoa(os.Getuid())) cmd.Stdout = \u0026stdout if err := cmd.Run(); err != nil { // If the error is ErrNotFound, we ignore it. Otherwise, return it. if err != exec.ErrNotFound { return \"\", err } } else { if passwd := strings.TrimSpace(stdout.String()); passwd != \"\" { // username:password:uid:gid:gecos:home:shell passwdParts := strings.SplitN(passwd, \":\", 7) if len(passwdParts) \u003e 5 { return passwdParts[5], nil } } } } // If all else fails, try the shell stdout.Reset() cmd := exec.Command(\"sh\", \"-c\", \"cd \u0026\u0026 pwd\") cmd.Stdout = \u0026stdout if err := cmd.Run(); err != nil { return \"\", err } result := strings.TrimSpace(stdout.String()) if result == \"\" { return \"\", errors.New(\"blank output when reading home directory\") } return result, nil } 流程如下： 先读取环境变量HOME（注意 plan9 系统上为home），如果不为空，返回这个值； 使用getnet命令查看系统的数据库中的相关记录，我们知道passwd文件中存储了用户信息，包括用户的主目录。使用getent命令查看passwd中当前用户的那条记录，然后从中找到主目录部分返回； 如果上一个步骤失败了，我们知道cd后不加参数是直接切换到用户主目录的，而pwd可以显示当前目录。那么就可以结合这两个命令返回主目录。 这里分析源码并不是表示使用任何库都要熟悉它的源码，毕竟使用库就是为了方便开发。 但是源码是我们学习和提高的一个非常重要的途径。我们在使用库遇到问题的时候也要有能力从文档或甚至源码中查找原因。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:3","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"Go Fsnotify库 官方仓库：github.com/fsnotify/fsnotify 用于监控文件或目录的改变 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fsnotify/:1:0","tags":["Go","fsnotify"],"title":"Go fsnotify","uri":"/posts/2023-11-11-go-fsnotify/"},{"categories":["Go 库文档"],"content":"1、官网示例 package main import ( \"log\" \"github.com/fsnotify/fsnotify\" ) func main() { watcher, err := fsnotify.NewWatcher() if err != nil { log.Fatal(err) } defer watcher.Close() done := make(chan bool) go func() { for { select { case event := \u003c-watcher.Events: log.Println(\"event:\", event) if event.Op\u0026fsnotify.Write == fsnotify.Write { log.Println(\"modified file:\", event.Name) } case err := \u003c-watcher.Errors: log.Println(\"error:\", err) } } }() err = watcher.Add(\"/tmp/foo\") if err != nil { log.Fatal(err) } \u003c-done } fsnotify的使用比较简单: 先条用NewWatcher创建一个监听器 然后条用监听器的Add监听文件或目录 如果目录或文件有事件发生，监听器的通道Events可以取出事件。如果出现错误，监听器中的通道Errors可以取出错误信息。 其实，重命名时会产生两个事件，一个是原文件的RENAME事件，一个是新文件的CREATE事件。 注意，fsnotify使用了操作系统接口，监听器中保存了系统资源的句柄，所以使用后需要关闭。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fsnotify/:1:1","tags":["Go","fsnotify"],"title":"Go fsnotify","uri":"/posts/2023-11-11-go-fsnotify/"},{"categories":["Go 库文档"],"content":"2、事件 上面示例中的事件是fsnotify.Event类型： // fsnotify/fsnotify.go type Event struct { Name string Op Op } 事件只有两个字段，Name表示发生变化的文件或目录名，Op表示具体的变化。Op有 5 中取值： // fsnotify/fsnotify.go type Op uint32 const ( Create Op = 1 \u003c\u003c iota Write Remove Rename Chmod ) 3、监控目录 参考链接：https://blog.csdn.net/finghting321/article/details/102852746 package main; import ( \"github.com/fsnotify/fsnotify\" \"fmt\" \"path/filepath\" \"os\" ) type NotifyFile struct { watch *fsnotify.Watcher } func NewNotifyFile() *NotifyFile { w := new(NotifyFile) w.watch, _ = fsnotify.NewWatcher() return w } //监控目录 func (this *NotifyFile) WatchDir(dir string) { //通过Walk来遍历目录下的所有子目录 filepath.Walk(dir, func(path string, info os.FileInfo, err error) error { //判断是否为目录，监控目录,目录下文件也在监控范围内，不需要加 if info.IsDir() { path, err := filepath.Abs(path) if err != nil { return err } err = this.watch.Add(path) if err != nil { return err } fmt.Println(\"监控 : \", path) } return nil }) go this.WatchEvent() //协程 } func (this *NotifyFile) WatchEvent() { for { select { case ev := \u003c-this.watch.Events: { if ev.Op\u0026fsnotify.Create == fsnotify.Create { fmt.Println(\"创建文件 : \", ev.Name) //获取新创建文件的信息，如果是目录，则加入监控中 file, err := os.Stat(ev.Name) if err == nil \u0026\u0026 file.IsDir() { this.watch.Add(ev.Name) fmt.Println(\"添加监控 : \", ev.Name) } } if ev.Op\u0026fsnotify.Write == fsnotify.Write { //fmt.Println(\"写入文件 : \", ev.Name) } if ev.Op\u0026fsnotify.Remove == fsnotify.Remove { fmt.Println(\"删除文件 : \", ev.Name) //如果删除文件是目录，则移除监控 fi, err := os.Stat(ev.Name) if err == nil \u0026\u0026 fi.IsDir() { this.watch.Remove(ev.Name) fmt.Println(\"删除监控 : \", ev.Name) } } if ev.Op\u0026fsnotify.Rename == fsnotify.Rename { //如果重命名文件是目录，则移除监控 ,注意这里无法使用os.Stat来判断是否是目录了 //因为重命名后，go已经无法找到原文件来获取信息了,所以简单粗爆直接remove fmt.Println(\"重命名文件 : \", ev.Name) this.watch.Remove(ev.Name) } if ev.Op\u0026fsnotify.Chmod == fsnotify.Chmod { fmt.Println(\"修改权限 : \", ev.Name) } } case err := \u003c-this.watch.Errors: { fmt.Println(\"error : \", err) return } } } func main() { watch := FSNotify.NewNotifyFile() watch.WatchDir(\"G:\\\\Ferry\") select {} return } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fsnotify/:1:2","tags":["Go","fsnotify"],"title":"Go fsnotify","uri":"/posts/2023-11-11-go-fsnotify/"},{"categories":["Go 库文档"],"content":"Go fmt模块 参考链接：https://www.liwenzhou.com/posts/Go/go_fmt/ fmt fmt包实现了类似C语言printf和scanf的格式化I/O。主要分为向外输出内容和获取输入内容两大部分。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:0","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"向外输出 标准库fmt提供了以下几种输出相关函数。 Print Print系列函数会将内容输出到系统的标准输出，区别在于Print函数直接输出内容，Printf函数支持格式化输出字符串，Println函数会在输出内容的结尾添加一个换行符。 func Print(a ...interface{}) (n int, err error) func Printf(format string, a ...interface{}) (n int, err error) func Println(a ...interface{}) (n int, err error) 例如： func main() { fmt.Print(\"在终端打印该信息。\") name := \"沙河小王子\" fmt.Printf(\"我是：%s\\n\", name) fmt.Println(\"在终端打印单独一行显示\") } 输出结果： 在终端打印该信息。我是：沙河小王子 在终端打印单独一行显示 Fprint Fprint系列函数会将内容输出到一个io.Writer接口类型的变量w中，我们通常用这个函数往文件中写入内容。 func Fprint(w io.Writer, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error) 例如： // 向标准输出写入内容 fmt.Fprintln(os.Stdout, \"向标准输出写入内容\") fileObj, err := os.OpenFile(\"./xx.txt\", os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644) if err != nil { fmt.Println(\"打开文件出错，err:\", err) return } name := \"沙河小王子\" // 向打开的文件句柄中写入内容 fmt.Fprintf(fileObj, \"往文件中写如信息：%s\", name) Sprint Sprint系列函数会把传入的数据生成并返回一个字符串。 func Sprint(a ...interface{}) string func Sprintf(format string, a ...interface{}) string func Sprintln(a ...interface{}) string 示例： s1 := fmt.Sprint(\"沙河小王子\") name := \"沙河小王子\" age := 18 s2 := fmt.Sprintf(\"name:%s,age:%d\", name, age) s3 := fmt.Sprintln(\"沙河小王子\") fmt.Println(s1, s2, s3) Errorf Errorf函数根据format参数生成格式化字符串并返回一个包含该字符串的错误。 func Errorf(format string, a ...interface{}) error 通常使用这种方式来自定义错误类型，例如： err := fmt.Errorf(\"这是一个错误\") Go1.13版本为fmt.Errorf函数新加了一个%w占位符用来生成一个可以包裹Error的Wrapping Error。 e := errors.New(\"原始错误e\") w := fmt.Errorf(\"Wrap了一个错误%w\", e) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:1","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"格式化占位符 *printf系列函数都支持format格式化参数，在这里我们按照占位符将被替换的变量类型划分，方便查询和记忆。 通用占位符 占位符 说明 %v 值的默认格式表示 %+v 类似%v，但输出结构体时会添加字段名 %#v 值的Go语法表示 %T 打印值的类型 %% 百分号 示例代码如下： fmt.Printf(\"%v\\n\", 100) fmt.Printf(\"%v\\n\", false) o := struct{ name string }{\"小王子\"} fmt.Printf(\"%v\\n\", o) fmt.Printf(\"%#v\\n\", o) fmt.Printf(\"%T\\n\", o) fmt.Printf(\"100%%\\n\") 输出结果如下： 100 false {小王子} struct { name string }{name:\"小王子\"} struct { name string } 100% 布尔型 占位符 说明 %t true或false 整型 占位符 说明 %b 表示为二进制 %c 该值对应的unicode码值 %d 表示为十进制 %o 表示为八进制 %x 表示为十六进制，使用a-f %X 表示为十六进制，使用A-F %U 表示为Unicode格式：U+1234，等价于”U+%04X” %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 示例代码如下： n := 65 fmt.Printf(\"%b\\n\", n) fmt.Printf(\"%c\\n\", n) fmt.Printf(\"%d\\n\", n) fmt.Printf(\"%o\\n\", n) fmt.Printf(\"%x\\n\", n) fmt.Printf(\"%X\\n\", n) 输出结果如下： 1000001 A 65 101 41 41 浮点数与复数 占位符 说明 %b 无小数部分、二进制指数的科学计数法，如-123456p-78 %e 科学计数法，如-1234.456e+78 %E 科学计数法，如-1234.456E+78 %f 有小数部分但无指数部分，如123.456 %F 等价于%f %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） %G 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） 示例代码如下： f := 12.34 fmt.Printf(\"%b\\n\", f) fmt.Printf(\"%e\\n\", f) fmt.Printf(\"%E\\n\", f) fmt.Printf(\"%f\\n\", f) fmt.Printf(\"%g\\n\", f) fmt.Printf(\"%G\\n\", f) 输出结果如下： 6946802425218990p-49 1.234000e+01 1.234000E+01 12.340000 12.34 12.34 字符串和[]byte 占位符 说明 %s 直接输出字符串或者[]byte %q 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 %x 每个字节用两字符十六进制数表示（使用a-f %X 每个字节用两字符十六进制数表示（使用A-F） 示例代码如下： s := \"小王子\" fmt.Printf(\"%s\\n\", s) fmt.Printf(\"%q\\n\", s) fmt.Printf(\"%x\\n\", s) fmt.Printf(\"%X\\n\", s) 输出结果如下： 小王子 \"小王子\" e5b08fe78e8be5ad90 E5B08FE78E8BE5AD90 指针 占位符 说明 %p 表示为十六进制，并加上前导的0x 示例代码如下： a := 10 fmt.Printf(\"%p\\n\", \u0026a) fmt.Printf(\"%#p\\n\", \u0026a) 输出结果如下： 0xc000094000 c000094000 宽度标识符 宽度通过一个紧跟在百分号后面的十进制数指定，如果未指定宽度，则表示值时除必需之外不作填充。精度通过（可选的）宽度后跟点号后跟的十进制数指定。如果未指定精度，会使用默认精度；如果点号后没有跟数字，表示精度为0。举例如下： 占位符 说明 %f 默认宽度，默认精度 %9f 宽度9，默认精度 %.2f 默认宽度，精度2 %9.2f 宽度9，精度2 %9.f 宽度9，精度0 示例代码如下： n := 12.34 fmt.Printf(\"%f\\n\", n) fmt.Printf(\"%9f\\n\", n) fmt.Printf(\"%.2f\\n\", n) fmt.Printf(\"%9.2f\\n\", n) fmt.Printf(\"%9.f\\n\", n) 输出结果如下： 12.340000 12.340000 12.34 12.34 12 其他falg 占位符 说明 ’+’ 总是输出数值的正负号；对%q（%+q）会生成全部是ASCII字符的输出（通过转义）； ’ ‘ 对数值，正数前加空格而负数前加负号；对字符串采用%x或%X时（% x或% X）会给各打印的字节之间加空格 ’-’ 在输出右边填充空白而不是默认的左边（即从默认的右对齐切换为左对齐）； ’#’ 八进制数前加0（%#o），十六进制数前加0x（%#x）或0X（%#X），指针去掉前面的0x（%#p）对%q（%#q），对%U（%#U）会输出空格和单引号括起来的go字面值； ‘0’ 使用0而不是空格填充，对于数值类型会把填充的0放在正负号后面； 举个例子： s := \"小王子\" fmt.Printf(\"%s\\n\", s) fmt.Printf(\"%5s\\n\", s) fmt.Printf(\"%-5s\\n\", s) fmt.Printf(\"%5.7s\\n\", s) fmt.Printf(\"%-5.7s\\n\", s) fmt.Printf(\"%5.2s\\n\", s) fmt.Printf(\"%05s\\n\", s) 输出结果如下： 小王子 小王子 小王子 小王子 小王子 小王 00小王子 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:2","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"获取输入 Go语言fmt包下有fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，可以在程序运行过程中从标准输入获取用户的输入。 fmt.Scan 函数定签名如下： func Scan(a ...interface{}) (n int, err error) Scan从标准输入扫描文本，读取由空白符分隔的值保存到传递给本函数的参数中，换行符视为空白符。 本函数返回成功扫描的数据个数和遇到的任何错误。如果读取的数据个数比提供的参数少，会返回一个错误报告原因。 具体代码示例如下： func main() { var ( name string age int married bool ) fmt.Scan(\u0026name, \u0026age, \u0026married) fmt.Printf(\"扫描结果 name:%s age:%d married:%t \\n\", name, age, married) } 将上面的代码编译后在终端执行，在终端依次输入小王子、28和false使用空格分隔。 $ ./scan_demo 小王子 28 false 扫描结果 name:小王子 age:28 married:false fmt.Scan从标准输入中扫描用户输入的数据，将以空白符分隔的数据分别存入指定的参数。 fmt.Scanf 函数签名如下： func Scanf(format string, a ...interface{}) (n int, err error) Scanf从标准输入扫描文本，根据format参数指定的格式去读取由空白符分隔的值保存到传递给本函数的参数中。 本函数返回成功扫描的数据个数和遇到的任何错误。 代码示例如下： func main() { var ( name string age int married bool ) fmt.Scanf(\"1:%s 2:%d 3:%t\", \u0026name, \u0026age, \u0026married) fmt.Printf(\"扫描结果 name:%s age:%d married:%t \\n\", name, age, married) } 将上面的代码编译后在终端执行，在终端按照指定的格式依次输入小王子、28和false。 $ ./scan_demo 1:小王子 2:28 3:false 扫描结果 name:小王子 age:28 married:false fmt.Scanf不同于fmt.Scan简单的以空格作为输入数据的分隔符，fmt.Scanf为输入数据指定了具体的输入内容格式，只有按照格式输入数据才会被扫描并存入对应变量。 例如，我们还是按照上个示例中以空格分隔的方式输入，fmt.Scanf就不能正确扫描到输入的数据。 $ ./scan_demo 小王子 28 false 扫描结果 name: age:0 married:false fmt.Scanln 函数签名如下： func Scanln(a ...interface{}) (n int, err error) Scanln类似Scan，它在遇到换行时才停止扫描。最后一个数据后面必须有换行或者到达结束位置。 本函数返回成功扫描的数据个数和遇到的任何错误。 具体代码示例如下： func main() { var ( name string age int married bool ) fmt.Scanln(\u0026name, \u0026age, \u0026married) fmt.Printf(\"扫描结果 name:%s age:%d married:%t \\n\", name, age, married) } 将上面的代码编译后在终端执行，在终端依次输入小王子、28和false使用空格分隔。 $ ./scan_demo 小王子 28 false 扫描结果 name:小王子 age:28 married:false fmt.Scanln遇到回车就结束扫描了，这个比较常用。 bufio.NewReader 有时候我们想完整获取输入的内容，而输入的内容可能包含空格，这种情况下可以使用bufio包来实现。示例代码如下： func bufioDemo() { reader := bufio.NewReader(os.Stdin) // 从标准输入生成读对象 fmt.Print(\"请输入内容：\") text, _ := reader.ReadString('\\n') // 读到换行 text = strings.TrimSpace(text) fmt.Printf(\"%#v\\n\", text) } Fscan系列 这几个函数功能分别类似于fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，只不过它们不是从标准输入中读取数据而是从io.Reader中读取数据。 func Fscan(r io.Reader, a ...interface{}) (n int, err error) func Fscanln(r io.Reader, a ...interface{}) (n int, err error) func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) Sscan系列 这几个函数功能分别类似于fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，只不过它们不是从标准输入中读取数据而是从指定字符串中读取数据。 func Sscan(str string, a ...interface{}) (n int, err error) func Sscanln(str string, a ...interface{}) (n int, err error) func Sscanf(str string, format string, a ...interface{}) (n int, err error) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:3","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"Go文件操作 参考链接：https://www.liwenzhou.com/posts/Go/go_file/ ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:0","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"文件 计算机中的文件是存储在外部介质（通常是磁盘）上的数据集合，文件分为文本文件和二进制文件 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:1","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"文件打开和关闭 os.Open()函数能够打开一个文件，返回一个*File和一个err。对得到的文件实例调用close()方法能够关闭文件。 package main import ( \"fmt\" \"os\" ) func main() { // 只读方式打开当前目录下的main.go文件 file, err := os.Open(\"./main.go\") if err != nil { fmt.Println(\"open file failed!, err:\", err) return } // 关闭文件 file.Close() } 为了防止文件忘记关闭，我们通常使用defer注册文件关闭语句。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:2","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"读取文件 file.Read() 基本使用 Read方法的定义如下： func (f *File) Read(b []byte) (n int, err error) 它接收一个字节切片，返回读取的字节数和可能的具体错误，读到文件末尾时会返回0和io.EOF。 举个例子： func main() { // 只读方式打开当前目录下的main.go文件 file, err := os.Open(\"./main.go\") if err != nil { fmt.Println(\"open file failed!, err:\", err) return } defer file.Close() // 使用Read方法读取数据 var tmp = make([]byte, 128) n, err := file.Read(tmp) if err == io.EOF { fmt.Println(\"文件读完了\") return } if err != nil { fmt.Println(\"read file failed, err:\", err) return } fmt.Printf(\"读取了%d字节数据\\n\", n) fmt.Println(string(tmp[:n])) } 循环读取 使用for循环读取文件中所有的数据 func main() { // 只读方式打开当前目录下的main.go文件 file, err := os.Open(\"./main.go\") if err != nil { fmt.Println(\"open file failed!, err:\", err) return } defer file.Close() // 循环读取文件 var content []byte var tmp = make([]byte, 128) for { n, err := file.Read(tmp) if err == io.EOF { fmt.Println(\"文件读完了\") break } if err != nil { fmt.Println(\"read file failed, err:\", err) return } content = append(content, tmp[:n]...) } fmt.Println(string(content)) } bufio读取文件 bufio是在file的基础上封装了一层API，支持更多的功能。 package main import ( \"bufio\" \"fmt\" \"io\" \"os\" ) // bufio按行读取示例 func main() { file, err := os.Open(\"./xx.txt\") if err != nil { fmt.Println(\"open file failed, err:\", err) return } defer file.Close() reader := bufio.NewReader(file) for { line, err := reader.ReadString('\\n') //注意是字符 if err == io.EOF { if len(line) != 0 { fmt.Println(line) } fmt.Println(\"文件读完了\") break } if err != nil { fmt.Println(\"read file failed, err:\", err) return } fmt.Print(line) } } ioutil读取整个文件 io/ioutil包的ReadFile方法能够读取完整的文件，只需要将文件名作为参数传入。 package main import ( \"fmt\" \"io/ioutil\" ) // ioutil.ReadFile读取整个文件 func main() { content, err := ioutil.ReadFile(\"./main.go\") if err != nil { fmt.Println(\"read file failed, err:\", err) return } fmt.Println(string(content)) } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:3","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"文件写入 os.OpenFile()函数能够以指定模式打开文件，从而实现文件写入相关功能。 func OpenFile(name string, flag int, perm FileMode) (*File, error) { ... } 其中： name：要打开的文件名 flag：打开文件的模式。 模式有以下几种： 模式 含义 os.O_WRONLY 只写 os.O_CREATE 创建文件 os.O_RDONLY 只读 os.O_RDWR 读写 os.O_TRUNC 清空 os.O_APPEND 追加 perm：文件权限，一个八进制数。r（读）4，w（写）2，x（执行）1。 Write和WriteString func main() { file, err := os.OpenFile(\"xx.txt\", os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0666) if err != nil { fmt.Println(\"open file failed, err:\", err) return } defer file.Close() str := \"hello 沙河\" file.Write([]byte(str)) //写入字节切片数据 file.WriteString(\"hello 小王子\") //直接写入字符串数据 } bufio.NewWriter func main() { file, err := os.OpenFile(\"xx.txt\", os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0666) if err != nil { fmt.Println(\"open file failed, err:\", err) return } defer file.Close() writer := bufio.NewWriter(file) for i := 0; i \u003c 10; i++ { writer.WriteString(\"hello沙河\\n\") //将数据先写入缓存 } writer.Flush() //将缓存中的内容写入文件 } ioutil.WriteFile func main() { str := \"hello 沙河\" err := ioutil.WriteFile(\"./xx.txt\", []byte(str), 0666) if err != nil { fmt.Println(\"write file failed, err:\", err) return } } 练习： 1、实现cp命令 借助io.Copy()实现一个拷贝文件函数。 // CopyFile 拷贝文件函数 func CopyFile(dstName, srcName string) (written int64, err error) { // 以读方式打开源文件 src, err := os.Open(srcName) if err != nil { fmt.Printf(\"open %s failed, err:%v.\\n\", srcName, err) return } defer src.Close() // 以写|创建的方式打开目标文件 dst, err := os.OpenFile(dstName, os.O_WRONLY|os.O_CREATE, 0644) if err != nil { fmt.Printf(\"open %s failed, err:%v.\\n\", dstName, err) return } defer dst.Close() return io.Copy(dst, src) //调用io.Copy()拷贝内容 } func main() { _, err := CopyFile(\"dst.txt\", \"src.txt\") if err != nil { fmt.Println(\"copy file failed, err:\", err) return } fmt.Println(\"copy done!\") } 2、实现cat命令 使用文件操作相关知识，模拟实现linux平台cat命令的功能 package main import ( \"bufio\" \"flag\" \"fmt\" \"io\" \"os\" ) // cat命令实现 func cat(r *bufio.Reader) { for { buf, err := r.ReadBytes('\\n') //注意是字符 if err == io.EOF { // 退出之前将已读到的内容输出 fmt.Fprintf(os.Stdout, \"%s\", buf) break } fmt.Fprintf(os.Stdout, \"%s\", buf) } } func main() { flag.Parse() // 解析命令行参数 if flag.NArg() == 0 { // 如果没有参数默认从标准输入读取内容 cat(bufio.NewReader(os.Stdin)) } // 依次读取每个指定文件的内容并打印到终端 for i := 0; i \u003c flag.NArg(); i++ { f, err := os.Open(flag.Arg(i)) if err != nil { fmt.Fprintf(os.Stdout, \"reading from %s failed, err:%v\\n\", flag.Arg(i), err) continue } cat(bufio.NewReader(f)) } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:4","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"Excel库excelize 参考链接：[Go 语言读写 Excel - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/33417413#:~:text=Excelize 是 Go 语言编写的用于操作 Office Excel 文档类库，基于 ECMA-376,标准。 可以使用它来读取、写入由 Microsoft Excel™ 2007 及以上版本创建的 XLSX 文档。) Excelize 是 Go 语言编写的用于操作 Office Excel 文档类库，基于 ECMA-376 Office OpenXML 标准。可以使用它来读取、写入由 Microsoft Excel™ 2007 及以上版本创建的 XLSX 文档。相比较其他的开源类库，Excelize 支持写入原本带有图片(表)、透视表和切片器等复杂样式的文档，还支持向 Excel 文档中插入图片与图表，并且在保存后不会丢失文档原有样式，可以应用于各类报表系统中。使用本类库要求使用的 Go 语言为 1.8 或更高版本，完整的 API 使用文档请访问 godoc.org 或查看参考文档。 GitHub: excelize 官方文档：https://xuri.me/excelize ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-excelize/:1:0","tags":["Go","excelize","xls","xlsx"],"title":"Go excelize","uri":"/posts/2023-11-11-go-excelize/"},{"categories":["Go 库文档"],"content":"1、简单使用 安装 go get github.com/xuri/excelize/v2 1）创建XLSX package main import \"github.com/360EntSecGroup-Skylar/excelize\" func main() { f := excelize.NewFile() // 创建一个工作表 index := f.NewSheet(\"Sheet2\") // 设置单元格的值 f.SetCellValue(\"Sheet1\", \"A2\", \"Hello world.\") f.SetCellValue(\"Sheet1\", \"B2\", 100) f.SetCellValue(\"Sheet1\", \"B3\", \"github\") // 设置工作簿的默认工作表 f.SetActiveSheet(index) // 根据指定路径保存文件 if err := f.SaveAs(\"Book1.xlsx\"); err != nil { println(err.Error()) } } 结果： SetCellValue函数解释 f.SetCellValue(sheet string, axis string, value interface{}) f.SetCellValue(\"Sheet1\", \"B3\", \"github\") sheet：是sheet表格的的名字。 axis：包含两部分，字母表示列，数字表示行。 value：表示值。 2）读取xlsx func ReadXlsx() { filename := \"Book1.xlsx\" f, err := excelize.OpenFile(filename) if err != nil { fmt.Printf(\"无法打开xlsx：%v 错误原因：%v\", filename, err) return } // 获取工作表中指定单元格的值 cell, err := f.GetCellValue(\"Sheet1\", \"B3\") if err != nil { fmt.Printf(\"获取 %v 的%v的 值 失败,失败原因：%v\", \"Sheet1\", \"B3\", err) } fmt.Printf(\"读取的内容为：%v\", cell) // 获取 Sheet1 上所有单元格 rows, err := f.GetRows(\"Sheet1\") if err != nil { fmt.Printf(\"获取 %v的单元格失败,失败原因：%v\", \"Sheet1\", err) } for _, row := range rows { for _, colCell := range row { print(colCell, \"\\t\") } println() } } 3）插入一行数据 func (exa *ExcelService) ParseInfoList2Excel(infoList []system.SysBaseMenu, filePath string) error { excel := excelize.NewFile() excel.SetSheetRow(\"Sheet1\", \"A1\", \u0026[]string{\"ID\", \"路由Name\", \"路由Path\", \"是否隐藏\", \"父节点\", \"排序\", \"文件名称\"}) for i, menu := range infoList { axis := fmt.Sprintf(\"A%d\", i+2) excel.SetSheetRow(\"Sheet1\", axis, \u0026[]interface{}{ menu.ID, menu.Name, menu.Path, menu.Hidden, menu.ParentId, menu.Sort, menu.Component, }) } err := excel.SaveAs(filePath) return err } 4）从表格中导入数据 func PasreExcel2List(filepath string, fileHeader []string, skipHeader bool) (data [][]string, err error) { file, err := excelize.OpenFile(filepath) if err != nil { return } defer file.Close() rows, err := file.GetRows(\"Sheet1\") if err != nil { return } if skipHeader { if ForEqualStringSlice(rows[0], fileHeader) { rows = rows[1:] } else { err = errors.New(\"FileHeader not Equal.\") return } } data = rows return } func (exa *ExcelService) ParseExcel2InfoList() ([]system.SysBaseMenu, error) { skipHeader := true fixedHeader := []string{\"ID\", \"路由Name\", \"路由Path\", \"是否隐藏\", \"父节点\", \"排序\", \"文件名称\"} file, err := excelize.OpenFile(global.GVA_CONFIG.Excel.Dir + \"ExcelImport.xlsx\") if err != nil { return nil, err } menus := make([]system.SysBaseMenu, 0) rows, err := file.Rows(\"Sheet1\") if err != nil { return nil, err } for rows.Next() { row, err := rows.Columns() if err != nil { return nil, err } if skipHeader { if exa.compareStrSlice(row, fixedHeader) { skipHeader = false continue } else { return nil, errors.New(\"Excel格式错误\") } } if len(row) != len(fixedHeader) { continue } id, _ := strconv.Atoi(row[0]) hidden, _ := strconv.ParseBool(row[3]) sort, _ := strconv.Atoi(row[5]) menu := system.SysBaseMenu{ GVA_MODEL: global.GVA_MODEL{ ID: uint(id), }, Name: row[1], Path: row[2], Hidden: hidden, ParentId: row[4], Sort: sort, Component: row[6], } menus = append(menus, menu) } return menus, nil } func (exa *ExcelService) compareStrSlice(a, b []string) bool { if len(a) != len(b) { return false } if (b == nil) != (a == nil) { return false } for key, value := range a { if value != b[key] { return false } } return true } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-excelize/:1:1","tags":["Go","excelize","xls","xlsx"],"title":"Go excelize","uri":"/posts/2023-11-11-go-excelize/"},{"categories":["Go 库文档"],"content":"cron定时任务 参考链接：https://segmentfault.com/a/1190000023029219 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:0","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"简介 cron一个用于管理定时任务的库，用 Go 实现 Linux 中crontab这个命令的效果。之前我们也介绍过一个类似的 Go 库——gron。gron代码小巧，用于学习是比较好的。但是它功能相对简单些，并且已经不维护了。如果有定时任务需求，还是建议使用cron。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:1","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"快速使用 安装cron，目前最新稳定版本为 v3： $ go get github.com/robfig/cron/v3 使用 package main import ( \"fmt\" \"time\" \"github.com/robfig/cron/v3\" ) func main() { c := cron.New() c.AddFunc(\"@every 1s\", func() { fmt.Println(\"tick every 1 second\") }) c.Start() time.Sleep(time.Second * 5) } 使用非常简单，创建cron对象，这个对象用于管理定时任务。 调用cron对象的AddFunc()方法向管理器中添加定时任务。AddFunc()接受两个参数，参数 1 以字符串形式指定触发时间规则，参数 2 是一个无参的函数，每次触发时调用。@every 1s表示每秒触发一次，@every后加一个时间间隔，表示每隔多长时间触发一次。例如@every 1h表示每小时触发一次，@every 1m2s表示每隔 1 分 2 秒触发一次。time.ParseDuration()支持的格式都可以用在这里。 调用c.Start()启动定时循环。 注意一点，因为c.Start()启动一个新的 goroutine 做循环检测，我们在代码最后加了一行time.Sleep(time.Second * 5)防止主 goroutine 退出。 运行效果，每隔 1s 输出一行字符串： $ go run main.go tick every 1 second tick every 1 second tick every 1 second tick every 1 second tick every 1 second ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:2","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"时间格式 与Linux 中crontab命令相似，cron库支持用 5 个空格分隔的域来表示时间。这 5 个域含义依次为： Minutes：分钟，取值范围[0-59]，支持特殊字符* / , -； Hours：小时，取值范围[0-23]，支持特殊字符* / , -； Day of month：每月的第几天，取值范围[1-31]，支持特殊字符* / , - ?； Month：月，取值范围[1-12]或者使用月份名字缩写[JAN-DEC]，支持特殊字符* / , -； Day of week：周历，取值范围[0-6]或名字缩写[JUN-SAT]，支持特殊字符* / , - ?。 注意，月份和周历名称都是不区分大小写的，也就是说SUN/Sun/sun表示同样的含义（都是周日）。 特殊字符含义如下： *：使用*的域可以匹配任何值，例如将月份域（第 4 个）设置为*，表示每个月； /：用来指定范围的步长，例如将小时域（第 2 个）设置为3-59/15表示第 3 分钟触发，以后每隔 15 分钟触发一次，因此第 2 次触发为第 18 分钟，第 3 次为 33 分钟。。。直到分钟大于 59； ,：用来列举一些离散的值和多个范围，例如将周历的域（第 5 个）设置为MON,WED,FRI表示周一、三和五； -：用来表示范围，例如将小时的域（第 1 个）设置为9-17表示上午 9 点到下午 17 点（包括 9 和 17）； ?：只能用在月历和周历的域中，用来代替*，表示每月/周的任意一天。 了解规则之后，我们可以定义任意时间： 30 * * * *：分钟域为 30，其他域都是*表示任意。每小时的 30 分触发； 30 3-6,20-23 * * *：分钟域为 30，小时域的3-6,20-23表示 3 点到 6 点和 20 点到 23 点。3,4,5,6,20,21,22,23 时的 30 分触发； 0 0 1 1 *：1（第 4 个） 月 1（第 3 个） 号的 0（第 2 个） 时 0（第 1 个） 分触发。 记熟了这几个域的顺序，再多练习几次很容易就能掌握格式。熟悉规则了之后，就能熟练使用crontab命令了。 func main() { c := cron.New() c.AddFunc(\"30 * * * *\", func() { fmt.Println(\"Every hour on the half hour\") }) c.AddFunc(\"30 3-6,20-23 * * *\", func() { fmt.Println(\"On the half hour of 3-6am, 8-11pm\") }) c.AddFunc(\"0 0 1 1 *\", func() { fmt.Println(\"Jun 1 every year\") }) c.Start() for { time.Sleep(time.Second) } } 预定义时间规则 为了方便使用，cron预定义了一些时间规则： @yearly：也可以写作@annually，表示每年第一天的 0 点。等价于0 0 1 1 *； @monthly：表示每月第一天的 0 点。等价于0 0 1 * *； @weekly：表示每周第一天的 0 点，注意第一天为周日，即周六结束，周日开始的那个 0 点。等价于0 0 * * 0； @daily：也可以写作@midnight，表示每天 0 点。等价于0 0 * * *； @hourly：表示每小时的开始。等价于0 * * * *。 例如： func main() { c := cron.New() c.AddFunc(\"@hourly\", func() { fmt.Println(\"Every hour\") }) c.AddFunc(\"@daily\", func() { fmt.Println(\"Every day on midnight\") }) c.AddFunc(\"@weekly\", func() { fmt.Println(\"Every week\") }) c.Start() for { time.Sleep(time.Second) } } 上面代码只是演示用法，实际运行可能要等待非常长的时间才能有输出。 固定时间间隔 cron支持固定时间间隔，格式为： @every \u003cduration\u003e 含义为每隔duration触发一次。``会调用time.ParseDuration()函数解析，所以ParseDuration支持的格式都可以。例如1h30m10s。在快速开始部分，我们已经演示了@every的用法了，这里就不赘述了。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:3","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"时区 默认情况下，所有时间都是基于当前时区的。当然我们也可以指定时区，有 2 两种方式： 在时间字符串前面添加一个CRON_TZ= + 具体时区，具体时区的格式在之前carbon的文章中有详细介绍。东京时区为Asia/Tokyo，纽约时区为America/New_York； 创建cron对象时增加一个时区选项cron.WithLocation(location)，location为time.LoadLocation(zone)加载的时区对象，zone为具体的时区格式。或者调用已创建好的cron对象的SetLocation()方法设置时区。 示例： func main() { nyc, _ := time.LoadLocation(\"America/New_York\") c := cron.New(cron.WithLocation(nyc)) c.AddFunc(\"0 6 * * ?\", func() { fmt.Println(\"Every 6 o'clock at New York\") }) c.AddFunc(\"CRON_TZ=Asia/Tokyo 0 6 * * ?\", func() { fmt.Println(\"Every 6 o'clock at Tokyo\") }) c.Start() for { time.Sleep(time.Second) } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:4","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"Job接口 除了直接将无参函数作为回调外，cron还支持Job接口： // cron.go type Job interface { Run() } 我们定义一个实现接口Job的结构： type GreetingJob struct { Name string } func (g GreetingJob) Run() { fmt.Println(\"Hello \", g.Name) } 调用cron对象的AddJob()方法将GreetingJob对象添加到定时管理器中： func main() { c := cron.New() c.AddJob(\"@every 1s\", GreetingJob{\"dj\"}) c.Start() time.Sleep(5 * time.Second) } 运行效果： $ go run main.go Hello dj Hello dj Hello dj Hello dj Hello dj 使用自定义的结构可以让任务携带状态（Name字段）。 实际上AddFunc()方法内部也调用了AddJob()方法。首先，cron基于func()类型定义一个新的类型FuncJob： // cron.go type FuncJob func() 然后让FuncJob实现Job接口： // cron.go func (f FuncJob) Run() { f() } 在AddFunc()方法中，将传入的回调转为FuncJob类型，然后调用AddJob()方法： func (c *Cron) AddFunc(spec string, cmd func()) (EntryID, error) { return c.AddJob(spec, FuncJob(cmd)) } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:5","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"线程安全 cron会创建一个新的 goroutine 来执行触发回调。如果这些回调需要并发访问一些资源、数据，我们需要显式地做同步。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:6","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"自定义时间格式 cron支持灵活的时间格式，如果默认的格式不能满足要求，我们可以自己定义时间格式。时间规则字符串需要cron.Parser对象来解析。我们先来看看默认的解析器是如何工作的。 首先定义各个域： // parser.go const ( Second ParseOption = 1 \u003c\u003c iota SecondOptional Minute Hour Dom Month Dow DowOptional Descriptor ) 除了Minute/Hour/Dom(Day of month)/Month/Dow(Day of week)外，还可以支持Second。相对顺序都是固定的： // parser.go var places = []ParseOption{ Second, Minute, Hour, Dom, Month, Dow, } var defaults = []string{ \"0\", \"0\", \"0\", \"*\", \"*\", \"*\", } 默认的时间格式使用 5 个域。 我们可以调用cron.NewParser()创建自己的Parser对象，以位格式传入使用哪些域，例如下面的Parser使用 6 个域，支持Second（秒）： parser := cron.NewParser( cron.Second | cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.Dow | cron.Descriptor, ) 调用cron.WithParser(parser)创建一个选项传入构造函数cron.New()，使用时就可以指定秒了： c := cron.New(cron.WithParser(parser)) c.AddFunc(\"1 * * * * *\", func () { fmt.Println(\"every 1 second\") }) c.Start() 这里时间格式必须使用 6 个域，顺序与上面的const定义一致。 因为上面的时间格式太常见了，cron定义了一个便捷的函数： // option.go func WithSeconds() Option { return WithParser(NewParser( Second | Minute | Hour | Dom | Month | Dow | Descriptor, )) } 注意Descriptor表示对@every/@hour等的支持。有了WithSeconds()，我们不用手动创建Parser对象了： c := cron.New(cron.WithSeconds()) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:7","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"选项 cron对象创建使用了选项模式，我们前面已经介绍了 3 个选项： WithLocation：指定时区； WithParser：使用自定义的解析器； WithSeconds：让时间格式支持秒，实际上内部调用了WithParser。 cron还提供了另外两种选项： WithLogger：自定义Logger； WithChain：Job 包装器。 WithLogger WithLogger可以设置cron内部使用我们自定义的Logger： func main() { c := cron.New( cron.WithLogger( cron.VerbosePrintfLogger(log.New(os.Stdout, \"cron: \", log.LstdFlags)))) c.AddFunc(\"@every 1s\", func() { fmt.Println(\"hello world\") }) c.Start() time.Sleep(5 * time.Second) } 上面调用cron.VerbosPrintfLogger()包装log.Logger，这个logger会详细记录cron内部的调度过程： $ go run main.go cron: 2020/06/26 07:09:14 start cron: 2020/06/26 07:09:14 schedule, now=2020-06-26T07:09:14+08:00, entry=1, next=2020-06-26T07:09:15+08:00 cron: 2020/06/26 07:09:15 wake, now=2020-06-26T07:09:15+08:00 cron: 2020/06/26 07:09:15 run, now=2020-06-26T07:09:15+08:00, entry=1, next=2020-06-26T07:09:16+08:00 hello world cron: 2020/06/26 07:09:16 wake, now=2020-06-26T07:09:16+08:00 cron: 2020/06/26 07:09:16 run, now=2020-06-26T07:09:16+08:00, entry=1, next=2020-06-26T07:09:17+08:00 hello world cron: 2020/06/26 07:09:17 wake, now=2020-06-26T07:09:17+08:00 cron: 2020/06/26 07:09:17 run, now=2020-06-26T07:09:17+08:00, entry=1, next=2020-06-26T07:09:18+08:00 hello world cron: 2020/06/26 07:09:18 wake, now=2020-06-26T07:09:18+08:00 hello world cron: 2020/06/26 07:09:18 run, now=2020-06-26T07:09:18+08:00, entry=1, next=2020-06-26T07:09:19+08:00 cron: 2020/06/26 07:09:19 wake, now=2020-06-26T07:09:19+08:00 hello world cron: 2020/06/26 07:09:19 run, now=2020-06-26T07:09:19+08:00, entry=1, next=2020-06-26T07:09:20+08:0 我们看看默认的Logger是什么样的： // logger.go var DefaultLogger Logger = PrintfLogger(log.New(os.Stdout, \"cron: \", log.LstdFlags)) func PrintfLogger(l interface{ Printf(string, ...interface{}) }) Logger { return printfLogger{l, false} } func VerbosePrintfLogger(l interface{ Printf(string, ...interface{}) }) Logger { return printfLogger{l, true} } type printfLogger struct { logger interface{ Printf(string, ...interface{}) } logInfo bool } WithChain Job 包装器可以在执行实际的Job前后添加一些逻辑： 捕获panic； 如果Job上次运行还未结束，推迟本次执行; 如果Job上次运行还未介绍，跳过本次执行； 记录每个Job的执行情况。 我们可以将Chain类比为 Web 处理器的中间件。实际上就是在Job的执行逻辑外在封装一层逻辑。我们的封装逻辑需要写成一个函数，传入一个Job类型，返回封装后的Job。cron为这种函数定义了一个类型JobWrapper： // chain.go type JobWrapper func(Job) Job 然后使用一个Chain对象将这些JobWrapper组合到一起： type Chain struct { wrappers []JobWrapper } func NewChain(c ...JobWrapper) Chain { return Chain{c} } 调用Chain对象的Then(job)方法应用这些JobWrapper，返回最终的`Job： func (c Chain) Then(j Job) Job { for i := range c.wrappers { j = c.wrappers[len(c.wrappers)-i-1](j) } return j } 注意应用JobWrapper的顺序。 内置JobWrapper cron内置了 3 个用得比较多的JobWrapper： Recover：捕获内部Job产生的 panic； DelayIfStillRunning：触发时，如果上一次任务还未执行完成（耗时太长），则等待上一次任务完成之后再执行； SkipIfStillRunning：触发时，如果上一次任务还未完成，则跳过此次执行。 下面分别介绍。 Recover 先看看如何使用： type panicJob struct { count int } func (p *panicJob) Run() { p.count++ if p.count == 1 { panic(\"oooooooooooooops!!!\") } fmt.Println(\"hello world\") } func main() { c := cron.New() c.AddJob(\"@every 1s\", cron.NewChain(cron.Recover(cron.DefaultLogger)).Then(\u0026panicJob{})) c.Start() time.Sleep(5 * time.Second) } panicJob在第一次触发时，触发了panic。因为有cron.Recover()保护，后续任务还能执行： go run main.go cron: 2020/06/27 14:02:00 panic, error=oooooooooooooops!!!, stack=... goroutine 18 [running]: github.com/robfig/cron/v3.Recover.func1.1.1(0x514ee0, 0xc0000044a0) D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/chain.go:45 +0xbc panic(0x4cf380, 0x513280) C:/Go/src/runtime/panic.go:969 +0x174 main.(*panicJob).Run(0xc0000140e8) D:/code/golang/src/github.com/darjun/go-daily-lib/cron/recover/main.go:17 +0xba github.com/robfig/cron/v3.Recover.func1.1() D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/chain.go:53 +0x6f github.com/robfig/cron/v3.FuncJob.Run(0xc000070390) D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/cron.go:136 +0x2c github.com/robfig/cron/v3.(*Cron).startJob.func1(0xc00005c0a0, 0x514d20, 0xc000070390) D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/cron.go:312 +0x68 created by github.com/robfig/cron/v3.(*Cron).startJob D:","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:8","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"Go goph库 链接地址： github.com/melbahja/goph github.com/serialt/goph (方便指定端口) ","date":"2023-11-10","objectID":"/posts/go-goth/:0:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"特性 易于使用，简化 ssh api。 支持ssh 密码、私钥，带密码的私钥。 支持从本地上传文件和从远程下载文件。 支持 ssh 使用 ssh-agent 连接会话。 支持增加主机到 known_hosts 文件。 ","date":"2023-11-10","objectID":"/posts/go-goth/:1:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"安装 go get github.com/serialt/goph ","date":"2023-11-10","objectID":"/posts/go-goth/:2:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"使用示例 ","date":"2023-11-10","objectID":"/posts/go-goth/:3:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"1、使用执行命令 package main import ( \"fmt\" \"log\" \"github.com/serialt/goph\" ) var Client *goph.Client func init() { auth, err := goph.Key(os.Getenv(\"HOME\")+\"/.ssh/id_rsa\", \"\") if err != nil { log.Fatalf(\"cat read the ssh private key: %v\", err) } client, err := goph.New(\"root\", \"10.10.16.10\", 22, auth) if err != nil { log.Fatalf(\"ssh link faild: %v\", err) } Client = client } func main() { result, err := Client.Run(\"date\") fmt.Printf(\"result: %v\\nerr: %v\", string(result), err) defer Client.Close() } ","date":"2023-11-10","objectID":"/posts/go-goth/:3:1","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"2、从字符串中读取私钥 package main import ( \"fmt\" \"log\" \"github.com/serialt/goph\" ) var Client *goph.Client var sshkey = ` -----BEGIN OPENSSH PRIVATE KEY----- NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID AAAECptYaTKFA2Omsb67+FN2SPr3daBAA0IxpVwv5KYJ1QKWR98JYVP7/WAqffRO NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID -----END OPENSSH PRIVATE KEY----- ` func init() { auth, err := goph.RawKey(sshkey, \"\") if err != nil { log.Fatalf(\"cat read the ssh private key: %v\", err) } client, err := goph.New(\"root\", \"10.10.16.10\", 22, auth) if err != nil { log.Fatalf(\"ssh link faild: %v\", err) } Client = client } func main() { result, err := Client.Run(\"date\") fmt.Printf(\"result: %v\\nerr: %v\", string(result), err) defer Client.Close() } ","date":"2023-11-10","objectID":"/posts/go-goth/:3:2","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"3、密钥带密码 auth, err := goph.Key(os.Getenv(\"HOME\")+\"/.ssh/id_rsa\", \"you_passphrase_here\") if err != nil { // handle error } client, err := goph.New(\"root\", \"192.1.1.3\", auth) ","date":"2023-11-10","objectID":"/posts/go-goth/:3:3","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"4、使用密码 auth, err := goph.UseAgent() if err != nil { // handle error } client, err := goph.New(\"root\", \"192.1.1.1\", auth) ","date":"2023-11-10","objectID":"/posts/go-goth/:3:4","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"5、上传和下载文件 // upload local file to remote err := client.Upload(\"/path/to/local/file\", \"/path/to/remote/file\") // download remote file to local err := client.Download(\"/path/to/remote/file\", \"/path/to/local/file\") ","date":"2023-11-10","objectID":"/posts/go-goth/:3:5","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"6、执行shell命令 // execute bash commands out, err := client.Run(\"bash -c 'printenv'\") // execute bash command whith timeout context, cancel := context.WithTimeout(ctx, time.Second) defer cancel() // will send SIGINT and return error after 1 second out, err := client.RunContext(ctx, \"sleep 5\") // execute bash command whith env variables out, err := client.Run(`env MYVAR=\"MY VALUE\" bash -c 'echo $MYVAR;'`) ","date":"2023-11-10","objectID":"/posts/go-goth/:3:6","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"7、使用goph cmd Goph.Cmd struct is like the Go standard os/exec.Cmd. // Get new `Goph.Cmd` cmd, err := client.Command(\"ls\", \"-alh\", \"/tmp\") // or with context: // cmd, err := client.CommandContext(ctx, \"ls\", \"-alh\", \"/tmp\") if err != nil { // handle the error! } // You can set env vars, but the server must be configured to `AcceptEnv line`. cmd.Env = []string{\"MY_VAR=MYVALUE\"} // Run you command. err = cmd.Run() ust like os/exec.Cmd you can run CombinedOutput, Output, Start, Wait, and ssh.Session methods like Signal… ","date":"2023-11-10","objectID":"/posts/go-goth/:3:7","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"8、使用sftp操作文件系统 sftp, err := client.NewSftp() if err != nil { // handle the error! } file, err := sftp.Create(\"/tmp/remote_file\") file.Write([]byte(`Hello world`)) file.Close() For more file operations see SFTP Docs. ","date":"2023-11-10","objectID":"/posts/go-goth/:3:8","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"官方示例 package main import ( \"bufio\" \"context\" \"errors\" \"flag\" \"fmt\" \"log\" \"net\" \"os\" osuser \"os/user\" \"path/filepath\" \"strings\" \"time\" \"github.com/pkg/sftp\" \"github.com/serialt/goph\" \"golang.org/x/crypto/ssh\" \"golang.org/x/crypto/ssh/terminal\" ) // // Run command and auth via password: // \u003e go run main.go --ip 192.168.122.102 --pass --cmd ls // // Run command and auth via private key: // \u003e go run main.go --ip 192.168.122.102 --cmd ls // Or: // \u003e go run main.go --ip 192.168.122.102 --key /path/to/private_key --cmd ls // // Run command and auth with private key and passphrase: // \u003e go run main.go --ip 192.168.122.102 --passphrase --cmd ls // // Run a command and interrupt it after 1 second: // \u003e go run main.go --ip 192.168.122.102 --cmd \"sleep 10\" --timeout=1s // // You can test with the interactive mode without passing --cmd flag. // var ( err error auth goph.Auth client *goph.Client addr string user string port uint key string cmd string pass bool passphrase bool timeout time.Duration agent bool sftpc *sftp.Client ) func init() { usr, err := osuser.Current() if err != nil { fmt.Println(\"couldn't determine current user. defaulting to 'root'\") usr.Username = \"root\" } flag.StringVar(\u0026addr, \"ip\", \"127.0.0.1\", \"machine ip address.\") flag.StringVar(\u0026user, \"user\", usr.Username, \"ssh user.\") flag.UintVar(\u0026port, \"port\", 22, \"ssh port number.\") flag.StringVar(\u0026key, \"key\", filepath.Join(os.Getenv(\"HOME\"), \".ssh\", \"id_rsa\"), \"private key path.\") flag.StringVar(\u0026cmd, \"cmd\", \"\", \"command to run.\") flag.BoolVar(\u0026pass, \"pass\", false, \"ask for ssh password instead of private key.\") flag.BoolVar(\u0026agent, \"agent\", false, \"use ssh agent for authentication (unix systems only).\") flag.BoolVar(\u0026passphrase, \"passphrase\", false, \"ask for private key passphrase.\") flag.DurationVar(\u0026timeout, \"timeout\", 0, \"interrupt a command with SIGINT after a given timeout (0 means no timeout)\") } func VerifyHost(host string, remote net.Addr, key ssh.PublicKey) error { // // If you want to connect to new hosts. // here your should check new connections public keys // if the key not trusted you shuld return an error // // hostFound: is host in known hosts file. // err: error if key not in known hosts file OR host in known hosts file but key changed! hostFound, err := goph.CheckKnownHost(host, remote, key, \"\") // Host in known hosts but key mismatch! // Maybe because of MAN IN THE MIDDLE ATTACK! if hostFound \u0026\u0026 err != nil { return err } // handshake because public key already exists. if hostFound \u0026\u0026 err == nil { return nil } // Ask user to check if he trust the host public key. if askIsHostTrusted(host, key) == false { // Make sure to return error on non trusted keys. return errors.New(\"you typed no, aborted!\") } // Add the new host to known hosts file. return goph.AddKnownHost(host, remote, key, \"\") } func main() { flag.Parse() var err error if agent || goph.HasAgent() { auth, err = goph.UseAgent() } else if pass { auth = goph.Password(askPass(\"Enter SSH Password: \")) } else { auth, err = goph.Key(key, getPassphrase(passphrase)) } if err != nil { panic(err) } client, err = goph.NewConn(\u0026goph.Config{ User: user, Addr: addr, Port: port, Auth: auth, Callback: VerifyHost, }) if err != nil { panic(err) } // Close client net connection defer client.Close() // If the cmd flag exists if cmd != \"\" { ctx := context.Background() // create a context with timeout, if supplied in the argumetns if timeout \u003e 0 { var cancel context.CancelFunc ctx, cancel = context.WithTimeout(ctx, timeout) defer cancel() } out, err := client.RunContext(ctx, cmd) fmt.Println(string(out), err) return } // else open interactive mode. playWithSSHJustForTestingThisProgram(client) } func askPass(msg string) string { fmt.Print(msg) pass, err := terminal.ReadPassword(0) if err != nil { panic(err) } fmt.Println(\"\") return strings.TrimSpace(string(pass)) } func getPassphrase(ask bool) string { if ask { return askPass(\"Enter Private Key Passphrase: \") } return \"\" } func askIsHostTrusted(host string, key ssh.Public","date":"2023-11-10","objectID":"/posts/go-goth/:4:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["DevOps"],"content":"镜像同步 参考链接： https://lework.github.io/2020/04/13/skopeo/ https://blog.k8s.li/skopeo.html 日常工作中，需要将各种镜像搬到对应的仓库中，docker 适合于构建镜像，将镜像推送于仓库中。镜像被推送到仓库中后，如果需要对镜像进行搬运，在仓库不提供这个功能的情况下，同步镜像是比较困难的。 skopeo 是红帽开源的容器镜像管理工具。相比于docker，它有一下的优点： 支持多个平台：skopeo 支持 Linux，Mac 和 Windows。 无需 docker 或者 podman：skopeo 可以构建为单一的 cli，不依赖于 docker 服务或者 podman。 支持多个 OCI 镜像仓库间同步：支持 OCI 的镜像托管服务，都可以相互同步。 支持多架构镜像同步：可以同步多种架构的镜像。 镜像验签：skopeo 支持镜像签名，可确保镜像的完整性和可靠性。 ","date":"2023-11-08","objectID":"/posts/skopeo/:0:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"一、编译skopeo skopeo 官方并不提供编译好的静态二进制可执行文件，常见的系统源中已经包含了 skopeo，但由于 skopeo 的版本迭代比较快，新的功能也随之增加，部分操作系统里提供的安装包版本可能比较低，无法适用，且 skopeo 大多都是链接了动态库，无法通用于多个 linux 发行版，因此可以借助docker实现skopeo的静态编译。 基于github action构建skopeo: skopeo ","date":"2023-11-08","objectID":"/posts/skopeo/:1:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"下载 skopeo 源码 # download source code git clone --depth=1 https://github.com/containers/skopeo.git ","date":"2023-11-08","objectID":"/posts/skopeo/:1:1","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"构建build镜像的Dockerfile 国内构建则需要修改 alpine 和 go 镜像地址，可直连 github 的可以忽略此步 FROM golang:1.19-alpine3.16 AS builder ENV LANG=C.UTF-8 ENV TZ=Asia/Shanghai ENV CGO_ENABLED=0 ENV GOPROXY=https://goproxy.cn,direct RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories RUN apk update --no-cache \u0026\u0026 apk add --no-cache ca-certificates ","date":"2023-11-08","objectID":"/posts/skopeo/:1:2","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"构建 build 镜像 docker build -t skopeo-build . ","date":"2023-11-08","objectID":"/posts/skopeo/:1:3","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"构建 skopeo 静态二进制可执行文件 cd skopeo/ # 构建 linux amd64 架构 docker run --rm -t -v $PWD:/build skopeo-build sh -c \"apk update \u0026\u0026 apk add gpgme btrfs-progs-dev llvm13-dev gcc musl-dev \u0026\u0026 cd /build \u0026\u0026 CGO_ENABLE=0 GO111MODULE=on GOOS=linux GOARCH=amd64 go build -mod=vendor '-buildmode=pie' -ldflags '-extldflags -static' -gcflags '' -tags 'exclude_graphdriver_devicemapper exclude_graphdriver_btrfs containers_image_openpgp' -o ./bin/skopeo-linux-amd64 ./cmd/skopeo \" # 构建 linux arm64 架构 docker run --rm -t -v $PWD:/build skopeo-build sh -c \"apk update \u0026\u0026 apk add gpgme btrfs-progs-dev llvm13-dev gcc musl-dev \u0026\u0026 cd /build \u0026\u0026 CGO_ENABLE=0 GO111MODULE=on GOOS=linux GOARCH=arm64 go build -mod=vendor '-buildmode=pie' -ldflags '-extldflags -static' -gcflags '' -tags 'exclude_graphdriver_devicemapper exclude_graphdriver_btrfs containers_image_openpgp' -o ./bin/skopeo-linux-arm64 ./cmd/skopeo \" ","date":"2023-11-08","objectID":"/posts/skopeo/:1:4","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"二、skopeo 命令使用 [root@tc ~]# skopeo -v skopeo version 1.11.1-dev [root@tc ~]# skopeo --help Various operations with container images and container image registries Usage: skopeo [flags] skopeo [command] Available Commands: copy Copy an IMAGE-NAME from one location to another delete Delete image IMAGE-NAME generate-sigstore-key Generate a sigstore public/private key pair help Help about any command inspect Inspect image IMAGE-NAME list-tags List tags in the transport/repository specified by the SOURCE-IMAGE login Login to a container registry logout Logout of a container registry manifest-digest Compute a manifest digest of a file standalone-sign Create a signature using local files standalone-verify Verify a signature using local files sync Synchronize one or more images from one location to another Flags: --command-timeout duration timeout for the command execution --debug enable debug output -h, --help help for skopeo --insecure-policy run the tool without any policy check --override-arch ARCH use ARCH instead of the architecture of the machine for choosing images --override-os OS use OS instead of the running OS for choosing images --override-variant VARIANT use VARIANT instead of the running architecture variant for choosing images --policy string Path to a trust policy file --registries.d DIR use registry configuration files in DIR (e.g. for container signature storage) --tmpdir string directory used to store temporary files -v, --version Version for Skopeo Use \"skopeo [command] --help\" for more information about a command. # 登录与登出 oci skopeo login -u username docker.io skopeo logout docker.io 不下载镜像情况下获取镜像信息 [root@tc ~]# skopeo inspect docker://docker.io/alpine { \"Name\": \"docker.io/library/alpine\", \"Digest\": \"sha256:eece025e432126ce23f223450a0326fbebde39cdf496a85d8c016293fc851978\", \"RepoTags\": [ \"20220316\", \"20220328\", \"20220715\", \"20221110\", \"20230208\", \"20230329\", \"20230901\", \"3\", \"3.17\", \"3.17.0\", \"3.17.0_rc1\", \"3.17.1\", \"3.17.2\", \"3.17.3\", \"3.17.4\", \"3.17.5\", \"3.18\", \"3.18.0\", \"3.18.2\", \"3.18.3\", \"3.18.4\", \"edge\", \"latest\" ], \"Created\": \"2023-09-28T21:19:27.801479409Z\", \"DockerVersion\": \"20.10.23\", \"Labels\": null, \"Architecture\": \"amd64\", \"Os\": \"linux\", \"Layers\": [ \"sha256:96526aa774ef0126ad0fe9e9a95764c5fc37f409ab9e97021e7b4775d82bf6fa\" ], \"LayersData\": [ { \"MIMEType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\", \"Digest\": \"sha256:96526aa774ef0126ad0fe9e9a95764c5fc37f409ab9e97021e7b4775d82bf6fa\", \"Size\": 3401967, \"Annotations\": null } ], \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ] } docker://: 是使用 Docker Registry HTTP API V2 进行连接远端 docker.io: 远程仓库 alpine: 镜像名称 获取本地镜像信息 [root@tc ~]# skopeo inspect docker-daemon:alpine:3 { \"Name\": \"docker.io/library/alpine\", \"Digest\": \"sha256:844bc35fdf7a96e5b6bf5e76e20989a797cc75976fad73275061a36f448b92b9\", \"RepoTags\": [], \"Created\": \"2023-09-28T21:19:27.801479409Z\", \"DockerVersion\": \"20.10.23\", \"Labels\": null, \"Architecture\": \"amd64\", \"Os\": \"linux\", \"Layers\": [ \"sha256:cc2447e1835a40530975ab80bb1f872fbab0f2a0faecf2ab16fbbb89b3589438\" ], \"LayersData\": [ { \"MIMEType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\", \"Digest\": \"sha256:cc2447e1835a40530975ab80bb1f872fbab0f2a0faecf2ab16fbbb89b3589438\", \"Size\": 7625728, \"Annotations\": null } ], \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ] } docker-daemon: docker守护镜像的镜像 alpine:3: 本地镜像的名称 ","date":"2023-11-08","objectID":"/posts/skopeo/:2:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"copy镜像 # skopeo --insecure-policy copy docker://nginx:1.17.6 docker-archive:/tmp/nginx.tar Getting image source signatures Copying blob 8ec398bc0356 done Copying blob 465560073b6f done Copying blob f473f9fd0a8c done Copying config f7bb5701a3 done Writing manifest to image destination Storing signatures # ls -alh /tmp/nginx.tar -rw-r--r-- 1 root root 125M 4月 13 15:22 /tmp/nginx.tar --insecure-policy: 用于忽略安全策略配置文件 docker://nginx:1.17.6: 该命令将会直接通过 http 下载目标镜像 docker-archive: 存储为 /tmp/nginx.tar，此文件可以直接通过 docker load 命令导入 相应的，可以将下载的文件导入到本地 # skopeo copy docker-archive:/tmp/nginx.tar docker-daemon:nginx:latest Getting image source signatures Copying blob 556c5fb0d91b done Copying blob 49434cc20e95 done Copying blob 75248c0d5438 done Copying config f7bb5701a3 done Writing manifest to image destination Storing signatures # docker images nginx REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest f7bb5701a33c 3 months ago 126MB COPY # 也可以将镜像下载到指定目录 # skopeo copy docker://busybox:latest dir:/tmp/busybox Getting image source signatures Copying blob 0669b0daf1fb done Copying config 83aa35aa1c done Writing manifest to image destination Storing signatures # ls -alh /tmp/busybox/ 总用量 760K drwxr-xr-x 2 root root 186 4月 13 15:26 . drwxrwxrwt. 12 root root 4.0K 4月 13 15:25 .. -rw-r--r-- 1 root root 743K 4月 13 15:26 0669b0daf1fba90642d105f3bc2c94365c5282155a33cc65ac946347a90d90d1 -rw-r--r-- 1 root root 1.5K 4月 13 15:26 83aa35aa1c79e4b6957e018da6e322bfca92bf3b4696a211b42502543c242d6f -rw-r--r-- 1 root root 527 4月 13 15:26 manifest.json -rw-r--r-- 1 root root 33 4月 13 15:25 version #或者从指定目录导入到本地 # skopeo copy dir:/tmp/busybox docker-daemon:busybox:latest Getting image source signatures Copying blob 0669b0daf1fb done Copying config 83aa35aa1c done Writing manifest to image destination Storing signatures # docker images busybox REPOSITORY TAG IMAGE ID CREATED SIZE busybox latest 83aa35aa1c79 4 weeks ago 1.22MB ","date":"2023-11-08","objectID":"/posts/skopeo/:2:1","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"删除镜像 skopeo delete docker://localhost:5000/nginx:latest ","date":"2023-11-08","objectID":"/posts/skopeo/:2:2","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"认证文件 认证文件默认存放在 $HOME/.docker/config.json 文件内容 { \"auths\": { \"myregistrydomain.com:5000\": { \"auth\": \"dGVzdHVzZXI6dGVzdHxxxxxxxx\", \"email\": \"cc@local.com\" } } } ","date":"2023-11-08","objectID":"/posts/skopeo/:2:3","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"sync 在 OCI 间同步镜像 使用 docke r在 OCI 间同步镜像的时候，需要先把镜像拉下来，打上 tag ，然后在推送到目的 OCI 上。在这个操作的过程中，即占用了存储，又占用了带宽，在同步大的镜像或者大量的镜像的时候，存储会严重影响镜像在 OCI 间同步的效率。skopeo 正好可以解决这个缺点，skopeo 在同步 OCI 镜像的过程中，只占用带宽，不会把镜像下载到本地。 基于 yaml 文件的同步 # sync.yaml ghcr.io: images: kube-vip/kube-vip: - 'v0.6.0' - 'v0.4.4' k3d-io/k3d-tools: - '5.5.2' 同步镜像 skopeo --insecure-policy sync -a --src yaml --dest docker sync.yaml repo.local.com/serialt ","date":"2023-11-08","objectID":"/posts/skopeo/:2:4","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"三、同步镜像 目前，常用的 OCI 仓库有：docker.io，quay.io，gcr.io，registry.k8s.io，ghcr.io 等。众所周知，因为某些原因，这些 OCI 仓库在国内无法访问，而一些项目又严重依赖于存储在这些 OCI 仓库的镜像，虽然有热心的大佬们会把 gcr 和 ghcr 上存储的镜像同步到 docker hub 中，但因为这些被推送到 docker hub 中的镜像不是官方维护的，可能会存在比较大的镜像的同步时间差，某些需要的镜像无法在 docker hub 上找到，同时也容易引起容器镜像的供应链安全问题。因此，可以使用 github action 使用 skopeo 进行同步镜像。 项目地址：sync-image ","date":"2023-11-08","objectID":"/posts/skopeo/:3:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"1、安装sync-image 和 skopeo wget https://github.com/serialt/skopeo/releases/download/v1.13.3/skopeo-linux-amd64 go install github.com/serialt/sync-image@latest ","date":"2023-11-08","objectID":"/posts/skopeo/:3:1","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"2、配置sync-image yaml 配置文件 # config.yaml # 镜像同步的个数 last: 10 # mcr同步的个数，mcr中包含多个 vscode 容器开发的镜像 mcrLast: 50 autoSyncfile: sync.yaml # 不同步带有以下关键字的镜像的tag exclude: - 'alpha' - 'beta' - 'rc' - 'amd64' - 'ppc64le' - 'arm64' - 'arm' - 's390x' - 'SNAPSHOT' - 'snapshot' - 'debug' - 'master' - 'latest' - 'main' - 'sig' - 'sha' - 'mips' # 需要同步的镜像 images: docker.elastic.co: - elasticsearch/elasticsearch - kibana/kibana - logstash/logstash - beats/filebeat - beats/heartbeat - beats/packetbeat - beats/auditbeat - beats/journalbeat - beats/metricbeat - apm/apm-server - app-search/app-search quay.io: - coreos/flannel - ceph/ceph - cephcsi/cephcsi - csiaddons/k8s-sidecar - csiaddons/volumereplication-operator - prometheus/prometheus - prometheus/alertmanager - prometheus/pushgateway - prometheus/blackbox-exporter - prometheus/node-exporter - prometheus-operator/prometheus-config-reloader - prometheus-operator/prometheus-operator - brancz/kube-rbac-proxy - jetstack/cert-manager-webhook - jetstack/cert-manager-controller - jetstack/cert-manager-cainjector k8s.gcr.io: - conformance - dns/k8s-dns-node-cache - metrics-server/metrics-server - kube-state-metrics/kube-state-metrics - prometheus-adapter/prometheus-adapter registry.k8s.io: - sig-storage/local-volume-provisioner - metrics-server/metrics-server - defaultbackend - ingress-nginx/controller - ingress-nginx/kube-webhook-certgen - sig-storage/nfs-subdir-external-provisioner - sig-storage/csi-node-driver-registrar - sig-storage/csi-provisioner - sig-storage/csi-resizer - sig-storage/csi-snapshotter - sig-storage/snapshot-controller - sig-storage/snapshot-validation-webhook - sig-storage/nfsplugin - sig-storage/csi-attacher - sig-storage/livenessprobe - defaultbackend-amd64 - defaultbackend-arm64 - pause - etcd - kube-proxy - kube-apiserver - kube-scheduler - kube-controller-manager - coredns/coredns - build-image/kube-cross gcr.io: - kaniko-project/executor ghcr.io: - k3d-io/k3d-tools - k3d-io/k3d-proxy - kube-vip/kube-vip mcr.microsoft.com: - devcontainers/base - devcontainers/go docker.io: - flannel/flannel - flannel/flannel-cni-plugin - calico/kube-controllers - serialt/rocky - serialt/alma - calico/cni - calico/pod2daemon-flexvol - calico/kube-controllers - calico/node - rancher/mirrored-flannelcni-flannel-cni-plugin - rancher/mirrored-flannelcni-flanne ","date":"2023-11-08","objectID":"/posts/skopeo/:3:2","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"3、生成动态同步的 yaml 文件 sync-image -c config.yaml ","date":"2023-11-08","objectID":"/posts/skopeo/:3:3","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"4、同步镜像 依赖的环境变量 DEST_HUB_USERNAME DEST_HUB_PASSWORD MY_GITHUB_TOKEN 同步的shell脚本 hub=\"docker.io\" repo=\"$hub/${DEST_HUB_USERNAME}\" hub2=\"registry.cn-hangzhou.aliyuncs.com\" repo2=\"$hub2/${DEST_HUB_USERNAME}\" if [ -f sync.yaml ]; then echo \"[Start] sync.......\" sudo skopeo login -u ${DEST_HUB_USERNAME} -p ${DEST_HUB_PASSWORD} ${hub} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker sync.yaml ${repo} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker custom_sync.yaml ${repo} sleep 3 sudo skopeo login -u ${DEST_HUB_USERNAME} -p ${DEST_HUB_PASSWORD} ${hub2} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker sync.yaml ${repo2} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker custom_sync.yaml ${repo2} echo \"[End] done.\" else echo \"[Error]not found sync.yaml!\" fi ","date":"2023-11-08","objectID":"/posts/skopeo/:3:4","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"5、github action 配置文件 name: sync on: push: branches: - master - main schedule: - cron: \"0 2 * * *\" # Allows you to run this workflow manually from the Actions tab workflow_dispatch: jobs: sync: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Set up Go uses: actions/setup-go@v4 with: go-version: '\u003e=1.21.0' - name: Install dependencies run: | export version=v1.10.0 \u0026\u0026 export arch=amd64 \u0026\u0026 sudo wget https://github.com/lework/skopeo-binary/releases/download/${version}/skopeo-linux-${arch} -O /usr/bin/skopeo \u0026\u0026 sudo chmod +x /usr/bin/skopeo skopeo --version go install github.com/serialt/sync-image@latest - name: generate_sync_yaml env: SRC_HUB_USERNAME: ${{ secrets.SRC_HUB_USERNAME }} DEST_HUB_USERNAME: ${{ secrets.DEST_HUB_USERNAME }} DEST_HUB_PASSWORD: ${{ secrets.DEST_HUB_PASSWORD }} MY_GITHUB_TOKEN: ${{ secrets.MY_GITHUB_TOKEN }} timeout-minutes: 10 run: | sync-image - name: sync image env: SRC_HUB_USERNAME: ${{ secrets.SRC_HUB_USERNAME }} DEST_HUB_USERNAME: ${{ secrets.DEST_HUB_USERNAME }} DEST_HUB_PASSWORD: ${{ secrets.DEST_HUB_PASSWORD }} run: | bash sync.sh ","date":"2023-11-08","objectID":"/posts/skopeo/:3:5","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["morse编码"],"content":"Morse Code 二叉树记忆法 start E T I A N M S U R W D K G O H V F L P J B X C Y Z Q . - E T .. .- -. -- I A N M ... ..- .-. ..- -.. -.- --. --- S U R W D K G O .... ...- ..-. .-.. .--. .--- -... -..- -.-. -.-- --.. --.- H v F L P J B X C Y Z Q ","date":"2023-11-08","objectID":"/posts/morse-code/:1:0","tags":["morse","morse-code"],"title":"Morse Code","uri":"/posts/morse-code/"},{"categories":["系统或软件换源"],"content":"操作系统或者软件换源加速 ","date":"2023-11-07","objectID":"/posts/mirror-cn/:0:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["系统或软件换源"],"content":"1、操作系统 ","date":"2023-11-07","objectID":"/posts/mirror-cn/:1:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["系统或软件换源"],"content":"rocky # 8 base sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/rocky|g' \\ -i.bak /etc/yum.repos.d/Rocky*.repo # 8 epel sed -e 's|^metalink=|#metalink=|g' \\ -e 's|^#baseurl=https\\?://download.fedoraproject.org/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -e 's|^#baseurl=https\\?://download.example/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -i.bak /etc/yum.repos.d/epel*.repo # 9 base sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/rocky|g' \\ -i.bak /etc/yum.repos.d/rocky*.repo # 9 epel sed -e 's|^metalink=|#metalink=|g' \\ -e 's|^#baseurl=https\\?://download.fedoraproject.org/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -e 's|^#baseurl=https\\?://download.example/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -i.bak /etc/yum.repos.d/epel*.repo ","date":"2023-11-07","objectID":"/posts/mirror-cn/:1:1","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["系统或软件换源"],"content":"ubuntu # http sed -e \"s@http://.*archive.ubuntu.com@http://mirrors.aliyun.com@g\" \\ -e \"s@http://.*security.ubuntu.com@http://mirrors.aliyun.com@g\" \\ -i.bak -i /etc/apt/sources.list # https sed -e \"s@http://.*archive.ubuntu.com@https://mirrors.aliyun.com@g\" \\ -e \"s@http://.*security.ubuntu.com@https://mirrors.aliyun.com@g\" \\ -i.bak -i /etc/apt/sources.list ","date":"2023-11-07","objectID":"/posts/mirror-cn/:1:2","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["系统或软件换源"],"content":"debian # debian 12及以上 sed -i 's/\\w*.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list.d/debian.sources sed -i \"s@http://mirrors.ustc.edu.cn@https://mirrors.ustc.edu.cn@g\" /etc/apt/sources.list.d/debian.sources # debian 12以下 sed -i 's/\\w*.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list sed -i \"s@http://mirrors.ustc.edu.cn@https://mirrors.ustc.edu.cn@g\" /etc/apt/sources.list ","date":"2023-11-07","objectID":"/posts/mirror-cn/:1:3","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["系统或软件换源"],"content":"alpine # alpine 官方源 https://dl-cdn.alpinelinux.org/alpine/v3.18/main https://dl-cdn.alpinelinux.org/alpine/v3.18/community # ustc sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories # edge 源 echo \"https://mirrors.ustc.edu.cn/alpine/edge/main\" \u003e\u003e /etc/apk/repositories echo \"https://mirrors.ustc.edu.cn/alpine/edge/community\" \u003e\u003e /etc/apk/repositories echo \"https://mirrors.ustc.edu.cn/alpine/edge/testing\" \u003e\u003e /etc/apk/repositories ","date":"2023-11-07","objectID":"/posts/mirror-cn/:1:4","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["系统或软件换源"],"content":"2、开发语言类 go export GOPROXY=https://goproxy.cn,direct # aliyun export GOPROXY=https://mirrors.aliyun.com/goproxy/ python export PIP_MIRROR=mirrors.aliyun.com echo -e \"[global]\\nindex-url=https://${PIP_MIRROR}/pypi/simple\\n[install]\\ntrusted-host=${PIP_MIRROR}\" \u003e /etc/pip.conf # 命令配置 pip3 install xxx -i https://mirrors.aliyun.com/pypi/simple/ npm # 设置全局 npm config set registry https://registry.npmmirror.com # cmd npm install -y --registry=https://registry.npmmirror.com # 官方地址 https://registry.npmjs.org/ # 阿里云地址 https://registry.npmmirror.com # 腾讯 http://mirrors.cloud.tencent.com/npm/ # 华为 https://repo.huaweicloud.com/repository/npm/ # 南京大学 https://repo.nju.edu.cn/repository/npm/ ","date":"2023-11-07","objectID":"/posts/mirror-cn/:2:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["系统或软件换源"],"content":"3、容器代理 配置模版 { \"insecure-registries\": [ \"repo.local.com\" ], \"exec-opts\": [ \"native.cgroupdriver=systemd\" ], \"registry-mirrors\": [ \"https://docker.mirrors.sjtug.sjtu.edu.cn\", \"https://docker.nju.edu.cn\", \"http://hub-mirror.c.163.com\" ], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\", \"max-file\": \"3\" }, \"bip\":\"192.161.20.1/24\", \"dns\": [ \"119.29.29.29\", \"223.5.5.5\" ], \"data-root\": \"/var/lib/docker\", \"features\": { \"buildkit\": true } } docker registry # 上海交大 https://docker.mirrors.sjtug.sjtu.edu.cn # 南京大学 https://docker.nju.edu.cn # dockerproxy https://dockerproxy.com gcr.io # 上海交大 https://gcr-io.mirrors.sjtug.sjtu.edu.cn # 南京大学 https://gcr.nju.edu.cn # dockerproxy https://gcr.dockerproxy.com ghcr.io # 南京大学 https://htghcr.nju.edu.cn # dockerproxy https://ghcr.dockerproxy.com nvcr.io # 南京大学 https://nvcr.nju.edu.cn quay.io # 南京大学 https://quay.nju.edu.cn # dockerproxy quay.dockerproxy.com registry.k8s.io # 南京大学 k8s.mirror.nju.edu.cn # dockerproxy k8s.dockerproxy.com Microsoft Artifact Registry mcr.dockerproxy.com ","date":"2023-11-07","objectID":"/posts/mirror-cn/:3:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/mirror-cn/"},{"categories":["Go req 库文档"],"content":"req Go语言人性化HTTP请求库 特性 轻量级 简单 容易操作JSON和XML 容易调试和日志记录 容易上传和下载文件 容易管理Cookie 容易设置代理 容易设置超时 容易自定义HTTP客户端 安装 go get github.com/serialt/req 概要 req 基于标准库 net/http 实现了一个友好的API. Req 和 Resp 是两个最重要的结构体, 你可以把 Req 看作客户端， 把Resp 看作存放请求及其响应的容器，它们都提供许多简洁方便的API，让你可以很轻松做很多很多事情。 func (r *Req) Post(url string, v ...interface{}) (*Resp, error) 大多情况下，发起请求只有url是必选参数，其它都可选，比如请求头、请求参数、文件或请求体等。 包中含一个默认的 Req 对象, 它所有的公有方法都被req包对应的公有方法包装了，所以大多数情况下，你直接可以把req包看作一个Req对象来使用。 // 创建Req对象来发起请求 r := req.New() r.Get(url) // 直接使用req包发起请求 req.Get(url) 你可以使用 req.New() 方法来创建 *Req 作为一个单独的客户端 例子 基础用法 设置请求头 设置请求参数 设置请求体 调试 输出格式 ToJSON \u0026 ToXML 获取 *http.Response 上传 下载 Cookie 设置超时 设置代理 自定义 http.Client ","date":"2023-10-09","objectID":"/posts/req/:0:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"基础用法 header := req.Header{ \"Accept\": \"application/json\", \"Authorization\": \"Basic YWRtaW46YWRtaW4=\", } param := req.Param{ \"name\": \"imroc\", \"cmd\": \"add\", } // 只有url必选，其它参数都是可选 r, err = req.Post(\"http://foo.bar/api\", header, param) if err != nil { log.Fatal(err) } r.ToJSON(\u0026foo) // 响应体转成对象 log.Printf(\"%+v\", r) // 打印详细信息 ","date":"2023-10-09","objectID":"/posts/req/:1:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置请求头 使用 req.Header (它实际上是一个 map[string]string) authHeader := req.Header{ \"Accept\": \"application/json\", \"Authorization\": \"Basic YWRtaW46YWRtaW4=\", } req.Get(\"https://www.baidu.com\", authHeader, req.Header{\"User-Agent\": \"V1.1\"}) 使用 http.Header header := make(http.Header) header.Set(\"Accept\", \"application/json\") req.Get(\"https://www.baidu.com\", header) 你可以使用 struct 来设置请求头，用 HeaderFromStruct 这个函数来解析你的 struct type HeaderStruct struct { UserAgent string `json:\"User-Agent\"` Authorization string `json:\"Authorization\"` } func main(){ h := HeaderStruct{ \"V1.0.0\", \"roc\", } authHeader := req.HeaderFromStruct(h) req.Get(\"https://www.baidu.com\", authHeader, req.Header{\"User-Agent\": \"V1.1\"}) } 注：请给你的 struct 加上 json tag. ","date":"2023-10-09","objectID":"/posts/req/:2:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置请求参数 Use req.Param (它实际上是一个 map[string]interface{}) param := req.Param{ \"id\": \"imroc\", \"pwd\": \"roc\", } req.Get(\"http://foo.bar/api\", param) // http://foo.bar/api?id=imroc\u0026pwd=roc req.Post(url, param) // 请求体 =\u003e id=imroc\u0026pwd=roc 使用 req.QueryParam 强制将请求参数拼在url后面 (它实际上也是一个 map[string]interface{}) req.Post(\"http://foo.bar/api\", req.Param{\"name\": \"roc\", \"age\": \"22\"}, req.QueryParam{\"access_token\": \"fedledGF9Hg9ehTU\"}) /* POST /api?access_token=fedledGF9Hg9ehTU HTTP/1.1 Host: foo.bar User-Agent: Go-http-client/1.1 Content-Length: 15 Content-Type: application/x-www-form-urlencoded;charset=UTF-8 Accept-Encoding: gzip age=22\u0026name=roc */ ","date":"2023-10-09","objectID":"/posts/req/:3:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置请求体 Put string, []byte and io.Reader as body directly. req.Post(url, \"id=roc\u0026cmd=query\") 将对象作为JSON或XML请求体（自动添加 Content-Type 请求头） req.Post(url, req.BodyJSON(\u0026foo)) req.Post(url, req.BodyXML(\u0026bar)) ","date":"2023-10-09","objectID":"/posts/req/:4:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"调试 将全局变量 req.Debug 设置为true，将会把所有请求的详细信息打印在标准输出。 req.Debug = true req.Post(\"http://localhost/test\" \"hi\") ","date":"2023-10-09","objectID":"/posts/req/:5:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"输出格式 您可以使用指定类型的输出格式在日志文件中记录请求和响应的信息。例如，在开发阶段使用％+v格式，可以让你观察请求和响应的细节信息。 在生产阶段使用％v或％-v输出格式，只记录所需要的信息。 ","date":"2023-10-09","objectID":"/posts/req/:6:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"%+v 或 %+s 详细输出 r, _ := req.Post(url, header, param) log.Printf(\"%+v\", r) // 输出格式和Debug开启时的格式一样 ","date":"2023-10-09","objectID":"/posts/req/:6:1","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"%v 或 %s 简单输出（默认格式） r, _ := req.Get(url, param) log.Printf(\"%v\\n\", r) // GET http://foo.bar/api?name=roc\u0026cmd=add {\"code\":\"0\",\"msg\":\"success\"} log.Prinln(r) // 和上面一样 ","date":"2023-10-09","objectID":"/posts/req/:6:2","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"%-v 或 %-s 简单输出并保持所有内容在一行内（请求体或响应体可能包含多行，这种格式会将所有换行、回车替换成\" \", 这在会让你在查日志的时候非常有用） ","date":"2023-10-09","objectID":"/posts/req/:6:3","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"Flag 你可以调用 SetFlags 控制输出内容，决定哪些部分能够被输出。 const ( LreqHead = 1 \u003c\u003c iota // 输出请求首部（包含请求行和请求头） LreqBody // 输出请求体 LrespHead // 输出响应首部（包含响应行和响应头） LrespBody // 输出响应体 Lcost // 输出请求所消耗掉时长 LstdFlags = LreqHead | LreqBody | LrespHead | LrespBody ) req.SetFlags(req.LreqHead | req.LreqBody | req.LrespHead) ","date":"2023-10-09","objectID":"/posts/req/:6:4","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"监控请求耗时 req.SetFlags(req.LstdFlags | req.Lcost) // 输出格式显示请求耗时 r,_ := req.Get(url) log.Println(r) // http://foo.bar/api 3.260802ms {\"code\":0 \"msg\":\"success\"} if r.Cost() \u003e 3 * time.Second { // 检查耗时 log.Println(\"WARN: slow request:\", r) } ","date":"2023-10-09","objectID":"/posts/req/:6:5","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"ToJSON \u0026 ToXML r, _ := req.Get(url) r.ToJSON(\u0026foo) r, _ = req.Post(url, req.BodyXML(\u0026bar)) r.ToXML(\u0026baz) ","date":"2023-10-09","objectID":"/posts/req/:7:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"获取 *http.Response // func (r *Req) Response() *http.Response r, _ := req.Get(url) resp := r.Response() fmt.Println(resp.StatusCode) ","date":"2023-10-09","objectID":"/posts/req/:8:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"上传 使用 req.File 匹配文件 req.Post(url, req.File(\"imroc.png\"), req.File(\"/Users/roc/Pictures/*.png\")) 使用 req.FileUpload 细粒度控制上传 file, _ := os.Open(\"imroc.png\") req.Post(url, req.FileUpload{ File: file, FieldName: \"file\", // FieldName 是表单字段名 FileName: \"avatar.png\", // Filename 是要上传的文件的名称，我们使用它来猜测mimetype，并将其上传到服务器上 }) 使用req.UploadProgress监听上传进度 progress := func(current, total int64) { fmt.Println(float32(current)/float32(total)*100, \"%\") } req.Post(url, req.File(\"/Users/roc/Pictures/*.png\"), req.UploadProgress(progress)) fmt.Println(\"upload complete\") ","date":"2023-10-09","objectID":"/posts/req/:9:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"下载 r, _ := req.Get(url) r.ToFile(\"imroc.png\") 使用req.DownloadProgress监听下载进度 progress := func(current, total int64) { fmt.Println(float32(current)/float32(total)*100, \"%\") } r, _ := req.Get(url, req.DownloadProgress(progress)) r.ToFile(\"hello.mp4\") fmt.Println(\"download complete\") ","date":"2023-10-09","objectID":"/posts/req/:10:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"Cookie 默认情况下，底层的 *http.Client 会自动管理你的cookie（如果服务器给你发了cookie，之后的请求它会自动带上cookie请求头给服务器）, 你可以调用这个方法取消自动管理： req.EnableCookie(false) 你还可以在发送请求的时候自己传入 *http.Cookie cookie := new(http.Cookie) // ...... req.Get(url, cookie) ","date":"2023-10-09","objectID":"/posts/req/:11:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置超时 req.SetTimeout(50 * time.Second) ","date":"2023-10-09","objectID":"/posts/req/:12:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置代理 默认情况下，如果系统环境变量有 http_proxy 或 https_proxy ，req会讲对应的地址作为对应协议的代理，你也可以自定义设置代理，或者将其置为nil，即取消代理。 req.SetProxy(func(r *http.Request) (*url.URL, error) { if strings.Contains(r.URL.Hostname(), \"google\") { return url.Parse(\"http://my.vpn.com:23456\") } return nil, nil }) 设置简单代理（将所有请求都转发到指定代理url地址上） req.SetProxyUrl(\"http://my.proxy.com:23456\") ","date":"2023-10-09","objectID":"/posts/req/:13:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"自定义HTTP客户端 使用 SetClient 改变底层的 *http.Client req.SetClient(client) 给某个请求制定特定的 *http.Client client := \u0026http.Client{Timeout: 30 * time.Second} req.Get(url, client) 改变底层 *http.Client 的某些属性 req.Client().Jar, _ = cookiejar.New(nil) trans, _ := req.Client().Transport.(*http.Transport) trans.MaxIdleConns = 20 trans.TLSHandshakeTimeout = 20 * time.Second trans.DisableKeepAlives = true trans.TLSClientConfig = \u0026tls.Config{InsecureSkipVerify: true} ","date":"2023-10-09","objectID":"/posts/req/:14:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go 库文档"],"content":"Go 原生http库 Go语言内置的net/http包十分的优秀，提供了HTTP客户端和服务端的实现。 ","date":"2023-10-09","objectID":"/posts/go-http/:0:0","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"一、net/http介绍 Go语言内置的net/http包提供了HTTP客户端和服务端的实现。 HTTP协议 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络传输协议，所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。 ","date":"2023-10-09","objectID":"/posts/go-http/:1:0","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"二、HTTP客户端 Get、Head、Post和PostForm函数发出HTTP/HTTPS请求。 resp, err := http.Get(\"http://example.com/\") ... resp, err := http.Post(\"http://example.com/upload\", \"image/jpeg\", \u0026buf) ... resp, err := http.PostForm(\"http://example.com/form\", url.Values{\"key\": {\"Value\"}, \"id\": {\"123\"}}) 程序在使用完response后必须关闭回复的主体。 resp, err := http.Get(\"http://example.com/\") if err != nil { // handle error } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) // ... ","date":"2023-10-09","objectID":"/posts/go-http/:2:0","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"GET请求示例 package main import ( \"fmt\" \"io\" \"net/http\" ) func main() { resp, err := http.Get(\"https://httpbin.org/uuid\") if err != nil { fmt.Printf(\"get failed, err:%v\\n\", err) return } defer resp.Body.Close() body, err := io.ReadAll(resp.Body) if err != nil { fmt.Printf(\"read from resp.Body failed, err:%v\\n\", err) return } fmt.Print(string(body)) } 自定义请求 package main import ( \"encoding/json\" \"fmt\" \"io\" \"net/http\" \"net/url\" ) type UUID struct { Uuid string `json:\"uuid\"` } func main() { apiURL := \"https://httpbin.org/uuid\" query := url.Values{} query.Add(\"q\", \"golang\") query.Add(\"page\", \"1\") ApiURL, _ := url.ParseRequestURI(apiURL) ApiURL.RawQuery = query.Encode() req, _ := http.NewRequest(\"GET\", ApiURL.String(), nil) req.Header.Add(\"Accept\", \"*/*\") client := \u0026http.Client{} resp, err := client.Do(req) if err != nil { return } defer resp.Body.Close() var uuid UUID body, err := io.ReadAll(resp.Body) if err != nil { fmt.Printf(\"read from resp.Body failed, err:%v\\n\", err) return } json.Unmarshal(body, \u0026uuid) fmt.Println(uuid.Uuid) } ","date":"2023-10-09","objectID":"/posts/go-http/:2:1","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"POST 请求示例 package main import ( \"encoding/json\" \"io\" \"net/http\" \"net/url\" ) type dockerToken struct { Token string `json:\"token\"` } func main() { apiUrl := \"https://hub.docker.com/v2/users/login\" data := url.Values{} data.Set(\"username\", \"username\") data.Set(\"password\", \"password\") resp, err := http.PostForm(apiUrl, data) if err != nil { return } defer resp.Body.Close() _data, _ := io.ReadAll(resp.Body) var tmpT dockerToken json.Unmarshal(_data, \u0026tmpT) } package main import ( \"bytes\" \"io\" \"net/http\" \"net/url\" \"strings\" \"log/slog\" ) func POST1() { apiURL := \"https://httpbin.org/post\" form := url.Values{} form.Add(\"ln\", \"ln222\") form.Add(\"ip\", \"1.1.1.1\") form.Add(\"ua\", \"ua123\") client := \u0026http.Client{} req, _ := http.NewRequest(\"POST\", apiURL, strings.NewReader(form.Encode())) req.Header.Set(\"User-Agent\", \"test\") req.Header.Set(\"Content-Type\", \"application/x-www-form-urlencoded\") // 发送请求 resp, err := client.Do(req) if err != nil { slog.Error(\"POST request failed\", \"err\", err) return } defer resp.Body.Close() // 读取内容 body, err := io.ReadAll(resp.Body) if err != nil { slog.Error(\"POST request\", \"err\", err) } else { slog.Info(string(body)) } } func POSTJson() { apiURL := \"https://httpbin.org/post\" var jsonStr = []byte(`{\"title\":\"this is a title\", \"cate\": 1}`) client := \u0026http.Client{} req, _ := http.NewRequest(\"POST\", apiURL, bytes.NewBuffer(jsonStr)) req.Header.Set(\"User-Agent\", \"test\") req.Header.Set(\"Content-Type\", \"application/x-www-form-urlencoded\") // 发送请求 resp, err := client.Do(req) if err != nil { slog.Error(\"POST request failed\", \"err\", err) return } defer resp.Body.Close() // 读取内容 body, err := io.ReadAll(resp.Body) if err != nil { slog.Error(\"POST request\", \"err\", err) } else { slog.Info(string(body)) } } func main() { // POST1() POSTJson() } ","date":"2023-10-09","objectID":"/posts/go-http/:2:2","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Kubernetes","DevOps"],"content":"Dev in kubernetes ​ 传统的开发模式中，是代码存放在本地，使用 IDE 进行编辑和 debug 。但随着容器化火了之后，很多单一服务都进行了拆分，微服务化。在开发阶段，需要本地同时启动多个服务，这使得本地开发调试变得越来越困难。Okteto 是一个通过在 Kubernetes 中来开发和测试代码的应用程序开发工具。可以通过 Okteto 在 Kubernetes 中一键为我们启动一个开发环境，非常简单方便。Google 推出的 Skaffold 只是把 CICD 集成到本地，使用起来也比较困难。Okteto 的工作原理是在 kubernetes 中启动一个服务，把本地代码同步到 pod 中，然后执行命令让服务运行起来，Okteto 可以进行端口的转发，转发pod里服务的端口到本地，在进行 debug 的时候，pod里启动的端口可以被 kubernetes 内的其他服务所访问，本地转发的端口可以被本地的工具（例如 postman ）访问。 okteto官网文档：https://www.okteto.com/docs Go 配置文档：https://www.okteto.com/docs/samples/golang/ 示例环境： vscode 1.82.1(需要安装 Remote - Kubernetes 插件，插件code：okteto.remote-kubernetes) k3d mac ","date":"2023-09-26","objectID":"/posts/okteto/:0:0","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"安装与配置 下载okteto：https://github.com/okteto/okteto/releases [crab@Sugar ~]🐳 wget https://ghproxy.com/https://github.com/okteto/okteto/releases/download/2.20.0/okteto-Darwin-arm64 [crab@Sugar ~]🐳 chmod +x okteto-Darwin-arm64 [crab@Sugar ~]🐳 sudo mv okteto-Darwin-arm64 /usr/local/bin/okteto ","date":"2023-09-26","objectID":"/posts/okteto/:1:0","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"下载示例代码 [crab@Sugar ~]🐳 git clone https://github.com/okteto/go-getting-started go-okteto [crab@Sugar ~]🐳 cd go-okteto ","date":"2023-09-26","objectID":"/posts/okteto/:1:1","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"配置port-forward端口 需要转发两个，一个是服务的端口，另一个是debug使用的端口 okteto.yaml build: hello-world: image: serialt/go-hello-world:1.0.0 context: . deploy: - kubectl apply -f k8s.yml dev: hello-world: # 被替换的服务名 image: okteto/golang:1 command: bash sync: - .:/usr/src/app volumes: - /go - /root/.cache securityContext: capabilities: add: - SYS_PTRACE forward: - 2345:2345 - 8080:8080 # \u003c---- 增加8080服务端口转发 设置okteto context，okteto 默认会优先使用KUBECONFIG环境变量的配置文件，如果没有设置，则使用 ~/.kube/config文件 [crab@Sugar go-okteto]🐳 okteto context ✓ Context 'k3d-mycluster' selected ✓ Using dev @ k3d-mycluster ","date":"2023-09-26","objectID":"/posts/okteto/:1:2","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"启动服务 [crab@Sugar go-okteto]🐳 okteto up i Using dev @ k3d-mycluster as context i 'go-getting-started' was already deployed. To redeploy run 'okteto deploy' or 'okteto up --deploy' i Images were already built. To rebuild your images run 'okteto build' or 'okteto deploy --build' ✓ Images successfully pulled ✓ Files synchronized Context: k3d-mycluster Namespace: dev Name: hello-world Forward: 2345 -\u003e 2345 8080 -\u003e 8080 Welcome to your development container. Happy coding! dev:hello-world app\u003e dev:hello-world app\u003e ls Dockerfile LICENSE Makefile README.md bashrc go.mod k8s.yml main.go okteto.yml ","date":"2023-09-26","objectID":"/posts/okteto/:1:3","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"远程开发 # okteto终端 dev:hello-world app\u003e go run main.go Starting hello-world server... # 终端测试 [crab@Sugar ~]🐳 curl 127.0.0.1:8080 Hello world! ","date":"2023-09-26","objectID":"/posts/okteto/:1:4","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"远程调试 # okteto终端, 执行dlv命令 dev:hello-world app\u003e dlv debug --headless --listen=:2345 --log --api-version=2 API server listening at: [::]:2345 2023-09-26T13:40:51Z warning layer=rpc Listening for remote connections (connections are not authenticated nor encrypted) 2023-09-26T13:40:51Z info layer=debugger launching process with args: [./__debug_bin3213431902] 2023-09-26T13:40:51Z debug layer=debugger Adding target 575 \"/usr/src/app/__debug_bin3213431902\" # main.go 打上debug标记 func helloServer(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \"Hello world from Okteto!, k3d is great! \") fmt.Println(\"okteto ccccccc\") # 标记此行 } 在vscode debug中点击开始debug 使用命令请求 http://127.0.0.1:8080，即可debug到标记点 [sugar@Sugar go-okteto]🐳 curl http://127.0.0.1:8080 Hello world from Okteto!, k3d is great! ","date":"2023-09-26","objectID":"/posts/okteto/:1:5","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["vscode","DevOps"],"content":"Debug shell 1、安装插件 安装bashdb插件 rogalmic.bash-debug 2、增加一个vscode launch.json配置文件 Select Debug -\u003e Add Configuration to add custom debug configuration 示例： { \"configurations\": [ { \"type\": \"bashdb\", \"request\": \"launch\", \"name\": \"Bash-Debug\", \"cwd\": \"${workspaceFolder}\", \"program\": \"${workspaceFolder}/ccc.sh\", \"args\": [] }, ] } 就可以像debug其他语言一样进行调试shell脚本 ","date":"2023-09-24","objectID":"/posts/debug-shell-in-vscode/:0:0","tags":["shell"],"title":"Debug Shell in VSCode","uri":"/posts/debug-shell-in-vscode/"},{"categories":["DevOps"],"content":"清华镜像网页搭建镜像站 tuna mirror-web地址：https://github.com/tuna/mirror-web.git tuna mirror-web基于jekyll开发，由于ruby环境安装复杂，因此采用docker编译，但在build镜像的时候，出现安装包依赖安装失败，在多次测试后，无法build成镜像。前段时间，在查看mirror-web段issues时，有人询问mirror-web段README.md文档的下一步，官方给了一点提示，有关于基于nginx的第三方模块来实现目录第渲染的提示说明，再次尝试后，经历各种困难和折磨，终于摸索出。 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:0","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"1、下载mirror-web的jekyll编译环境 tuna的编译镜像：tunathu/mirror-web 在下载tunathu/mirror-web时发生了一个小问题，由于在国内使用的docker镜像加速，下载的镜像是旧版本的，但境外的服务器下载的镜像是最新的，在踩坑后果断推到自己的dockerhub上，新的下载地址：serialt/tuna-mirror-web。 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:1","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"2、下载github仓库 git clone https://github.com/tuna/mirror-web.git /opt/mirror-web ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:2","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"3、下载额外资源和编译 cd /opt/mirror-web wget https://mirrors.tuna.tsinghua.edu.cn/static/tunasync.json -O static/tunasync.json wget https://mirrors.tuna.tsinghua.edu.cn/static/tunet.json -O static/tunet.json mkdir -p static/status wget https://mirrors.tuna.tsinghua.edu.cn/static/status/isoinfo.json -O static/status/isoinfo.json docker run -it -v /opt/mirror-web/:/data serialt/tuna-mirror-web:20211006 编译的后静态文件在_site里 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:3","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"4、编译nginx 需要安装第三方模块 modules/ngx_http_js_module.so modules/ngx_http_fancyindex_module.so [root@serialt nginx]# ll 总用量 1068 drwxr-xr-x 9 sonar sonar 186 10月 5 22:27 nginx-1.20.1 -rw-r--r-- 1 root root 1061461 5月 25 23:34 nginx-1.20.1.tar.gz drwxrwxr-x 3 root root 217 10月 27 2020 ngx-fancyindex-0.5.1 -rw-r--r-- 1 root root 25148 10月 27 2020 ngx-fancyindex-0.5.1.tar.xz drwxr-xr-x 10 root root 228 10月 6 15:49 njs # njs下载 git clone https://github.com/nginx/njs # ngx-fancyindex 下载 wget https://github.com/aperezdc/ngx-fancyindex/releases/download/v0.5.1/ngx-fancyindex-0.5.1.tar.xz 编译： [root@serialt nginx]# ls nginx-1.20.1 nginx-1.20.1.tar.gz ngx-fancyindex-0.5.1 ngx-fancyindex-0.5.1.tar.xz njs [root@serialt nginx]# cd nginx-1.20.1/ [root@serialt nginx-1.20.1]# ./configure --prefix=/usr/local/nginx --with-pcre --with-http_auth_request_module --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-mail --with-mail_ssl_module --with-stream --with-stream_ssl_module --with-stream_realip_module --add-dynamic-module=/root/nginx/ngx-fancyindex-0.5.1 --add-dynamic-module=/root/nginx/njs/nginx # add m 3997 [2022-02-25 00:49:21] [root] [10.5.0.10] ./configure --with-compat --add-dynamic-module=/root/github/tuna-mirror-web/njs-0.6.2/nginx 3998 [2022-02-25 00:49:31] [root] [10.5.0.10] make modules nginx配置文件内容 [root@serialt mirrors]# cat /usr/local/nginx/conf/nginx.conf #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; load_module modules/ngx_http_js_module.so; load_module modules/ngx_http_fancyindex_module.so; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; map $http_user_agent $isbrowser { default 0; \"~*validation server\" 0; \"~*mozilla\" 1; } js_path /opt/mirror-web/_site/static/njs; js_include /opt/mirror-web/_site/static/njs/all.njs; #js_path /opt/mirror-web/static/njs; #js_include /opt/mirror-web/static/njs/all.njs; server { listen 8007; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; #root /opt/mirror-web/_site; fancyindex_header /fancy-index/before; fancyindex_footer /fancy-index/after; fancyindex_exact_size off; fancyindex_time_format \"%d %b %Y %H:%M:%S +0000\"; fancyindex_name_length 256; error_page 404 /404.html; location /fancy-index { internal; root /opt/mirror-web/_site; subrequest_output_buffer_size 100k; location = /fancy-index/before { js_content fancyIndexBeforeRender; } location = /fancy-index/after { js_content fancyIndexAfterRender; } } location / { root /opt/mirror-web/_site; index index.html index.htm; #try_files /_site/$uri $uri/ /_site/$uri; fancyindex on; } # location / { # root html; # index index.html index.htm; # } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } [root@serialt mirrors]# ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:4","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"5、镜像资源暴露 方法1：以软链接形式存放在/opt/mirror-web/_site中 [root@serialt _site]# pwd /opt/mirror-web/_site [root@serialt _site]# ll 总用量 160 -rw-r--r-- 1 root root 16415 10月 6 15:37 404.html drwxr-xr-x 2 root root 6 10月 6 17:14 cc drwxr-xr-x 2 root root 19 10月 6 17:14 centos drwxr-xr-x 2 root root 94 10月 6 09:25 fancy-index -rw-r--r-- 1 root root 36650 10月 6 15:37 feed.xml drwxr-xr-x 103 root root 4096 10月 6 09:25 help -rw-r--r-- 1 root root 27679 10月 6 15:37 index.html -rw-r--r-- 1 root root 20728 10月 6 15:37 legacy_index.html -rw-r--r-- 1 root root 18092 10月 6 15:37 LICENSE drwxr-xr-x 47 root root 4096 10月 6 09:25 news -rw-r--r-- 1 root root 58 10月 6 15:37 robots.txt -rw-r--r-- 1 root root 19134 10月 6 15:37 sitemap.xml drwxr-xr-x 8 root root 115 10月 6 15:37 static drwxr-xr-x 2 root root 24 10月 6 09:25 status 方法二：把/opt/mirror-web/_site里的文件以软链接的方式链接到镜像的跟目录（建议使用） ln -snf /opt/mirror-web/_site/* /opt/imau 目录描述文件：_data/options.yml 站点资源显示控制：static/tunasync.json tunasync.json [ { \"name\": \"ant\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"book\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"centos\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"dev\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"frp\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"git\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"go\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"grafana\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"iso\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"jdk\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"jmeter\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"kubernetes\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"mac\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"monitor\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"node\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"root-ca\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"other\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"printer\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"prometheus\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"pycharm\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"python\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"repo\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"script\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"test\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"tool\", \"is_master\": true, \"status\": \"success\" } ] \"last_update\": \"2022-01-11 16:39:37 +0800\", \"last_update_ts\": 1641890377, \"last_started\": \"2022-01-11 16:39:21 +0800\", \"last_started_ts\": 1641890361, \"last_ended\": \"2022-01-11 16:39:37 +0800\", \"last_ended_ts\": 1641890377, \"next_schedule\": \"2022-01-11 22:39:37 +0800\", \"next_schedule_ts\": 1641911977, \"upstream\": \"rsync://msync.centos.org/CentOS/\", - status: 'success' last_update: '-' name: \"AUR\" url: 'https://aur.tuna.tsinghua.edu.cn/' upstream: 'https://aur.archlinux.org/' is_master: true options.yml # Content Related mirror_desc: - name: git desc: git 二进制编译版本 - name: go desc: golang 开发环境 - name: grafana desc: grafana 的安装包 - name: helm desc: helm 的二进制发行包 - name: ios desc: 镜像文件，如centos, ubuntu, rocky等 - name: jdk desc: java 开发环境安装包 new_mirrors: - hugging-face-models - endeavouros - ubuntukylin - putty - postmarketOS - postmarketOS-images - obs-studio - stellarium unlisted_mirrors: - status: 'success' last_update: '-' name: \"AUR\" url: 'https://aur.tuna.tsinghua.edu.cn/' upstream: 'https://aur.archlinux.org/' is_master: true - link_to: 'osdn' name: \"manjaro-cd\" url: '/osdn/storage/g/m/ma/manjaro/' - link_to: 'osdn' name: \"manjaro-arm-cd\" url: '/osdn/storage/g/m/ma/manjaro-arm/' - link_to: 'osdn' name: \"mxlinux-isos\" url: '/osdn/storage/g/m/mx/mx-linux/ISOs/' - link_to: 'osdn' name: \"garuda-linux\" url: '/osdn/storage/g/g/ga/garuda-linux/' - link_to: 'osdn' name: \"linuxlite-cd\" url: '/osdn/storage/g/l/li/linuxlite/' - link_to: 'github-release' name: \"prometheus\" url: '/github-rele","date":"2023-09-24","objectID":"/posts/tuna-web/:1:5","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"6、docker镜像使用 静态文件编译 构建 Jekyll 的 docker 镜像环境复杂，建议直接使用官方或者已经存在的镜像tunathu/mirror-web或者serialt/tuna-mirror-web [root@tc ~]# docker run -it -v /path/to/mirror-web/:/data serialt/tuna-mirror-web 一些动态数据已经下载，若需要最新的，可以就行以下操作,然后在构建 下载最新的动态数据文件 wget https://mirrors.tuna.tsinghua.edu.cn/static/tunasync.json -O static/tunasync.json wget https://mirrors.tuna.tsinghua.edu.cn/static/tunet.json -O static/tunet.json mkdir -p static/status wget https://mirrors.tuna.tsinghua.edu.cn/static/status/isoinfo.json -O static/status/isoinfo.json 运行服务 docker镜像网页根目录: /opt/mirror-web 镜像站资源根目录: /opt/mirror 启动服务 docker run -tid -v /opt/tuna-mirror-web/_site:/opt/mirror-web -v /opt/mirror:/opt/mirror -p 8099:80 --name=tuna-mirror-nginx serialt/tuna-mirror-web-nginx:7b0c89d version: \"3\" networks: tuna-mirror-nginx: external: false services: tuna-mirror-nginx: image: serialt/tuna-mirror-web-nginx:latest container_name: mirror-nginx hostname: mirror-nginx restart: always networks: - tuna-mirror-nginx volumes: - \"/etc/localtime:/etc/localtime:ro\" - \"/opt/mirror-web/_site:/opt/mirror-web\" - \"/opt/mirror:/opt/mirror\" ports: - \"80:80\" dns: - 223.5.5.5 - 223.6.6.6 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:6","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"新镜像站版本发布 docker run -it --rm -v /opt/tuna-mirror-web:/data serialt/tuna-mirror-web docker restart tuna-mirror-nginx ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:7","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"编写说明 _data/options.yml: 是显示在镜像站主页对各个目录的说明 static/tunasync.json: 是对当前repo的同步信息的描述，可以自行编辑，也可以从tuna上下载 help: help目录里存有各个repo的帮助信息，在主页上会显示有个\"?\" news: 镜像站的新闻信息 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:8","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"help 说明 permalink 是表示help的首页的路径，必须要有 --- layout: help category: help mirrorid: app permalink: /help/app/ --- ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:9","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["Kubernetes","DevOps"],"content":"helm oci ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:0","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"},{"categories":["Kubernetes","DevOps"],"content":"缘由 Helm 3.8 版本开始，支持使用oci进行存储chart。镜像存储常用的Harbor在v1.6版本开始支持Helm Chart仓库功能， chart仓库由chartmuseum以插件的方式提供。随着兼容OCI规范的Helm Chart在社区上被更广泛地接受，Helm Chart能以Artifact的形式在Harbor中存储和管理，不再依赖ChartMuseum，因此Harbor在v2.8.0版本中，移除对ChartMuseum的支持。 ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:1","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"},{"categories":["Kubernetes","DevOps"],"content":"registry 仓库使用 基本使用 ### registry # 登录 helm registry login -u serialt docker.io # 注销 helm registry logout docker.io # pull chart helm fetch oci://docker.io/serialt/loki-stack --version=2.9.11 # push chart helm push loki-stack-2.9.11.tgz oci://docker.io/serialt oci支持的其他命令 helm pull helm show helm template helm install helm upgrade $ helm pull oci://localhost:5000/helm-charts/mychart --version 0.1.0 Pulled: localhost:5000/helm-charts/mychart:0.1.0 Digest: sha256:0be7ec9fb7b962b46d81e4bb74fdcdb7089d965d3baca9f85d64948b05b402ff $ helm show all oci://localhost:5000/helm-charts/mychart --version 0.1.0 apiVersion: v2 appVersion: 1.16.0 description: A Helm chart for Kubernetes name: mychart ... $ helm template myrelease oci://localhost:5000/helm-charts/mychart --version 0.1.0 --- # Source: mychart/templates/serviceaccount.yaml apiVersion: v1 kind: ServiceAccount ... $ helm install myrelease oci://localhost:5000/helm-charts/mychart --version 0.1.0 NAME: myrelease LAST DEPLOYED: Wed Oct 27 15:11:40 2021 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: ... $ helm upgrade myrelease oci://localhost:5000/helm-charts/mychart --version 0.2.0 Release \"myrelease\" has been upgraded. Happy Helming! NAME: myrelease LAST DEPLOYED: Wed Oct 27 15:12:05 2021 NAMESPACE: default STATUS: deployed REVISION: 2 NOTES: ... ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:2","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"},{"categories":["Kubernetes","DevOps"],"content":"迁移 chart repo 到 oci 仓库 基于 github action 镜像 helm repo 仓库到 docker hub，以加速 helm repo 到访问。 migrate-chart ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:3","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"}]