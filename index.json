[{"categories":["DevOps"],"content":"镜像同步 参考链接： https://lework.github.io/2020/04/13/skopeo/ https://blog.k8s.li/skopeo.html 日常工作中，需要将各种镜像搬到对应的仓库中，docker 适合于构建镜像，将镜像推送于仓库中。镜像被推送到仓库中后，如果需要对镜像进行搬运，在仓库不提供这个功能的情况下，同步镜像是比较困难的。 skopeo 是红帽开源的容器镜像管理工具。相比于docker，它有一下的优点： 支持多个平台：skopeo 支持 Linux，Mac 和 Windows。 无需 docker 或者 podman：skopeo 可以构建为单一的 cli，不依赖于 docker 服务或者 podman。 支持多个 OCI 镜像仓库间同步：支持 OCI 的镜像托管服务，都可以相互同步。 支持多架构镜像同步：可以同步多种架构的镜像。 镜像验签：skopeo 支持镜像签名，可确保镜像的完整性和可靠性。 ","date":"2024-08-19","objectID":"/posts/skopeo/:0:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"一、编译skopeo skopeo 官方并不提供编译好的静态二进制可执行文件，常见的系统源中已经包含了 skopeo，但由于 skopeo 的版本迭代比较快，新的功能也随之增加，部分操作系统里提供的安装包版本可能比较低，无法适用，且 skopeo 大多都是链接了动态库，无法通用于多个 linux 发行版，因此可以借助docker实现skopeo的静态编译。 基于github action构建skopeo: skopeo ","date":"2024-08-19","objectID":"/posts/skopeo/:1:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"下载 skopeo 源码 # download source code git clone --depth=1 https://github.com/containers/skopeo.git ","date":"2024-08-19","objectID":"/posts/skopeo/:1:1","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"构建build镜像的Dockerfile 国内构建则需要修改 alpine 和 go 镜像地址，可直连 github 的可以忽略此步 FROM golang:1.19-alpine3.16 AS builder ENV LANG=C.UTF-8 ENV TZ=Asia/Shanghai ENV CGO_ENABLED=0 ENV GOPROXY=https://goproxy.cn,direct RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories RUN apk update --no-cache \u0026\u0026 apk add --no-cache ca-certificates ","date":"2024-08-19","objectID":"/posts/skopeo/:1:2","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"构建 build 镜像 docker build -t skopeo-build . ","date":"2024-08-19","objectID":"/posts/skopeo/:1:3","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"构建 skopeo 静态二进制可执行文件 cd skopeo/ # 构建 linux amd64 架构 docker run --rm -t -v $PWD:/build skopeo-build sh -c \"apk update \u0026\u0026 apk add gpgme btrfs-progs-dev llvm13-dev gcc musl-dev \u0026\u0026 cd /build \u0026\u0026 CGO_ENABLE=0 GO111MODULE=on GOOS=linux GOARCH=amd64 go build -mod=vendor '-buildmode=pie' -ldflags '-extldflags -static' -gcflags '' -tags 'exclude_graphdriver_devicemapper exclude_graphdriver_btrfs containers_image_openpgp' -o ./bin/skopeo-linux-amd64 ./cmd/skopeo \" # 构建 linux arm64 架构 docker run --rm -t -v $PWD:/build skopeo-build sh -c \"apk update \u0026\u0026 apk add gpgme btrfs-progs-dev llvm13-dev gcc musl-dev \u0026\u0026 cd /build \u0026\u0026 CGO_ENABLE=0 GO111MODULE=on GOOS=linux GOARCH=arm64 go build -mod=vendor '-buildmode=pie' -ldflags '-extldflags -static' -gcflags '' -tags 'exclude_graphdriver_devicemapper exclude_graphdriver_btrfs containers_image_openpgp' -o ./bin/skopeo-linux-arm64 ./cmd/skopeo \" ","date":"2024-08-19","objectID":"/posts/skopeo/:1:4","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"二、skopeo 命令使用 [root@tc ~]# skopeo -v skopeo version 1.11.1-dev [root@tc ~]# skopeo --help Various operations with container images and container image registries Usage: skopeo [flags] skopeo [command] Available Commands: copy Copy an IMAGE-NAME from one location to another delete Delete image IMAGE-NAME generate-sigstore-key Generate a sigstore public/private key pair help Help about any command inspect Inspect image IMAGE-NAME list-tags List tags in the transport/repository specified by the SOURCE-IMAGE login Login to a container registry logout Logout of a container registry manifest-digest Compute a manifest digest of a file standalone-sign Create a signature using local files standalone-verify Verify a signature using local files sync Synchronize one or more images from one location to another Flags: --command-timeout duration timeout for the command execution --debug enable debug output -h, --help help for skopeo --insecure-policy run the tool without any policy check --override-arch ARCH use ARCH instead of the architecture of the machine for choosing images --override-os OS use OS instead of the running OS for choosing images --override-variant VARIANT use VARIANT instead of the running architecture variant for choosing images --policy string Path to a trust policy file --registries.d DIR use registry configuration files in DIR (e.g. for container signature storage) --tmpdir string directory used to store temporary files -v, --version Version for Skopeo Use \"skopeo [command] --help\" for more information about a command. # 登录与登出 oci skopeo login -u username docker.io skopeo logout docker.io 不下载镜像情况下获取镜像信息 [root@tc ~]# skopeo inspect docker://docker.io/alpine { \"Name\": \"docker.io/library/alpine\", \"Digest\": \"sha256:eece025e432126ce23f223450a0326fbebde39cdf496a85d8c016293fc851978\", \"RepoTags\": [ \"20220316\", \"20220328\", \"20220715\", \"20221110\", \"20230208\", \"20230329\", \"20230901\", \"3\", \"3.17\", \"3.17.0\", \"3.17.0_rc1\", \"3.17.1\", \"3.17.2\", \"3.17.3\", \"3.17.4\", \"3.17.5\", \"3.18\", \"3.18.0\", \"3.18.2\", \"3.18.3\", \"3.18.4\", \"edge\", \"latest\" ], \"Created\": \"2023-09-28T21:19:27.801479409Z\", \"DockerVersion\": \"20.10.23\", \"Labels\": null, \"Architecture\": \"amd64\", \"Os\": \"linux\", \"Layers\": [ \"sha256:96526aa774ef0126ad0fe9e9a95764c5fc37f409ab9e97021e7b4775d82bf6fa\" ], \"LayersData\": [ { \"MIMEType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\", \"Digest\": \"sha256:96526aa774ef0126ad0fe9e9a95764c5fc37f409ab9e97021e7b4775d82bf6fa\", \"Size\": 3401967, \"Annotations\": null } ], \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ] } docker://: 是使用 Docker Registry HTTP API V2 进行连接远端 docker.io: 远程仓库 alpine: 镜像名称 获取本地镜像信息 [root@tc ~]# skopeo inspect docker-daemon:alpine:3 { \"Name\": \"docker.io/library/alpine\", \"Digest\": \"sha256:844bc35fdf7a96e5b6bf5e76e20989a797cc75976fad73275061a36f448b92b9\", \"RepoTags\": [], \"Created\": \"2023-09-28T21:19:27.801479409Z\", \"DockerVersion\": \"20.10.23\", \"Labels\": null, \"Architecture\": \"amd64\", \"Os\": \"linux\", \"Layers\": [ \"sha256:cc2447e1835a40530975ab80bb1f872fbab0f2a0faecf2ab16fbbb89b3589438\" ], \"LayersData\": [ { \"MIMEType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\", \"Digest\": \"sha256:cc2447e1835a40530975ab80bb1f872fbab0f2a0faecf2ab16fbbb89b3589438\", \"Size\": 7625728, \"Annotations\": null } ], \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ] } docker-daemon: docker守护镜像的镜像 alpine:3: 本地镜像的名称 ","date":"2024-08-19","objectID":"/posts/skopeo/:2:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"copy镜像 # skopeo --insecure-policy copy docker://nginx:1.17.6 docker-archive:/tmp/nginx.tar Getting image source signatures Copying blob 8ec398bc0356 done Copying blob 465560073b6f done Copying blob f473f9fd0a8c done Copying config f7bb5701a3 done Writing manifest to image destination Storing signatures # ls -alh /tmp/nginx.tar -rw-r--r-- 1 root root 125M 4月 13 15:22 /tmp/nginx.tar --insecure-policy: 用于忽略安全策略配置文件 docker://nginx:1.17.6: 该命令将会直接通过 http 下载目标镜像 docker-archive: 存储为 /tmp/nginx.tar，此文件可以直接通过 docker load 命令导入 相应的，可以将下载的文件导入到本地 # skopeo copy docker-archive:/tmp/nginx.tar docker-daemon:nginx:latest Getting image source signatures Copying blob 556c5fb0d91b done Copying blob 49434cc20e95 done Copying blob 75248c0d5438 done Copying config f7bb5701a3 done Writing manifest to image destination Storing signatures # docker images nginx REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest f7bb5701a33c 3 months ago 126MB COPY # 也可以将镜像下载到指定目录 # skopeo copy docker://busybox:latest dir:/tmp/busybox Getting image source signatures Copying blob 0669b0daf1fb done Copying config 83aa35aa1c done Writing manifest to image destination Storing signatures # ls -alh /tmp/busybox/ 总用量 760K drwxr-xr-x 2 root root 186 4月 13 15:26 . drwxrwxrwt. 12 root root 4.0K 4月 13 15:25 .. -rw-r--r-- 1 root root 743K 4月 13 15:26 0669b0daf1fba90642d105f3bc2c94365c5282155a33cc65ac946347a90d90d1 -rw-r--r-- 1 root root 1.5K 4月 13 15:26 83aa35aa1c79e4b6957e018da6e322bfca92bf3b4696a211b42502543c242d6f -rw-r--r-- 1 root root 527 4月 13 15:26 manifest.json -rw-r--r-- 1 root root 33 4月 13 15:25 version #或者从指定目录导入到本地 # skopeo copy dir:/tmp/busybox docker-daemon:busybox:latest Getting image source signatures Copying blob 0669b0daf1fb done Copying config 83aa35aa1c done Writing manifest to image destination Storing signatures # docker images busybox REPOSITORY TAG IMAGE ID CREATED SIZE busybox latest 83aa35aa1c79 4 weeks ago 1.22MB ","date":"2024-08-19","objectID":"/posts/skopeo/:2:1","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"删除镜像 skopeo delete docker://localhost:5000/nginx:latest ","date":"2024-08-19","objectID":"/posts/skopeo/:2:2","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"认证文件 认证文件默认存放在 $HOME/.docker/config.json 文件内容 { \"auths\": { \"myregistrydomain.com:5000\": { \"auth\": \"dGVzdHVzZXI6dGVzdHxxxxxxxx\", \"email\": \"cc@local.com\" } } } ","date":"2024-08-19","objectID":"/posts/skopeo/:2:3","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"sync 在 OCI 间同步镜像 使用 docke r在 OCI 间同步镜像的时候，需要先把镜像拉下来，打上 tag ，然后在推送到目的 OCI 上。在这个操作的过程中，即占用了存储，又占用了带宽，在同步大的镜像或者大量的镜像的时候，存储会严重影响镜像在 OCI 间同步的效率。skopeo 正好可以解决这个缺点，skopeo 在同步 OCI 镜像的过程中，只占用带宽，不会把镜像下载到本地。 基于 yaml 文件的同步 # sync.yaml ghcr.io: images: kube-vip/kube-vip: - 'v0.6.0' - 'v0.4.4' k3d-io/k3d-tools: - '5.5.2' 同步镜像 skopeo --insecure-policy sync -a --src yaml --dest docker sync.yaml repo.local.com/serialt skopeo --insecure-policy copy docker://docker.io/library/nginx:latest docker://registry.cn-hangzhou.aliyuncs.com/serialt/nginx:latest ","date":"2024-08-19","objectID":"/posts/skopeo/:2:4","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"查看镜像所有tag [root@tc ~]# skopeo list-tags docker://registry.cn-hangzhou.aliyuncs.com/serialt/go ","date":"2024-08-19","objectID":"/posts/skopeo/:2:5","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"三、同步镜像 目前，常用的 OCI 仓库有：docker.io，quay.io，gcr.io，registry.k8s.io，ghcr.io 等。众所周知，因为某些原因，这些 OCI 仓库在国内无法访问，而一些项目又严重依赖于存储在这些 OCI 仓库的镜像，虽然有热心的大佬们会把 gcr 和 ghcr 上存储的镜像同步到 docker hub 中，但因为这些被推送到 docker hub 中的镜像不是官方维护的，可能会存在比较大的镜像的同步时间差，某些需要的镜像无法在 docker hub 上找到，同时也容易引起容器镜像的供应链安全问题。因此，可以使用 github action 使用 skopeo 进行同步镜像。 项目地址：sync-image ","date":"2024-08-19","objectID":"/posts/skopeo/:3:0","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"1、安装sync-image 和 skopeo wget https://github.com/serialt/skopeo/releases/download/v1.13.3/skopeo-linux-amd64 go install github.com/serialt/sync-image@latest ","date":"2024-08-19","objectID":"/posts/skopeo/:3:1","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"2、配置sync-image yaml 配置文件 # config.yaml # 镜像同步的个数 last: 10 # mcr同步的个数，mcr中包含多个 vscode 容器开发的镜像 mcrLast: 50 autoSyncfile: sync.yaml # 不同步带有以下关键字的镜像的tag exclude: - 'alpha' - 'beta' - 'rc' - 'amd64' - 'ppc64le' - 'arm64' - 'arm' - 's390x' - 'SNAPSHOT' - 'snapshot' - 'debug' - 'master' - 'latest' - 'main' - 'sig' - 'sha' - 'mips' # 需要同步的镜像 images: docker.elastic.co: - elasticsearch/elasticsearch - kibana/kibana - logstash/logstash - beats/filebeat - beats/heartbeat - beats/packetbeat - beats/auditbeat - beats/journalbeat - beats/metricbeat - apm/apm-server - app-search/app-search quay.io: - coreos/flannel - ceph/ceph - cephcsi/cephcsi - csiaddons/k8s-sidecar - csiaddons/volumereplication-operator - prometheus/prometheus - prometheus/alertmanager - prometheus/pushgateway - prometheus/blackbox-exporter - prometheus/node-exporter - prometheus-operator/prometheus-config-reloader - prometheus-operator/prometheus-operator - brancz/kube-rbac-proxy - jetstack/cert-manager-webhook - jetstack/cert-manager-controller - jetstack/cert-manager-cainjector k8s.gcr.io: - conformance - dns/k8s-dns-node-cache - metrics-server/metrics-server - kube-state-metrics/kube-state-metrics - prometheus-adapter/prometheus-adapter registry.k8s.io: - sig-storage/local-volume-provisioner - metrics-server/metrics-server - defaultbackend - ingress-nginx/controller - ingress-nginx/kube-webhook-certgen - sig-storage/nfs-subdir-external-provisioner - sig-storage/csi-node-driver-registrar - sig-storage/csi-provisioner - sig-storage/csi-resizer - sig-storage/csi-snapshotter - sig-storage/snapshot-controller - sig-storage/snapshot-validation-webhook - sig-storage/nfsplugin - sig-storage/csi-attacher - sig-storage/livenessprobe - defaultbackend-amd64 - defaultbackend-arm64 - pause - etcd - kube-proxy - kube-apiserver - kube-scheduler - kube-controller-manager - coredns/coredns - build-image/kube-cross gcr.io: - kaniko-project/executor ghcr.io: - k3d-io/k3d-tools - k3d-io/k3d-proxy - kube-vip/kube-vip mcr.microsoft.com: - devcontainers/base - devcontainers/go docker.io: - flannel/flannel - flannel/flannel-cni-plugin - calico/kube-controllers - serialt/rocky - serialt/alma - calico/cni - calico/pod2daemon-flexvol - calico/kube-controllers - calico/node - rancher/mirrored-flannelcni-flannel-cni-plugin - rancher/mirrored-flannelcni-flanne ","date":"2024-08-19","objectID":"/posts/skopeo/:3:2","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"3、生成动态同步的 yaml 文件 sync-image -c config.yaml ","date":"2024-08-19","objectID":"/posts/skopeo/:3:3","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"4、同步镜像 依赖的环境变量 DEST_HUB_USERNAME DEST_HUB_PASSWORD MY_GITHUB_TOKEN 同步的shell脚本 hub=\"docker.io\" repo=\"$hub/${DEST_HUB_USERNAME}\" hub2=\"registry.cn-hangzhou.aliyuncs.com\" repo2=\"$hub2/${DEST_HUB_USERNAME}\" if [ -f sync.yaml ]; then echo \"[Start] sync.......\" sudo skopeo login -u ${DEST_HUB_USERNAME} -p ${DEST_HUB_PASSWORD} ${hub} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker sync.yaml ${repo} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker custom_sync.yaml ${repo} sleep 3 sudo skopeo login -u ${DEST_HUB_USERNAME} -p ${DEST_HUB_PASSWORD} ${hub2} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker sync.yaml ${repo2} \\ \u0026\u0026 sudo skopeo --insecure-policy sync -a --src yaml --dest docker custom_sync.yaml ${repo2} echo \"[End] done.\" else echo \"[Error]not found sync.yaml!\" fi ","date":"2024-08-19","objectID":"/posts/skopeo/:3:4","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps"],"content":"5、github action 配置文件 name: sync on: push: branches: - master - main schedule: - cron: \"0 2 * * *\" # Allows you to run this workflow manually from the Actions tab workflow_dispatch: jobs: sync: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Set up Go uses: actions/setup-go@v4 with: go-version: '\u003e=1.21.0' - name: Install dependencies run: | export version=v1.10.0 \u0026\u0026 export arch=amd64 \u0026\u0026 sudo wget https://github.com/lework/skopeo-binary/releases/download/${version}/skopeo-linux-${arch} -O /usr/bin/skopeo \u0026\u0026 sudo chmod +x /usr/bin/skopeo skopeo --version go install github.com/serialt/sync-image@latest - name: generate_sync_yaml env: SRC_HUB_USERNAME: ${{ secrets.SRC_HUB_USERNAME }} DEST_HUB_USERNAME: ${{ secrets.DEST_HUB_USERNAME }} DEST_HUB_PASSWORD: ${{ secrets.DEST_HUB_PASSWORD }} MY_GITHUB_TOKEN: ${{ secrets.MY_GITHUB_TOKEN }} timeout-minutes: 10 run: | sync-image - name: sync image env: SRC_HUB_USERNAME: ${{ secrets.SRC_HUB_USERNAME }} DEST_HUB_USERNAME: ${{ secrets.DEST_HUB_USERNAME }} DEST_HUB_PASSWORD: ${{ secrets.DEST_HUB_PASSWORD }} run: | bash sync.sh ","date":"2024-08-19","objectID":"/posts/skopeo/:3:5","tags":["skopeo","image","oci-image-sync"],"title":"Skopeo","uri":"/posts/skopeo/"},{"categories":["DevOps","k8s"],"content":"MetalLB 自建k8s的 loadbalancer https://www.lixueduan.com/posts/cloudnative/01-metallb/ https://www.bboy.app/2021/01/11/metallb%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8/ https://ieevee.com/tech/2019/06/30/metallb.html https://cloud.tencent.com/developer/article/2146391#:~:text=%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85,Metallb%E6%94%AF%E6%8C%81%E9%80%9A%E8%BF%87Kuberntes%E6%B8%85%E5%8D%95%E3%80%81Helm%E5%92%8CKustomize%E6%96%B9%E5%BC%8F%E8%BF%9B%E8%A1%8C%E9%83%A8%E7%BD%B2%EF%BC%8C%E6%9C%AC%E6%96%87%E6%88%91%E4%BB%AC%E5%B0%86%E4%BB%A5Kuberntes%E6%B8%85%E5%8D%95%E4%B8%BA%E4%BE%8B%E4%BB%8B%E7%BB%8D%E4%BA%A7%E5%93%81%E7%9A%84%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85%EF%BC%8C%E9%83%A8%E7%BD%B2%E7%9A%84%E7%89%88%E6%9C%AC%E4%B8%BA%E6%9C%80%E6%96%B0%E7%9A%84v0.13.4%E3%80%82 简介 在Kubernetes部署完成服务后，我们经常需要将服务开放给到外部用户访问 。如果是使用云平台（阿里云、腾讯云、AWS等）的话，这个需求处理起来非常简单，可以通过云平台的LoadBalancer来实现。 但如果是自建的kubernetes裸机集群，那则要麻烦得多。祼机集群默认不支持负载均衡的方式，可用的方案不外乎Ingress、NodePort、ExternalIPs等方式来实现外部访问。可惜这些方案本身并不完美，他们或多或少都存在着一些缺点，这使得裸金属集群成为Kubernetes生态系统中的二等公民。 而MetalLB 旨在通过提供与标准网络设备集成的LoadBalancer来解决这个痛点，从而使裸机群集上的外部服务也尽可能“正常运行”，减少运维上的管理成本。 metallb支持两种工作模式,一种是layer 2 mode,也就是工作在2层来负责相应arp请求，对于局域网中的人来说仿佛就是给服务分配了一个ip，但是2层模式不是真正的负载均衡，因为所有的流量会经过集群中的一个节点，当这个节点挂了的话，metallb会迁移ip到另外一个节点上，另外一种是bgp模式，在bgp模式下，集群中每一个节点都会和路由器建立bgp会话，所以bgp模式是高可用的，但是需要你的路由器支持bgp。这边我的路由器是不支持bgp的，所以就采用二层模式 Layer 2 模式 Layer 2模式下，每个service会有集群中的一个node来负责。当服务客户端发起ARP解析的时候，对应的node会响应该ARP请求，之后，该service的流量都会指向该node（看上去该node上有多个地址）。 Layer 2模式并不是真正的负载均衡，因为流量都会先经过1个node后，再通过kube-proxy转给多个end points。如果该node故障，MetalLB会迁移 IP到另一个node，并重新发送免费ARP告知客户端迁移。现代操作系统基本都能正确处理免费ARP，因此failover不会产生太大问题。 Layer 2模式更为通用，不需要用户有额外的设备；但由于Layer 2模式使用ARP/ND，地址池分配需要跟客户端在同一子网，地址分配略为繁琐。 BGP模式 BGP模式下，集群中所有node都会跟上联路由器建立BGP连接，并且会告知路由器应该如何转发service的流量。 BGP模式是真正的LoadBalancer。 部署要求 MetalLB部署需要以下环境才能运行： 运行Kubernetes 1.13.0或更高版本的群集，尚不具有网络负载平衡功能； 一些用于MetalLB分配的IPv4地址； 如果使用BGP模式，需要准备一台或多台支持BGP的路由器； 如果使用layer 2模式时，集群节点间必须允许7946端口的访问 ，用户代理之间的通信； 集群的网络类型需要支持MetalLB，详见下图 网络类型 兼容性 Antrea Yes Calico Mostly Canal Yes Cilium Yes Flannel Yes Kube-ovn Yes Kube-router Mostly Weave Net Mostly 工作原理： Metallb包含两个组件，Controller和Speaker，Controller为Deployment部署方式，而Speaker则采用Daemonset方式部署到集群内部各个Node节点。 具体的工作原理如下图所示，Controller负责监听Service变化，当Service配置为LoadBalancer模式时，从IP池分配给到相应的IP地址并对该IP的生命周期进行管理。Speaker则会依据选择的协议进行相应的广播或应答，实现IP地址的通信响应。当业务流量通过TCP/UDP协议到达指定的Node时，由Node上面运行的Kube-Proxy组件对流量进行处理，并分发到对应服务的Pod上面。 MetalLB支持两种模式，一种是Layer2模式，一种是BGP模式。 Layer2模式 在2层模式下，Metallb会在Node节点中选出一台作为Leader，与服务IP相关的所有流量都会流向该节点。在该节点上， kube-proxy将接收到的流量传播到对应服务的Pod。当leader节点出现故障时，会由另一个节点接管。从这个角度来看，2层模式更像是高可用，而不是负载均衡，因为同时只能在一个节点负责接收数据。 在二层模式中会存在以下两种局限性：单节点瓶颈和故障转移慢的情况。 由于Layer 2 模式会使用单个选举出来的Leader来接收服务IP的所有流量，这就意味着服务的入口带宽被限制为单个节点的带宽，单节点的流量处理能力将成为整个集群的接收外部流量的瓶颈。 在故障转移方面，目前的机制是MetalLB通过发送2层数据包来通知各个节点，并重新选举Leader，这通常能在几秒内完成。但如果是计划外的事故导致的，此时在有故障的客户端刷新其缓存条目之前，将无法访问服务IP。 BGP模式 BGP模式是真正的负载均衡，该模式需要路由器支持BGP协议 ，群集中的每个节点会与网络路由器建议基于BGP的对等会话，并使用该会话来通告负载均衡的IP。MetalLB发布的路由彼此等效，这意味着路由器将使用所有的目标节点，并在它们之间进行负载平衡。数据包到达节点后，kube-proxy负责流量路由的最后一跳，将数据包发送到对应服务的Pod。 负载平衡的方式取决于您特定的路由器型号和配置，常见的有基于数据包哈希对每个连接进行均衡，这意味着单个TCP或UDP会话的所有数据包都将定向到群集中的单个计算机。 BGP模式也存在着自身的局限性，该模式通过对数据包头中的某些字段进行哈希处理，并将该哈希值用作后端数组的索引，将给定的数据包分配给特定的下一跳。但路由器中使用的哈希通常不稳定，因此只要后端节点数量发生变化时，现有连接就会被随机地重新哈希，这意味着大多数现有连接将被转发到另一后端，而该后端并不清楚原有的连接状态。为了减少这种麻烦，建议使用更加稳定的BGP算法，如：ECMP散列算法。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:0:1","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"安装使用 Metallb支持通过Kuberntes清单、Helm和Kustomize方式进行部署，本文我们将以Kuberntes清单为例介绍产品的部署安装，部署的版本为最新的v0.13.7。 注：由于Metallb从v0.13.0版本开始不再使用configmap而改用自定义资源方式配置，因此本示例与旧版本的配置方式会有所不同 1）确定ipvs集群开启strictARP kubectl edit configmap -n kube-system kube-proxy #设置strictARP值为true apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: \"ipvs\" ipvs: strictARP: true 2）安装metallb wget https://raw.githubusercontent.com/metallb/metallb/v0.13.4/config/manifests/metallb-native.yaml kubectl apply -f metallb-native.yaml # helm helm repo add metallb https://metallb.github.io/metallb helm fetch metallb/metallb --version=0.13.7 helm install metallb metallb/metallb --version=0.13.7 3）配置模式 Layer2 模式 创建IPAddressPool，并指定用于分配的IP池。 [root@sugar metallb]# cat \u003c\u003cEOF \u003e IPAdressPool.yaml apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: ip-pool namespace: metallb-system spec: addresses: - 192.168.214.50-192.168.214.80 #分配给LB的IP池,注意这里的addresses需要和k8s的节点处于同一个网段 EOF 创建广播声明，此处未指定IP池，则默认会使用所有IP池地址。 cat \u003c\u003cEOF \u003e L2Advertisement.yaml apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: l2adver namespace: metallb-system EOF # 也可以指定ip地址池 cat \u003c\u003cEOF \u003e L2Advertisement.yaml apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: example namespace: metallb-system spec: ipAddressPools: - ip-pool #上一步创建的 ip 地址池，通过名字进行关联 EOF BGP模式配置 对于具有一个BGP路由器和一个IP地址范围的基本配置，您需要4条信息： MetalLB应该连接的路由器IP地址， 路由器的AS号， MetalLB应该使用的AS号， 以CIDR前缀表示的IP地址范围。(分配的LB ip) 示例：现在分配给MetalLB的AS编号为64500和192.168.10.0/24的IP地址池，并将其连接到AS编号为64501的地址为10.0.0.1的路由器，则配置如下所示： 创建BGPPeer apiVersion: metallb.io/v1beta2 kind: BGPPeer metadata: name: sample namespace: metallb-system spec: myASN: 64500 peerASN: 64501 peerAddress: 10.0.0.1 配置IP地址池 apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: first-pool namespace: metallb-system spec: addresses: - 192.168.10.0/24 - 172.16.78.141/32 # - 192.168.214.50-192.168.214.80 创建广播声明 apiVersion: metallb.io/v1beta1 kind: BGPAdvertisement metadata: name: bgpadver namespace: metallb-system ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:0:2","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"测试 简单测试： 1）创建示例yaml文件并执行，包括svc与deployment。 apiVersion: v1 kind: Service metadata: name: myapp spec: selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 80 type: LoadBalancer #类型选择LoadBalancer --- apiVersion: apps/v1 kind: Deployment metadata: name: myapp labels: app: myapp spec: replicas: 2 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: nginx image: nginx ports: - containerPort: 80 2）查看创建的SVC状态，已获取到IP [root@master-01 metalLB]# kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 3h47m myapp-svc LoadBalancer 10.99.108.212 172.16.78.141 80:31542/TCP 17m 3）访问测试 helm 测试： https://artifacthub.io/packages/helm/bitnami/nginx $ helm repo add bitnami https://charts.bitnami.com/bitnami $ helm install my-release bitnami/nginx [root@sugar metallb]# kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 36m my-release-nginx LoadBalancer 10.110.219.132 172.16.5.48 80:32026/TCP 27m mysql ClusterIP 10.109.126.5 \u003cnone\u003e 3306/TCP 14m mysql-headless ClusterIP None \u003cnone\u003e 3306/TCP 14m nginx-svc LoadBalancer 10.103.199.38 172.16.5.47 80:32559/TCP 31m [root@ftp ~]# curl 172.16.5.48 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to nginx!\u003c/h1\u003e \u003cp\u003eIf you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u003c/p\u003e \u003cp\u003eFor online documentation and support please refer to \u003ca href=\"http://nginx.org/\"\u003enginx.org\u003c/a\u003e.\u003cbr/\u003e Commercial support is available at \u003ca href=\"http://nginx.com/\"\u003enginx.com\u003c/a\u003e.\u003c/p\u003e \u003cp\u003e\u003cem\u003eThank you for using nginx.\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:0:3","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"工作流程 MetalLB 做的工作可以分为两个部分： 1）地址分配：当创建 LoadBalancer Service 时，MetalLB 会为其分配 IP 地址。这个 IP 地址是从预先配置的 IP 地址库获取的。同样，当 Service 删除后，已分配的 IP 地址会重新回到地址库。 2）对外广播：分配了 IP 地址之后，需要让集群外的网络知道这个地址的存在。MetalLB 使用了标准路由协议实现：ARP、NDP 或者 BGP。 在 Layer 2 模式，使用 ARP（ipv4）/NDP（ipv6） 协议； 在 BPG 模式，自然是使用 BGP 协议。 ARP（Address Resolution Protocol）：是根据IP地址获取物理地址的一个TCP/IP协议。 NDP（neighbor Discovery protocol）：是ICMPv6的子协议是IPV6协议体系中一个重要的基础协议，邻居发现协议替代了IPV4的ARP，ICMP路由器发现。它定义了使用ICMPv6报文实现地址解析，跟踪邻居状态，重复地址检测，路由器发现，以及重定向等功能。 同时 MetalLB 分别使用两个组件来实现了上述两个功能： Controller：实现地址分配，以 Deployment 方式运行，用于监听 Service 的变更，分配/回收 IP 地址。 Speaker：实现地址对外广播，以 DaemonSet 方式运行，对外广播 Service 的 IP 地址。 具体的工作流如下： Controller 负责监听 Service 变化并分配或回收 IP ，当 Service 配置为 LoadBalancer 模式时，从 IP 池分配给到相应的 IP 地址并对该 IP 的生命周期进行管理。 创建 Service 时（或者从非 LoadBalancer 类型修改为 LoadBalancer 类型）时从 IP 池选择一个 IP 并分配， 删除 Service （或者从 LoadBalancer 类型修改为非 LoadBalancer 类型）时回收该 IP 到 IP 池 Speaker 则会依据选择的协议进行相应的广播或应答，实现 IP 地址的通信响应 。当业务流量通过 TCP/UDP 协议到达指定的 Node 时，由 Node 上面运行的 Kube-Proxy 组件对流量进行处理，并分发到对应服务的 Pod 上面。 如果是 Layer2 模式 Speaker 就会响应 ARP（ipv4）/NDP（ipv6）请求 如果是 BGP 模式 Speaker 则发送 BGP 广播，将路由规则同步给 peer。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:0:4","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"Layer2 模式工作原理 METALLB IN LAYER 2 MODE 大致原理 Layer 2 中的 Speaker 工作负载是 DeamonSet 类型，在每个节点上都调度一个 Pod，首先，几个 Pod 会先进行选举，选举出 Leader。 由 Leader Pod 获取所有 LoadBalancer 类型的 Service，并将已分配的 IP 地址绑定到当前主机到网卡上。同时该 Leader 会响应对 ExternalIP 的 ARP（ipv4）/NDP（ipv6） 请求，因此从局域网层面来看，speaker 所在的机器是有多个 IP 地址的，当前其中也包含 ExternalIP。 从网络的角度来看，计算机的网络接口分配了多个IP地址,因为对不同 ip 地址的 arp 请求返回的都是这个节点的 mac 地址。 因此与 ExternalIP 相关的所有流量都会流向该节点。在该节点上， kube-proxy 将接收到的流量传播到对应 Service 的后端 Pod。 也就是说，所有 LoadBalancer 类型的 Service 的 IP 同一时间都是绑定在同一台节点的网卡上。 局限性 在 Layer2 模式中会存在以下两种局限性：单节点瓶颈和故障转移慢。 单节点瓶颈 由于 Layer 2 模式会使用单个选举出来的 Leader 来接收 ExternalIP 的所有流量，这就意味着服务的入口带宽被限制为单个节点的带宽，单节点的流量处理能力将成为整个集群的接收外部流量的瓶颈。 从这个角度来看，Layer2 模式更像是实现了故障转移，而不是负载均衡，因为同时只能在一个节点负责接收数据。 故障转移慢 在故障转移方面，MetalLB 也实现了自动故障转移。目前的机制是通过 memberlist 这个基于 gossip 协议的成员和故障检测的库，其他节点检测到 Leader 故障后自动重新选举出新 Leader，新的 Leader 自动接管所有 ExternalIP 并发送大量 二层数据包来通知客户端(也就是区域网中的其他节点) ExternalIP 的 MAC 地址变化。 大部分操作系统都能处理这部分 二层数据包并更新 neighbor caches，但是也有极少部分系统不能正确处理这个数据包，从而无法及时更新缓存，还会继续请求旧的 Leader 节点，这种情况下可以让旧 Leader 多存活几分钟，用于处理这部分客户端的请求。 根据官网文档描述故障转移正常情况下会在几秒内完成，一般不会超过 10 秒。但是在更新完成前 ExternalIP 会无法访问。 即：会出现几秒钟的服务中断 这个 10s 只是官方说的，可能经常测试或者是一个大概值，和这段 代码#announcer.go#L51 里的10s 的循环不是一回事 ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:0:5","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"BGP 模式工作原理 METALLB IN BGP MODE 大致原理 在 BGP 模式下每个节点（ 上的 Speaker Pod）都会和路由器建立一个 BGP peer session，并且通过这些 peer session 来告知外部网络 ExternalIPs 的存在。 BGP模式是以集群中的主机与对等体进行共享路由信息，从而实现集群外部的服务能够访问到集群内部的服务。 和 Layer2 模式不同，BGP模式真正的实现了负载均衡，不过具体的负载均衡行为和路由器以及配置有关系。一般默认的行为是根据数据包中的某些关键字段进行 hash，并更新 hash 值分配给其中某一个连接。 原文：but the common behavior is to balance per-connection, based on a packet hash. 关键字段常见选择为 三元组（协议、源IP、目的IP） 或者五元组（协议、源IP、目的IP、源端口、目的端口） 也就是说默认情况下一个连接里的所有数据包都会发送到固定的节点，这样能拥有更好的性能。 局限性 BGP 模式最大的弊端就是不能优雅的处理节点下线。当集群中某个节点下线时，所有客户端对这个节点的连接都会被主动断开。 客户端一般会出现一个 Connection reset by peer 错误 同时由于是对每个数据包基于 hash 值进行负载均衡，因此对后端节点数是非常敏感的，这也是 BGP 的一个优点，故障转移非常快。 正因为 BGP 故障转移很快，反而引发了一个 BGP 模式的最大缺点：由于 BGP 会对每个数据包做负载均衡，在主机发生故障时会快速切换到新的主机上，从而引发节点变动时同一连接的不同数据包可能会发送到不同主机上导致网络导致的网络重排问题。 比如第一个包转发到节点 A，然后处理第二个包时添加或故障了一个节点，按照新的节点数进行负载均衡计算，可能第二个数据包就被分到节点 B 了，节点 B 很明显是不能正确处理这个数据包的。 对客户端来说就是这次请求直接失败了。 解决该弊端的方法没有太理想的解决办法，只能尽量采取一些优化手段： 1）路由器配置更加稳定的 hash 算法，比如 “resilient ECMP” 或者 “resilient LAG”。使用这样的算法极大地减少了 后端节点更改时受影响的连接。 2）尽量少的增删节点 3）在流量少时变更节点，以降低影响 4）使用 ingress 来对外暴露服务等等 二者实现原理 MetalLB 包括 Layer2 模式和 BGP 模式，主要区别在于 IP 通告部分的实现不一样： Layer2 模式通过响应对 ExternalIP 的 ARP（ipv4）/NDP（ipv6） 请求来告知其他节点某个 IP 在这台机器上 arp 请求是在 二层的，这可能就是该模式为什么叫做 Layer2 BGP 模式则通过于路由器建立 BGP peer session，从而进行数据同步，让路由器知道某个 IP 在这台机器上 二者优缺点 Layer2 模式 优点：通用性好，适用于任何网络环境，不需要特殊的硬件，甚至不需要花哨的路由器。 缺点：单节点瓶颈和故障转移慢 Layer2 模式是一种基础、通用的实现，能用，而且易于使用，没有任何限制，但是局限性比较大。 BGP 模式： 优点：使用 BGP 可以在多节点间负载均衡，没有单节点瓶颈，同时故障转移很快。 缺点： 需要支持 BGP 路由协议的软路由或者硬件路由器设备。 其实不能算缺点了，想要功能总得付出代价。 使用建议 BGP 模式则是比较理想的实现，除了依赖支持 BGP 的路由之外，其他方面则没有任何限制，并且没有可用性的问题 一句话总结：如果说 Layer2 模式为基础实现，那么 BGP 模式则是 LoadBalance 的终极实现，能用 BGP 模式就尽量用 BGP 模式，否则的话就只能用 Layer2 模式了，如果不知道用什么模式的话直接用 Layer2 模式即可。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:0:6","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"Istio + MetalLB 基于helm 参考链接：https://www.jianshu.com/p/fe6e0911b71c ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:1:0","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"一、MetaLB Kubernetes 不为裸机集群提供网络负载均衡器的实现（LoadBalancer 类型的服务)。 Kubernetes 附带的 Network LB 的实现都是调用各种 IaaS 平台（GCP，AWS，Azure 等）的粘合代码。 如果你未在受支持的 IaaS 平台（GCP，AWS，Azure 等）上运行，则 LoadBalancers 在创建后将无限期保持 “pending” 状态。 MetalLB 可以解决 istio ingress gateway EXTERNAL-IP “pending” 的问题. 安装： 1）确定ipvs集群开启strictARP kubectl edit configmap -n kube-system kube-proxy #设置strictARP值为true apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: \"ipvs\" ipvs: strictARP: true 2）安装metallb [root@master-01 ~]# kubectl create ns metallb-system [root@master-01 ~]# helm repo add metallb https://metallb.github.io/metallb # 有需要可以下载chart [root@master-01 ~]# helm fetch metallb/metallb --version=0.13.7 [root@master-01 ~]# helm install metallb metallb/metallb --version=0.13.7 -n metallb-system 3）配置模式 Layer2 模式 创建IPAddressPool，并指定用于分配的IP池。 [root@master-01 ~]# cat ip-pool.yaml apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: ip-pool namespace: metallb-system spec: addresses: - 192.168.214.50-192.168.214.80 #分配给LB的IP池,注意这里的addresses需要和k8s的节点处于同一个网段 autoAssign: false # 不自动分配ip，默认为ture，若部署服务的LoadBalancer要指定ip的话需要设置为false 创建广播声明，此处未指定IP池，则默认会使用所有IP池地址。 apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: l2adver namespace: metallb-system 使用helm配置layer2 helm repo add serialt https://serialt.github.io/helm-charts helm install metallb-config serialt/metallb-config --set \"ipPoolRange=172.16.1.40-172.16.1.49\" -n metallb-system --version 0.0.1 BGP模式配置 对于具有一个BGP路由器和一个IP地址范围的基本配置，您需要4条信息： MetalLB应该连接的路由器IP地址， 路由器的AS号， MetalLB应该使用的AS号， 以CIDR前缀表示的IP地址范围。(分配的LB ip) 示例：现在分配给MetalLB的AS编号为64500和192.168.10.0/24的IP地址池，并将其连接到AS编号为64501的地址为10.0.0.1的路由器，则配置如下所示： 创建BGPPeer apiVersion: metallb.io/v1beta2 kind: BGPPeer metadata: name: sample namespace: metallb-system spec: myASN: 64500 peerASN: 64501 peerAddress: 10.0.0.1 配置IP地址池 apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: first-pool namespace: metallb-system spec: addresses: - 192.168.10.0/24 - 172.16.78.141/32 # - 192.168.214.50-192.168.214.80 创建广播声明 apiVersion: metallb.io/v1beta1 kind: BGPAdvertisement metadata: name: bgpadver namespace: metallb-system ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:1:1","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"一、Istio 1）增加helm repo [root@master-01 ~]# helm repo add istio https://istio-release.storage.googleapis.com/charts # 有需求可以下载chart [root@master-01 ~]# helm fetch istio/base --version 1.13.6 [root@master-01 ~]# helm fetch istio/istiod --version 1.13.6 [root@master-01 ~]# helm fetch istio/gateway --version 1.13.6 2）部署istio组件 [root@master-01 ~]# kubectl create namespace istio-system [root@master-01 ~]# helm install istio-base istio/base -n istio-system --version 1.13.6 [root@master-01 ~]# helm install istiod istio/istiod -n istio-system --wait --version 1.13.6 若关闭了自动分配ip，这需要配置一下 gateway 的 annotations 参考链接： 弃用Service.Spec.LoadBalancerIP metallb 分配https://metallb.universe.tf/usage/ annotations里指定IP # istio-values.yaml service: annotations: metallb.universe.tf/loadBalancerIPs: 172.16.78.143 autoscaling: enabled: true minReplicas: 3 [root@master-01 ~]# helm install istio-ingressgateway istio/gateway -n istio-system --version 1.13.6 --set replicaCount=3 --set autoscaling.enabled=false 使用以下命令确认所有 Pod 都在运行。 $ kubectl get pod -n istio-system -w NAME READY STATUS RESTARTS AGE istio-ingressgateway-7cc49dcd99-c4mtf 1/1 Running 0 94s istiod-687f965684-n8rkv 1/1 Running 0 3m26s 3）安装多个istio gateway [root@master-01 ~]# helm install istio-ingressgateway-mgt istio/gateway -n istio-system --version 1.13.6 --set replicaCount=3 --set autoscaling.enabled=false apiVersion: networking.istio.io/v1beta1 kind: Gateway metadata: name: local-gateway-mgt spec: selector: istio: ingressgateway-mgt # use istio ingressgateway-mgt servers: - port: number: 80 name: http protocol: HTTP hosts: - \"*.local.local.com\" - hosts: - '*.local.imau.cc' port: name: https number: 443 protocol: HTTPS tls: mode: PASSTHROUGH ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:1:2","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"测试 apiVersion: v1 kind: Service metadata: name: myapp-svc spec: type: ClusterIP selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 80 --- apiVersion: apps/v1 kind: Deployment metadata: name: myapp-deployment labels: app: myapp spec: replicas: 2 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: nginx image: nginx ports: - containerPort: 80 resources: requests: cpu: 100m memory: 100Mi limits: cpu: 100m memory: 100Mi --- apiVersion: networking.istio.io/v1beta1 kind: VirtualService metadata: name: myapp-vs spec: gateways: - local-gateway hosts: - myapp.local.com http: - route: - destination: host: myapp-svc port: number: 80 --- apiVersion: networking.istio.io/v1beta1 kind: Gateway metadata: name: local-gateway spec: selector: istio: ingressgateway # use istio default controller servers: - port: number: 80 name: http protocol: HTTP hosts: - \"*.local.com\" # tls: # httpsRedirect: true # sends 301 redirect for http requests - port: number: 443 name: https protocol: HTTPS tls: mode: SIMPLE credentialName: local-credential # must be the same as secret hosts: - \"*.local.com\" ","date":"2024-08-11","objectID":"/posts/2024-08-11-metallb/:1:3","tags":["metallb"],"title":"metallb","uri":"/posts/2024-08-11-metallb/"},{"categories":["DevOps","k8s"],"content":"Kubeadm 搭建 集群 Version: 1.26 kubeadm是Kubernetes官方提供的用于快速安部署Kubernetes集群的工具，伴随Kubernetes每个版本的发布都会同步更新，kubeadm会对集群配置方面的一些实践做调整，通过实验kubeadm可以学习到Kubernetes官方在集群配置上一些新的最佳实践。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:0","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"1、主机名与域名解析 节点加入集群时默认以节点的主机名为节点名，内部访问的时候默认使用节点名，如果不想配置主机名，可以设置加入集群时节点名为该节点的ip [root@k8s-m1 ~]# cat \u003c\u003cEOF \u003e\u003e /etc/hosts 192.168.8.173 m1 192.168.8.174 m2 192.168.8.175 m3 192.168.8.176 n1 EOF ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:1","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"2、关闭selinux与防火墙 [root@k8s-m1 ~]# systemctl stop firewalld [root@k8s-m1 ~]# systemctl disable firewalld [root@k8s-m1 ~]# sed -i \"s/SELINUX=enforcing/SELINUX=disabled/\" /etc/selinux/config [root@k8s-m1 ~]# setenforce 0 如果各个主机启用了防火墙策略，需要开放Kubernetes各个组件所需要的端口，可以查看Ports and Protocols中的内容, 开放相关端口或者关闭主机的防火墙。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:2","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"3、同步时间 [root@k8s-m1 ~]# yum -y install chrony [root@k8s-m1 ~]# systemctl restart chronyd [root@k8s-m1 ~]# systemctl enable chronyd [root@k8s-m1 ~]# timedatectl set-timezone Asia/Shanghai [root@k8s-m1 ~]# timedatectl set-local-rtc 0 ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:3","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"4、升级系统内核和修改内核模块参数 centos7 需要升级内核 [root@k8s-m1 ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org [root@k8s-m1 ~]# rpm -Uvh https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm [root@k8s-m1 ~]# yum --enablerepo=elrepo-kernel install kernel-lt -y [root@k8s-m1 ~]# grub2-set-default 0 # 查看系统可用内核 [root@k8s-m1 ~]# awk -F\\' '$1==\"menuentry \" {print i++ \" : \" $2}' /etc/grub2.cfg [root@k8s-m1 ~]# reboot [root@k8s-m1 ~]# cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf # https://github.com/moby/moby/issues/31208 # ipvsadm -l --timout # 修复ipvs模式下长连接timeout问题 小于900即可 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.ip_forward = 1 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 # 要求iptables不对bridge的数据进行处理 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.netfilter.nf_conntrack_max = 2310720 fs.inotify.max_user_watches=89100 fs.may_detach_mounts = 1 fs.file-max = 52706963 fs.nr_open = 52706963 vm.swappiness = 0 vm.overcommit_memory=1 vm.panic_on_oom=0 EOF 加载内核参数 [root@k8s-m1 ~]# sysctl -p 升级软件 [root@k8s-m1 ~]# yum -y upgrade ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:4","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"5、ipvs配置 [root@k8s-m1 ~]# yum -y install ipvsadm ipset 参考链接：https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md Notes: use nf_conntrack instead of nf_conntrack_ipv4 for Linux kernel 4.19 and later [root@k8s-m1 ~]# yum install ipset ipvsadm -y [root@k8s-m1 ~]# cat \u003e/etc/modules-load.d/ipvs.conf\u003c\u003cEOF ip_vs # 负载均衡调度算法-最少连接 ip_vs_lc # 负载均衡调度算法-加权最少连接 ip_vs_wlc # 负载均衡调度算法-轮询 ip_vs_rr # 负载均衡调度算法-加权轮询 ip_vs_wrr # 源地址散列调度算法 ip_vs_sh nf_conntrack br_netfilter # containerd overlay EOF [root@k8s-m1 ~]# systemctl restart systemd-modules-load.service 查看加载情况 [root@k8s-m1 ~]# lsmod | grep -e ip_vs -e nf_conntrack -e br_netfilter ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:5","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"6、配置yum源 epel-release [root@k8s-m1 ~]# yum -y install epel-release [root@k8s-m1 ~]# sed -e 's|^metalink=|#metalink=|g' \\ -e 's|^#baseurl=https\\?://download.fedoraproject.org/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -e 's|^#baseurl=https\\?://download.example/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -i.bak \\ /etc/yum.repos.d/epel.repo kubernetes 新版安装包目录结构已经更改 # amd64 [root@k8s-m1 ~]# cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # arm64 [root@k8s-m1 ~]# cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-aarch64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:6","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"7、安装 containerd安装方式有两种，可以使用docker安装源里的containerd，也可以使用二进制包安装 使用docker源安装containerd [root@k8s-m1 ~]# curl -sL https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo -o /etc/yum.repos.d/docker-ce.repo [root@k8s-m1 ~]# sed -i 's+download.docker.com+mirrors.ustc.edu.cn/docker-ce+' /etc/yum.repos.d/docker-ce.repo [root@k8s-m1 ~]# yum -y install containerd 配置镜像加速 https://github.com/containerd/containerd/blob/main/docs/cri/registry.md https://github.com/containerd/containerd/blob/main/docs/cri/config.md#registry-configuration https://www.cnblogs.com/liy36/p/16590745.html cp /etc/containerd/config.toml{,.bak} containerd config default \u003e /etc/containerd/config.toml 使用二进制安装containerd 压缩包中已经按照官方二进制部署推荐的目录结构布局好。 里面包含了systemd配置文件，containerd以及cni的部署文件。 将解压缩到系统的根目录/中: [root@k8s-m1 ~]# curl -sL https://github.com/containerd/containerd/releases/download/v1.6.21/cri-containerd-cni-1.6.21-linux-amd64.tar.gz -o cri-containerd-cni-1.6.21-linux-amd64.tar.gz [root@k8s-m1 ~]# tar -xf cri-containerd-cni-1.6.21-linux-amd64.tar.gz -C / etc/ etc/cni/ etc/cni/net.d/ etc/cni/net.d/10-containerd-net.conflist etc/systemd/ etc/systemd/system/ etc/systemd/system/containerd.service etc/crictl.yaml usr/ usr/local/ usr/local/sbin/ usr/local/sbin/runc usr/local/bin/ usr/local/bin/containerd-stress usr/local/bin/containerd-shim usr/local/bin/containerd-shim-runc-v1 usr/local/bin/crictl usr/local/bin/critest usr/local/bin/containerd-shim-runc-v2 usr/local/bin/ctd-decoder usr/local/bin/containerd usr/local/bin/ctr opt/ opt/cni/ opt/cni/bin/ opt/cni/bin/ptp opt/cni/bin/bandwidth opt/cni/bin/static opt/cni/bin/dhcp ... opt/containerd/ opt/containerd/cluster/ ... 生成containerd的配置文件 mkdir -p /etc/containerd containerd config default \u003e /etc/containerd/config.toml 根据文档Container runtimes 中的内容，对于使用systemd作为init system的Linux的发行版，使用systemd作为容器的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定，因此这里配置各个节点上containerd的cgroup driver为systemd。 修改前面生成的配置文件/etc/containerd/config.toml： 配置镜像加速 sjtu 镜像已不可用 # 使用SystemdCgroup sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml # 修改配置目录 sed -i 's+config_path = \"\"+config_path = \"/etc/containerd/certs.d\"+' /etc/containerd/config.toml mkdir /etc/containerd/certs.d/docker.io -pv # 配置加速 sed -i 's+registry.k8s.io+registry.cn-hangzhou.aliyuncs.com/serialt+' /etc/containerd/config.toml cat \u003e /etc/containerd/certs.d/docker.io/hosts.toml \u003c\u003c EOF server = \"https://docker.io\" [host.\"https://docker.mirrors.sjtug.sjtu.edu.cn\"] capabilities = [\"pull\", \"resolve\", \"push\"] # skip_verify = true # ca = \"/path/to/ca.crt\" EOF systemctl restart containerd systemctl enable containerd 使用crictl工具管理containerd容器 tee /etc/crictl.yaml \u003c\u003cEOF runtime-endpoint: unix:///run/containerd/containerd.sock image-endpoint: unix:///run/containerd/containerd.sock timeout: 10 debug: false EOF 关闭交换分区 # 临时方法 [root@k8s-m1 ~]# swapoff -a [root@k8s-m1 ~]# free -h total used free shared buff/cache available Mem: 972M 344M 67M 8.1M 559M 456M Swap: 0B 0B 0B # 永久方法 [root@k8s-m1 ~]# sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab 安装kubernetes [root@k8s-m1 ~]# yum -y install kubeadm-1.26.5 kubectl-1.26.5 kubelet-1.26.5 kubectl 在node节点上可以不安装 ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:7","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"8、获取k8s的镜像 [root@k8s-m1 ~]# kubeadm config images list --kubernetes-version=v1.26.5 于k8s是谷歌开发的，如果能科学上网，就直接获取k8s镜像，不然需要国内镜像加速） 注意：k8s对镜像版本要求比较高，以下操作建议使用脚本进行 [root@k8s9 ~]# cat pull-k8s.sh #!/bin/bash version=v1.26.5 K8S_URL=registry.k8s.io # MIRROR_URL=docker.io/serialt MIRROR_URL=registry.cn-hangzhou.aliyuncs.com/serialt images=`kubeadm config images list --kubernetes-version=${version} |awk -F '/' '{print $NF}'` for imageName in ${images[@]} do ctr images pull ${MIRROR_URL}/${imageName} echo ${imageName} | grep coredns if [[ $? == 0 ]];then ctr images tag ${MIRROR_URL}/${imageName} ${K8S_URL}/coredns/${imageName} else ctr images tag ${MIRROR_URL}/${imageName} ${K8S_URL}/${imageName} fi ctr images rm ${MIRROR_URL}/$imageName done [root@k8s9 ~]# cat pull-k8s.sh #!/bin/bash version=v1.26.4 K8S_URL=registry.k8s.io # MIRROR_URL=docker.io/serialt MIRROR_URL=registry.cn-hangzhou.aliyuncs.com/serialt images=`kubeadm config images list --kubernetes-version=${version} |awk -F '/' '{print $NF}'` for imageName in ${images[@]} do ctr -n k8s.io images pull ${MIRROR_URL}/${imageName} echo ${imageName} | grep coredns if [[ $? == 0 ]];then ctr -n k8s.io images tag ${MIRROR_URL}/${imageName} ${K8S_URL}/coredns/${imageName} else ctr -n k8s.io images tag ${MIRROR_URL}/${imageName} ${K8S_URL}/${imageName} fi ctr -n k8s.io images rm ${MIRROR_URL}/$imageName done ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:8","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"9、初始化集群 方法一：适用于单master节点 设置kubelet开机自启 [root@k8s-m1 ~]# systemctl enable kubelet 初始化节点 [root@k8s-m1 ~]# kubeadm init --kubernetes-version=v1.26.4 --pod-network-cidr=10.244.0.0/16 --ignore-preflight-errors=SystemVerification 若想忽略某些信息，加上–ignore-preflight-errors=[提示信息的名] 例如 –ignore-preflight-errors=SystemVerification kubeadm初始化整个集群的过程，生成相关的各种证书、kubeconfig文件、bootstraptoken等等，后边是使用kubeadm join往集群中添加节点时用到的命令，下面的命令是配置如何使用kubectl访问集群的方式： [root@k8s-m1 ~]# mkdir -p $HOME/.kube [root@k8s-m1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@k8s-m1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config 使用配置文件进行初始化节点 官网链接：https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-config/ 方法二：使用配置文件初始化节点 生成文件 [root@k8s-m1 ~]# kubeadm config print init-defaults --component-configs KubeProxyConfiguration,KubeletConfiguration \u003e kubeadm-init.yml 初始化k8s集群 自定义kubelet参数： https://kubernetes.io/zh-cn/docs/reference/config-api/kubelet-config.v1beta1/ https://blog.dianduidian.com/post/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96kubelet%E5%BD%93%E5%89%8D%E9%85%8D%E7%BD%AE/ https://www.cnblogs.com/shenyuanhaojie/p/16407553.html https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/node-pressure-eviction/ imageMinimumGCAge: 20m #是对未使用镜像进行垃圾搜集之前允许其存在的时长。 imageGCHighThresholdPercent: 80 imageGCLowThresholdPercent: 70 maxPods: 200 示例文件 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 172.16.1.136 # 需要修改为本机ip bindPort: 6443 nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: r1 taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controlPlaneEndpoint: \"172.16.1.200:6443\" # 控制平面ip controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.k8s.io kind: ClusterConfiguration kubernetesVersion: 1.26.0 networking: dnsDomain: cluster.local podSubnet: \"10.244.0.0/16\" # 指定pod网段 serviceSubnet: 10.96.0.0/12 scheduler: {} --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 bindAddress: 0.0.0.0 bindAddressHardFail: false clientConnection: acceptContentTypes: \"\" burst: 0 contentType: \"\" kubeconfig: /var/lib/kube-proxy/kubeconfig.conf qps: 0 clusterCIDR: \"\" configSyncPeriod: 0s conntrack: maxPerCore: null min: null tcpCloseWaitTimeout: null tcpEstablishedTimeout: null detectLocal: bridgeInterface: \"\" interfaceNamePrefix: \"\" detectLocalMode: \"\" enableProfiling: false healthzBindAddress: \"\" hostnameOverride: \"\" iptables: localhostNodePorts: null masqueradeAll: false masqueradeBit: null minSyncPeriod: 0s syncPeriod: 0s ipvs: excludeCIDRs: null minSyncPeriod: 0s scheduler: \"wrr\" # 设置轮询算法 strictARP: true # 方便使用metallb syncPeriod: 0s tcpFinTimeout: 0s tcpTimeout: 0s udpTimeout: 0s kind: KubeProxyConfiguration metricsBindAddress: \"\" mode: \"ipvs\" # 使用ipvs nodePortAddresses: null oomScoreAdj: null portRange: \"\" showHiddenMetricsForVersion: \"\" winkernel: enableDSR: false forwardHealthCheckVip: false networkName: \"\" rootHnsEndpointName: \"\" sourceVip: \"\" --- apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: cacheTTL: 0s enabled: true x509: clientCAFile: /etc/kubernetes/pki/ca.crt authorization: mode: Webhook webhook: cacheAuthorizedTTL: 0s cacheUnauthorizedTTL: 0s cgroupDriver: systemd clusterDNS: - 10.96.0.10 clusterDomain: cluster.local cpuManagerReconcilePeriod: 0s evictionPressureTransitionPeriod: 0s fileCheckFrequency: 0s healthzBindAddress: 127.0.0.1 healthzPort: 10248 httpCheckFrequency: 0s imageMinimumGCAge: 20m # 镜像回收时间 imageGCHighThresholdPercent: 80 # 触发镜像回收的百分比 imageGCLowThresholdPercent: 70 maxPods: 200 # 设置node 节点最大pod数 kind: KubeletConfiguration logging: flushFrequency: 0 options: json: infoBufferSize: \"0\" verbosity: 0 memorySwap: {} n","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:9","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"10、安装网卡 安装flannel # Needs manual creation of namespace to avoid helm error kubectl create ns kube-flannel kubectl label --overwrite ns kube-flannel pod-security.kubernetes.io/enforce=privileged helm repo add flannel https://flannel-io.github.io/flannel/ helm install flannel --set podCidr=\"10.244.0.0/16\" --namespace kube-flannel flannel/flannel 下载flannel镜像 #!/bin/bash SRC_URL=docker.io/rancher #MIRROR_URL=docker.io/serialt MIRROR_URL=registry.cn-hangzhou.aliyuncs.com/serialt imageListFlannel=( ${SRC_URL}/mirrored-flannelcni-flannel-cni-plugin:v1.1.0 ${SRC_URL}/mirrored-flannelcni-flannel:v0.19.2 ) for imageNameFlannel in ${imageListFlannel[@]} do imageNameFlannel=`echo ${imageNameFlannel} |awk -F '/' '{print $NF}'` docker pull ${MIRROR_URL}/${imageNameFlannel} docker tag ${MIRROR_URL}/${imageNameFlannel} ${SRC_URL}/${imageNameFlannel} docker rmi ${MIRROR_URL}/${imageNameFlannel} done 删除node节点上残留的网络 # 删除cni0 ifconfig cni0 down ip link delete cni0 rm -rf /var/lib/cni/ # 删除flannel网络 ifconfig flannel.1 down ip link delete flannel.1 rm -f /etc/cni/net.d/* # 重启kubelet systemctl restart kubelet 安装calico网卡 [root@k8s-m1 ~]# helm repo add projectcalico https://projectcalico.docs.tigera.io/charts [root@k8s-m1 ~]# helm repo update [root@k8s-m1 ~]# helm install calico projectcalico/tigera-operator --version v3.25.1 --namespace tigera-operator --create-namespace #!/bin/bash SRC_URL=docker.io/calico #MIRROR_URL=docker.io/serialt MIRROR_URL=registry.cn-hangzhou.aliyuncs.com/serialt imageListCalico=( ${MIRROR_URL}/cni:v3.22.5 ${MIRROR_URL}/pod2daemon-flexvol:v3.22.5 ${MIRROR_URL}/node:v3.22.5 ${MIRROR_URL}/kube-controllers:v3.22.5 ) for imageNameCalico in ${imageListCalico[@]} do imageNameCalico=`echo ${imageNameCalico} |awk -F '/' '{print $NF}'` docker pull ${MIRROR_URL}/${imageNameCalico} docker tag ${MIRROR_URL}/${imageNameCalico} ${SRC_URL}/${imageNameCalico} docker rmi ${MIRROR_URL}/${imageNameCalico} done 11、节点加入 node节点加入 [root@k8s-n1 ~]# kubeadm join 192.168.122.100:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:174be9ec793b09d1b5a17da472bdb33c25463c65b0a42c8c09c4248783103b8b master节点查看 [root@k8s-m1 ~]# kubectl get node NAME STATUS ROLES AGE VERSION k8s-m1.com Ready master 60m v1.18.15 k8s-n1.com Ready \u003cnone\u003e 113s v1.18.15 如果长时间是NotReady，则检测是否有flannel镜像，或查看日志/var/log/messages 检查集群状态 [root@k8s-m1 ~]# kubectl get pod --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-66bff467f8-fp948 1/1 Running 0 109s kube-system coredns-66bff467f8-vmhwq 1/1 Running 0 109s kube-system etcd-k8s-m1.com 1/1 Running 0 2m4s kube-system kube-apiserver-k8s-m1.com 1/1 Running 0 2m4s kube-system kube-controller-manager-k8s-m1.com 1/1 Running 0 2m4s kube-system kube-flannel-ds-8wpjv 1/1 Running 0 22s kube-system kube-flannel-ds-dhwtr 1/1 Running 0 38s kube-system kube-proxy-dd8l9 1/1 Running 0 22s kube-system kube-proxy-wh9bc 1/1 Running 0 109s kube-system kube-scheduler-k8s-m1.com 1/1 Running 0 2m4s [root@k8s-m1 ~]# kubectl get node NAME STATUS ROLES AGE VERSION k8s-m1.com Ready master 2m16s v1.18.15 k8s-n1.com Ready \u003cnone\u003e 30s v1.18.15 token的创建及使用 token用于机器加入kubernetes集群时用到，默认token 24小时就会过期，后续的机器要加入集群需要重新生成token [root@k8s-m1 ~]# kubeadm token list TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS f2b012.1416e09e3d1fff4d 23h 2018-06-24T21:26:17+08:00 authentication,signing The default bootstrap token generated by 'kubeadm init'. system:bootstrappers:kubeadm:default-node-token 24小时后需要重新创建token 加入node节点 # 24 小时有效 [root@k8s-m1 ~]# kubeadm token create --print-join-command kubeadm join --token 48a5ec.6297ad9983652bc6 192.168.191.175:6443 --discovery-token-ca-cert-hash sha256:25e52920789d850d1b04b032e0da4a814fa0efd9ee85542500769b86f3f9b6dc [root@k8s-m1 ~]# kubeadm token create --ttl 0 --print-join-command可以创建一个永不过期的token. # node节点执行以上命令 加入master节点 # 新版本 [root@k8s-m1 ~]# kubeadm init phase upload-certs --upload-certs [upload-certs] Storing the certificates in ConfigMap \"kubeadm-certs\" in the \"kube-system\" Namespace ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:10","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"12、firewalld开放kubernetes端口 https://www.cnblogs.com/Dev0ps/p/11401530.html k8s master需要开启以下端口 firewall-cmd --permanent --add-port=6443/tcp \\ --add-port=2379-2380/tcp \\ --add-port=10250/tcp \\ --add-port=10251/tcp \\ --add-port=10252/tcp \\ --add-port=10255/tcp \\ --add-port=8472/udp \\ --add-port=443/udp \\ --add-port=53/udp \\ --add-port=53/tcp \\ --add-port=9153/tcp firewall-cmd --add-masquerade --permanent firewall-cmd --reload # only if you want NodePorts exposed on control plane IP as well firewall-cmd --permanent --add-port=30000-32767/tcp systemctl restart firewalld k8s node需要开启以下端口 firewall-cmd --permanent --add-port=10250/tcp \\ --add-port=10255/tcp \\ --add-port=8472/udp \\ --add-port=443/udp \\ --add-port=30000-32767/tcp \\ --add-port=53/udp \\ --add-port=53/tcp \\ --add-port=9153/tcp firewall-cmd --add-masquerade --permanent firewall-cmd --reload 以下几点需要特别注意： 8472/udp为flannel的通信端口 443/tcp 为Kubernetes server端口 注意一点：一定要执行以下命令打开NAT，默认是关闭状态 firewall-cmd --add-masquerade --permanent # 检查是否允许NAT转发 firewall-cmd --query-masquerade # 关闭NAT转发 firewall-cmd --remove-masquerade 如果你使用了istio还有把istio-pilot的端口加到防火墙里： firewall-cmd --permanent --add-port=15010-15014/tcp 否则会出现以下报错： Envoy proxy is NOT ready ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm/:1:11","tags":["kubeadm"],"title":"kubeadm","uri":"/posts/2024-08-11-kubeadm/"},{"categories":["DevOps","k8s"],"content":"kubeadm-cert 官方的 kubeadm 部署的集群 CA 有效期默认是10年，其他证书有效期默认是1年，1年有效期在真实使用过程中，往往不够，因此需要自行修改 CA 的有效期然后编译；对于已经存在的集群，则可以修改 renew 的时间在让证书有效期达到10年。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm-cert/:1:0","tags":["kubeadm-cert"],"title":"kubeadm-cert","uri":"/posts/2024-08-11-kubeadm-cert/"},{"categories":["DevOps","k8s"],"content":"一、更新证书 1、检查证书有效期 kubeadm certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf Aug 06, 2022 19:03 UTC 344d no apiserver Aug 06, 2022 19:03 UTC 344d ca no apiserver-etcd-client Aug 06, 2022 19:03 UTC 344d etcd-ca no apiserver-kubelet-client Aug 06, 2022 19:03 UTC 344d ca no controller-manager.conf Aug 06, 2022 19:03 UTC 344d no etcd-healthcheck-client Aug 06, 2022 19:03 UTC 344d etcd-ca no etcd-peer Aug 06, 2022 19:03 UTC 344d etcd-ca no etcd-server Aug 06, 2022 19:03 UTC 344d etcd-ca no front-proxy-client Aug 06, 2022 19:03 UTC 344d front-proxy-ca no scheduler.conf Aug 06, 2022 19:03 UTC 344d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca Aug 04, 2031 19:03 UTC 9y no etcd-ca Aug 04, 2031 19:03 UTC 9y no front-proxy-ca Aug 04, 2031 19:03 UTC 9y no 该命令显示 /etc/kubernetes/pki 文件夹中的客户端证书以及 kubeadm（admin.conf,controller-manager.conf 和 scheduler.conf）使用的 KUBECONFIG 文件中嵌入的客户端证书的到期时间 / 剩余时间。 另外，kubeadm 会显示用户证书是否由外部管理（EXTERNALLY MANAGED）。在这种情况下，用户应该小心的手动 / 使用其他工具来管理证书更新。 **说明：**上面的列表中没有包含 kubelet.conf，因为 kubeadm 将 kubelet 配置为自动更新证书。轮换的证书位于目录 /var/lib/kubelet/pki。要修复过期的 kubelet 客户端证书，请参阅 kubelet 客户端证书轮换失败。 2、更新证书 1）备份集群证书 **说明：**如果你运行了一个 HA 集群，以下命令需要在所有 Master 节点上执行。 cp -a /etc/kubernetes/ /etc/kubernetes-`date +%Y%m%d` kubectl get cm kubeadm-config -n kube-system -o yaml \u003e /root/kubeadm-config.yaml 2）更新证书 执行如下命令更新所有证书 **说明：**如果你运行了一个 HA 集群，这个命令需要在所有 Master 节点上执行。 kubeadm certs renew all 出现类似以下输出说明证书更新完成，并且最后一行 Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates. 提示要求要重启 kube-apiserver、kube-controller-manager、kube-scheduler 和 etcd 使其使用新证书。 [renew] Reading configuration from the cluster... [renew] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml' certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed certificate for serving the Kubernetes API renewed certificate the apiserver uses to access etcd renewed certificate for the API server to connect to kubelet renewed certificate embedded in the kubeconfig file for the controller manager to use renewed certificate for liveness probes to healthcheck etcd renewed certificate for etcd nodes to communicate with each other renewed certificate for serving etcd renewed certificate for the front proxy client renewed certificate embedded in the kubeconfig file for the scheduler manager to use renewed Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates. 确认证书是否续期成功 # kubeadm certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf Aug 29, 2022 04:20 UTC 364d no apiserver Aug 29, 2022 04:20 UTC 364d ca no apiserver-etcd-client Aug 29, 2022 04:20 UTC 364d etcd-ca no apiserver-kubelet-client Aug 29, 2022 04:20 UTC 364d ca no controller-manager.conf Aug 29, 2022 04:20 UTC 364d no etcd-healthcheck-client Aug 29, 2022 04:20 UTC 364d etcd-ca no etcd-peer Aug 29, 2022 04:20 UTC 364d etcd-ca no etcd-server Aug 29, 2022 04:20 UTC 364d etcd-ca no front-proxy-client Aug 29, 2022 04:20 UTC 364d front-proxy-ca no scheduler.conf Aug 29, 2022 04:20 UTC 364d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca Aug 04, 2031 19:03 UTC 9y no etcd-ca Aug 04, 2031 19:03 UTC 9y no front-proxy-ca Aug 04, 2031 19:03 UTC 9y no **说明：**从命令输出可以看到，所有客户端证书的到期时间均发生了变化，不过不是顺延一年， 而是从执行 renew 成功的时间开始续签一年。 3）修改kube-controller-manager 续签kubelet证书时间 kubelet","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm-cert/:1:1","tags":["kubeadm-cert"],"title":"kubeadm-cert","uri":"/posts/2024-08-11-kubeadm-cert/"},{"categories":["DevOps","k8s"],"content":"二、编译kubeadm kubeadm 默认证书为一年，一年过期后，会导致 api service 不可用，使用过程中会出现：x509: certificate has expired or is not yet valid，Google 建议通过不停更新版本来自动更新证书，若需要长期有效，建议自己编译kubeadm 参考文档：https://zhuanlan.zhihu.com/p/444057661 以下兼容版本： 1.17.0 1.18.0 1.19.0 1.20.0 1.21.0 1.22.0 1.23.0 1、下载源码 [sugar@imau github]$ wget https://github.com/kubernetes/kubernetes/archive/v1.21.14.tar.gz [sugar@imau github]$ tar -xf v1.21.14.tar.gz [sugar@imau kubernetes-1.21.14]$ 2、修改ca有效期 # ca证书默认10年 [sugar@imau kubernetes-1.21.14]$ vim staging/src/k8s.io/client-go/util/cert/cert.go // 这个方法里面 NotAfter: now.Add(duration365d * 10).UTC() // 默认有效期就是 10 年，改成 100 年 // 输入 /NotAfter 查找，回车定位 func NewSelfSignedCACert(cfg Config, key crypto.Signer) (*x509.Certificate, error) { now := time.Now() tmpl := x509.Certificate{ SerialNumber: new(big.Int).SetInt64(0), Subject: pkix.Name{ CommonName: cfg.CommonName, Organization: cfg.Organization, }, NotBefore: now.UTC(), // NotAfter: now.Add(duration365d * 10).UTC(), NotAfter: now.Add(duration365d * 100).UTC(), KeyUsage: x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature | x509.KeyUsageCertSign, BasicConstraintsValid: true, IsCA: true, } certDERBytes, err := x509.CreateCertificate(cryptorand.Reader, \u0026tmpl, \u0026tmpl, key.Public(), key) if err != nil { return nil, err } return x509.ParseCertificate(certDERBytes) } 修改证书有效期为 100 年（默认为 1 年） vim ./cmd/kubeadm/app/constants/constants.go // 就是这个常量定义 CertificateValidity，改成 * 100 年 // 输入 /CertificateValidity 查找，回车定位 const ( // KubernetesDir is the directory Kubernetes owns for storing various configuration files KubernetesDir = \"/etc/kubernetes\" // ManifestsSubDirName defines directory name to store manifests ManifestsSubDirName = \"manifests\" // TempDirForKubeadm defines temporary directory for kubeadm // should be joined with KubernetesDir. TempDirForKubeadm = \"tmp\" // CertificateValidity defines the validity for all the signed certificates generated by kubeadm // CertificateValidity = time.Hour * 24 * 365 CertificateValidity = time.Hour * 24 * 365 * 100 // CACertAndKeyBaseName defines certificate authority base name CACertAndKeyBaseName = \"ca\" // CACertName defines certificate name CACertName = \"ca.crt\" // CAKeyName defines certificate name CAKeyName = \"ca.key\" 验证一下已经正确修改： cat ./staging/src/k8s.io/client-go/util/cert/cert.go | grep NotAfter cat ./cmd/kubeadm/app/constants/constants.go | grep CertificateValidity git diff 3、编译 为了不影响机器环境，采用docker 中编译 1）制作build的基础镜像 FROM rockylinux:9 LABEL mantainer=\"serialt \u003ctserialt@gmail.com\u003e rocky9 image\" # change yum repo to ustc RUN sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/rocky|g' \\ -i.bak \\ /etc/yum.repos.d/rocky*.repo \u0026\u0026 \\ yum -y install epel-release \u0026\u0026 \\ sed -e 's|^metalink=|#metalink=|g' \\ -e 's|^#baseurl=https\\?://download.fedoraproject.org/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -e 's|^#baseurl=https\\?://download.example/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -i.bak \\ /etc/yum.repos.d/epel*.repo # install base software RUN yum -y install git vim-enhanced bash-completion wget gcc make golang \u0026\u0026 \\ yum groupinstall \"Development Tools\" -y \u0026\u0026 \\ yum -y upgrade \u0026\u0026 \\ yum clean all ENV LANG zh_CN.UTF-8 ENV TZ \"Asia/Shanghai\" WORKDIR /root EXPOSE 22 80 443 CMD /bin/bash # 编译kubeadm, 这里主要编译 kubeadm 即可 make all WHAT=cmd/kubeadm GOFLAGS=-v # 编译 kubelet # make all WHAT=cmd/kubelet GOFLAGS=-v # 编译 kubectl # make all WHAT=cmd/kubectl GOFLAGS=-v CentOS： yum groupinstall \"Development Tools\" -y #gcc, make etc. yum install rsync jq -y Ubuntu： sudo apt install build-essential #(Following command will install essential commands like gcc, make etc.) sudo apt install rsync jq -y GoLang 环境 查看 kube-cross 的 TAG 版本号 [root@51 kubernetes-1.21.14]# cat ./build/build-image/cross/VERSION v1.21.0-go1.16.15-buster.0 GitHub：https://github.com/serialt/kubeadm 4、更新证书 如果是使用原版 kubeadm 安装之后，可以手动执行命令更新证书有效期到 100 年，但因为ca有效期是10年，使用kubeadm更新证书的时候并不会更新ca证书，建议修改到9年；或者使用编译的kub","date":"2024-08-11","objectID":"/posts/2024-08-11-kubeadm-cert/:1:2","tags":["kubeadm-cert"],"title":"kubeadm-cert","uri":"/posts/2024-08-11-kubeadm-cert/"},{"categories":["DevOps","k8s"],"content":"服务暴露 ","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-metallb-istio/:1:0","tags":["metallb-istio"],"title":"metallb-istio","uri":"/posts/2024-08-11-k8s-metallb-istio/"},{"categories":["DevOps","k8s"],"content":"一、metallb helm repo add metallb https://metallb.github.io/metallb helm install metallb metallb/metallb --version=0.13.7 -n metallb-system --create-namespace helm repo add serialt https://serialt.github.io/helm-charts helm install metallb-config serialt/metallb-config --set \"ipPoolRange=192.168.80.40-192.168.80.49\" -n metallb-system --version 0.0.1 helm 测试： https://artifacthub.io/packages/helm/bitnami/nginx $ helm repo add bitnami https://charts.bitnami.com/bitnami $ helm install my-release bitnami/nginx [root@localhost k3s]# kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 \u003cnone\u003e 443/TCP 4h my-release-nginx LoadBalancer 10.43.100.152 192.168.8.200 80:30840/TCP 63m [root@localhost k3s]# curl 192.168.8.200 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to nginx!\u003c/h1\u003e \u003cp\u003eIf you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u003c/p\u003e \u003cp\u003eFor online documentation and support please refer to \u003ca href=\"http://nginx.org/\"\u003enginx.org\u003c/a\u003e.\u003cbr/\u003e Commercial support is available at \u003ca href=\"http://nginx.com/\"\u003enginx.com\u003c/a\u003e.\u003c/p\u003e \u003cp\u003e\u003cem\u003eThank you for using nginx.\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-metallb-istio/:1:1","tags":["metallb-istio"],"title":"metallb-istio","uri":"/posts/2024-08-11-k8s-metallb-istio/"},{"categories":["DevOps","k8s"],"content":"二、Ingress-nginx controller: name: controller image: ## Keep false as default for now! chroot: false registry: docker.io image: serialt/controller digest: digestChroot: dnsPolicy: ClusterFirstWithHostNet hostNetwork: true ingressClassResource: # -- Name of the ingressClass name: nginx # -- Is this ingressClass enabled or not enabled: true # -- Is this the default ingressClass for the cluster default: true controllerValue: \"k8s.io/ingress-nginx\" publishService: # hostNetwork 模式下设置为false，通过节点IP地址上报ingress status数据 enabled: false # 是否需要处理不带 ingressClass 注解或者 ingressClassName 属性的 Ingress 对象 # 设置为 true 会在控制器启动参数中新增一个 --watch-ingress-without-class 标注 watchIngressWithoutClass: false kind: DaemonSet # tolerations: # kubeadm 安装的集群默认情况下master是有污点，需要容忍这个污点才可以部署 # - key: \"node-role.kubernetes.io/master\" # operator: \"Equal\" # effect: \"NoSchedule\" # nodeSelector: # 固定到master1节点 # kubernetes.io/hostname: master1 service: # HostNetwork 模式不需要创建service enabled: false admissionWebhooks: # 强烈建议开启 admission webhook enabled: true createSecretJob: resources: limits: cpu: 10m memory: 20Mi requests: cpu: 10m memory: 20Mi patchWebhookJob: resources: limits: cpu: 10m memory: 20Mi requests: cpu: 10m memory: 20Mi patch: enabled: true image: registry: docker.io image: serialt/kube-webhook-certgen digest: defaultBackend: # 配置默认后端 enabled: true name: defaultbackend image: registry: docker.io # arm64 架构配置 serialt/defaultbackend-arm64 image: serialt/defaultbackend-amd64 tcp: {} # 8080: \"default/example-tcp-svc:9000\" udp: {} # 53: \"kube-system/kube-dns:53\" helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update helm upgrade --install ingress-nginx -n ingress-nginx --create-namespace ingress-nginx/ingress-nginx --version 4.5.2 -f ingress-nginx.yaml ","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-metallb-istio/:1:2","tags":["metallb-istio"],"title":"metallb-istio","uri":"/posts/2024-08-11-k8s-metallb-istio/"},{"categories":["DevOps","k8s"],"content":"k8s doc ","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-doc/:1:0","tags":["k8s-doc"],"title":"k8s-doc","uri":"/posts/2024-08-11-k8s-doc/"},{"categories":["DevOps","k8s"],"content":"1、节点加入失败 日志信息 ...... [control-plane] Creating static Pod manifest for \"kube-controller-manager\" W0329 00:01:51.364121 19209 manifests.go:214] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" W0329 00:01:51.373807 19209 manifests.go:214] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [check-etcd] Checking that the etcd cluster is healthy error execution phase check-etcd: etcd cluster is not healthy: failed to dial endpoint https://10.8.18.105:2379 with maintenance client: context deadline exceeded To see the stack trace of this error execute with --v=5 or higher 根据关键信息 \"error execution phase check-etcd\" 可知，可能是在执行加入 etcd 时候出现的错误，导致 master 无法加入原先的 kubernetes 集群。 解决办法： 1）获取 Etcd 镜像列表 [root@k8s-master01 ~]# kubectl get pods -n kube-system | grep etcd etcd-k8s-master01 1/1 Running 4 4d20h etcd-k8s-master03 1/1 Running 1 4d20h 2）进入 Etcd 容器并删除节点信息 选择上面两个 etcd 中任意一个 pod，通过 kubectl 工具进入 pod 内部 [root@k8s-master01 ~]# kubectl exec -it -n kube-system etcd-k8s-master01 sh kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead. 进入容器后，按下面步执行 ## 配置环境 # export ETCDCTL_API=3 # alias etcdctl='etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key' ## 查看 etcd 集群成员列表 # etcdctl member list a9b6a1341829d62a, started, k8s-master03, https://172.20.5.13:2380, https://172.20.5.13:2379, false d1c737a26ea4dd70, started, k8s-master01, https://172.20.5.11:2380, https://172.20.5.11:2379, false fe2d4a2a33304913, started, k8s-master02, https://172.20.5.12:2380, https://172.20.5.12:2379, false ## 删除 etcd 集群成员 k8s-master02 # etcdctl member remove fe2d4a2a33304913 Member fe2d4a2a33304913 removed from cluster 36067d1f1ca3f1db ## 退出容器 # exit 3）再次尝试加入集群 通过 kubeadm 命令再次尝试将 k8s-master02 节点加入集群，在执行前首先进入到 k8s-master02 节点服务器，执行 kubeadm 的清除命令： $ kubeadm reset 然后尝试加入 kubernetes 集群： [check-etcd] Checking that the etcd cluster is healthy[kubelet-start] Downloading configuration for the kubelet from the \"kubelet-config-1.18\" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...[etcd] Announced new etcd member joining to the existing etcd cluster[etcd] Creating static Pod manifest for \"etcd\"[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s{\"level\":\"warn\",\"ts\":\"2020-12-22T11:26:23.560+0800\",\"caller\":\"clientv3/retry_interceptor.go:61\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"passthrough:///https://172.20.5.12:2379\",\"attempt\":0,\"error\":\"rpc error: code = DeadlineExceeded desc = context deadline exceeded\"}[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace[mark-control-plane] Marking the node k8s-master02 as control-plane by adding the label \"node-role.kubernetes.io/master=''\"[mark-control-plane] Marking the node k8s-master02 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]This node has joined the cluster and a new control plane instance was created:* Certificate signing request was sent to apiserver and approval was received.* The Kubelet was informed of the new secure connection details.* Control plane (master) label and taint were applied to the new node.* The Kubernetes control plane instances scaled up.* A new etcd member was added to the local/stacked etcd cluster.To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-doc/:1:1","tags":["k8s-doc"],"title":"k8s-doc","uri":"/posts/2024-08-11-k8s-doc/"},{"categories":["DevOps","k8s"],"content":"1、svc命名问题，导致ingress nginx无法映射端口 在ingress-nginx的tcp端口映射过程中，只支持xxx-svc，并且，name中，不能使用下划线 # 错误用法 metadata: name: imau1_conf # 正确用法 metadata: name: imau1-conf ","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-doc/:1:2","tags":["k8s-doc"],"title":"k8s-doc","uri":"/posts/2024-08-11-k8s-doc/"},{"categories":["DevOps","k8s"],"content":"2、deployment创建pod失败 参考链接：https://developer.aliyun.com/article/791261 简介：eployment创建pod失败，通过describe deployment ${DEPLOY_NAME} 没能看到具体原因。最终在“edit deployment ${DEPLOY_NAME}”中看到错误原因。 通过deployment创建pod失败 在k8s集群中，deployment启动后没有成功创建pod，通过“kubectl describe deployment ${DEPLOY_NAME} ”，看到如下日志，只看到“ReplicaFailure True FailedCreate”，但是没有failed的原因。 \u003e kubectl describe deployment ${DEPLOY_NAME} ---------------------------------------------- Conditions: Type Status Reason ---- ------ ------ Progressing True NewReplicaSetCreated Available False MinimumReplicasUnavailable ReplicaFailure True FailedCreate OldReplicaSets: \u003cnone\u003e NewReplicaSet: james-mtfnwnbu4z7v5umk-67cc5d6b98 (0/1 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 40s deployment-controller Scaled up replica set james-mtfnwnbu4z7v5umk-67cc5d6b98 to 1 其实原因藏在edit deployment里面。可以通过\"edit deploy\"来查看。 \u003e kubectl edit deployment ${DEPLOY_NAME} -------------------------------------------------------------- 'pods \"james-mtfnwnbu4z7v5umk-67cc5d6b98\" is forbidden: error looking up service account ns-james/davis: serviceaccount \"davis\" not found' 原因很清楚，这个pod是需要指定的serviceaccount创建，但是集群没有提前创建好sa导致pod启动失败。 创建serviceaccount ns下默认有一个default的sa，其他sa需要自己创建 root@titum:~# kubectl create sa ${SA_NAME} -n ns-james serviceaccount/davis created root@titum:~# kubectl get sa -n test NAME SECRETS AGE default 1 94s davis 1 2s 重新调度服务 ","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-doc/:1:3","tags":["k8s-doc"],"title":"k8s-doc","uri":"/posts/2024-08-11-k8s-doc/"},{"categories":["DevOps","k8s"],"content":"3、debug pod kubectl run sugar --image=serialt/debug --restart=Never ","date":"2024-08-11","objectID":"/posts/2024-08-11-k8s-doc/:1:4","tags":["k8s-doc"],"title":"k8s-doc","uri":"/posts/2024-08-11-k8s-doc/"},{"categories":["DevOps","k8s"],"content":"Ingress-Nginx kubernetes中暴露服务的三种方式： ClusterIP NodePort LoadBalance ​ 这几种方式都是在service的维度提供的，service的作用体现在两个方面，对集群内部，它不断跟踪pod的变化，更新endpoint中对应pod的对象，提供了ip不断变化的pod的服务发现机制，对集群外部，他类似负载均衡器，可以在集群内外部对pod进行访问。但是，单独用service暴露服务的方式，在实际生产环境中不太合适： ClusterIP的方式只能在集群内部访问。 NodePort方式的话，测试环境使用还行，当有几十上百的服务在集群中运行时，NodePort的端口管理是灾难。 LoadBalance方式受限于云平台，且通常在云平台部署ELB还需要额外的费用。 ​ 所幸k8s还提供了一种集群维度暴露服务的方式，也就是ingress。ingress可以简单理解为service的service，他通过独立的ingress对象来制定请求转发的规则，把请求路由到一个或多个service中。这样就把服务与请求规则解耦了，可以从业务维度统一考虑业务的暴露，而不用为每个service单独考虑。 举个例子，现在集群有api、文件存储、前端3个service，可以通过一个ingress对象来实现图中的请求转发： ","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:0","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"ingress 与ingress-controller 要理解ingress，需要区分两个概念，ingress和ingress-controller： ingress对象： 指的是k8s中的一个api对象，一般用yaml配置。作用是定义请求如何转发到service的规则，可以理解为配置模板。 ingress-controller： 具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发。 简单来说，ingress-controller才是负责具体转发的组件，通过各种方式将它暴露在集群入口，外部对集群的请求流量会先到ingress-controller，而ingress对象是用来告诉ingress-controller该如何转发请求，比如哪些域名哪些path要转发到哪些服务等等。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:1","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"ingress-controller ingress-controller并不是k8s自带的组件，实际上ingress-controller只是一个统称，用户可以选择不同的ingress-controller实现，目前，由k8s维护的ingress-controller只有google云的GCE与ingress-nginx两个，其他还有很多第三方维护的ingress-controller，具体可以参考官方文档。但是不管哪一种ingress-controller，实现的机制都大同小异，只是在具体配置上有差异。一般来说，ingress-controller的形式都是一个pod，里面跑着daemon程序和反向代理程序。daemon负责不断监控集群的变化，根据ingress对象生成配置并应用新配置到反向代理，比如nginx-ingress就是动态生成nginx配置，动态更新upstream，并在需要的时候reload程序应用新配置。为了方便，后面的例子都以k8s官方维护的nginx-ingress为例。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:2","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"ingress ingress是一个API对象，和其他对象一样，通过yaml文件来配置。ingress通过http或https暴露集群内部service，给service提供外部URL、负载均衡、SSL/TLS能力以及基于host的方向代理。ingress要依靠ingress-controller来具体实现以上功能。前一小节的图如果用ingress来表示，大概就是如下配置： apiVersion: extensions/v1beta1 kind: Ingress metadata: name: abc-ingress annotations: kubernetes.io/ingress.class: \"nginx\" nginx.ingress.kubernetes.io/use-regex: \"true\" spec: tls: - hosts: - api.abc.com secretName: abc-tls rules: - host: api.abc.com http: paths: - backend: serviceName: apiserver servicePort: 80 - host: www.abc.com http: paths: - path: /image/* backend: serviceName: fileserver servicePort: 80 - host: www.abc.com http: paths: - backend: serviceName: feserver servicePort: 8080 与其他k8s对象一样，ingress配置也包含了apiVersion、kind、metadata、spec等关键字段。有几个关注的在spec字段中，tls用于定义https密钥、证书。rule用于指定请求路由规则。这里值得关注的是metadata.annotations字段。在ingress配置中，annotations很重要。前面有说ingress-controller有很多不同的实现，而不同的ingress-controller就可以根据\"kubernetes.io/ingress.class:“来判断要使用哪些ingress配置，同时，不同的ingress-controller也有对应的annotations配置，用于自定义一些参数。列如上面配置的’nginx.ingress.kubernetes.io/use-regex: “true”’,最终是在生成nginx配置中，会采用location ~来表示正则匹配。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:3","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"ingress的部署 ingress的部署，需要考虑两个方面： ingress-controller是作为pod来运行的，以什么方式部署比较好 ingress解决了把如何请求路由到集群内部，那它自己怎么暴露给外部比较好 下面列举一些目前常见的部署和暴露方式，具体使用哪种方式还是得根据实际需求来考虑决定。 Deployment+LoadBalancer模式的Service 如果要把ingress部署在公有云，那用这种方式比较合适。用Deployment部署ingress-controller，创建一个type为LoadBalancer的service关联这组pod。大部分公有云，都会为LoadBalancer的service自动创建一个负载均衡器，通常还绑定了公网地址。只要把域名解析指向该地址，就实现了集群服务的对外暴露。 Deployment+NodePort模式的Service 同样用deployment模式部署ingress-controller，并创建对应的服务，但是type为NodePort。这样，ingress就会暴露在集群节点ip的特定端口上。由于nodeport暴露的端口是随机端口，一般会在前面再搭建一套负载均衡器来转发请求。该方式一般用于宿主机是相对固定的环境ip地址不变的场景。 NodePort方式暴露ingress虽然简单方便，但是NodePort多了一层NAT，在请求量级很大时可能对性能会有一定影响。 DaemonSet+HostNetwork+nodeSelector 用DaemonSet结合nodeselector来部署ingress-controller到特定的node上，然后使用HostNetwork直接把该pod与宿主机node的网络打通，直接使用宿主机的80/433端口就能访问服务。这时，ingress-controller所在的node机器就很类似传统架构的边缘节点，比如机房入口的nginx服务器。该方式整个请求链路最简单，性能相对NodePort模式更好。缺点是由于直接利用宿主机节点的网络和端口，一个node只能部署一个ingress-controller pod。比较适合大并发的生产环境使用。 因此，在自建的kubernetes生产环境中，建议使用DaemonSet+HostNetwork+nodeSelector方式去部署 ","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:4","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"ingress测试 我们来实际部署和简单测试一下ingress。测试集群中已经部署有2个服务gowebhost与gowebip，每次请求能返回容器hostname与ip。测试搭建一个ingress来实现通过域名的不同path来访问这两个服务： 测试ingress使用k8s社区的ingress-nginx，部署方式用DaemonSet+HostNetwork。 部署ingress-controller 部署ingress-controller pod及相关资源 官方文档中，部署只要简单的执行一个yaml https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml mandatory.yaml这一个yaml中包含了很多资源的创建，包括namespace、ConfigMap、role，ServiceAccount等等所有部署ingress-controller需要的资源，配置太多就不粘出来了，我们重点看下deployment部分： apiVersion: apps/v1 kind: Deployment metadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx spec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: \"10254\" prometheus.io/scrape: \"true\" spec: serviceAccountName: nginx-ingress-serviceaccount containers: - name: nginx-ingress-controller image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.0 args: - /nginx-ingress-controller - --configmap=$(POD_NAMESPACE)/nginx-configuration - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services - --udp-services-configmap=$(POD_NAMESPACE)/udp-services - --publish-service=$(POD_NAMESPACE)/ingress-nginx - --annotations-prefix=nginx.ingress.kubernetes.io securityContext: allowPrivilegeEscalation: true capabilities: drop: - ALL add: - NET_BIND_SERVICE # www-data -\u003e 33 runAsUser: 33 env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace ports: - name: http containerPort: 80 - name: https containerPort: 443 livenessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 10 readinessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 10 可以看到主要使用了“quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.0”这个镜像，指定了一些启动参数。同时开放了80与443两个端口，并在10254端口做了健康检查。 我们需要使用daemonset部署到特定node，需要修改部分配置：先给要部署nginx-ingress的node打上特定标签,这里测试部署在\"node-1\"这个节点。 $ kubectl label node node-1 isIngress=\"true\" 然后修改上面mandatory.yaml的deployment部分配置为： # 修改api版本及kind # apiVersion: apps/v1 # kind: Deployment apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx spec: # 删除Replicas # replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: \"10254\" prometheus.io/scrape: \"true\" spec: serviceAccountName: nginx-ingress-serviceaccount # 选择对应标签的node nodeSelector: isIngress: \"true\" # 使用hostNetwork暴露服务 hostNetwork: true containers: - name: nginx-ingress-controller image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.0 args: - /nginx-ingress-controller - --configmap=$(POD_NAMESPACE)/nginx-configuration - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services - --udp-services-configmap=$(POD_NAMESPACE)/udp-services - --publish-service=$(POD_NAMESPACE)/ingress-nginx - --annotations-prefix=nginx.ingress.kubernetes.io securityContext: allowPrivilegeEscalation: true capabilities: drop: - ALL add: - NET_BIND_SERVICE # www-data -\u003e 33 runAsUser: 33 env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace ports: - name: http containerPort: 80 - name: https containerPort: 443 livenessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThr","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:5","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"安装ingress-nginx 获取镜像 [root@k8s-n1 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v0.44.0 [root@k8s-n1 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v0.44.0 k8s.gcr.io/ingress-nginx/controller:v0.44.0 下载资源清单文件 [root@k8s-m1 ~]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.44.0/deploy/static/provider/baremetal/deploy.yaml ","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:6","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"Ingress controller暴露端口 版本：v0.44.0 参考链接： https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/ https://www.cnblogs.com/fengjian2016/p/8301668.html https://www.cnblogs.com/hongdada/p/11491974.html https://segmentfault.com/a/1190000019908991 https://www.servicemesher.com/blog/kubernetes-ingress-controller-deployment-and-ha/ https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.44.0/deploy/static/provider/baremetal/deploy.yaml 修改deploy文件 修改字段： 1）320行增加了 hostNetwork: true 2）335和336增加了tcp和udp暴露端口的参数 335 - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services 336 - --udp-services-configmap=$(POD_NAMESPACE)/udp-services 318 spec: 319 dnsPolicy: ClusterFirst 320 hostNetwork: true 321 containers: 322 - name: controller 323 image: k8s.gcr.io/ingress-nginx/controller:v0.44.0 324 imagePullPolicy: IfNotPresent 325 lifecycle: 326 preStop: 327 exec: 328 command: 329 - /wait-shutdown 330 args: 331 - /nginx-ingress-controller 332 - --election-id=ingress-controller-leader 333 - --ingress-class=nginx 334 - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller 335 - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services 336 - --udp-services-configmap=$(POD_NAMESPACE)/udp-services 337 - --validating-webhook=:8443 338 - --validating-webhook-certificate=/usr/local/certificates/cert 339 - --validating-webhook-key=/usr/local/certificates/key 增加hostNetwork的原因：官方的ingress controller没有绑定到宿主机 80 端口，也就是说前端 Nginx 没有监听宿主机 80 端口，因而需要收到修改资源清单文件，增加一个 hostNetwork: true 创建Ingress controller [root@k8s-m1 k8s]# kubectl apply -f deploy.yaml # 保证 ingress-nginx-controller正在运行 [root@k8s-m1 k8s]# kubectl get pod --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE default nginx-test1-655ddd64cd-mbcq6 1/1 Running 0 3h15m default nginx-test1-655ddd64cd-nlprg 1/1 Running 0 3h15m default nginx-test1-655ddd64cd-s5sjf 1/1 Running 0 3h15m default nginx-test2-68c89f98c9-2tftz 1/1 Running 0 178m default nginx-test2-68c89f98c9-kx6hv 1/1 Running 0 178m default nginx-test2-68c89f98c9-sj7zn 1/1 Running 0 178m default nginx-test4-6d69f4ff55-dtg2k 1/1 Running 0 170m default nginx-test4-6d69f4ff55-j8h7c 1/1 Running 0 170m default nginx-test4-6d69f4ff55-wn8px 1/1 Running 0 170m default nginx-test5-b4d644bdf-7gxqf 1/1 Running 0 126m default nginx-test5-b4d644bdf-ptshz 1/1 Running 0 132m default nginx-test5-b4d644bdf-q6sj7 1/1 Running 0 132m default nginx-test5-b4d644bdf-zrq66 1/1 Running 0 132m ingress-nginx ingress-nginx-admission-create-g56c4 0/1 Completed 0 15m ingress-nginx ingress-nginx-admission-patch-c62nl 0/1 Completed 1 15m ingress-nginx ingress-nginx-controller-5fcc5f76dd-crz2g 1/1 Running 0 15m kube-system coredns-66bff467f8-fp948 1/1 Running 3 46h kube-system coredns-66bff467f8-vmhwq 1/1 Running 3 46h kube-system etcd-k8s-m1.com 1/1 Running 4 46h kube-system kube-apiserver-k8s-m1.com 1/1 Running 2 74m kube-system kube-controller-manager-k8s-m1.com 1/1 Running 5 46h kube-system kube-flannel-ds-8wpjv 1/1 Running 3 46h kube-system kube-flannel-ds-dhwtr 1/1 Running 4 46h kube-system kube-proxy-dd8l9 1/1 Running 4 46h kube-system kube-proxy-wh9bc 1/1 Running 3 46h kube-system kube-scheduler-k8s-m1.com 1/1 Running 4 46h kube-system tiller-deploy-56b574c76d-qbxhj 1/1 Running 1 18h 建立暴露tcp端口的configmap [root@k8s-m1 k8s]# cat tcp-services-configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: tcp-services namespace: ingress-nginx data: 27004: \"default/nginx-test5:80\" 7004: \"default/nginx-test5:80\" [root@k8s-m1 k8s]# kubectl apply -f tcp-services-configmap.yaml 查看ingress-nginx-controller运行的节点 [root@k8s-m1 k8s]# kubectl get pod --all-namespaces -o wide ... ingress-nginx ingress-nginx-controller-5fcc5f76dd-crz2g 1/1 Running 0 16m 192.168.122.101 k8s-n1.com \u003cnone\u003e \u003cnone\u003e ... 检测端口运行状态 [root@k8s-n1 ~]# ss -anpl | grep 7004 tcp LISTEN 0 511 *:7004 *:* users:((\"nginx\",pid=24817,fd=41),(\"nginx\",pid=24816,fd=41),(\"nginx\",pid=24815,fd=41),(\"nginx\",pid=24813,fd=41),(\"nginx\",pid=19891,fd=41)) tcp LISTEN 0 511 *:27004 *:* users:((\"nginx\",pid=2","date":"2024-08-11","objectID":"/posts/2024-08-11-ingress-nginx/:1:7","tags":["ingress-nginx"],"title":"Ingress-Nginx","uri":"/posts/2024-08-11-ingress-nginx/"},{"categories":["DevOps","k8s"],"content":"容器退出状态码 参考链接：https://blog.hdls.me/16581348863966.html 当容器终止时，容器引擎使用退出码来报告容器终止的原因。如果您是 Kubernetes 用户，容器故障是 pod 异常最常见的原因之一，了解容器退出码可以帮助您在排查时找到 pod 故障的根本原因。 以下是容器使用的最常见的退出码： 退出码 名称 含义 0 正常退出 开发者用来表明容器是正常退出 1 应用错误 容器因应用程序错误或镜像规范中的错误引用而停止 125 容器未能运行 docker run 命令没有执行成功 126 命令调用错误 无法调用镜像中指定的命令 127 找不到文件或目录 找不到镜像中指定的文件或目录 128 退出时使用的参数无效 退出是用无效的退出码触发的（有效代码是 0-255 之间的整数） 134 异常终止 (SIGABRT) 容器使用 abort() 函数自行中止 137 立即终止 (SIGKILL) 容器被操作系统通过 SIGKILL 信号终止 139 分段错误 (SIGSEGV) 容器试图访问未分配给它的内存并被终止 143 优雅终止 (SIGTERM) 容器收到即将终止的警告，然后终止 255 退出状态超出范围 容器退出，返回可接受范围之外的退出代码，表示错误原因未知 ","date":"2024-08-11","objectID":"/posts/2024-08-11-containerd-exit/:1:0","tags":["containerd-exit"],"title":"containerd-exit-code","uri":"/posts/2024-08-11-containerd-exit/"},{"categories":["DevOps","k8s"],"content":"容器生命周期 为了更好地理解容器故障的原因，让我们先讨论容器的生命周期。以 Docker 为例 —— 在任何给定时间，Docker 容器都会处于以下几种状态之一： Created：Docker 容器已创建但尚未启动（这是运行 docker create 后但实际运行容器之前的状态） Up：Docker 容器当前正在运行。这意味着容器管理的操作系统进程正在运行。当您使用命令 docker start 或 docker run 时会发生这种情况，使用 docker start 或 docker run 可能会发生这种情况。 Paused：容器进程正在运行，但 Docker 暂停了容器。通常，当您运行 docker pause 命令时会发生这种情况 Exited：Docker 容器已经被终止，通常是因为容器的进程被杀死了 当一个容器达到 Exited 状态时，Docker 会在日志中报告一个退出码，告诉你容器发生了什么导致它退出。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-containerd-exit/:1:1","tags":["containerd-exit"],"title":"containerd-exit-code","uri":"/posts/2024-08-11-containerd-exit/"},{"categories":["DevOps","k8s"],"content":"了解容器退出码 下面我们将更详细地介绍每个退出码。 退出码 0：正常退出 退出代码 0 由开发人员在任务完成后故意停止容器时触发。从技术上讲，退出代码 0 意味着前台进程未附加到特定容器。 如果容器以退出码 0 终止怎么办？ 检查容器日志，确定哪个库导致容器退出； 查看现有库的代码，并确定它触发退出码 0 的原因，以及它是否正常运行。 退出码 1：应用错误 退出代码 1 表示容器由于以下原因之一停止： 应用程序错误：这可能是容器运行的代码中的简单编程错误，例如“除以零”，也可能是与运行时环境相关的高级错误，例如 Java、Python 等； 无效引用：这意味着镜像规范引用了容器镜像中不存在的文件。 如果容器以退出码 1 终止怎么办？ 检查容器日志以查看是否找不到映像规范中列出的文件之一。如果这是问题所在，请更正镜像以指向正确的路径和文件名。 如果您找不到不正确的文件引用，请检查容器日志以查找应用程序错误，并调试导致错误的库。 退出码 125：容器未能运行 退出码 125 表示该命令用于运行容器。例如 docker run 在 shell 中被调用但没有成功执行。以下是可能发生这种情况的常见原因： 命令中使用了未定义的 flag，例如 docker run --abcd； 镜像中用户的定义命令在本机权限不足； 容器引擎与宿主机操作系统或硬件不兼容。 如果容器以退出码 125 终止怎么办？ 检查运行容器的命令语法是否正确； 检查运行容器的用户，或者镜像中执行命令的上下文，是否有足够的权限在宿主机上创建容器； 如果您的容器引擎提供了运行容器的 option，请尝试它们。例如，在 Docker 中，尝试 docker start 而不是 docker run； 测试您是否能够使用相同的用户名或上下文在主机上运行其他容器。如果不能，重新安装容器引擎，或者解决容器引擎和主机设置之间的底层兼容性问题。 退出码 126：命令调用错误 退出码 126 表示无法调用容器镜像中使用的命令。这通常是用于运行容器的持续集成脚本中缺少依赖项或错误的原因。 如果容器以退出码 126 终止怎么办？ 检查容器日志，查看无法调用哪个命令； 尝试在没有命令的情况下运行容器以确保隔离问题； 对命令进行故障排除以确保您使用正确的语法，并且所有依赖项都可用； 更正容器规范并重试运行容器。 退出码 127：找不到文件或目录 退出码 127 表示容器中指定的命令引用了不存在的文件或目录。 如果容器以退出码 127 终止怎么办？ 与退出码 126 相同，识别失败的命令，并确保容器镜像中引用的文件名或文件路径真实有效。 退出码 128：退出时使用的参数无效 退出码 128 表示容器内的代码触发了退出命令，但没有提供有效的退出码。 Linux exit 命令只允许 0-255 之间的整数，因此如果进程以退出码 3.5 退出，则日志将报告退出代码 128。 如果容器以退出码 128 终止怎么办？ 检查容器日志以确定哪个库导致容器退出。 确定有问题的库在哪里使用了 exit 命令，并更正它以提供有效的退出代码。 退出码 134：异常终止 (SIGABRT) 退出码 134 表示容器自身异常终止，关闭进程并刷新打开的流。此操作是不可逆的，类似 SIGKILL（请参阅下面的退出码 137）。进程可以通过执行以下操作之一来触发 SIGABRT： 调用 libc 库中的 abort() 函数； 调用 assert() 宏，用于调试。如果断言为假，则该过程中止。 如果容器以退出码 134 终止怎么办？ 检查容器日志，查看哪个库触发了 SIGABRT 信号； 检查中止进程是否是预期内的（例如，因为库处于调试模式），如果不是，则对库进行故障排除，并修改以避免中止容器。 退出码 137：立即终止 (SIGKILL) 退出码 137 表示容器已收到来自主机操作系统的 SIGKILL 信号。该信号指示进程立即终止，没有宽限期。可能的原因是： 当通过容器引擎杀死容器时触发，例如使用 docker kill 命令时； 由 Linux 用户向进程发送 kill -9 命令触发； 在尝试终止容器并等待 30 秒的宽限期后由 Kubernetes 触发（默认情况下）； 由主机自动触发，通常是由于内存不足。在这种情况下，docker inspect 命令将指示 OOMKilled 错误。 如果容器以退出码 137 终止怎么办？ 检查主机上的日志，查看在容器终止之前发生了什么，以及在接收到 SIGKILL 之前是否之前收到过 SIGTERM 信号（优雅终止）； 如果之前有 SIGTERM 信号，请检查您的容器进程是否处理 SIGTERM 并能够正常终止； 如果没有 SIGTERM 并且容器报告了 OOMKilled 错误，则排查主机上的内存问题。 退出码 139：分段错误 (SIGSEGV) 退出码 139 表示容器收到了来自操作系统的 SIGSEGV 信号。这表示分段错误 —— 内存违规，由容器试图访问它无权访问的内存位置引起。SIGSEGV 错误有三个常见原因： 编码错误：容器进程没有正确初始化，或者它试图通过指向先前释放的内存的指针来访问内存 二进制文件和库之间不兼容：容器进程运行的二进制文件与共享库不兼容，因此可能会尝试访问不适当的内存地址 硬件不兼容或配置错误：如果您在多个库中看到多个分段错误，则主机上的内存子系统可能存在问题或系统配置问题 如果容器以退出码 139 终止怎么办？ 检查容器进程是否处理 SIGSEGV。在 Linux 和 Windows 上，您都可以处理容器对分段错误的响应。例如，容器可以收集和报告堆栈跟踪； 如果您需要对 SIGSEGV 进行进一步的故障排除，您可能需要将操作系统设置为即使在发生分段错误后也允许程序运行，以便进行调查和调试。然后，尝试故意造成分段错误并调试导致问题的库； 如果您无法复现问题，请检查主机上的内存子系统并排除内存配置故障。 退出码 143：优雅终止 (SIGTERM) 退出码 143 表示容器收到来自操作系统的 SIGTERM 信号，该信号要求容器正常终止，并且容器成功正常终止（否则您将看到退出码 137）。该退出码可能的原因是： 容器引擎停止容器时触发，例如使用 docker stop 或 docker-compose down 命令时； 由 Kubernetes 将 Pod 设置为 Terminating 状态触发，并给容器 30 秒的时间以正常关闭。 如果容器以退出码 143 终止怎么办？ 检查主机日志，查看操作系统发送 SIGTERM 信号的上下文。如果您使用的是 Kubernetes，请检查 kubelet 日志，查看 pod 是否以及何时关闭。 一般来说，退出码 143 不需要故障排除。这意味着容器在主机指示后正确关闭。 退出码 255：退出状态超出范围 当您看到退出码 255 时，意味着容器的 entrypoint 以该状态停止。这意味着容器停止了，但不知道是什么原因。 如果容器以退出码 255 终止怎么办？ 如果容器在虚拟机中运行，首先尝试删除虚拟机上配置的 overlay 网络并重新创建它们。 如果这不能解决问题，请尝试删除并重新创建虚拟机，然后在其上重新运行容器。 如果上述操作失败，则 bash 进入容器并检查有关 entrypoint 进程及其失败原因的日志或其他线索。 ","date":"2024-08-11","objectID":"/posts/2024-08-11-containerd-exit/:1:2","tags":["containerd-exit"],"title":"containerd-exit-code","uri":"/posts/2024-08-11-containerd-exit/"},{"categories":["Database"],"content":"PostgreSQL ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:0:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"一、安装 docker 安装 # docker-compose.yaml version: \"3\" services: postgres10-5432: image: \"postgres:10-bullseye\" container_name: postgres10-5432 shm_size: \"1gb\" restart: always ports: - \"5432:5432\" volumes: - /data/postgresql:/var/lib/postgresql/data - $PWD/init.sql:/docker-entrypoint-initdb.d/init.sql environment: - POSTGRES_PASSWORD=xxxxxxxxxxx # init.sql CREATE USER db_user WITH CREATEDB ENCRYPTED PASSWORD 'xxxxxxxxxx'; alter user db_user superuser; mac ### install # 安装指定版本需要加@,例如 @14 brew install postgresql@14 # 查看安装的包 [localhost@Sugar ~]🐳 brew list ==\u003e Formulae icu4c openssl@1.1 postgresql@10 readline # 查看包安装的位置 [localhost@Sugar ~]🐳 brew list postgresql@14 /opt/homebrew/Cellar/postgresql@14/14.12/bin/clusterdb /opt/homebrew/Cellar/postgresql@14/14.12/bin/createdb /opt/homebrew/Cellar/postgresql@14/14.12/bin/createuser /opt/homebrew/Cellar/postgresql@14/14.12/bin/dropdb /opt/homebrew/Cellar/postgresql@14/14.12/bin/dropuser /opt/homebrew/Cellar/postgresql@14/14.12/bin/ecpg # 配置环境变量 export PG_HOME=\"/opt/homebrew/opt/postgresql@14\" export PATH=$PG_HOME/bin:$PATH # 加载环境变量 source ~/.bash_profile ### 初始化数据库 # 查看版本 [localhost@Sugar ~]🐳 pg_ctl -V pg_ctl (PostgreSQL) 14.12 (Homebrew) # 初始化数据库 initdb --locale=C -E UTF-8 /opt/homebrew/var/postgresql@14 # 启动服务 brew services start postgresql@14 # 停止服务 brew services start postgresql@14 # 非后台启动 /opt/homebrew/opt/postgresql@14/bin/postgres -D /opt/homebrew/var/postgresql@14 ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:1:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"二、配置 ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:2:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"1、修改数据库时区 postgres=# show timezone; TimeZone ---------- Etc/UTC (1 row) sed -i \"s+timezone = 'Etc/UTC'+timezone = 'Asia/Shanghai\" postgresql.conf sed -i \"s+log_timezone = 'Etc/UTC'+log_timezone = 'Asia/Shanghai'\" postgresql.conf postgres=# select pg_reload_conf(); pg_reload_conf ---------------- t (1 row) postgres=# show timezone; TimeZone --------------- Asia/Shanghai (1 row) ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:2:1","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"2、sql使用 查询数据库大小： select datname, pg_size_pretty (pg_database_size(datname)) AS size from pg_database order by size; 查看表大小 --数据库中单个表的大小（不包含索引） select pg_size_pretty(pg_relation_size('表名')); --查出所有表（包含索引）并排序 SELECT table_schema || '.' || table_name AS table_full_name, pg_size_pretty(pg_total_relation_size('\"' || table_schema || '\".\"' || table_name || '\"')) AS size FROM information_schema.tables ORDER BY pg_total_relation_size('\"' || table_schema || '\".\"' || table_name || '\"') DESC limit 20; --查出表大小按大小排序并分离data与index SELECT table_name, pg_size_pretty(table_size) AS table_size, pg_size_pretty(indexes_size) AS indexes_size, pg_size_pretty(total_size) AS total_size FROM ( SELECT table_name, pg_table_size(table_name) AS table_size, pg_indexes_size(table_name) AS indexes_size, pg_total_relation_size(table_name) AS total_size FROM ( SELECT ('\"' || table_schema || '\".\"' || table_name || '\"') AS table_name FROM information_schema.tables ) AS all_tables ORDER BY total_size DESC ) AS pretty_sizes -- 修改用户密码 ALTER USER postgres with password 'hello_world'; -- 修改数据库名 alter database db1 rename to db2; schema 管理 -- 创建schema create schema test; -- 查看schema \\dn -- 修改schema 属主 alter schema test owner to highgo; -- 修改schema名称 alter schema test rename to testa; create schema test authorization highgo;; -- 切换schema set search_path to test_schema 修改数据库名 -- 修改数据库名 alter database src_dbname rename to dst_dbname; -- 将数据库的名称由database2改成database1 UPDATE pg_database SET datname = 'database1' WHERE datname = 'database2'; 慢查询配置 # postgresql.conf # 10s log_min_duration_statement=10000 # 热加载配置 postgres=# select pg_reload_conf(); 1 # 查看配置： postgres=# show log_min_duration_statement; log_min_duration_statement ---------------------------- 10s (1 row) # 也可以针对某个用户或者某数据库进行设置： postgres=# alter database test set log_min_duration_statement=5000; # sql 查询慢语句，超过1s postgres=# select * from pg_stat_activity where state\u003c\u003e'idle' and now()-query_start \u003e interval '1 s' order by query_start; select * from pg_stat_activity where state\u003c\u003e'idle' and now()-query_start \u003e interval '5 s' order by query_start; # 断开数据库连接 select pg_terminate_backend(pid) from (select pid from pg_stat_activity where datname = 'db_name' ) as a; # 创建一个数据库归属其他用户 create database 'db_name' OWNER db_user; # 查看数据库连接数 select count(*) from pg_stat_activity; select * from pg_stat_activity; # 查询数据库最大连接数，默认是100 postgres=\u003e show max_connections; # docker 部署到数据库修改最大连接数 # 进入容器，修改最大连接数 root@ip142:~# docker exec -ti postgres10-5433 bash root@568a83e098a5:/# sed -ri '/max_connections/c max_connections = 2000' /var/lib/postgresql/data/postgresql.conf # sql 加载配置 select pg_reload_conf(); 用户只读权限设置：https://blog.csdn.net/qq_41018743/article/details/105492884 -- 以super user创建只读用户 CREATE USER readonly WITH PASSWORD '*****'; -- 以super user设置用户默认事务只读 alter user readonly set default_transaction_read_only=on; -- 使用数据库的创建所有者去执行以下操作 -- 增加连接数据库权限 GRANT CONNECT ON DATABASE testDB to readonly; -- 切换到 testDB \\c testDB; -- 赋予用户权限访问public模式 GRANT USAGE ON SCHEMA public to readonly; -- 赋予表序列查看权限 GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO readonly; GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly; -- 新增加的表都默认增加权限 alter default privileges in schema public grant select on tables to readonly; -- 新增加的序列都默认增加权限 alter default privileges in schema public grant select on SEQUENCES to readonly; ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:2:2","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"三、从库配置 参考链接：https://help.aliyun.com/document_detail/53096.html ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:3:0","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"1、配置PostgreSQL主节点 1）输入以下SQL语句创建数据库账号replica，并设置密码及登录权限和备份权限。 本示例中将密码设置为replica。 CREATE ROLE replica login replication encrypted password 'replica'; CREATE ROLE replica login replication encrypted password 'rRweb9iojLxhVeWNddddddddddd'; 2）修改配置文件 data/pg_hba.conf 在IPv4 local connections段添加下面两行内容。 host all all \u003c从节点的VPC IPv4网段\u003e md5 #允许VPC网段中md5密码认证连接 host replication replica \u003c从节点的VPC IPv4网段\u003e md5 #允许用户从replication数据库进行数据同步 postgresql.conf listen_addresses = '*' #监听的IP地址 wal_level = hot_standby #启用热备模式 synchronous_commit = on #开启同步复制 max_wal_senders = 32 #同步最大的进程数量 wal_sender_timeout = 60s #流复制主机发送数据的超时时间 max_connections = 100 #最大连接数，从库的max_connections必须要大于主库的 修改完后重启服务 ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:3:1","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"2、从节点上操作 参考链接：https://blog.51cto.com/u_13482808/6875114 pg_basebackup --help 用法： pg_basebackup [选项] ... 控制输出的选项： -D, --pgdata=DIRECTORY 接收基本备份到目录，如果不存在会自动创建 -F, --format=p|t 输出格式（plain,直接拷贝数据文件，tar 配合 -z -Z 进行打包压缩） -r, --max-rate=RATE 传输数据目录的最大传输速率（以 kB/s 为单位，或使用后缀“k”或“M”） -R,--write-recovery-conf 是否输出recovery-conf文件，方便后续使用备份快速搭建出从节点 -T, --tablespace-mapping=OLDDIR=NEWDIR 将 OLDDIR 中的表空间重定位到 NEWDIR --waldir=WALDIR 预写日志目录的位置 -X, --wal-method=none|fetch|stream 包含指定方法所需的 WAL 文件 -z, --gzip 压缩 tar 输出 -Z, --compress=0-9 使用给定的压缩级别压缩 tar 输出 常规选项： -c, --checkpoint=fast|spread 设置快速或扩展检查点 -C, --create-slot 创建复制槽 -l, --label=LABEL 设置备份标签 -n, --no-clean 出错后不清理 -N, --no-sync 不等待更改安全写入磁盘 -P, --progress 显示进度信息 -S, --slot=SLOTNAME 要使用的复制槽 -v, --verbose 输出详细信息 -V, --version 输出版本信息，然后退出 --no-slot 防止创建临时复制槽 --no-verify-checksums 不验证校验和 -?, --help 显示此帮助，然后退出 连接选项： -d, --dbname 数据库名称 -h, --host 数据库服务器主机ip或套接字目录 -p, --port 数据库口号 -s, --status-interval=状态包发送到服务器的间隔时间（以秒为单位） -U, --username 连接用户，要有super权限 -w, --no-password 从不提示输入密码 1）备份数据 使用pg_basebackup基础备份工具指定备份目录。 #保持pg data目录格式 pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv # 自动创建recovery.conf pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv -R # 打包成tar文件 pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv -Ft # 打包成tar.gz文件 pg_basebackup -h 192.168.1.1 -p 5432 -U replica -D /data/test -cfast -Xs -Pv -Ft -z 新建并修改recovery.conf配置文件。 vim /var/lib/pgsql/11/data/recovery.conf ####分别找到以下参数，并将参数修改为以下内容： standby_mode = on #声明此节点为从库 primary_conninfo = 'host=\u003c主节点IP\u003e port=5432 user=replica password=replica' #对应主库的连接信息 recovery_target_timeline = 'latest' #流复制同步到最新的数据 修改postgresql.conf文件 max_connections = 1000 # 最大连接数，从节点需设置比主节点大 hot_standby = on # 开启热备 max_standby_streaming_delay = 30s # 数据流备份的最大延迟时间 wal_receiver_status_interval = 5s # 从节点向主节点报告自身状态的最长间隔时间 hot_standby_feedback = on # 如果有错误的数据复制向主进行反馈 修改数据目录的权限 chown -R postgres.postgres /var/lib/pgsql/11/data 启动服务 ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:3:2","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"3、验证 1）在主节点中运行以下命令，查看sender进程。 ps aux |grep sender 返回结果如下，表示可成功查看到sender进程。 postgres 2916 0.0 0.3 340388 3220 ? Ss 15:38 0:00 postgres: wal sender process replica 192.168.**.**(49640) streaming 0/F01C1A8 2）在从节点中运行以下命令，查看receiver进程。 ps aux |grep receiver 返回结果如下，表示可成功查看到receiver进程。 postgres 23284 0.0 0.3 387100 3444 ? Ss 16:04 0:00 postgres: wal receiver process streaming 0/F01C1A8 3）在主节点中进入PostgreSQL交互终端，输入以下SQL语句，在主库中查看从库状态。 select * from pg_stat_replication; 返回结果如下，表示可成功查看到从库状态。 pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_location | write_locati on | flush_location | replay_location | sync_priority | sync_state ------+----------+---------+------------------+---------------+-----------------+------------- +-------------------------------+--------------+-----------+---------------+------------- ---+----------------+-----------------+---------------+------------ 2916 | 16393 | replica | walreceiver | 192.168.**.** | | 49640 | 2017-05-02 15:38:06.188988+08 | 1836 | streaming | 0/F01C0C8 | 0/F01C0C8 | 0/F01C0C8 | 0/F01C0C8 | 0 | async (1 rows) ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:3:3","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Database"],"content":"4、查看主从延迟 如果主库没有插入或者修改的数据的sql执行，主从同步的延时会逐渐增加 select now() - pg_last_xact_replay_timestamp() AS replication_delay; ","date":"2024-08-11","objectID":"/posts/2023-11-12-postgresql/:3:4","tags":["pg","postgresql","db"],"title":"postgresql","uri":"/posts/2023-11-12-postgresql/"},{"categories":["Go 基础"],"content":"1、变量定义 var name string var isOk bool // 隐式申明 a := 100 str := \"sugar\" // 批量声明 var ( a string b int c bool d float32 ) // 变量的初始化 var name string = \"github\" var age int = 10 var name, age = \"github\", 11 // 类型推导 var name = \"github\" var age = 11 // 常量声明 const pi = 3.1415 const e = 2.7182 const ( pi = 3.1415 e = 2.7182 ) // const同时声明多个常量时，如果省略了值则表示和上面一行的值相同。 const ( n1 = 100 n2 n3 ) // 枚举 const ( n1 = iota //0 n2 //1 n3 //2 n4 //3 ) // 使用_跳过某些值 const ( n1 = iota //0 n2 //1 _ n4 //3 ) ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:1:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"2、流程控制 func ifDemo1() { score := 65 if score \u003e= 90 { fmt.Println(\"A\") } else if score \u003e 75 { fmt.Println(\"B\") } else { fmt.Println(\"C\") } } func forDemo() { for i := 0; i \u003c 10; i++ { fmt.Println(i) } } func forDemo3() { i := 0 for i \u003c 10 { fmt.Println(i) i++ } } // 无限循环 for { 循环体语句 } // switch 语法 func testSwitch3() { n := 7 switch n { case 1, 3, 5, 7, 9: fmt.Println(\"奇数\") case 2, 4, 6, 8: fmt.Println(\"偶数\") default: fmt.Println(n) } } ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:2:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"3、slice a := []int{1, 2, 3, 4, 5} // 从切片中删除元素 func main() { // 从切片中删除元素 a := []int{30, 31, 32, 33, 34, 35, 36, 37} // 要删除索引为2的元素 a = append(a[:2], a[3:]...) fmt.Println(a) //[30 31 33 34 35 36 37] } ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:3:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"4、函数 // 匿名函数 func(x, y int) { fmt.Println(x + y) }(10, 20) ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:4:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"结构体 // 嵌套匿名字段 type Address struct { Province string City string } //User 用户结构体 type User struct { Name string Gender string Address //匿名字段 } ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:4:1","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"5、编译 Mac 下编译 Linux 和 Windows平台 64位 可执行程序： CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build # go 1.16+版本 CGO_ENABLED=0 GOOS=linux GOARCH=arm64 go build CGO_ENABLED=0 GOOS=windows GOARCH=arm64 go build Linux 下编译 Mac 和 Windows 平台64位可执行程序： CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build Windows下编译Mac平台64位可执行程序： SET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 go build 国内镜像设置 export GOPROXY=https://goproxy.cn,direct export GOPATH=/root/go export GO111MODULE=\"on\" export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:5:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"6、私有仓库设置 go env -w GOPRIVATE=\"github.com/private_org/private_repo\" go env -w GOPRIVATE=\"github.com/private_org\" 强制走ssh协议get私有包代码 [url \"ssh://git@github.com/\"] insteadOf = https://github.com/ # 或者 git config --global url.\"ssh://git@github.com/\".insteadOf https://github.com/ # go get/install 默认是走https的，默认go get发起请求使用的是HTTPS，如果自己的私有服务是HTTP的，则需要配置下。 go env -w GOINSECURE=git.local.com ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:6:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"7、makefile PROJECT_NAME= cli GOBASE=$(shell pwd) GOFILES=$(wildcard *.go) BRANCH := $(shell git symbolic-ref HEAD 2\u003e/dev/null | cut -d\"/\" -f 3) # BRANCH := `git fetch --tags \u0026\u0026 git tag | sort -V | tail -1` # BUILD := $(shell git rev-parse --short HEAD) BUILD_DIR := $(GOBASE)/dist VERSION = $(BRANCH) BuildTime := $(shell date -u '+%Y-%m-%d %H:%M:%S %Z') GitHash := $(shell git rev-parse HEAD) GoVersion = $(shell go version | cut -d \" \" -f 3 ) Maintainer := cccc@gmail.com KEY := wzFdVccccccccccccccc PKGFLAGS := \" -s -w -X 'main.APPVersion=$(VERSION)' -X 'main.GoVersion=$(GoVersion)' -X 'main.BuildTime=$(BuildTime)' -X 'main.GitCommit=$(GitHash)' -X 'main.AesKey=$(KEY)' \" APP_NAME = $(PROJECT_NAME) # go-pkg.v0.1.1-linux-amd64 .PHONY: clean clean: @-rm -rf dist/$(PROJECT_NAME)* .PHONY: serve serve: go run . .PHONY: build build: clean @go build -trimpath -ldflags $(PKGFLAGS) -o \"dist/$(APP_NAME)\" @echo \"\\n******************************\" @echo \" build succeed \" @echo \"******************************\\n\" @ls -la dist/$(PROJECT_NAME)* @echo .PHONY: build-linux build-linux: clean @go mod tidy @GOOS=\"linux\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-amd64\" @GOOS=\"linux\" GOARCH=\"arm64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-arm64\" @echo \"\\n******************************\" @echo \" build linux succeed \" @echo \"******************************\\n\" @ls -la dist/$(PROJECT_NAME)* @echo .PHONY: release release: clean @go mod tidy @GOOS=\"windows\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-windows-amd64.exe\" @GOOS=\"linux\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-amd64\" @GOOS=\"linux\" GOARCH=\"arm64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-linux-arm64\" @GOOS=\"darwin\" GOARCH=\"amd64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-darwin-amd64\" @GOOS=\"darwin\" GOARCH=\"arm64\" go build -trimpath -ldflags $(PKGFLAGS) -v -o \"dist/$(APP_NAME)-darwin-arm64\" @echo \"\\n******************************\" @echo \" release succeed \" @echo \"******************************\\n\" @ls -la dist/$(PROJECT_NAME)* @echo ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:7:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"8、go work 参考链接：https://cloud.tencent.com/developer/article/1970405 go 1.18 新增加 workspace的开发模式， ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:8:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"Go work 使用介绍 1）创建一个workspace [root@tc ~]$ mkdir github [root@tc ~]$ cd github 2）创建包 p1 [root@tc p1]$ tree . . ├── go.mod └── p1.go 0 directories, 2 files [root@tc p1]$ cat p1.go package p1 import \"fmt\" func Hello(obj string) { fmt.Printf(\"Hello %s\\n\", obj) } 3）回到github目录，生成go.work [root@tc github]$ go work init ./p1 [root@tc github]$ cat go.work go 1.18 use ( ./p1 ) 4、创建p2，go [root@tc p2]$ tree . . ├── go.mod └── main.go 0 directories, 2 files [root@tc p2]$ cat main.go package main import ( \"github.com/serialt/p1\" ) func main() { p1.Hello(\"world\") } [root@tc p2]$ go run main.go Hello world 注意：以上操作不能build成二进制文件，因为p2 没有被添加go work里，需要把p2 添加进go work才能使用，可以直接编辑github目录下的go.work，也可使用go work use p2 把p2添加到go work里，然后再执行go build [root@tc p2]$ go build [root@tc p2]$ ls go.mod main.go p2 [root@tc p2]$ ./p2 Hello world 注意：因为此时p1 没有提交到远程git仓库，所以在执行go mod tidy 的时候是会去远程仓库下载解决依赖，可以等p1 开发完后 把p1 提交到远程仓库后再对p2 进行go mod tidy。 ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:8:1","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"9、依赖版本控制 go 版本依赖库管理方式主要有三种 ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:9:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"方式1： v1版本go.mod module github.com/serialt/sugar v2版本go.md module github.com/serialt/sugar/v2 使用库时库名仍然是sugar.xxxx 参考地址 https://github.com/serialt/sugar ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:9:1","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"方式2: github.com/go-git/go-git/v5 使用库时候库名是git，使用库名时候会自动去掉go-，直接使用git。 参考地址： https://github.com/serialt/git-mirror/blob/master/service/github.go ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:9:2","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"方式3： gopkg.in/yaml.v3 参考地址： https://github.com/go-yaml/yaml 使用库是时候是yaml.xxxxx，会自动去掉.v3 注意，以上方式一个repo多个版本共存的基础是需要与go.md对应。 ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:9:3","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"10、可选参数 type Option func(*OptionSet) func New(opts ...Option){ //下面设置默认值 options:=OptionSet{ A:\"default-a\", B:\"default-b\", C:\"default-c\", } for _,fun:=range opts{ fun(\u0026options) } } //如果我们需要提供option选项,比方说设置A func WithA(a string) Option{ return func(opt *OptionSet){ opt.A=a } } // 使用的时候 a=New(WithA(\"abc\")) ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:10:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"11、进程退出 // 进程持续运行 c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGTERM, syscall.SIGINT) s := \u003c-c slog.Info(\"Aborting...\", \"signal\", s) os.Exit(2) ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:11:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["Go 基础"],"content":"12、升级Go版本 官方推荐方法示例 [sugar@Sugar ~]🐳 go install golang.org/dl/go1.22.6@latest go: downloading golang.org/dl v0.0.0-20240806160245-f9b8f0a29fb9 [sugar@Sugar ~]🐳 go1.22.6 download Downloaded 0.0% ( 16384 / 67301095 bytes) ... Downloaded 1.8% ( 1179648 / 67301095 bytes) ... Downloaded 7.8% ( 5242880 / 67301095 bytes) ... Downloaded 12.9% ( 8667136 / 67301095 bytes) ... Downloaded 18.3% (12337136 / 67301095 bytes) ... Downloaded 23.9% (16056304 / 67301095 bytes) ... Downloaded 27.7% (18661344 / 67301095 bytes) ... Downloaded 31.7% (21348352 / 67301095 bytes) ... Downloaded 36.9% (24821744 / 67301095 bytes) ... Downloaded 44.3% (29818880 / 67301095 bytes) ... Downloaded 50.1% (33750880 / 67301095 bytes) ... Downloaded 55.6% (37437424 / 67301095 bytes) ... Downloaded 61.2% (41205680 / 67301095 bytes) ... Downloaded 65.9% (44367568 / 67301095 bytes) ... Downloaded 71.8% (48348944 / 67301095 bytes) ... Downloaded 77.4% (52084672 / 67301095 bytes) ... Downloaded 82.5% (55492320 / 67301095 bytes) ... Downloaded 88.9% (59834080 / 67301095 bytes) ... Downloaded 95.1% (63995424 / 67301095 bytes) ... Downloaded 100.0% (67301095 / 67301095 bytes) Unpacking /home/sugar/sdk/go1.22.6/go1.22.6.darwin-arm64.tar.gz ... Success. You may now run 'go1.22.6' [sugar@Sugar ~]🐳 官方推荐方法会把安装包下载到 ~/sdk，GOPATH 设置为 ~/sdk/go，做软链接即可方便使用 [sugar@Sugar sdk]🐳 ll total 0 lrwxr-xr-x@ 1 sugar staff 27 Jul 24 09:43 go -\u003e /home/sugar/sdk/go1.21.1 drwxr-xr-x 20 sugar staff 640 Jul 22 20:57 go1.21.1 drwxr-xr-x@ 20 sugar staff 640 Aug 11 13:07 go1.22.6 gvm shell 简单版，放入bash_profile中 gvm(){ MY_GO_VERSION=$1 cd \"${HOME}\"/sdk [[ -d \"${HOME}\"/sdk/go${MY_GO_VERSION} ]] if [[ $? -ne 0 ]]; then go install golang.org/dl/go${MY_GO_VERSION}@latest \u0026\u003e/dev/null go${MY_GO_VERSION} download \u0026\u003e/dev/null fi ln -snf \"${HOME}\"/sdk/go${MY_GO_VERSION} \"${HOME}\"/sdk/go } [sugar@Sugar sdk]🐳 gvm 1.22.3 [sugar@Sugar sdk]🐳 go version go version go1.22.3 darwin/arm64 [sugar@Sugar sdk]🐳 gvm 1.22.6 [sugar@Sugar sdk]🐳 go version go version go1.22.6 darwin/arm64 [sugar@Sugar sdk]🐳 ","date":"2024-08-11","objectID":"/posts/2023-11-11-go-basic/:12:0","tags":["Go","basic"],"title":"Go basic","uri":"/posts/2023-11-11-go-basic/"},{"categories":["DevOps"],"content":"Terraform 常用 provider http tls helm kubernetes vault null local dns random ad cloud： aws aliyun tencent cloud huaweicloud 第三方库： shell，执行命令，获取返回值：shell gitlab harbor nexus：datadrivers serialt postgresql mysql rabbitmq proxmox libvirt grafana docker keycloak restapi kafka virtualbox kubectl kubectl elasticsearch argocd acme artifactory kong hyperv minio elasticstack ovirt eksctl jenkins jira sonarqube kibana zabbix mssql ssh ldap filesystem ","date":"2024-07-21","objectID":"/posts/2024-07-21-tf-lib/:1:0","tags":["terraform-lib","tf-lib"],"title":"TF-lib","uri":"/posts/2024-07-21-tf-lib/"},{"categories":["DevOps"],"content":"Dev terraform provider 基于新框架tpf开发 开发示例： https://github.com/hashicorp/terraform-provider-scaffolding-framework https://github.com/serialt/terraform-provider-demo 参考示例： https://github.com/hashicorp/terraform-provider-hashicups ","date":"2024-07-20","objectID":"/posts/2024-06-30-dev-terraform-provider/:0:0","tags":["terraform-dev","tf-dev"],"title":"TF-dev","uri":"/posts/2024-06-30-dev-terraform-provider/"},{"categories":["DevOps"],"content":"一、调试 provider 1、debug terraform # makefile default: install build: go build -v ./... install: go install -v ./... vscode 调试 terraform provider 1）vscode launch cat .vscode/launch.json { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Debug Terraform Provider\", \"type\": \"go\", \"request\": \"launch\", \"mode\": \"debug\", // this assumes your workspace is the root of the repo \"program\": \"${workspaceFolder}\", \"env\": {}, \"args\": [ \"-debug\", ] } ] } run debug 2）ready terraform code 3）run terraform TF_REATTACH_PROVIDERS='{\"registry.terraform.io/serialt/message\":{\"Protocol\":\"grpc\",\"ProtocolVersion\":5,\"Pid\":50972,\"Test\":true,\"Addr\":{\"Network\":\"unix\",\"String\":\"/var/folders/vm/zlhwbdyj2031f088_w9q3f8w0000gn/T/plugin3117659601\"}}}' terraform apply dev模式覆盖 provider cat ~/.terraformrc provider_installation { dev_overrides { \"serialt/message\" = \"/Users/serialt/go/bin\" } direct {} } # TF_LOG=TRACE terraform apply terraform apply ","date":"2024-07-20","objectID":"/posts/2024-06-30-dev-terraform-provider/:0:1","tags":["terraform-dev","tf-dev"],"title":"TF-dev","uri":"/posts/2024-06-30-dev-terraform-provider/"},{"categories":["DevOps"],"content":"二、TPF框架 目前官方在维护的开发 provider sdk 有两个版本： terraform-plugin-sdk/v2 terraform-plugin-framework 如果要支持老版本的terraform，建议是使用 terraform-plugin-sdk/v2 开发，否则还是建议使用terraform-plugin-framework开发。 TPF开发示例：https://github.com/hashicorp/terraform-provider-hashicups 解释说明 插件开发主要涉及的文件分为三种类型： provider datasource resource provider 文件中主要是一些 配置文件的读取和对第三分 api 客户端的初始化，主要由五个方法组成： Metadata：provider的名字 Schema：provider的配置参数 Configure：读取配置provider中的值和环境变量的值，初始化调用第三方api的client Resources：定义的resource资源 DataSources：定义的datasource资源 datasource 通过第三方api的client调用，查询已存在的资源信息： Metadata：定义datasource的名字 Schema：datasource配置的参数 Read：client调用api，读取具体的数据，生成state Configure：从provider中获取传入的调用api的client resource 通过第三方api的client调用，对资源进行增删改查和导入资源对象 Metadata：定义resource的名字 Schema：resource配置的参数 Configure：从provider中获取传入的调用api的client Create：创建资源 Read：查询资源 Update：更新资源 Delete：删除资源，用于在销毁时删除资源 ImportState：导入资源，用terraform管理存量的资源对象。 main.go package main import ( \"context\" \"flag\" \"log\" \"github.com/hashicorp/terraform-plugin-framework/providerserver\" \"github.com/serialt/terraform-provider-harbor/internal/provider\" ) //go:generate go run github.com/hashicorp/terraform-plugin-docs/cmd/tfplugindocs func main() { var debug bool flag.BoolVar(\u0026debug, \"debug\", false, \"set to true to run the provider with support for debuggers like delve\") flag.Parse() err := providerserver.Serve(context.Background(), provider.New, providerserver.ServeOpts{ Address: \"registry.terraform.io/serialt/harbor\", Debug: debug, }) if err != nil { log.Fatal(err) } } provider.go // Copyright (c) HashiCorp, Inc. // SPDX-License-Identifier: MPL-2.0 package provider import ( \"context\" \"os\" \"strings\" \"github.com/goharbor/go-client/pkg/harbor\" \"github.com/hashicorp/terraform-plugin-framework/datasource\" \"github.com/hashicorp/terraform-plugin-framework/path\" \"github.com/hashicorp/terraform-plugin-framework/provider\" \"github.com/hashicorp/terraform-plugin-framework/provider/schema\" \"github.com/hashicorp/terraform-plugin-framework/resource\" \"github.com/hashicorp/terraform-plugin-framework/types\" \"github.com/hashicorp/terraform-plugin-log/tflog\" ) var _ provider.Provider = \u0026HarborProvider{} func New() provider.Provider { return \u0026HarborProvider{} } type HarborProvider struct { } type HarborProviderModel struct { URL types.String `tfsdk:\"url\"` Username types.String `tfsdk:\"username\"` Password types.String `tfsdk:\"password\"` BearerToken types.String `tfsdk:\"bearer_token\"` Insecure types.Bool `tfsdk:\"insecure\"` } func (p *HarborProvider) Metadata(ctx context.Context, req provider.MetadataRequest, resp *provider.MetadataResponse) { resp.TypeName = \"harbor\" } func (p *HarborProvider) Schema(_ context.Context, _ provider.SchemaRequest, resp *provider.SchemaResponse) { resp.Schema = schema.Schema{ Description: \"Harbor config\", Attributes: map[string]schema.Attribute{ \"url\": schema.StringAttribute{ Description: \"Harbor url.\", Optional: true, }, \"username\": schema.StringAttribute{ Description: \"Harbor username.\", Optional: true, }, \"password\": schema.StringAttribute{ Description: \"Harbor.\", Optional: true, Sensitive: true, }, \"bearer_token\": schema.StringAttribute{ Description: \"Harbor.\", Optional: true, }, \"insecure\": schema.BoolAttribute{ Description: \"Harbor.\", Optional: true, }, }, } } func (p *HarborProvider) Configure(ctx context.Context, req provider.ConfigureRequest, resp *provider.ConfigureResponse) { tflog.Info(ctx, \"Configuring harbor client\") // Retrieve provider data from configuration var config HarborProviderModel diags := req.Config.Get(ctx, \u0026config) resp.Diagnostics.Append(diags...) if resp.Diagnostics.HasError() { return } if config.URL.IsUnknown() { resp.Diagnostics.AddAttributeError( path.Root(\"url\"), \"Unknown url\", \"\", ) } if resp.Diagnostics.HasError() { return } url := os.Getenv(\"HARBOR_URL\") username := os.Getenv(\"HARBOR_USERNAME\") password := os.Getenv(\"HARBOR_PASSWORD\") insecure := false if strings.HasSuffix(url, \"/\") { url = strings.Trim(url, \"/\") } if !config.URL.IsNull() { url = config.URL.ValueString() } if !config.Use","date":"2024-07-20","objectID":"/posts/2024-06-30-dev-terraform-provider/:0:2","tags":["terraform-dev","tf-dev"],"title":"TF-dev","uri":"/posts/2024-06-30-dev-terraform-provider/"},{"categories":["Dev"],"content":"Protobuf gRPC推荐使用proto3，这里只介绍常用语法，按照官方文档的结构翻译，英文水平有限，复杂的部分果断放弃，更多高级使用姿势请参考官方文档 ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:0","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"Message定义 一个message类型定义描述了一个请求或响应的消息格式，可以包含多种类型字段。 例如定义一个搜索请求的消息格式SearchRequest，每个请求包含查询字符串、页码、每页数目。每个字段声明以分号结尾。 syntax = \"proto3\"; message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; } ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:1","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"分配Tags 消息的定义中，每个字段都有一个唯一的数值标签。这些标签用于标识该字段在消息中的二进制格式，使用中的类型不应该随意改动。其中，[1-15]内的标识在编码时占用一个字节，包含标识和字段类型。[16-2047]之间的标识符占用2个字节。建议为频繁出现的消息元素分配[1-15]间的标签。如果考虑到以后可能或扩展频繁元素，可以预留一些。 最小的标识符可以从1开始，最大到229 - 1，或536,870,911。不可以使用[19000－19999]之间的标识符， Protobuf协议实现中预留了这些标识符。在.proto文件中使用这些预留标识号，编译时会报错。 ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:2","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"字段规则 单数形态：一个message内同名单数形态的字段不能超过一个 repeated：前置repeated关键词，声明该字段为数组类型 proto3不支持proto2中的required和optional关键字 ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:3","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"添加注释 向.proto文件中添加注释，支持C/C++风格双斜线//单行注释。 syntax = \"proto3\"; // 协议版本声明 // SearchRequest 搜索请求消息 message SearchRequest { string query = 1; // 查询字符串 int32 page_number = 2; // 页码 int32 result_per_page = 3; // 每页条数 } ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:4","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"保留字段名与Tag 可以使用reserved关键字指定保留字段名和标签。 message Foo { reserved 2, 15, 9 to 11; reserved \"foo\", \"bar\"; } ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:5","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"基本数据类型 .proto C++ Java Python Go Ruby C# double double double float float64 Float double float float float float float32 Float float int32 int32 int int int32 Fixnum or Bignum int int64 int64 long ing/long[3] int64 Bignum long uint32 uint32 int[1] int/long[3] uint32 Fixnum or Bignum uint uint64 uint64 long[1] int/long[3] uint64 Bignum ulong sint32 int32 int intj int32 Fixnum or Bignum int sint64 int64 long int/long[3] int64 Bignum long fixed32 uint32 int[1] int uint32 Fixnum or Bignum uint fixed64 uint64 long[1] int/long[3] uint64 Bignum ulong sfixed32 int32 int int int32 Fixnum or Bignum int sfixed64 int64 long int/long[3] int64 Bignum long bool bool boolean boolean bool TrueClass/FalseClass bool string string String str/unicode[4] string String(UTF-8) string bytes string ByteString str []byte String(ASCII-8BIT) ByteString ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:6","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"Message嵌套 message SearchResponse { message Result { string url = 1; string title = 2; repeated string snippets = 3; } repeated Result results = 1; } message Outer { // Level 0 message MiddleAA { // Level 1 message Inner { // Level 2 int64 ival = 1; bool booly = 2; } } message MiddleBB { // Level 1 message Inner { // Level 2 int32 ival = 1; bool booly = 2; } } } ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:7","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"Protobuf —\u003e Go proto中的message对应go中的struct，全部使用驼峰命名规则。嵌套定义的message，enum转换为go之后，名称变为Parent_Child结构。 // Test 测试 message Test { int32 age = 1; int64 count = 2; double money = 3; float score = 4; string name = 5; bool fat = 6; bytes char = 7; // Status 枚举状态 enum Status { OK = 0; FAIL = 1; } Status status = 8; // Child 子结构 message Child { string sex = 1; } Child child = 9; map\u003cstring, string\u003e dict = 10; } // Status 枚举状态 type Test_Status int32 const ( Test_OK Test_Status = 0 Test_FAIL Test_Status = 1 ) // Test 测试 type Test struct { Age int32 `protobuf:\"varint,1,opt,name=age\" json:\"age,omitempty\"` Count int64 `protobuf:\"varint,2,opt,name=count\" json:\"count,omitempty\"` Money float64 `protobuf:\"fixed64,3,opt,name=money\" json:\"money,omitempty\"` Score float32 `protobuf:\"fixed32,4,opt,name=score\" json:\"score,omitempty\"` Name string `protobuf:\"bytes,5,opt,name=name\" json:\"name,omitempty\"` Fat bool `protobuf:\"varint,6,opt,name=fat\" json:\"fat,omitempty\"` Char []byte `protobuf:\"bytes,7,opt,name=char,proto3\" json:\"char,omitempty\"` Status Test_Status `protobuf:\"varint,8,opt,name=status,enum=test.Test_Status\" json:\"status,omitempty\"` Child *Test_Child `protobuf:\"bytes,9,opt,name=child\" json:\"child,omitempty\"` Dict map[string]string `protobuf:\"bytes,10,rep,name=dict\" json:\"dict,omitempty\" protobuf_key:\"bytes,1,opt,name=key\" protobuf_val:\"bytes,2,opt,name=value\"` } // Child 子结构 type Test_Child struct { Sex string `protobuf:\"bytes,1,opt,name=sex\" json:\"sex,omitempty\"` } ","date":"2024-07-20","objectID":"/posts/2024-07-07-protobuf/:1:8","tags":["Protobuf"],"title":"Protobuf","uri":"/posts/2024-07-07-protobuf/"},{"categories":["Dev"],"content":"Kratos 目录结构 . ├── Dockerfile ├── LICENSE ├── Makefile ├── README.md ├── api // 下面维护了微服务使用的proto文件以及根据它们所生成的go文件 │ └── helloworld │ └── v1 │ ├── error_reason.pb.go │ ├── error_reason.proto │ ├── error_reason.swagger.json │ ├── greeter.pb.go │ ├── greeter.proto │ ├── greeter.swagger.json │ ├── greeter_grpc.pb.go │ └── greeter_http.pb.go ├── cmd // 整个项目启动的入口文件 │ └── server │ ├── main.go │ ├── wire.go // 我们使用wire来维护依赖注入 │ └── wire_gen.go ├── configs // 这里通常维护一些本地调试用的样例配置文件 │ └── config.yaml ├── generate.go ├── go.mod ├── go.sum ├── internal // 该服务所有不对外暴露的代码，通常的业务逻辑都在这下面，使用internal避免错误引用 │ ├── biz // 业务逻辑的组装层，类似 DDD 的 domain 层，data 类似 DDD 的 repo，而 repo 接口在这里定义，使用依赖倒置的原则。 │ │ ├── README.md │ │ ├── biz.go │ │ └── greeter.go │ ├── conf // 内部使用的config的结构定义，使用proto格式生成 │ │ ├── conf.pb.go │ │ └── conf.proto │ ├── data // 业务数据访问，包含 cache、db 等封装，实现了 biz 的 repo 接口。我们可能会把 data 与 dao 混淆在一起，data 偏重业务的含义，它所要做的是将领域对象重新拿出来，我们去掉了 DDD 的 infra层。 │ │ ├── README.md │ │ ├── data.go │ │ └── greeter.go │ ├── server // http和grpc实例的创建和配置 │ │ ├── grpc.go │ │ ├── http.go │ │ └── server.go │ └── service // 实现了 api 定义的服务层，类似 DDD 的 application 层，处理 DTO 到 biz 领域实体的转换(DTO -\u003e DO)，同时协同各类 biz 交互，但是不应处理复杂逻辑 │ ├── README.md │ ├── greeter.go │ └── service.go └── third_party // api 依赖的第三方proto ├── README.md ├── google │ └── api │ ├── annotations.proto │ ├── http.proto │ └── httpbody.proto └── validate ├── README.md └── validate.proto ","date":"2024-07-20","objectID":"/posts/2024-07-07-kratos/:0:1","tags":["kratos"],"title":"kratos","uri":"/posts/2024-07-07-kratos/"},{"categories":["Dev"],"content":"kratos 命令 # 创建项目 kratos new helloworld # 生成所有proto源码、wire等等 go generate ./... ### 运行项目 kratos run # 或者 go run cmd/hello/ # makefile make init # 生成配置文件 make config # 生成 api proto make api make generate ","date":"2024-07-20","objectID":"/posts/2024-07-07-kratos/:0:2","tags":["kratos"],"title":"kratos","uri":"/posts/2024-07-07-kratos/"},{"categories":["DevOps"],"content":"CVE OpenSSH CVE-2024-6387 该漏洞是 OpenSSH 服务器 （sshd） 中的信号处理程序争用条件，允许在基于 glibc 的 Linux 系统上以 root 身份执行未经身份验证的远程代码执行 （RCE）;这带来了重大的安全风险。此争用条件会影响 sshd 的默认配置。 https://avd.aliyun.com/detail?id=AVD-2024-6387 缓解措施 # /etc/ssh/sshd_config LoginGraceTime 0 systemctl restart sshd 8.5p1 \u003c= OpenSSH \u003c 9.8p1 ubuntu 22.04 ubuntu 24.04 debian 12 bookworm ubuntu：https://ubuntu.com/security/CVE-2024-6387 jammy 22.04 fixed version: 1:8.9p1-3ubuntu0.10 noble 24.04 fixed version: 1:9.6p1-3ubuntu13.3 apt --only-upgrade install openssh-client openssh-server debian：https://security-tracker.debian.org/tracker/CVE-2024-6387 bookworm （12） fixed version: 1:9.2p1-2+deb12u3 almalinux: https://almalinux.org/blog/2024-07-01-almalinux-9-cve-2024-6387/ 9 fixed version: openssh-8.7p1-38.el9.alma.2 dnf --refresh upgrade openssh RHEL: https://access.redhat.com/security/cve/CVE-2024-6387 使用缓解措施 Rocky: https://forums.rockylinux.org/t/openssh-vulnerability-cve-2024-6387/14883/2 yum install rocky-release-security yum update openssh openssh-server ","date":"2024-07-01","objectID":"/posts/2024-07-01-cve/:1:0","tags":["openssh","cve"],"title":"openssh-cve","uri":"/posts/2024-07-01-cve/"},{"categories":["DevOps"],"content":"WinSW 服务管理 ​ ​ 有时候需要将bat、exe等文件作为Windows的服务，可以使用bat、nssm等工具将此类文件设置为Windows服务，但使用winsw可以更简单。 使用winsw 注册成系统的服务后默认开启开机自启 ","date":"2024-06-30","objectID":"/posts/2024-06-27.winsw/:1:0","tags":["winsw"],"title":"winsw","uri":"/posts/2024-06-27.winsw/"},{"categories":["DevOps"],"content":"1、下载地址 https://github.com/winsw/winsw/releases ","date":"2024-06-30","objectID":"/posts/2024-06-27.winsw/:1:1","tags":["winsw"],"title":"winsw","uri":"/posts/2024-06-27.winsw/"},{"categories":["DevOps"],"content":"2、配置示例 以下已frp作为配置示例介绍 下载下来的WinSW-x64.exe文件复制到frpc的安装目录并重命名（方便写命令，如service.exe） 在frpc的安装目录中新建一个名称为service的xml文件（必须要和WinSW-x64.exe重命名的service名称一致），目的是WinSW会去读取和自己相同名称的xml文件中的配置进行相关设置，xml文件中的具体配置如下所示： \u003cservice\u003e \u003c!-- 服务ID名称（唯一） --\u003e \u003cid\u003eFrpc-Server\u003c/id\u003e \u003c!-- 服务显示名称 --\u003e \u003cname\u003eFrpc-Server\u003c/name\u003e \u003c!-- 服务的描述信息 --\u003e \u003cdescription\u003eFrpc客户端\u003c/description\u003e \u003c!-- 可设置环境变量 --\u003e \u003cenv name=\"HOME\" value=\"%BASE%\"/\u003e \u003c!-- 要执行的可执行文件 --\u003e \u003cexecutable\u003e%BASE%\\frpc.exe\u003c/executable\u003e \u003c!-- 可执行文件传递的参数 --\u003e \u003c!-- \u003carguments\u003eserver \"%BASE%\\data\"\u003c/arguments\u003e --\u003e \u003clog mode=\"roll-by-size-time\"\u003e \u003c!-- 单位为KB，默认值10MB --\u003e \u003csizeThreshold\u003e102400\u003c/sizeThreshold\u003e \u003cpattern\u003eyyyyMMdd\u003c/pattern\u003e \u003cautoRollAtTime\u003e00:00:00\u003c/autoRollAtTime\u003e \u003c/log\u003e \u003c/service\u003e \u003cservice\u003e \u003c!-- 该服务的唯一标识 --\u003e \u003cid\u003efrp\u003c/id\u003e \u003c!-- 该服务的名称 --\u003e \u003cname\u003efrpc.exe\u003c/name\u003e \u003c!-- 该服务的描述 --\u003e \u003cdescription\u003efrpc客户端 这个服务用 frpc 实现内网穿透\u003c/description\u003e \u003c!-- 设置环境变量 --\u003e \u003cenv name=\"HOME\" value=\"%BASE%\"/\u003e \u003c!-- 要运行的程序路径 --\u003e \u003cexecutable\u003eD:\\frp\\frpc.exe\u003c/executable\u003e \u003c!-- 携带的参数 --\u003e \u003carguments\u003e-c frpc.ini\u003c/arguments\u003e \u003c!-- 第一次启动失败 60秒重启 --\u003e \u003confailure action=\"restart\" delay=\"60 sec\"/\u003e \u003c!-- 第二次启动失败 120秒后重启 --\u003e \u003confailure action=\"restart\" delay=\"120 sec\"/\u003e \u003c!-- 日志模式 --\u003e \u003clogmode\u003eappend\u003c/logmode\u003e \u003c!-- 指定日志文件目录(相对于executable配置的路径) --\u003e \u003clogpath\u003elogs\u003c/logpath\u003e \u003c/service\u003e yaml格式 service.yaml id: jenkins name: Jenkins description: This service runs Jenkins continuous integration system. env: - name: JENKINS_HOME value: \"%BASE%\" executable: java # arguments: arg1 arg2 arg3 arguments: \u003e -Xrs -Xmx256m -jar \"%BASE%\\jenkins.war\" --httpPort=8080 log: mode: roll-by-size logpath: '%BASE%\\log' # 100M sizeThreshold: 102400 keepFiles: 5 depend: - Eventlog - W32Time onFailure: - action: restart delay: 10 sec workingdirectory: '%BASE%\\workdir' 目录: D:\\frp Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 2022/11/10 15:36 logs -a---- 2022/11/10 9:54 11677696 frpc.exe -a---- 2022/11/10 15:20 451 frpc.ini -a---- 2022/11/10 15:34 17462251 service.exe -a---- 2022/11/10 15:34 831 service.xml ","date":"2024-06-30","objectID":"/posts/2024-06-27.winsw/:1:2","tags":["winsw"],"title":"winsw","uri":"/posts/2024-06-27.winsw/"},{"categories":["DevOps"],"content":"3、服务管理 打开CMD或Powershell 进行安装服务 # 安装服务 PS D:\\frp\u003e .\\service.exe install 2022-11-10 15:45:11,601 INFO - Installing service 'Frpc-Server (Frpc-Server)'... 2022-11-10 15:45:11,654 INFO - Service 'Frpc-Server (Frpc-Server)' was installed successfully. # 启动服务 PS D:\\frp\u003e .\\service.exe start 2022-11-10 15:45:20,538 INFO - Starting service 'Frpc-Server (Frpc-Server)'... 2022-11-10 15:45:21,705 INFO - Service 'Frpc-Server (Frpc-Server)' started successfully. # 查看服务状态 PS D:\\frp\u003e .\\service.exe status Started # 重启服务 PS D:\\frp\u003e .\\service.exe restart 2022-11-10 15:45:41,415 INFO - Stopping service 'Frpc-Server (Frpc-Server)'... 2022-11-10 15:45:41,703 INFO - Starting service 'Frpc-Server (Frpc-Server)'... 2022-11-10 15:45:43,255 INFO - Service 'Frpc-Server (Frpc-Server)' restarted successfully. # 停止服务 PS D:\\frp\u003e .\\service.exe stop 2022-11-10 15:45:51,015 INFO - Stopping service 'Frpc-Server (Frpc-Server)'... 2022-11-10 15:45:51,033 INFO - Service 'Frpc-Server (Frpc-Server)' stopped successfully. # 卸载服务 PS D:\\frp\u003e .\\service.exe uninstall 2022-11-10 15:45:57,827 INFO - Uninstalling service 'Frpc-Server (Frpc-Server)'... 2022-11-10 15:45:57,839 INFO - Service 'Frpc-Server (Frpc-Server)' was uninstalled successfully. # 查看help命令 PS D:\\frp\u003e .\\service.exe --help A wrapper binary that can be used to host executables as Windows services Usage: winsw \u003ccommand\u003e [\u003cargs\u003e] Missing arguments triggers the service mode Available commands: install install the service to Windows Service Controller uninstall uninstall the service start start the service (must be installed before) stop stop the service stopwait stop the service and wait until it's actually stopped restart restart the service restart! self-restart (can be called from child processes) status check the current status of the service test check if the service can be started and then stopped testwait starts the service and waits until a key is pressed then stops the service version print the version info help print the help info (aliases: -h,--help,-?,/?) Extra options: /redirect redirect the wrapper's STDOUT and STDERR to the specified file WinSW 2.11.0.0 More info: GitHub - winsw/winsw: A wrapper executable that can run any executable as a Windows service, in a pe Bug tracker: https://github.com/winsw/winsw/issues ","date":"2024-06-30","objectID":"/posts/2024-06-27.winsw/:1:3","tags":["winsw"],"title":"winsw","uri":"/posts/2024-06-27.winsw/"},{"categories":["DevOps"],"content":"4、windows 服务中检查 Win + R 打开运行 –\u003e 输入 services.msc ","date":"2024-06-30","objectID":"/posts/2024-06-27.winsw/:1:4","tags":["winsw"],"title":"winsw","uri":"/posts/2024-06-27.winsw/"},{"categories":["DevOps"],"content":"5、WinSW命令 命令 描述 install 安装服务 uninstall 卸载服务 start 启动服务 stop 停止服务 restart 重启服务 status 检查服务状态 refresh 刷新服务属性而不是重新安装 customize – ","date":"2024-06-30","objectID":"/posts/2024-06-27.winsw/:1:5","tags":["winsw"],"title":"winsw","uri":"/posts/2024-06-27.winsw/"},{"categories":["DevOps"],"content":"Java ","date":"2024-06-30","objectID":"/posts/2024-06-27-java/:1:0","tags":["java"],"title":"Java","uri":"/posts/2024-06-27-java/"},{"categories":["DevOps"],"content":"1、Hello world java 的包名需要和目录一致，类名需要与文件名一致 [sugar@Sugar java]🐳 tree . . └── Hello └── HelloWorld.java 1 directory, 1 file HelloWorld.java package Hello; public class HelloWorld { public static void main(String[] args) { System.out.println(\"hello,world\"); } } [sugar@Sugar Hello]🐳 java HelloWorld.java hello,world [sugar@Sugar Hello]🐳 2、变量定义 int y; int x = 1; String s = \"hello\"; final double PI = 3.14; // PI是一个常量 double r = 5.0; double area = PI * r * r; var sb = new StringBuilder(); int a, b, c; // 声明三个int型整数：a、 b、c int d = 3, e = 4, f = 5; // 声明三个整数并赋予初值 byte z = 22; // 声明并初始化 z String s = \"runoob\"; // 声明并初始化字符串 s double pi = 3.14159; // 声明了双精度浮点型变量 pi char x = 'x'; // 声明变量 x 的值是字符 'x'。 public class RunoobTest { // 成员变量 private int instanceVar; // 静态变量 private static int staticVar; public void method(int paramVar) { // 局部变量 int localVar = 10; // 使用变量 instanceVar = localVar; staticVar = paramVar; System.out.println(\"成员变量: \" + instanceVar); System.out.println(\"静态变量: \" + staticVar); System.out.println(\"参数变量: \" + paramVar); System.out.println(\"局部变量: \" + localVar); } public static void main(String[] args) { RunoobTest v = new RunoobTest(); v.method(20); } } 3、流程控制 出入输出 import java.util.Scanner; public class Main { public static void main(String[] args) { Scanner scanner = new Scanner(System.in); // 创建Scanner对象 System.out.print(\"Input your name: \"); // 打印提示 String name = scanner.nextLine(); // 读取一行输入并获取字符串 System.out.print(\"Input your age: \"); // 打印提示 int age = scanner.nextInt(); // 读取一行输入并获取整数 System.out.printf(\"Hi, %s, you are %d\\n\", name, age); // 格式化输出 } } ","date":"2024-06-30","objectID":"/posts/2024-06-27-java/:1:1","tags":["java"],"title":"Java","uri":"/posts/2024-06-27-java/"},{"categories":["DevOps"],"content":"Maven 配置settings 默认读取位置 ~/.m2 curl -O https://repo1.maven.org/maven2/archetype-catalog.xml \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e \u003clocalRepository\u003e/home/sugar/.m2/repository\u003c/localRepository\u003e \u003cmirrors\u003e \u003cmirror\u003e \u003cid\u003ealimaven\u003c/id\u003e \u003cmirrorOf\u003ecentral\u003c/mirrorOf\u003e \u003cname\u003ealiyun maven\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/nexus/content/groups/public/\u003c/url\u003e \u003c/mirror\u003e \u003c/mirrors\u003e \u003cprofiles\u003e \u003cprofile\u003e \u003cid\u003earchetype-catalog\u003c/id\u003e \u003cactivation\u003e \u003cactiveByDefault\u003etrue\u003c/activeByDefault\u003e \u003c/activation\u003e \u003cproperties\u003e \u003carchetypeCatalog\u003efile:///Users/sugar/.m2/archetype-catalog.xml\u003c/archetypeCatalog\u003e \u003c/properties\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003c/settings\u003e 手动下载依赖 mvn -B -f pom.xml -s /usr/share/maven/ref/settings.xml dependency:resolve 打包 mvn package mvn demo https://github.com/serialt/maven-java-demo ","date":"2024-06-30","objectID":"/posts/2024-06-27-java/:1:2","tags":["java"],"title":"Java","uri":"/posts/2024-06-27-java/"},{"categories":["web server"],"content":"Caddy Caddy 是一个 Go 编写的 Web 服务器，类似于 Nginx，Caddy 提供了更加强大的功能，随着 v2 版本发布 Caddy 已经可以作为中小型站点 Web 服务器的另一个选择；相较于 Nginx 来说使用 Caddy 的优势如下: 自动的 HTTPS 证书申请(ACME HTTP/DNS 挑战) 自动证书续期以及 OCSP stapling 等 更高的安全性包括但不限于 TLS 配置以及内存安全等 友好且强大的配置文件支持 支持 API 动态调整配置(有木有人可以搞个 Dashboard？) 支持 HTTP3(QUIC) 支持动态后端，例如连接 Consul、作为 k8s ingress 等 后端多种负载策略以及健康检测等 本身 Go 编写，高度模块化的系统方便扩展(CoreDNS 基于 Caddy1 开发) ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:0:0","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"一、Caddyfile ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:0","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"1、简单使用 在当前目录下新建Caddyfile文件 localhost { respond \"Hello, world!\" } localhost:2016 { respond \"Goodbye, world!\" } 服务管理 # 启动服务 caddy start # 重启服务，重启服务有两种方式 caddy reload curl localhost:2019/load \\ -X POST \\ -H \"Content-Type: text/caddyfile\" \\ --data-binary @Caddyfile # 停止服务 caddy stop ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:1","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"2、静态文件管理 显示文件列表 localhost file_server browse 文件夹作为站点根目录： localhost root * /home/me/mysite file_server ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:2","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"3、反向代理 localhost reverse_proxy 127.0.0.1:9000 ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:3","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"4、启用压缩算法 localhost encode zstd gzip file_server browse ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:4","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"5、多个站点 :8080 { respond \"I am 8080\" } :8081 { respond \"I am 8081\" } 多端口 :8080, :8081 { ... } ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:5","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"6、匹配器 对某一个api使用反向代理 localhost file_server reverse_proxy /api/* 127.0.0.1:9005 # 现在反向代理只会处理所有以/api/开始的请求。 使用环境变量 export SITE_ADDRESS=localhost:9055 {$SITE_ADDRESS} file_server root * /var/www # matcher token: * root /index.html /var/www # matcher token: /index.html root @post /var/www # matcher token: @post 占位符 简写 替换 {dir} {http.request.uri.path.dir} {file} {http.request.uri.path.file} {header.*} {http.request.header.*} {host} {http.request.host} {labels.*} {http.request.host.labels.*} {hostport} {http.request.hostport} {port} {http.request.port} {method} {http.request.method} {path} {http.request.uri.path} {path.*} {http.request.uri.path.*} {query} {http.request.uri.query} {query.*} {http.request.uri.query.*} {re.*.*} {http.regexp.*.*} {remote} {http.request.remote} {remote_host} {http.request.remote.host} {remote_port} {http.request.remote.port} {scheme} {http.request.scheme} {uri} {http.request.uri} {tls_cipher} {http.request.tls.cipher_suite} {tls_version} {http.request.tls.version} {tls_client_fingerprint} {http.request.tls.client.fingerprint} {tls_client_issuer} {http.request.tls.client.issuer} {tls_client_serial} {http.request.tls.client.serial} {tls_client_subject} {http.request.tls.client.subject} {tls_client_certificate_pem} {http.request.tls.client.certificate_pem} {tls_client_certificate_der_base64} {http.request.tls.client.certificate_der_base64} {upstream_hostport} {http.reverse_proxy.upstream.hostport} 在Caddyfile中，紧跟在指令后面的匹配器标记可以限制该指令的范围。匹配器标记可以是以下形式之一： \\* 匹配所有请求（通配符；默认）。 /path 以正斜杠开头以匹配请求路径。 @name 指定一个命名匹配器。 匹配器标记通常是可选的。如果省略匹配器标记，则它与通配符匹配器（*）相同。 命名匹配器 要匹配路径以外的任何内容，请定义一个命名匹配器并使用@name引用它： @postfoo { method POST path /foo/* } reverse_proxy @postfoo localhost:9000 @websockets { header Connection *Upgrade* header Upgrade websocket } reverse_proxy @websockets localhost:6001 file file { root \u003cpaths\u003e try_files \u003cfiles...\u003e try_policy first_exist|smallest_size|largest_size|most_recent_modified split_path \u003cdelims...\u003e } 通过文件进行匹配。 root定义在其中查找文件的目录。默认是当前工作目录，或者root变量 ({http.vars.root})对应的位置 (可以通过root指令设置)。 try_files检查其列表中与重试策略(try_policy)匹配的文件。如果try_policy是first_exist，那么列表中的最后一项可能是一个以=(比如=404)开头的数字，作为后备，将触发以这个数字作为错误码的回调; 该错误也可以使用handle_errors捕获和处理错误。 try_policy 指定如何选择文件。默认为 first_exist . first_exist检查文件是否存在。选择存在的第一个文件。 smallest_size选择大小最小的文件。 largest_size选择最大的文件。 most_recent_modified选择最近修改的文件。 split_path将导致路径在每个要尝试的文件路径中找到的列表中的第一个分隔符处拆分。对于每个拆分值，拆分的左侧（包括分隔符本身）将是尝试的文件路径。例如，/remote.php/dav/使用.php作为分隔符，将尝试文件/remote.php。每个分隔符必须出现在 URI 路径组件的末尾，才能用作拆分分隔符。这是一个小众设置，主要用于为 PHP 站点提供服务。 ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:6","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"7、地址 有效地址： localhost example.com :443 http://example.com localhost:8080 127.0.0.1 [::1]:2015 example.com/foo/* *.example.com http:// 注意：如果你的站点地址包含主机名或 IP 地址，则会启用自动HTTPS。然而，这种行为纯粹是隐含的，因此它永远不会覆盖任何显式配置。例如，如果站点的地址是http://example.com，则不会激活自动HTTPS，因为该方案是明确的http://。 如果找不到文件，则回退到发出404错误。 file {path}.html {path} =404 header header \u003cfield\u003e [\u003cvalue\u003e] 通过请求头字段进行匹配。 \u003cfield\u003e 是要检查的 HTTP 标头字段的名称。 如果以!为前缀，则该字段必须不存在才能匹配 (省略value参数). \u003cvalue\u003e 是字段必须匹配的值。 如果前缀是*，则执行快速后缀匹配。 如果后缀为*，则执行快速前缀匹配。 如果用*括起来，它将执行快速子字符串匹配。 否则，它是快速精确匹配。 统一集合的不同header字段是“和”的关系。每个字段的多个值之间是“或”的关系。 示例： 匹配请求Connection标头字段包含Upgrade的请求： header Connection *Upgrade* 匹配Foo标头字段包含bar或者baz的请求： @foo { header Foo bar header Foo baz } 匹配根本没有Foo标头字段的请求： @not_foo { header !Foo } ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:7","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"8、片段 可以定义称为片段的特殊块，方法是给它们一个用括号括起来的名称： (redirect) { @http { protocol http } redir @http https://{host}{uri} } 然后你可以在任何你需要的地方重复使用它： import redirect 例如： (snippet) { respond \"Yahaha! You found {args.0}!\" } a.example.com { import snippet \"Example A\" } b.example.com { import snippet \"Example B\" } ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:8","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"9、全局参数 { # General Options debug http_port \u003cport\u003e https_port \u003cport\u003e order \u003cdir1\u003e first|last|[before|after \u003cdir2\u003e] storage \u003cmodule_name\u003e { \u003coptions...\u003e } storage_clean_interval \u003cduration\u003e admin off|\u003caddr\u003e { origins \u003corigins...\u003e enforce_origin } log [name] { output \u003cwriter_module\u003e ... format \u003cencoder_module\u003e ... level \u003clevel\u003e include \u003cnamespaces...\u003e exclude \u003cnamespaces...\u003e } grace_period \u003cduration\u003e # TLS Options auto_https off|disable_redirects|ignore_loaded_certs email \u003cyours\u003e default_sni \u003cname\u003e local_certs skip_install_trust acme_ca \u003cdirectory_url\u003e acme_ca_root \u003cpem_file\u003e acme_eab \u003ckey_id\u003e \u003cmac_key\u003e acme_dns \u003cprovider\u003e ... on_demand_tls { ask \u003cendpoint\u003e interval \u003cduration\u003e burst \u003cn\u003e } key_type ed25519|p256|p384|rsa2048|rsa4096 cert_issuer \u003cname\u003e ... ocsp_stapling off preferred_chains [smallest] { root_common_name \u003ccommon_names...\u003e any_common_name \u003ccommon_names...\u003e } # Server Options servers [\u003clistener_address\u003e] { listener_wrappers { \u003clistener_wrappers...\u003e } timeouts { read_body \u003cduration\u003e read_header \u003cduration\u003e write \u003cduration\u003e idle \u003cduration\u003e } max_header_size \u003csize\u003e protocol { allow_h2c experimental_http3 strict_sni_host } } } ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:1:9","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"二、使用示例 1、静态文件服务器 example.com { root * /var/www file_server } 像往常一样，第一行是站点地址。该root指令指定站点根目录的路径（*匹配所有请求的方法，以便与路径匹配器消除歧义）；如果站点不是当前工作目录，则更改站点的路径。最后，我们启用静态文件服务器。 2、反向代理服务器 代理所有请求 example.com { reverse_proxy localhost:5000 } 只代理以/api/开头的请求，并为其他所有内容提供静态文件： example.com {} root * /var/www reverse_proxy /api/* localhost:5000 file_server } 3、php 在运行PHP FastCGI服务的情况下，类似这样的内容适用于大多数现代PHP应用程序 example.com root * /var/www php_fastcgi /blog/* localhost:9000 file_server 请对应地调整站点根目录和路径匹配器；此示例假定PHP仅位于/blog/子目录中——所有其他请求将作为静态文件提供。 该php_fastcgi指令实际上只是几个配置的快捷方式。 4、重定向到www.子域名 example.com { redir https://www.example.com{uri} } www.example.com { } www.example.com { redir https://example.com{uri} } example.com { } 5、通配符证书 *.example.com { tls { dns \u003cprovider_name\u003e [\u003cparams...\u003e] } @foo host foo.example.com handle @foo { respond \"Foo!\" } @bar host bar.example.com handle @bar { respond \"Bar!\" } # Fallback for otherwise unhandled domains handle { abort } } 6、web example.com { # 网站的域名信息 tls example.com.pem example.com.key # 证书和密钥的 PEM 格式的文件路径 encode zstd gzip # 启用压缩 root * ./ # 域名映射根路径 file_server # 启动文件服务 } example2.com { # 网站的域名信息 tls example2.com.pem example2.com.key # 证书和密钥的 PEM 格式的文件路径 reverse_proxy localhost:9000 # 反向代理 } ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:2:0","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["web server"],"content":"三、部署 docker-compose.yaml version: \"3.7\" services: caddy: image: caddy:\u003cversion\u003e restart: unless-stopped ports: - \"80:80\" - \"443:443\" volumes: - $PWD/Caddyfile:/etc/caddy/Caddyfile - $PWD/site:/srv - caddy_data:/data - caddy_config:/config volumes: caddy_data: caddy_config: caddyfile 示例 { http_port 9080 # 设置http类型 servers { protocols h1 h2 } # 关闭admin api admin off # auto_https off|disable_redirects|ignore_loaded_certs } (TLSC) { tls /etc/nginx/cert_files/local.com.crt /etc/nginx/cert_files/local.com.key } (LOGC) { log { format transform `{request\u003eremote_ip} - {user_id} [{ts}] \"{request\u003emethod} {request\u003euri} {request\u003eproto}\" {status} {size} \"{request\u003eheaders\u003eReferer\u003e[0]}\" \"{request\u003eheaders\u003eUser-Agent\u003e[0]}\"` { time_format \"iso8601\" } # {args.0} 声明引用传入的第一个参数 output file {args.0} { roll_size 100mb roll_keep 7 roll_local_time roll_keep_for 30d } } } https://terraform-registry.local.com:9090 { encode zstd gzip root * /data/terraform-registry try_files {path} /index.html file_server browse import TLSC import LOGC /var/log/nginx/tf-registry.log } (PROXY_HEADER) { header_up Host {host} header_up REMOTE-HOST {remote} header_up X-Real-IP {remote} header_up X-Forwarded-For {remote} } git.local.com:9090, local.com:9090 { encode zstd gzip import TLSC import LOGC /var/log/nginx/local.com.log reverse_proxy http://localhost4:5000 { import PROXY_HEADER } } ","date":"2024-06-26","objectID":"/posts/2024-06-26-caddy/:2:1","tags":["caddy","go-web","web-server"],"title":"caddy","uri":"/posts/2024-06-26-caddy/"},{"categories":["DevOps"],"content":"Nexus 参考： https://juejin.cn/post/6844904016762109959 https://cloud.tencent.com/developer/article/1764866 官网：https://help.sonatype.com/repomanager3/ ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:0:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"介绍 生产环境中，一般不会允许所有服务器都能访问公网，理想的情况是有几台服务器作为访问代理，同时作为缓存服务器。当服务器中有所需包时通过内网获取，如无则通过公网获取同时在本地保存。常用搭建私有yum源的方法是createrepo生成本地仓库，其它服务器通过http访问仓库。这种方法的弊端是如果当前仓库中没有所需软件包会导致安装失败，不会去其它源获取数据。Nexus是一个强大的仓库管理器，它极大地简化了自己内部仓库的维护和外部仓库的访问。 Nexus是一个强大的Maven仓库管理器，它极大地简化了本地内部仓库的维护和外部仓库的访问。 如果使用了公共的Maven仓库服务器，可以从Maven中央仓库下载所需要的构件（Artifact），但这通常不是一个好的做法。 正常做法是在本地架设一个Maven仓库服务器，即利用Nexus可以只在一个地方就能够完全控制访问和部署在你所维护仓库中的每个Artifact。 Nexus在代理远程仓库的同时维护本地仓库，以降低中央仓库的负荷,节省外网带宽和时间，Nexus就可以满足这样的需要。 Nexus是一套“开箱即用”的系统不需要数据库，它使用文件系统加Lucene来组织数据。 Nexus使用ExtJS来开发界面，利用Restlet来提供完整的REST APIs，通过m2eclipse与Eclipse集成使用。 Nexus支持WebDAV与LDAP安全身份认证。 Nexus还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。 为什么要构建Nexus私服？ 如果没有Nexus私服，我们所需的所有构件都需要通过maven的中央仓库和第三方的Maven仓库下载到本地，而一个团队中的所有人都重复的从maven仓库下载构件无疑加大了仓库的负载和浪费了外网带宽，如果网速慢的话，还会影响项目的进程。很多情况下项目的开发都是在内网进行的，连接不到maven仓库怎么办呢？开发的公共构件怎么让其它项目使用？这个时候我们不得不为自己的团队搭建属于自己的maven私服，这样既节省了网络带宽也会加速项目搭建的进程，当然前提条件就是你的私服中拥有项目所需的所有构件。 同时Nexus支持仓库有：Apt、Bower、CocoaPods、Conda、Docker、Git LFS、Go、Maven、Npm、NuGet、PyPi、Raw、RubyGems、Yum ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:1:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"二、安装 二进制安装 # 下载地址 https://help.sonatype.com/repomanager3/download # 解压 tar zxf nexus-3.23.0-03-unix.tar.gz mv nexus-3.23.0-03 sonatype-work /data echo 'NEXUS_HOME=\"/data/nexus-3.23.0-03\"' \u003e\u003e ~/.bashrc echo 'run_as_user=\"root\"' \u003e\u003e /data/nexus-3.23.0-03/bin/nexus.rc # 配置systemd服务 $ vim /etc/systemd/system/nexus.service [Unit] Description=nexus service After=network.target [Service] Type=forking LimitNOFILE=65536 ExecStart=/data/nexus-3.23.0-03/bin/nexus start ExecStop=/data/nexus-3.23.0-03/bin/nexus stop User=root Restart=on-abort [Install] WantedBy=multi-user.target # 启动服务 systemctl start nexus # 此处启动后，请耐心等待，netstat -tunlp 查看端口8081监听后继续 # 查看admin用户的密码 cat /data/sonatype-work/nexus3/admin.password 基于docker安装nexus mkdir -p /data/nexus/data \u0026\u0026 chown -R 200 /data/nexus/data docker run -d -p 8081:8081 --name nexus -v /data/nexus/data:/nexus-data sonatype/nexus3 docker-compose安装 mkdir -p /data/nexus/data \u0026\u0026 chown -R 200 /data/nexus/data # docker-compose cat \u003edocker-compose.yaml \u003c\u003cEOF version: \"3\" services: nexus3: image: sonatype/nexus3 container_name: nexus3 restart: always privileged: true environment: - TZ=Asia/Shanghai ports: - '8081:8081' volumes: - /data/nexus/data:/nexus-data EOF 查看密码 管理员：admin 密码：cat /data/nexus/data/admin.passwor nginx代理设置 upstream nexus-server{ server 127.0.0.1:8081; } #server { # listen 80; # server_name mirrors.cccc.io; # location / { # return 301 https://xx.xx; # } # location ~ /.well-known { # root /tmp; # } #} server { listen 80; server_name nexus.local.com; client_max_body_size 1024m; client_body_buffer_size 128k; location / { proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_max_temp_file_size 0; proxy_pass http://nexus-server; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_temp_file_write_size 64k; # Required for new HTTP-based CLI #proxy_http_version 1.1; #proxy_request_buffering off; #proxy_buffering off; # Required for HTTP-based CLI to work over SSL } #ssl_certificate cert/xx.pem; #ssl_certificate_key cert/xx.key; } server { listen 80; server_name mirrors.local.com ; client_max_body_size 1024m; client_body_buffer_size 128k; charset utf-8; location / { proxy_pass http://nexus.local.com/repository/; proxy_set_header Host nexus.local.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } access_log /var/log/nginx/mirrors.log; error_log /var/log/nginx/mirrors-error.log; } docker nginx # compose.yaml version: \"3\" services: nexus3: image: sonatype/nexus3:3.67.1-java11 container_name: nexus3 restart: always privileged: true environment: - TZ=Asia/Shanghai ports: - '8081:8081' volumes: - /data/nexus:/nexus-data - /data/nexus-databackup:/nexus3-databackup nginx: container_name: nginx image: nginx restart: always privileged: true volumes: - \"/etc/localtime:/etc/localtime:ro\" - \"${PWD}/ssl:/etc/nginx/cert_files\" - \"${PWD}/config:/etc/nginx/conf.d\" - \"/data/nginx/log:/var/log/nginx\" network_mode: \"host\" # config/nexus.conf upstream nexus-local { server localhost:8081; } server { listen 80; server_name nexus.local.com ; charset utf-8; client_max_body_size 100m; client_body_buffer_size 12800k; location / { proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://nexus-local; } access_log /var/log/nginx/nexus.log; error_log /var/log/nginx/nexus-error.log; } server { listen 443 ssl; server_name nexus.local.com ; charset utf-8; client_max_body_size 100m; client_body_buffer_size 12800k; location / { proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://nexus-local; } ssl_certificate /etc/","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:2:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"二、nexus仓库 Nexus 仓库按照类型（Type）区分，主要分为以下 3 个类型： 代理仓库（proxy）：主要用于代理缓存访问外网上其他公开的仓库，将每次从代理仓库拉取的制品缓存到nexus文件系统中，下次再拉取相同版本制品时就不需再次从外网拉取，起到代理访问缓存的功能。 宿主仓库（hosted）：类型的仓库主要用于存放各个项目组产出的、用于共享、不能放到公网上、私有的制品。有两种版本策略，一种是Snapshots版本策略类型的，对于相同版本制品的上传，nexus会自动追加时间戳加以区分；一种是Release版本策略类型的，对于相同的制品，要明确版本，不能存放相同版本。可以理解为snapshots仓库存放一些内容变更频繁的制品，这样不管上传还是使用时不用频繁变更版本号就能拉取到最新版本。而release仓库存放一些内容稳定变更少的制品，使用时指定好版本就行，无需经常变动。 仓库组（group）：主要用于组合其他仓库，统一对外使用方式。可设置组仓库组合其他仓库的顺序。例如组合顺序为先拉取maven格式aliyun代理仓库中的制品，如果其中没有想要的制品，再去拉取maven格式Central代理仓库中的制品。如果还没有，就去maven格式hosted类型仓库中拉取，直到遍历完所有的组合仓库。同时，拉取使用时不需要配置那么多的仓库地址，只需要配置group仓库地址就行。 group仓库可以包含proxy和hosted类型的仓库，并对外提供统一的服务 ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"1、yum 1）创建 proxy 类型格式为 yum 的 repo 2）创建group类型的 repo，在 member repository 中增加proxy 类型的repo 3）yum 源配置 group的地址 ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:1","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"2、npm 1）创建 proxy 类型的 repo ​ 创建proxy类型的repo，可以创建多个 # 官方地址 https://registry.npmjs.org/ # 阿里云地址 https://registry.npmmirror.com # 腾讯 http://mirrors.cloud.tencent.com/npm/ # 华为 https://repo.huaweicloud.com/repository/npm/ # 南京大学 https://repo.nju.edu.cn/repository/npm/ 2）创建group类型的 repo，在 member repository 中增加proxy 类型的repo 3） npm 配置 group的地址 # 配置 npm默认源 npm config set registry http://nexus.local.com/repository/npm # 或者直接使用npm命令 npm install -y --registry=http://nexus.local.com/repository/npm/ ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:2","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"3、pypi 1）创建 proxy 类型的 repo ​ 创建proxy类型的repo，可以创建多个 # 阿里云 https://mirrors.aliyun.com/pypi # tuna https://pypi.tuna.tsinghua.edu.cn # huaweicloud https://mirrors.huaweicloud.com/repository/pypi/ # nju https://mirror.nju.edu.cn/pypi/web/ # sjtu https://mirror.sjtu.edu.cn/pypi/web 2）创建group类型的 repo，在 member repository 中增加proxy 类型的repo 3）配置 group的地址 vim .pip/pip.conf [global] index-url = http://nexus.local.com/repository/pypi/simple trusted-host = nexus.local.com timeout = 120 # 不配置pip.conf直接使用 pip3 install redis -i http://mirrors.local.com/pypi/simple --truste d-host mirrors.local.com ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:3","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"4、maven 1）创建 proxy 类型的 repo ​ 创建proxy类型的repo，可以创建多个 # maven-central https://maven.aliyun.com/repository/central # maven-confluent https://packages.confluent.io/maven/ 2）创建group类型的 repo，在 member repository 中增加proxy 类型的repo 3）配置 group的地址 settings.xml \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e \u003clocalRepository\u003e/usr/share/maven/ref/repository\u003c/localRepository\u003e \u003cmirrors\u003e \u003cmirror\u003e \u003cid\u003enexus\u003c/id\u003e \u003cname\u003enexus\u003c/name\u003e \u003curl\u003ehttp://nexus.local.com/repository/maven/\u003c/url\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003c/mirror\u003e \u003c/mirrors\u003e \u003c/settings\u003e ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:4","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"5、apt 以debian仓库作为示例 1）创建 proxy 类型格式为 apt 的 repo，APT Settings —\u003e Distribution 配置为 * ，Proxy —\u003e Remote storage 配置为debian apt 源的地址 2）配置 proxy 的地址 # 示例: https://mirrors.ustc.edu.cn/debian/ https://nexus.local.com/repositories/debian/ # 修改命令 sed -i 's+\\w*.debian.org+nexus.local.com/repository+g' /etc/apt/sources.list ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:5","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"6、alpine 目前 nexus 官方暂时不支持配置 alpine proxy，但有社区开发了插件支持 alpine apk 代理 1）安装插件：到 https://central.sonatype.com/ 中搜索对应插件，并下载对应的 jar 包。下载后把 jar 包复制到nexus目录中的deploy目录里 https://sonatype-nexus-community.github.io/nexus-development-guides/plugin-install.html # for docker wget https://repo1.maven.org/maven2/org/sonatype/nexus/plugins/nexus-repository-apk/0.0.26/nexus-repository-apk-0.0.26.jar docker cp nexus-repository-apk-0.0.26.jar nexus3:/opt/sonatype/nexus/deploy 2）创建 proxy 类型格式为 apk 的 repo， 3）配置 apk 源 sed -i 's+https://dl-cdn.alpinelinux.org+http://nexus.local.com/repository+g' /etc/apk/repositories 4）自定义镜像 wget https://repo1.maven.org/maven2/org/sonatype/nexus/plugins/nexus-repository-apk/0.0.26/nexus-repository-apk-0.0.26.jar # dockerfile FROM sonatype/nexus3:3.68.1-java11 ADD nexus-repository-apk-0.0.26.jar /opt/sonatype/nexus/deploy/ ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:6","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"7、docker 1）在nexus3 后台页面中创建一个repository，类型选择docker(proxy) 2）填入相关参数 Name：repo 名 Allow anonymous docker pull：允许未登录的用户拉取镜像，看自己情况勾选 Proxy-Remote storage：代理的docker 镜像源。可以填入docker 官方镜像源https://registry-1.docker.io Proxy-Docker Index：选择 Use Docker Hub Storage-Blob store：本地镜像存储的地址 HTTP-Authentication：选填，Username和Password 填入docker 官网的用户名和密码，填的话每天可以下载更多镜像（大概是这么个效果，但不填影响不大） 点击Create repository创建 3）创建一个host repo host repo 作为本地创建的镜像的存放地址，如果不想将镜像存到docker hub，就可以上传到这边。 a、在nexus3 后台页面中创建一个repository，类型选择docker(host) b、填入相关参数 Name：repo 名 HTTP：用于推送到本repo 的http 端口，8082 Allow anonymous docker pull：允许未登录的用户拉取镜像，看自己情况勾选 Storage-Blob store：本地镜像存储的地址 Host-Deployment policy：上传镜像的规则 Allow redeploy：允许重传，一般选择这个即可 Disable redeploy：禁止重传 点击Create repository创建 4）创建一个group repo group repo 可以将多个其他repo 聚合起来，拉取镜像时直接选择group repo 即可。 在nexus3 后台页面中创建一个repository，类型选择docker(group) 填入相关参数 Name：repo 名 HTTP：用于下载镜像的http 端口，8083 Allow anonymous docker pull：允许未登录的用户拉取镜像，看自己情况勾选 Storage-Blob store：本地镜像存储的地址 Group-Menber repositiories：当前repo 包括的其他repo，将之前创建host repo 和proxy repo 加入右边的Members列表中（host repo 可以优先于proxy repo，以优先拉取本地上传的镜像） 点击Create repository创建 5）启用Docker Bearer Token Realm以允许docker 登录nexus ​ a、进入nexus 后台管理页面，Security - Realms ​ b、将Docker Bearer Token Realm添加到右边Active栏内 ​ c、保存 6）nginx配置文件 # web管理控制台 upstream nexus_web { server 10.0.0.5:8081; } # docker-group聚合仓库 upstream nexus_docker_get { server 10.0.0.5:8083; } # docker-hosted本地仓库 upstream nexus_docker_put { server 10.0.0.5:8082; } # HTTP 自动跳转 HTTPS server { listen 80; # 设置docker代理使用的域名，你可以将 docker-registry.hellogitlab.com 替换成你的域名 server_name docker.local.com; rewrite ^ https://$http_host$request_uri? permanent; } server { # 由于上面设置了HTTP 自动跳转 HTTPS，此处注释掉80端口 # listen 80; listen 443 ssl; # 设置docker代理使用的域名，你可以将 docker-registry.hellogitlab.com 替换成你的域名 server_name docker.local.com; # 设置日志文件，对应的日志格式使用main # main日志格式，在nginx.conf中log_format main行定义过 access_log /var/log/nginx/docker-registry.log main; error_log /var/log/nginx/docker-registry-error.log; # 证书 ssl_certificate /etc/nginx/cert_files/local.com.crt; ssl_certificate_key /etc/nginx/cert_files/local.com.key; ssl_protocols TLSv1.1 TLSv1.2; ssl_ciphers '!aNULL:kECDH+AESGCM:ECDH+AESGCM:RSA+AESGCM:kECDH+AES:ECDH+AES:RSA+AES:'; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; # disable any limits to avoid HTTP 413 for large image uploads client_max_body_size 0; # required to avoid HTTP 411: see Issue #1486 (https://github.com/docker/docker/issues/1486) chunked_transfer_encoding on; # 请求逻辑调整 # 设置默认使用docker-group聚合仓库，即拉取镜像的情况多些 set $upstream \"nexus_docker_put\"; # 当请求是GET，也就是拉取镜像的时候，这里改为拉取代理，如此便解决了拉取和推送的端口统一 if ( $request_method ~* 'GET') { set $upstream \"nexus_docker_get\"; } # 我测试的时候，docker-hosted本地仓库和docker-proxy代理仓库都支持搜索，所以将下面这段逻辑调整注释掉 # 只有本地仓库才支持搜索，所以将搜索请求转发到本地仓库，否则出现 500 报错 # if ($request_uri ~ '/search') { # set $upstream \"nexus_docker_put\"; # } index index.html index.htm index.php; location / { proxy_pass http://$upstream; proxy_set_header Host $host; proxy_connect_timeout 3600; proxy_send_timeout 3600; proxy_read_timeout 3600; proxy_set_header X-Real-IP $remote_addr; proxy_buffering off; proxy_request_buffering off; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 直接使用以下配置【proxy_set_header X-Forwarded-Proto http; 】时， # 在尝试向仓库中push推送镜像时，就是docker login登陆成功了也会报以下认证异常 # unauthorized: access to the requested resource is not authorized # proxy_set_header X-Forwarded-Proto http; # 修复docker push认证异常问题，将http替换成https即可 proxy_set_header X-Forwarded-Proto https; } } 配置docker registry-mirrors harbor 也可以搭建 registry-mirrors { \"insecure-registries\" : [\"docker.local.com\"], \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"registry-mirrors\": [ \"https://docker.local.com\"], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\", \"max-file\": \"3\" }, \"dns\": [\"119.29.29.29\", \"223.5.5.5\"], \"data-root\": \"/var/lib/docker\" } 重启docker服务，拉取镜像测试 若遇到docker login denied ，则可以先 docker logout [root@dev ~]# docker pull build/alpine:3.20 Error response from daemon: pull a","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:3:7","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"三、数据接入prometheus grafana模板： 155563 https://grafana.com/grafana/dashboards/16459 neuxs 官方参考地址： https://help.sonatype.com/repomanager3/nexus-repository-administration/support-features#SupportFeatures-Prometheus 配置文件模板 global: scrape_interval: 15s scrape_timeout: 10s evaluation_interval: 15s alerting: alertmanagers: - static_configs: - targets: [] scheme: http timeout: 10s scrape_configs: - job_name: nxrm scrape_interval: 15s scrape_timeout: 10s metrics_path: /service/metrics/prometheus scheme: http basic_auth: username: admin password: admin123 static_configs: - targets: - localhost:8081 ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:4:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"四、数据清理 nexus的repo在删除多个目标后，会发现实际物理磁盘并没有释放出来，是因为在后台只是被标记为deletion，若要清理，需要创建一个task去清理。 1、创建一个定时任务，任务类型为Admin Compact Blobstore，然后填写定时任务详情 2、手动运行一下定时任务，task回慢慢清理blob的数据 ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:5:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"五、主从同步 可以使用nexus proxy repo去实现主从同步，也可定时同步数据 #/bin/bash # sync nexus data to bak server # 限速 3MB/s rsync --delete -avzP --bwlimit=3000 --chown=200:200 /data/nexus/ root@172.16.80.234:/data/nexus 备 nexus上的数据在启动服务的时候可能需要修改一下数据权限，具体操作需要观察一下nexus日志 ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:6:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["DevOps"],"content":"六、Terraform 目前 nexus 没有 api 提供去配置 cleanup policy，需要配置 nexus 运行运行 script ，使用groovy脚本进行添加 开启nexus 允许运行script # nexus_dir/etc/nexus.properties nexus.scripts.allowCreation=true 重启 nexus ","date":"2024-06-16","objectID":"/posts/2024-06-16-nexus/:7:0","tags":["nexus","repo"],"title":"Nexus","uri":"/posts/2024-06-16-nexus/"},{"categories":["系统或软件换源"],"content":"操作系统或者软件换源加速 ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:0:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["系统或软件换源"],"content":"1、操作系统 ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:1:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["系统或软件换源"],"content":"rocky # 8 base sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/rocky|g' \\ -i.bak /etc/yum.repos.d/Rocky*.repo # 8 epel sed -e 's|^metalink=|#metalink=|g' \\ -e 's|^#baseurl=https\\?://download.fedoraproject.org/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -e 's|^#baseurl=https\\?://download.example/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -i.bak /etc/yum.repos.d/epel*.repo # 9 base sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/rocky|g' \\ -i.bak /etc/yum.repos.d/rocky*.repo # 9 epel sed -e 's|^metalink=|#metalink=|g' \\ -e 's|^#baseurl=https\\?://download.fedoraproject.org/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -e 's|^#baseurl=https\\?://download.example/pub/epel/|baseurl=https://mirrors.ustc.edu.cn/epel/|g' \\ -i.bak /etc/yum.repos.d/epel*.repo ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:1:1","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["系统或软件换源"],"content":"ubuntu # http sed -e \"s@http://.*archive.ubuntu.com@http://mirrors.aliyun.com@g\" \\ -e \"s@http://.*security.ubuntu.com@http://mirrors.aliyun.com@g\" \\ -i.bak -i /etc/apt/sources.list # https sed -e \"s@http://.*archive.ubuntu.com@https://mirrors.aliyun.com@g\" \\ -e \"s@http://.*security.ubuntu.com@https://mirrors.aliyun.com@g\" \\ -i.bak -i /etc/apt/sources.list ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:1:2","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["系统或软件换源"],"content":"debian # debian 12及以上 sed -i 's/\\w*.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list.d/debian.sources sed -i \"s@http://mirrors.ustc.edu.cn@https://mirrors.ustc.edu.cn@g\" /etc/apt/sources.list.d/debian.sources # debian 12以下 sed -i 's/\\w*.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list sed -i \"s@http://mirrors.ustc.edu.cn@https://mirrors.ustc.edu.cn@g\" /etc/apt/sources.list # 通用版 sed -i 's/\\w*.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list || sed -i 's/\\w*.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list.d/debian.sources ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:1:3","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["系统或软件换源"],"content":"alpine # alpine 官方源 https://dl-cdn.alpinelinux.org/alpine/v3.18/main https://dl-cdn.alpinelinux.org/alpine/v3.18/community # ustc sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories # edge 源 echo \"https://mirrors.ustc.edu.cn/alpine/edge/main\" \u003e\u003e /etc/apk/repositories echo \"https://mirrors.ustc.edu.cn/alpine/edge/community\" \u003e\u003e /etc/apk/repositories echo \"https://mirrors.ustc.edu.cn/alpine/edge/testing\" \u003e\u003e /etc/apk/repositories # alpine 容器包 apk update --no-cache \u0026\u0026 apk add --update --no-cache coreutils ca-certificates \u0026\u0026 apk add --no-cache tzdata coreutils ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:1:4","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["系统或软件换源"],"content":"2、开发语言类 go export GOPROXY=https://goproxy.cn,direct # aliyun export GOPROXY=https://mirrors.aliyun.com/goproxy/ python export PIP_MIRROR=mirrors.aliyun.com echo -e \"[global]\\nindex-url=https://${PIP_MIRROR}/pypi/simple\\n[install]\\ntrusted-host=${PIP_MIRROR}\" \u003e /etc/pip.conf # 命令配置 pip3 install xxx -i https://mirrors.aliyun.com/pypi/simple/ npm # 设置全局 npm config set registry https://registry.npmmirror.com # cmd npm install -y --registry=https://registry.npmmirror.com # 官方地址 https://registry.npmjs.org/ # 阿里云地址 https://registry.npmmirror.com # 腾讯 http://mirrors.cloud.tencent.com/npm/ # 华为 https://repo.huaweicloud.com/repository/npm/ # 南京大学 https://repo.nju.edu.cn/repository/npm/ java curl -O https://repo1.maven.org/maven2/archetype-catalog.xml settings.xml \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e \u003clocalRepository\u003e/home/sugar/.m2/repository\u003c/localRepository\u003e \u003cmirrors\u003e \u003cmirror\u003e \u003cid\u003ealimaven\u003c/id\u003e \u003cmirrorOf\u003ecentral\u003c/mirrorOf\u003e \u003cname\u003ealiyun maven\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/nexus/content/groups/public/\u003c/url\u003e \u003c/mirror\u003e \u003c/mirrors\u003e \u003cprofiles\u003e \u003cprofile\u003e \u003cid\u003earchetype-catalog\u003c/id\u003e \u003cactivation\u003e \u003cactiveByDefault\u003etrue\u003c/activeByDefault\u003e \u003c/activation\u003e \u003cproperties\u003e \u003carchetypeCatalog\u003efile:///Users/sugar/.m2/archetype-catalog.xml\u003c/archetypeCatalog\u003e \u003c/properties\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003c/settings\u003e # 下载依赖 mvn -B -f pom.xml -s /usr/share/maven/ref/settings.xml dependency:resolve ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:2:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["系统或软件换源"],"content":"3、容器代理 配置模版 { \"insecure-registries\": [ \"repo.local.com\" ], \"exec-opts\": [ \"native.cgroupdriver=systemd\" ], \"registry-mirrors\": [ \"https://docker.mirrors.sjtug.sjtu.edu.cn\", \"https://docker.nju.edu.cn\", \"http://hub-mirror.c.163.com\" ], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\", \"max-file\": \"3\" }, \"bip\":\"192.161.20.1/24\", \"dns\": [ \"119.29.29.29\", \"223.5.5.5\" ], \"data-root\": \"/var/lib/docker\", \"features\": { \"buildkit\": true } } docker registry 国内 docker registry 已暂时无法使用 gcr.io # 上海交大 https://gcr-io.mirrors.sjtug.sjtu.edu.cn # 南京大学 https://gcr.nju.edu.cn # dockerproxy https://gcr.dockerproxy.com ghcr.io # 南京大学 https://htghcr.nju.edu.cn # dockerproxy https://ghcr.dockerproxy.com nvcr.io # 南京大学 https://nvcr.nju.edu.cn quay.io # 南京大学 https://quay.nju.edu.cn # dockerproxy quay.dockerproxy.com registry.k8s.io # 南京大学 k8s.mirror.nju.edu.cn # dockerproxy k8s.dockerproxy.com Microsoft Artifact Registry mcr.dockerproxy.com 同步镜像脚本 #!/usr/bin/env bash SRC_REPO=swr.cn-east-3.myhuaweicloud.com/serialt DEST_REPO=docker.local.com/lib # 获取镜像 # docker images --format \"table {{.Repository}}:{{.Tag}}\" # registry.cn-hangzhou.aliyuncs.com/serialt/node:v3.22.5 # node:v3.22.5 imageList=( golang:1.22.4-alpine golang:1.21-alpine3.18 python:3.8-alpine python:3.9-alpine ) for imageName in ${imageList[@]} do imageName=`echo ${imageName} |awk -F '/' '{print $NF}'` docker pull ${SRC_REPO}/${imageName} docker tag ${SRC_REPO}/${imageName} ${DEST_REPO}/${imageName} docker push ${DEST_REPO}/${imageName} # docker rmi ${DEST_REPO}/${imageName} done v2版 #!/usr/bin/env bash imageList=( local.com/build/alpine:3=docker.local.cc/build/alpine:3 ) #!/usr/bin/env bash . images.sh for imageName in ${imageList[@]} do SRC_IMAGE=`echo ${imageName} | awk -F '=' '{print $1}' ` DST_IMAGE=`echo ${imageName} | awk -F '=' '{print $2}' ` docker pull ${SRC_IMAGE} docker tag ${SRC_IMAGE} ${DST_IMAGE} docker push ${DST_IMAGE} # docker rmi ${DEST_REPO}/${imageName} done ","date":"2024-06-13","objectID":"/posts/2024-06-13-mirror-cn/:3:0","tags":["mirror","source","mirror-to-cn"],"title":"To-mirror","uri":"/posts/2024-06-13-mirror-cn/"},{"categories":["contianerd"],"content":"containerd 参考链接： https://www.aneasystone.com/archives/2023/06/containerd-notes.html https://juejin.cn/post/7312330825206693939 ","date":"2024-06-13","objectID":"/posts/2024-06-13-containerd/:1:0","tags":["contianerd"],"title":"contianerd","uri":"/posts/2024-06-13-containerd/"},{"categories":["contianerd"],"content":"containerd 与 Docker 和 Kubernetes 的关系 仔细观察 containerd 架构图的上面部分，可以看出 containerd 通过提供 gRPC API 来供上层应用调用，上层应用可以直接集成 containerd client 来访问它的接口，诸如 Docker Engine、BuildKit 以及 containerd 自带的命令行工具 ctr 都是这样实现的；所以从 Docker 1.11 开始，当我们执行 docker run 命令时，整个流程大致如下： docker api grpc api docker ------------\u003e docker engine ----------\u003e containerd ----\u003e runc 当前kubelet cri kubectl ----------\u003e containerd ----\u003e runc ","date":"2024-06-13","objectID":"/posts/2024-06-13-containerd/:2:0","tags":["contianerd"],"title":"contianerd","uri":"/posts/2024-06-13-containerd/"},{"categories":["contianerd"],"content":"配置镜像 Containerd 默认配置文件路径是 /etc/containerd/config.toml Containerd配置文件详情可以参考官方文档，请选择对应版本。 https://github.com/containerd/containerd/blob/v2.0.0-rc.2/docs/cri/registry.md 1.6.24 # 使用SystemdCgroup sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml # 修改配置目录 sed -i 's+config_path = \"\"+config_path = \"/etc/containerd/certs.d\"+' /etc/containerd/config.toml mkdir /etc/containerd/certs.d/docker.io -pv # 配置加速 sed -i 's+registry.k8s.io+registry.cn-hangzhou.aliyuncs.com/serialt+' /etc/containerd/config.toml cat \u003e /etc/containerd/certs.d/docker.io/hosts.toml \u003c\u003c EOF server = \"https://docker.io\" [host.\"https://docker.mirrors.sjtug.sjtu.edu.cn\"] capabilities = [\"pull\", \"resolve\", \"push\"] # skip_verify = true # ca = \"/path/to/ca.crt\" EOF # Config file is parsed as version 1 by default. # To use the long form of plugin names set \"version = 2\" # explicitly use v2 config format version = 2 [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"] endpoint = [\"https://registry-1.docker.io\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"test.https-registry.io\"] endpoint = [\"https://HostIP1:Port1\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"test.http-registry.io\"] endpoint = [\"http://HostIP2:Port2\"] # wildcard matching is supported but not required. [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"*\"] endpoint = [\"https://HostIP3:Port3\"] [plugins.\"io.containerd.grpc.v1.cri\".registry] [plugins.\"io.containerd.grpc.v1.cri\".registry.auths] [plugins.\"io.containerd.grpc.v1.cri\".registry.configs] [plugins.\"io.containerd.grpc.v1.cri\".registry.headers] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors] #主要在这下面配置镜像加速服务 [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"] endpoint=[\"https://registry-1.docker.io\", \"https://xxx.mirror.aliyuncs.com\"] [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"registry.k8s.io\"] endpoint=[\"https://xxx.mirror.aliyuncs.com\", \"https://k8s.m.daocloud.io\", \"https://docker.mirrors.ustc.edu.cn\",\"https://hub-mirror.c.163.com\"] 验证 root@master:/etc/containerd# crictl info \"registry\": { \"configPath\": \"\", \"mirrors\": { \"docker.io\": { \"endpoint\": [ \"https://registry-1.docker.io\", \"https://45hrqeao.mirror.aliyuncs.com\" ] }, \"registry.k8s.io\": { \"endpoint\": [ \"https://45hrqeao.mirror.aliyuncs.com\", \"https://k8s.m.daocloud.io\", \"https://docker.mirrors.ustc.edu.cn\", \"https://hub-mirror.c.163.com\" ] } }, 完整配置 disabled_plugins = [] imports = [] oom_score = 0 plugin_dir = \"\" required_plugins = [] root = \"/var/lib/containerd\" state = \"/run/containerd\" temp = \"\" version = 2 [cgroup] path = \"\" [debug] address = \"\" format = \"\" gid = 0 level = \"\" uid = 0 [grpc] address = \"/run/containerd/containerd.sock\" gid = 0 max_recv_message_size = 16777216 max_send_message_size = 16777216 tcp_address = \"\" tcp_tls_ca = \"\" tcp_tls_cert = \"\" tcp_tls_key = \"\" uid = 0 [metrics] address = \"\" grpc_histogram = false [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] deletion_threshold = 0 mutation_threshold = 100 pause_threshold = 0.02 schedule_delay = \"0s\" startup_delay = \"100ms\" [plugins.\"io.containerd.grpc.v1.cri\"] device_ownership_from_security_context = false disable_apparmor = false disable_cgroup = false disable_hugetlb_controller = true disable_proc_mount = false disable_tcp_service = true enable_selinux = false enable_tls_streaming = false enable_unprivileged_icmp = false enable_unprivileged_ports = false ignore_image_defined_volumes = false max_concurrent_downloads = 3 max_container_log_line_size = 16384 netns_mounts_under_state_dir = false restrict_oom_score_adj = false sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.9\" selinux_category_range = 1024 stats_collect_period = 10 stream_idle_timeout = \"4h0m0s\" stream_server_address = \"127.0.0.1\" stream_server_port = \"0\" systemd_cgroup = false tolerate_missing_hugetlb_controller = true unset_seccomp_profile = \"\" [plugins.\"io.containerd.grpc.v1.cri\".cni] bin","date":"2024-06-13","objectID":"/posts/2024-06-13-containerd/:2:1","tags":["contianerd"],"title":"contianerd","uri":"/posts/2024-06-13-containerd/"},{"categories":["Podman"],"content":"Podman 参考连接：http://www.yunweipai.com/40798.html ​ Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用。Podman 提供与 Docker 非常相似的功能。正如前面提到的那样，它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。 ​ Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Podman 提供了一个与 Docker 兼容的命令行前端来管理 Docker 镜像 podman是什么 ​ podman系列主要包含三个命令podman、buildah、skopeo，其中podman本身负责运行、停止、管理容器，buildah负责构建容器镜像、skopeo负责与remote repo交互，拉取或推送镜像。但我们使用时不必这么麻烦，redhat为了方便用户从docker迁移到podman，在podman上几乎实现了大多数docker的常用命令，podman会替你转调buildah和skopeo，你甚至可以直接 alias docker=podman，然后像使用docker一样使用podman。 Podman ​ Podman可以替换Docker中了大多数子命令（RUN，PUSH，PULL等）。Podman不需要守护进程，而是使用用户命名空间来模拟容器中的root，无需连接到具有root权限的套接字保证容器的体系安全。Podman专注于维护和修改OCI镜像的所有命令和功能，例如拉动和标记。它还允许我们创建，运行和维护从这些图像创建的容器。 Buildah ​ Buildah用来构建OCI图像。虽然Podman也可以用户构建Docker镜像，但是构建速度超慢，并且默认情况下使用vfs存储驱动程序会耗尽大量磁盘空间。 buildah bud（使用Dockerfile构建）则会非常快，并使用覆盖存储驱动程序。Buildah专注于构建OCI镜像。 Buildah的命令复制了Dockerfile中的所有命令。可以使用Dockerfiles构建镜像，并且不需要任何root权限。 Buildah的最终目标是提供更低级别的coreutils界面来构建图像。Buildah也支持非Dockerfiles构建镜像，可以允许将其他脚本语言集成到构建过程中。 Buildah遵循一个简单的fork-exec模型，不以守护进程运行，但它基于golang中的综合API，可以存储到其他工具中。 Skopeo ​ Skopeo是一个工具，允许我们通过推、拉和复制镜像来处理Docker和OC镜像。 ","date":"2024-06-13","objectID":"/posts/2024-06-12-podman/:1:0","tags":["podman","contianerd"],"title":"Podman","uri":"/posts/2024-06-12-podman/"},{"categories":["Podman"],"content":"使用 1）安装 [root@dev ~]# yum -y install podman 2、配置镜像加速 podman的配置文件 # 配置镜像像仓库 [root@dev ~]# vim /etc/containers/registries.conf # 取消从默认地址搜索的仓库域名 #unqualified-search-registries = [\"registry.fedoraproject.org\", \"registry.access.redhat.com\", \"docker.io\", \"quay.io\"] unqualified-search-registries = [\"docker.io\"] # 自定义搜索器 [[registry]] # 仓库前缀 prefix = \"docker.io\" # 加速器地址 location = \"hub.local.com\" # 镜像别名 [root@localhost containers]# ls registries.conf.d/ 000-shortnames.conf 001-rhel-shortnames.conf 002-rhel-shortnames-overrides.conf # 配置镜像仓库和运行时目录 [root@localhost containers]# vim storage.conf [storage] # Default Storage Driver, Must be set for proper operation. driver = \"overlay\" # root 用户运行时目录 # Temporary storage location runroot = \"/run/containers/storage\" # Primary Read/Write location of container storage # When changing the graphroot location on an SELINUX system, you must # ensure the labeling matches the default locations labels with the # following commands: # semanage fcontext -a -e /var/lib/containers/storage /NEWSTORAGEPATH # restorecon -R -v /NEWSTORAGEPATH # root 用户镜像仓库目录 graphroot = \"/var/lib/containers/storage\" # Storage path for rootless users # # rootless_storage_path = \"$HOME/.local/share/containers/storage\" 3、podman常用命令 容器 podman run #创建并启动容器 podman start #启动容器 podman ps #查看容器 podman stop #终止容器 podman restart #重启容器 podman attach #进入容器 podman exec #进入容器 podman export #导出容器 podman import #导入容器快照 podman rm #删除容器 podman logs #查看日志 镜像 podman search #检索镜像 docke pull #获取镜像 podman images #列出镜像 podman image Is #列出镜像 podman rmi #删除镜像 podman image rm #删除镜像 podman save #导出镜像 podman load #导入镜像 podmanfile #定制镜像（三个） podman build #构建镜像 podman run #运行镜像 podmanfile #常用指令（四个） COPY #复制文件 ADD #高级复制 CMD #容器启动命令 ENV #环境变量 EXPOSE #暴露端口 4、使用podman 使用 Podman 非常的简单，Podman 的指令跟 Docker 大多数都是相同的。下面我们来看几个常用的例子： [root@localhost ~]# podman run -d --name httpd docker.io/library/httpd Trying to pull docker.io/library/httpd... Getting image source signatures Copying blob e5ae68f74026 done Copying blob d3576f2b6317 done Copying blob bc36ee1127ec done Copying blob f1aa5f54b226 done Copying blob aa379c0cedc2 done Copying config ea28e1b82f done Writing manifest to image destination Storing signatures 0492e405b9ecb05e6e6be1fec0ac1a8b6ba3ff949df259b45146037b5f355035 //查看镜像 [root@localhost ~]# podman images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/library/httpd latest ea28e1b82f31 11 days ago 148 MB [root@localhost ~]# podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0492e405b9ec docker.io/library/httpd:latest httpd-foreground About a minute ago Up About a minute ago httpd 查看容器里的进程 [root@localhost ~]# podman top httpd USER PID PPID %CPU ELAPSED TTY TIME COMMAND root 1 0 0.000 15m38.599711321s ? 0s httpd -DFOREGROUND www-data 7 1 0.000 15m38.599783256s ? 0s httpd -DFOREGROUND www-data 8 1 0.000 15m38.599845342s ? 0s httpd -DFOREGROUND www-data 9 1 0.000 15m38.599880444s ? 0s httpd -DFOREGROUND 停止容器，删除 [root@localhost ~]# podman stop --latest 2f3edf712621d3a41e03fa8c7f6a5cdba56fbbad43a7a59ede26cc88f31006c4 [root@localhost ~]# podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@localhost ~]# podman rm --latest 2f3edf712621d3a41e03fa8c7f6a5cdba56fbbad43a7a59ede26cc88f31006c4 [root@localhost ~]# podman ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 创建systemd服务 [root@localhost ~]# podman generate systemd nginx \u003e /etc/systemd/system/nginx-docker.service [root@localhost ~]# cat /etc/systemd/system/nginx-docker.service # container-26ce342439d6ca634e209711b12fd0653537912bdd0351800a293a7900967237.service # autogenerated by Podman 4.0.2 # Fri Apr 22 15:44:38 CST 2022 [Unit] Description=Podman container-26ce342439d6ca634e209711b12fd0653537912bdd0351800a293a7900967237.service Documentation=man:podman-generate-systemd(1) Wants=network-online.target After=network-online.target RequiresMountsFor=/run/containers/storage [Service] Environment=PODMAN_SYSTEMD_UNIT=%n Restart=on-failure TimeoutStopSec=70 ExecStart=/usr/bin/podman s","date":"2024-06-13","objectID":"/posts/2024-06-12-podman/:1:1","tags":["podman","contianerd"],"title":"Podman","uri":"/posts/2024-06-12-podman/"},{"categories":["Docker 镜像构建优化"],"content":"Docker 镜像体积优化 参考链接： https://icloudnative.io/posts/docker-images-part1-reducing-image-size/ ","date":"2024-06-13","objectID":"/posts/2024-06-12-docker-image/:1:0","tags":["Docker","Dockerfile"],"title":"Docker 镜像构建优化","uri":"/posts/2024-06-12-docker-image/"},{"categories":["Docker 镜像构建优化"],"content":"1、选择合适的基础镜像 常用的镜像有alpine，debian-slim 他们的体积都比 标准debian、ubuntu 和 rhel 系列的基础镜像小很多。 ","date":"2024-06-13","objectID":"/posts/2024-06-12-docker-image/:1:1","tags":["Docker","Dockerfile"],"title":"Docker 镜像构建优化","uri":"/posts/2024-06-12-docker-image/"},{"categories":["Docker 镜像构建优化"],"content":"2、多阶段构建 要想大幅度减少镜像的体积，多阶段构建是必不可少的。多阶段构建的想法很简单：“我不想在最终的镜像中包含一堆 C 或 Go 编译器和整个编译工具链，我只要一个编译好的可执行文件！” 多阶段构建可以由多个 FROM 指令识别，每一个 FROM 语句表示一个新的构建阶段，阶段名称可以用 AS 参数指定，例如： FROM gcc AS mybuildstage COPY hello.c . RUN gcc -o hello hello.c FROM ubuntu COPY --from=mybuildstage /src/hello . CMD [\"./hello\"] ","date":"2024-06-13","objectID":"/posts/2024-06-12-docker-image/:1:2","tags":["Docker","Dockerfile"],"title":"Docker 镜像构建优化","uri":"/posts/2024-06-12-docker-image/"},{"categories":["Docker 镜像构建优化"],"content":"3、对不同语言进行相应优化 Go FROM golang:alpine COPY hello.go . RUN go build hello.go FROM alpine COPY --from=0 /go/hello . CMD [\"./hello\"] Java Java 属于编译型语言，但运行时还是要跑在 JVM 中，这就意味着理论上可以使用任意的 JVM 来运行 Java 程序，系统标准库是 musl libc 还是 glibc 都无所谓。因此，也就可以使用任意带有 JVM 的基础镜像来构建 Java 程序，也可以使用任意带有 JVM 的镜像作为运行 Java 程序的基础镜像 解释型语言 Python 对于解释型语言来说，如果程序仅用到了标准库或者依赖项和程序本身使用的是同一种语言，且无需调用 C 库和外部依赖，那么使用 Alpine 作为基础镜像一般是没有啥问题的。一旦你的程序需要调用外部依赖，情况就复杂了，想继续使用 Alpine 镜像，就得安装这些依赖。或者换成slim镜像，slim 镜像一般都基于 Debian 和 glibc，删除了许多非必需的软件包，优化了体积。如果构建过程中需要编译器，那么 slim 镜像不适合，除此之外大多数情况下还是可以使用 slim 作为基础镜像的。 ","date":"2024-06-13","objectID":"/posts/2024-06-12-docker-image/:1:3","tags":["Docker","Dockerfile"],"title":"Docker 镜像构建优化","uri":"/posts/2024-06-12-docker-image/"},{"categories":["Go 库文档"],"content":"Go time包 参考链接：https://www.liwenzhou.com/posts/Go/go_time/ 时间和日期是我们编程中经常会用到的，本文主要介绍了Go语言内置的time包的基本用法。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:0","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"time包 time包提供了时间的显示和测量用的函数。日历的计算采用的是公历。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:1","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"时间格式 const ( ANSIC = \"Mon Jan _2 15:04:05 2006\" UnixDate = \"Mon Jan _2 15:04:05 MST 2006\" RubyDate = \"Mon Jan 02 15:04:05 -0700 2006\" RFC822 = \"02 Jan 06 15:04 MST\" RFC822Z = \"02 Jan 06 15:04 -0700\" // RFC822 with numeric zone RFC850 = \"Monday, 02-Jan-06 15:04:05 MST\" RFC1123 = \"Mon, 02 Jan 2006 15:04:05 MST\" RFC1123Z = \"Mon, 02 Jan 2006 15:04:05 -0700\" // RFC1123 with numeric zone RFC3339 = \"2006-01-02T15:04:05Z07:00\" RFC3339Nano = \"2006-01-02T15:04:05.999999999Z07:00\" Kitchen = \"3:04PM\" // Handy time stamps. Stamp = \"Jan _2 15:04:05\" StampMilli = \"Jan _2 15:04:05.000\" StampMicro = \"Jan _2 15:04:05.000000\" StampNano = \"Jan _2 15:04:05.000000000\" ) ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:2","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"时间类型 time.Time类型表示时间。我们可以通过time.Now()函数获取当前的时间对象，然后获取时间对象的年月日时分秒等信息。示例代码如下： func timeDemo() { now := time.Now() //获取当前时间 fmt.Printf(\"current time:%v\\n\", now) year := now.Year() //年 month := now.Month() //月 day := now.Day() //日 hour := now.Hour() //小时 minute := now.Minute() //分钟 second := now.Second() //秒 fmt.Printf(\"%d-%02d-%02d %02d:%02d:%02d\\n\", year, month, day, hour, minute, second) } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:3","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"时间戳 时间戳是自1970年1月1日（08:00:00GMT）至当前时间的总毫秒数。它也被称为Unix时间戳（UnixTimestamp）。 基于时间对象获取时间戳的示例代码如下： func timestampDemo() { now := time.Now() //获取当前时间 timestamp1 := now.Unix() //时间戳 timestamp2 := now.UnixNano() //纳秒时间戳 fmt.Printf(\"current timestamp1:%v\\n\", timestamp1) fmt.Printf(\"current timestamp2:%v\\n\", timestamp2) } 使用time.Unix()函数可以将时间戳转为时间格式。 func timestampDemo2(timestamp int64) { timeObj := time.Unix(timestamp, 0) //将时间戳转为时间格式 fmt.Println(timeObj) year := timeObj.Year() //年 month := timeObj.Month() //月 day := timeObj.Day() //日 hour := timeObj.Hour() //小时 minute := timeObj.Minute() //分钟 second := timeObj.Second() //秒 fmt.Printf(\"%d-%02d-%02d %02d:%02d:%02d\\n\", year, month, day, hour, minute, second) } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:4","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"时间间隔 time.Duration是time包定义的一个类型，它代表两个时间点之间经过的时间，以纳秒为单位。time.Duration表示一段时间间隔，可表示的最长时间段大约290年。 time包中定义的时间间隔类型的常量如下： const ( Nanosecond Duration = 1 Microsecond = 1000 * Nanosecond Millisecond = 1000 * Microsecond Second = 1000 * Millisecond Minute = 60 * Second Hour = 60 * Minute ) 例如：time.Duration表示1纳秒，time.Second表示1秒。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:5","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"时间操作 Add 我们在日常的编码过程中可能会遇到要求时间+时间间隔的需求，Go语言的时间对象有提供Add方法如下： func (t Time) Add(d Duration) Time 举个例子，求一个小时之后的时间： func main() { now := time.Now() later := now.Add(time.Hour) // 当前时间加1小时后的时间 fmt.Println(later) } Sub 求两个时间之间的差值： func (t Time) Sub(u Time) Duration 返回一个时间段t-u。如果结果超出了Duration可以表示的最大值/最小值，将返回最大值/最小值。要获取时间点t-d（d为Duration），可以使用t.Add(-d)。 Equal func (t Time) Equal(u Time) bool 判断两个时间是否相同，会考虑时区的影响，因此不同时区标准的时间也可以正确比较。本方法和用t==u不同，这种方法还会比较地点和时区信息。 Before func (t Time) Before(u Time) bool 如果t代表的时间点在u之前，返回真；否则返回假。 After func (t Time) After(u Time) bool 如果t代表的时间点在u之后，返回真；否则返回假。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:6","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"定时器 使用time.Tick(时间间隔)来设置定时器，定时器的本质上是一个通道（channel）。 func tickDemo() { ticker := time.Tick(time.Second) //定义一个1秒间隔的定时器 for i := range ticker { fmt.Println(i)//每秒都会执行的任务 } } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:7","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"时间格式化 时间类型有一个自带的方法Format进行格式化，需要注意的是Go语言中格式化时间模板不是常见的Y-m-d H:M:S而是使用Go的诞生时间2006年1月2号15点04分（记忆口诀为2006 1 2 3 4）。也许这就是技术人员的浪漫吧。 补充：如果想格式化为12小时方式，需指定PM。 func formatDemo() { now := time.Now() // 格式化的模板为Go的出生时间2006年1月2号15点04分 Mon Jan // 24小时制 fmt.Println(now.Format(\"2006-01-02 15:04:05.000 Mon Jan\")) // 12小时制 fmt.Println(now.Format(\"2006-01-02 03:04:05.000 PM Mon Jan\")) fmt.Println(now.Format(\"2006/01/02 15:04\")) fmt.Println(now.Format(\"15:04 2006/01/02\")) fmt.Println(now.Format(\"2006/01/02\")) } 解析字符串格式的时间 now := time.Now() fmt.Println(now) // 加载时区 loc, err := time.LoadLocation(\"Asia/Shanghai\") if err != nil { fmt.Println(err) return } // 按照指定时区和指定格式解析字符串时间 timeObj, err := time.ParseInLocation(\"2006/01/02 15:04:05\", \"2019/08/04 14:15:20\", loc) if err != nil { fmt.Println(err) return } fmt.Println(timeObj) fmt.Println(timeObj.Sub(now)) ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-time/:1:8","tags":["Go","time"],"title":"Go time","uri":"/posts/2024-06-02-go-time/"},{"categories":["Go 库文档"],"content":"Go Storm storm是一个使用BoltDB的上层orm框架 https://juejin.cn/post/7031361355856740389 数据查看工具: https://github.com/br0xen/boltbrowser 驱动: https://github.com/asdine/storm 下载boltbrowser go install github.com/br0xen/boltbrowser@latest 使用lib go get github.com/asdine/storm ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-storm/:1:0","tags":["Go","storm","boltdb"],"title":"Go storm","uri":"/posts/2024-06-02-go-storm/"},{"categories":["Go 库文档"],"content":"一、基本使用 初始化 db, err := storm.Open(\"my.db\") defer db.Close() 对象模型 type User struct { ID int // primary key Group string `storm:\"index\"` // this field will be indexed Email string `storm:\"unique\"` // this field will be indexed with a unique constraint Name string // this field will not be indexed Age int `storm:\"index\"` } 对象模型storm tag整理 可以符合使用, 各个值用 , (逗号) 分割 storm:\"index\" 添加索引 storm:\"id\" 主键标识 storm:\"increment\" 自增字段 storm:\"increment=20\" 自增字段, 从20开始自增 storm:\"unique\" 不能重复 storm:\"inline\" 内联标记嵌套 storm:\"__storm_index_\" ??? 保存数据 user := User{ ID: 10, Group: \"staff\", Email: \"john@provider.com\", Name: \"John\", Age: 21, CreatedAt: time.Now(), } err := db.Save(\u0026user) // err == nil user.ID++ err = db.Save(\u0026user) // err == storm.ErrAlreadyExists 修改 // Update multiple fields err := db.Update(\u0026User{ID: 10, Name: \"Jack\", Age: 45}) // Update a single field err := db.UpdateField(\u0026User{ID: 10}, \"Age\", 0) 删除数据 err := db.DeleteStruct(\u0026user) 表管理操作 初始化索引 err := db.Init(\u0026User{}) 重建索引: err := db.ReIndex(\u0026User{}) 删表: err := db.Drop(\u0026User) 或 err := db.Drop(\"User\") 简单查询 var user User err := db.One(\"Email\", \"john@provider.com\", \u0026user) // err == nil err = db.One(\"Name\", \"John\", \u0026user) // err == nil err = db.One(\"Name\", \"Jack\", \u0026user) // err == storm.ErrNotFound // Fetch multiple objects var users []User err := db.Find(\"Group\", \"staff\", \u0026users) // Fetch all objects var users []User err := db.All(\u0026users) // Fetch all objects sorted by index var users []User err := db.AllByIndex(\"CreatedAt\", \u0026users) // Fetch a range of objects var users []User err := db.Range(\"Age\", 10, 21, \u0026users) // Fetch objects by prefix var users []User err := db.Prefix(\"Name\", \"Jo\", \u0026users) // Skip, Limit and Reverse var users []User err := db.Find(\"Group\", \"staff\", \u0026users, storm.Skip(10)) err = db.Find(\"Group\", \"staff\", \u0026users, storm.Limit(10)) err = db.Find(\"Group\", \"staff\", \u0026users, storm.Reverse()) err = db.Find(\"Group\", \"staff\", \u0026users, storm.Limit(10), storm.Skip(10), storm.Reverse()) err = db.All(\u0026users, storm.Limit(10), storm.Skip(10), storm.Reverse()) err = db.AllByIndex(\"CreatedAt\", \u0026users, storm.Limit(10), storm.Skip(10), storm.Reverse()) err = db.Range(\"Age\", 10, 21, \u0026users, storm.Limit(10), storm.Skip(10), storm.Reverse()) 高级查询 import ( \"github.com/asdine/storm/q\" ) ... // Equality q.Eq(\"Name\", John) // Strictly greater than q.Gt(\"Age\", 7) // Lesser than or equal to q.Lte(\"Age\", 77) // Regex with name that starts with the letter D q.Re(\"Name\", \"^D\") // In the given slice of values q.In(\"Group\", []string{\"Staff\", \"Admin\"}) // Comparing fields q.EqF(\"FieldName\", \"SecondFieldName\") q.LtF(\"FieldName\", \"SecondFieldName\") q.GtF(\"FieldName\", \"SecondFieldName\") q.LteF(\"FieldName\", \"SecondFieldName\") q.GteF(\"FieldName\", \"SecondFieldName\") // Match if all match q.And( q.Gt(\"Age\", 7), q.Re(\"Name\", \"^D\") ) // Matchers can also be combined with And, Or and Not: // Match if one matches q.Or( q.Re(\"Name\", \"^A\"), q.Not( q.Re(\"Name\", \"^B\") ), q.Re(\"Name\", \"^C\"), q.In(\"Group\", []string{\"Staff\", \"Admin\"}), q.And( q.StrictEq(\"Password\", []byte(password)), q.Eq(\"Registered\", true) ) ) query := db.Select(q.Gte(\"Age\", 7), q.Lte(\"Age\", 77)) // Calls can also be chained query = query.Limit(10).Skip(20).OrderBy(\"Age\").Reverse() // But also to specify how to fetch them. var users []User err = query.Find(\u0026users) var user User err = query.First(\u0026user) // demo // Examples with Select: / Find all users with an ID between 10 and 100 err = db.Select(q.Gte(\"ID\", 10), q.Lte(\"ID\", 100)).Find(\u0026users) // Nested matchers err = db.Select(q.Or( q.Gt(\"ID\", 50), q.Lt(\"Age\", 21), q.And( q.Eq(\"Group\", \"admin\"), q.Gte(\"Age\", 21), ), )).Find(\u0026users) query := db.Select(q.Gte(\"ID\", 10), q.Lte(\"ID\", 100)).Limit(10).Skip(5).Reverse().OrderBy(\"Age\", \"Name\") // Find multiple records err = query.Find(\u0026users) // or err = db.Select(q.Gte(\"ID\", 10), q.Lte(\"ID\", 100)).Limit(10).Skip(5).Reverse().OrderBy(\"Age\", \"Name\").Find(\u0026users) // Find first record err = query.First(\u0026user) // or err = db.Select(q.Gte(\"ID\", 10), q.Lte(\"ID\", 100)).L","date":"2024-06-02","objectID":"/posts/2024-06-02-go-storm/:1:1","tags":["Go","storm","boltdb"],"title":"Go storm","uri":"/posts/2024-06-02-go-storm/"},{"categories":["Go 库文档"],"content":"slog 结构化日志 参考链接：https://betterstack.com/community/guides/logging/logging-in-go/#customizing-the-default-logger ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-slog/:1:0","tags":["Go","slog"],"title":"Go slog","uri":"/posts/2024-06-02-go-slog/"},{"categories":["Go 库文档"],"content":"1、下载 go get golang.org/x/exp/slog@latest ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-slog/:1:1","tags":["Go","slog"],"title":"Go slog","uri":"/posts/2024-06-02-go-slog/"},{"categories":["Go 库文档"],"content":"2、使用 1）简单实用 package main import ( \"errors\" \"golang.org/x/exp/slog\" ) func main() { slog.Debug(\"Debug message\") slog.Info(\"Info message\") slog.Warn(\"Warning message\") slog.Error(\"Error message\") } output 2023/03/15 12:55:56 INFO Info message 2023/03/15 12:55:56 WARN Warning message 2023/03/15 12:55:56 ERROR Error message 2）json格式输出 package main import ( \"errors\" \"os\" \"golang.org/x/exp/slog\" ) func main() { logger := slog.New(slog.NewJSONHandler(os.Stdout)) logger.Debug(\"Debug message\") logger.Info(\"Info message\") logger.Warn(\"Warning message\") logger.Error(\"Error message\") } output {\"time\":\"2023-03-15T12:59:22.227408691+01:00\",\"level\":\"INFO\",\"msg\":\"Info message\"} {\"time\":\"2023-03-15T12:59:22.227468972+01:00\",\"level\":\"WARN\",\"msg\":\"Warning message\"} {\"time\":\"2023-03-15T12:59:22.227472149+01:00\",\"level\":\"ERROR\",\"msg\":\"Error message\",\"!BADKEY\":\"an error\"} 3）自己定义 package sugar import ( \"os\" \"path/filepath\" \"golang.org/x/exp/slog\" ) type Log struct { Level string // 日志级别 string // 日志文件存放路径,如果为空，则输出到控制台 Type string // 日志类型，支持 txt 和 json ，默认txt Short bool // 以包/文件:行号 显示短路径，不显示全路径 } type LogOptions func(*Log) func WithLevel(level string) LogOptions { return func(lg *Log) { lg.Level = level } } func WithType(tp string) LogOptions { return func(lg *Log) { lg.Type = tp } } func WithShort(short bool) LogOptions { return func(lg *Log) { lg.Short = short } } // LevelToZapLevel 转换日志级别 func LevelToSlogLevel(level string) slog.Level { switch level { case \"debug\", \"DEBUG\": return slog.LevelDebug case \"info\", \"INFO\": return slog.LevelInfo case \"warn\", \"WARN\", \"WARNING\": return slog.LevelWarn case \"error\", \"ERROR\": return slog.LevelError default: return slog.LevelInfo } } func NewSlog(lg *Log) *slog.Logger { replace := func(groups []string, a slog.Attr) slog.Attr { // Remove the directory from the source's filename. if a.Key == slog.SourceKey \u0026\u0026 lg.Short { a.Value = slog.StringValue(filepath.Base(a.Value.String())) } return a } opts := slog.HandlerOptions{ AddSource: true, Level: LevelToSlogLevel(lg.Level), ReplaceAttr: replace, } var log *slog.Logger if lg.Type == \"json\" { log = slog.New(opts.NewJSONHandler(os.Stdout)) } else { log = slog.New(opts.NewTextHandler(os.Stdout)) } return log } func New(options ...LogOptions) *slog.Logger { // 默认值的设定 lg := \u0026Log{ Level: \"info\", Type: \"txt\", Short: true, } // 遍历可选参数，然后分别调用匿名函数，将连接对象指针传入，进行修改 for _, opt := range options { // 遍历调用函数，进行数据修改 opt(lg) } return NewSlog(lg) } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-slog/:1:2","tags":["Go","slog"],"title":"Go slog","uri":"/posts/2024-06-02-go-slog/"},{"categories":["Go 库文档"],"content":"Shamir密钥分享算法 参考：https://www.cxyzjd.com/article/shangsongwww/90266455 秘密共享技术是密码学和信息安全的一个重要研究内容，Shamir密钥分享算法最早是由Shamir和Blackly在1970年基于Lagrange插值和矢量方法提出的，其基本思想是分发者通过秘密多项式，将秘密s分解为n个秘密分发个持有者，其中任意不少于k个秘密均能恢复密文，而任意少于k个秘密均无法得到密文的任何信息。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-shamir/:1:0","tags":["Go","shamir"],"title":"Go shamir","uri":"/posts/2024-06-02-go-shamir/"},{"categories":["Go 库文档"],"content":"实际应用 比如在门限体系中，为了保证信息安全性，一个秘密通常不能由单个持有者保存。比如一些重要场所的通行，比如遗嘱的生效等，必须将秘密分由多人保管并且只有当多人同时在场时秘密才能得以恢复。在这些场合，就需要这样一套的密钥分享技术。 示例1： # 算法库 github.com/hashicorp/vault/shamir github.com/serialt/lancet/cryptor/shamir (基于vault) github.com/corvus-ch/shamir package main import ( \"encoding/base64\" \"fmt\" \"github.com/serialt/lancet/cryptor/shamir\" ) func main() { secret := []byte(\"dnwkUubRaEXr7TV7VswNqh4L3cHEbJjH\") // 将密码分成5份，最少需要3份才能合并成原始密码 msg, err := shamir.Split(secret, 5, 3) if err != nil { fmt.Println(err) } else { for k, v := range msg { fmt.Printf(\"shamir share secret %v: %v\\n\", k, base64.RawStdEncoding.EncodeToString(v)) } } deCode() } func combine(parts ...[]byte) []byte { var msgParts [][]byte for _, v := range parts { msgParts = append(msgParts, v) } result, err := shamir.Combine(msgParts) if err != nil { return nil } return result } func deCode() { msg1, _ := base64.StdEncoding.DecodeString(\"Im3P+3AOr7So+dB7feyrNGY0lAeT1Ou3I3Rn0PmWN5Ad\") msg2, _ := base64.StdEncoding.DecodeString(\"xguYlI5C77FDOln9R0gNT963V9B+RR12C7RlQVcSfCWX\") msg3, _ := base64.StdEncoding.DecodeString(\"9AytrQ+ZDzSHJNx4rq3qGYxKeM/bcBclWiCwZYqdUlC8\") // msg := [][]byte{ // msg1, // msg2, // msg3, // } fmt.Printf(\"\\ncomboine secret: %s \\n\", string(combine(msg1, msg2, msg3))) } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-shamir/:1:1","tags":["Go","shamir"],"title":"Go shamir","uri":"/posts/2024-06-02-go-shamir/"},{"categories":["Go 库文档"],"content":"Go 汉字转拼音库 汉语拼音转换工具 Go 版。 1、安装 go get -u github.com/mozillazg/go-pinyin 安装cli工具 go get -u github.com/mozillazg/go-pinyin/cmd/pinyin $ pinyin 中国人 zhōng guó rén 2、简单使用 package main import ( \"fmt\" \"github.com/mozillazg/go-pinyin\" ) func main() { hans := \"中国人\" // 默认 a := pinyin.NewArgs() fmt.Println(pinyin.Pinyin(hans, a)) // [[zhong] [guo] [ren]] // 包含声调 a.Style = pinyin.Tone fmt.Println(pinyin.Pinyin(hans, a)) // [[zhōng] [guó] [rén]] // 声调用数字表示 a.Style = pinyin.Tone2 fmt.Println(pinyin.Pinyin(hans, a)) // [[zho1ng] [guo2] [re2n]] // 开启多音字模式 a = pinyin.NewArgs() a.Heteronym = true fmt.Println(pinyin.Pinyin(hans, a)) // [[zhong zhong] [guo] [ren]] a.Style = pinyin.Tone2 fmt.Println(pinyin.Pinyin(hans, a)) // [[zho1ng zho4ng] [guo2] [re2n]] fmt.Println(pinyin.LazyPinyin(hans, pinyin.NewArgs())) // [zhong guo ren] fmt.Println(pinyin.Convert(hans, nil)) // [[zhong] [guo] [ren]] fmt.Println(pinyin.LazyConvert(hans, nil)) // [zhong guo ren] } 输出调试 package main import ( \"fmt\" \"github.com/mozillazg/go-pinyin\" ) func main() { hans := \"音乐\" // 默认 a := pinyin.NewArgs() p1 := pinyin.Pinyin(hans, a) fmt.Println(p1) // [[zhong] [guo] [ren]] // 包含声调 a.Style = pinyin.Tone p2 := pinyin.Pinyin(hans, a) fmt.Println(p2) // [[zhōng] [guó] [rén]] // 声调用数字表示 a.Style = pinyin.Tone2 p3 := pinyin.Pinyin(hans, a) fmt.Println(p3) // [[zho1ng] [guo2] [re2n]] // 开启多音字模式 a = pinyin.NewArgs() a.Heteronym = true p4 := pinyin.Pinyin(hans, a) fmt.Println(p4) // [[zhong zhong] [guo] [ren]] a.Style = pinyin.Tone2 p5 := pinyin.Pinyin(hans, a) fmt.Println(p5) // [[zho1ng zho4ng] [guo2] [re2n]] p6 := pinyin.LazyPinyin(hans, pinyin.NewArgs()) fmt.Println(p6) // [zhong guo ren] p7 := pinyin.Convert(hans, nil) fmt.Println(p7) // [[zhong] [guo] [ren]] p8 := pinyin.LazyConvert(hans, nil) fmt.Println(p8) // [zhong guo ren] } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-pinyin/:1:0","tags":["Go","pinyin"],"title":"Go pinyin","uri":"/posts/2024-06-02-go-pinyin/"},{"categories":["Go 库文档"],"content":"os/exec 系统内执行命令 1、查找命令所在的路径 func findCommandPath(str string) (string, error) { path, err := exec.LookPath(str) if err != nil { return \"\", err } return path, nil } 2、CombinedOutput组合输出，标准正确错误输出，类似于shell的将标准错误输出重定向到标准正确输出 func main() { cmd := exec.Command(\"/bin/bash\", \"-c\", \"datex\") std, err := cmd.CombinedOutput() if err != nil { } fmt.Println(string(std)) } 3、Output 标准正确输出 func main() { cmd := exec.Command(\"/bin/bash\", \"-c\", \"date\") result, err := cmd.Output() if err != nil { fmt.Println(\"命令执行失败\", err) } fmt.Println(string(result)) } 4、阻塞Run package main import ( \"log\" \"os/exec\" ) func main() { cmd := exec.Command(\"sleep\", \"1\") log.Printf(\"Running command and waiting for it to finish...\") err := cmd.Run() log.Printf(\"Command finished with error: %v\", err) } 可用函数 // 获取命令的路径 func findCommandPath(str string) (string, error) { path, err := exec.LookPath(str) if err != nil { return \"\", err } return path, nil } // 获取标准正确输出 func runCmd(str string) (string, error) { cmd := exec.Command(\"/bin/sh\", \"-c\", str) result, err := cmd.Output() if err != nil { return \"\", err } return string(result), nil } // 标准正确错误输出到标准正确输出 func runCMD(str string) (string, error) { cmd := exec.Command(\"/bin/sh\", \"-c\", str) result, err := cmd.CombinedOutput() if err != nil { return string(result), err } return string(result), nil } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-os-exec/:1:0","tags":["Go","exec"],"title":"Go exec","uri":"/posts/2024-06-02-go-os-exec/"},{"categories":["Go 库文档"],"content":"os 函数名 说明 备注 os.Hostname() 获取主机名 os.Getwd() 获取当前目录 os.Getuid() 获取用户ID os.Geteuid() 获取有效用户ID os.Getgid() 获取组ID os.Getegid() 获取有效组ID os.Getpid() 获取进程ID os.Getppid() 获取父进程ID os.Getenv(“GOPATH”) 获取环境变量的值 os.Setenv(“ORACLE_BASE”, “/op/oracle/orabase”) 设置环境变量的值 os.Chdir(\"/home/oracle\") 改变当前工作目录 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-os-exec/:1:1","tags":["Go","exec"],"title":"Go exec","uri":"/posts/2024-06-02-go-os-exec/"},{"categories":["Go 库文档"],"content":"Gorm 官网：https://gorm.io/ ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-gorm/:1:0","tags":["Go","gorm"],"title":"Go gorm","uri":"/posts/2024-06-02-go-gorm/"},{"categories":["Go 库文档"],"content":"特性： 全功能 ORM 关联 (Has One，Has Many，Belongs To，Many To Many，多态，单表继承) Create，Save，Update，Delete，Find 中钩子方法 支持 Preload、Joins 的预加载 事务，嵌套事务，Save Point，Rollback To Saved Point Context、预编译模式、DryRun 模式 批量插入，FindInBatches，Find/Create with Map，使用 SQL 表达式、Context Valuer 进行 CRUD SQL 构建器，Upsert，数据库锁，Optimizer/Index/Comment Hint，命名参数，子查询 复合主键，索引，约束 Auto Migration 自定义 Logger 灵活的可扩展插件 API：Database Resolver（多数据库，读写分离）、Prometheus… 每个特性都经过了测试的重重考验 开发者友好 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-gorm/:1:1","tags":["Go","gorm"],"title":"Go gorm","uri":"/posts/2024-06-02-go-gorm/"},{"categories":["Go 库文档"],"content":"quickstart sqlite go get -u gorm.io/gorm go get -u github.com/glebarez/sqlite package main import ( \"github.com/glebarez/sqlite\" \"gorm.io/gorm\" \"gorm.io/gorm/schema\" ) type Product struct { gorm.Model Code string Price uint } func main() { db, err := gorm.Open(sqlite.Open(\"test.db\"), \u0026gorm.Config{ DisableForeignKeyConstraintWhenMigrating: true, NamingStrategy: schema.NamingStrategy{ SingularTable: true, // 设置创建表名时不使用复数 }, }) if err != nil { panic(\"failed to connect database\") } // 迁移 schema db.AutoMigrate(\u0026Product{}) // Create db.Create(\u0026Product{Code: \"D42\", Price: 100}) // Read var product Product db.First(\u0026product, 1) // 根据整形主键查找 db.First(\u0026product, \"code = ?\", \"D42\") // 查找 code 字段值为 D42 的记录 // Update - 将 product 的 price 更新为 200 db.Model(\u0026product).Update(\"Price\", 200) // Update - 更新多个字段 db.Model(\u0026Product{}).Updates(Product{Price: 200, Code: \"F42\"}) // 仅更新非零值字段 db.Model(\u0026Product{}).Updates(map[string]interface{}{\"Price\": 200, \"Code\": \"F42\"}) // Delete - 删除 product db.Delete(\u0026product, 1) } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-gorm/:1:2","tags":["Go","gorm"],"title":"Go gorm","uri":"/posts/2024-06-02-go-gorm/"},{"categories":["Go 库文档"],"content":"模型定义 GORM 定义一个 gorm.Model 结构体，其包括字段 ID、CreatedAt、UpdatedAt、DeletedAt // gorm.Model 的定义 type Model struct { ID uint `gorm:\"primaryKey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt gorm.DeletedAt `gorm:\"index\"` } 嵌入结构体中使用 type Student struct{ gorm.Model StuName string StuAge uint } 字段控制 可导出的字段在使用 GORM 进行 CRUD 时拥有全部的权限，此外，GORM 允许您用标签控制字段级别的权限。这样您就可以让一个字段的权限是只读、只写、只创建、只更新或者被忽略 注意： 使用 GORM Migrator 创建表时，不会创建被忽略的字段 type User struct { Name string `gorm:\"\u003c-:create\"` // 允许读和创建 Name string `gorm:\"\u003c-:update\"` // 允许读和更新 Name string `gorm:\"\u003c-\"` // 允许读和写（创建和更新） Name string `gorm:\"\u003c-:false\"` // 允许读，禁止写 Name string `gorm:\"-\u003e\"` // 只读（除非有自定义配置，否则禁止写） Name string `gorm:\"-\u003e;\u003c-:create\"` // 允许读和写 Name string `gorm:\"-\u003e:false;\u003c-:create\"` // 仅创建（禁止从 db 读） Name string `gorm:\"-\"` // 通过 struct 读写会忽略该字段 } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-gorm/:1:3","tags":["Go","gorm"],"title":"Go gorm","uri":"/posts/2024-06-02-go-gorm/"},{"categories":["Go 库文档"],"content":"CRUD 创建 创建记录 user := User{Name: \"Jinzhu\", Age: 18, Birthday: time.Now()} result := db.Create(\u0026user) // 通过数据的指针来创建 user.ID // 返回插入数据的主键 result.Error // 返回 error result.RowsAffected // 返回插入记录的条数 用指定的字段创建记录 创建记录并更新给出的字段 db.Select(\"Name\", \"Age\", \"CreatedAt\").Create(\u0026user) // INSERT INTO `users` (`name`,`age`,`created_at`) VALUES (\"jinzhu\", 18, \"2020-07-04 11:05:21.775\") 创建记录并更新未给出的字段 db.Omit(\"Name\", \"Age\", \"CreatedAt\").Create(\u0026user) // INSERT INTO `users` (`birthday`,`updated_at`) VALUES (\"2020-01-01 00:00:00.000\", \"2020-07-04 11:05:21.775\") 批量插入 要有效地插入大量记录，请将一个 slice 传递给 Create 方法。 将切片数据传递给 Create 方法，GORM 将生成一个单一的 SQL 语句来插入所有数据，并回填主键的值，钩子方法也会被调用。 var users = []User{{Name: \"jinzhu1\"}, {Name: \"jinzhu2\"}, {Name: \"jinzhu3\"}} db.Create(\u0026users) for _, user := range users { user.ID // 1,2,3 } 使用 CreateInBatches 创建时，你还可以指定创建的数量，例如： var users = []User{{name: \"jinzhu_1\"}, ...., {Name: \"jinzhu_10000\"}} // 数量为 100 db.CreateInBatches(users, 100) 创建钩子 GORM 允许用户定义的钩子有 BeforeSave, BeforeCreate, AfterSave, AfterCreate 创建记录时将调用这些钩子方法，请参考 Hooks 中关于生命周期的详细信息 func (u *User) BeforeCreate(tx *gorm.DB) (err error) { u.UUID = uuid.New() if u.Role == \"admin\" { return errors.New(\"invalid role\") } return } 如果您想跳过 钩子 方法，您可以使用 SkipHooks 会话模式，例如： DB.Session(\u0026gorm.Session{SkipHooks: true}).Create(\u0026user) DB.Session(\u0026gorm.Session{SkipHooks: true}).Create(\u0026users) DB.Session(\u0026gorm.Session{SkipHooks: true}).CreateInBatches(users, 100) 根据Map创建 GORM 支持根据 map[string]interface{} 和 []map[string]interface{}{} 创建记录，例如： db.Model(\u0026User{}).Create(map[string]interface{}{ \"Name\": \"jinzhu\", \"Age\": 18, }) // batch insert from `[]map[string]interface{}{}` db.Model(\u0026User{}).Create([]map[string]interface{}{ {\"Name\": \"jinzhu_1\", \"Age\": 18}, {\"Name\": \"jinzhu_2\", \"Age\": 20}, }) 注意： 根据 map 创建记录时，association 不会被调用，且主键也不会自动填充 高级选项 关联创建 创建关联数据时，如果关联值是非零值，这些关联会被 upsert，且它们的 Hook 方法也会被调用 type CreditCard struct { gorm.Model Number string UserID uint } type User struct { gorm.Model Name string CreditCard CreditCard } db.Create(\u0026User{ Name: \"jinzhu\", CreditCard: CreditCard{Number: \"411111111111\"} }) // INSERT INTO `users` ... // INSERT INTO `credit_cards` ... 您也可以通过 Select、 Omit 跳过关联保存，例如： db.Omit(\"CreditCard\").Create(\u0026user) // 跳过所有关联 db.Omit(clause.Associations).Create(\u0026user) 默认值 您可以通过标签 default 为字段定义默认值，如： type User struct { ID int64 Name string `gorm:\"default:galeone\"` Age int64 `gorm:\"default:18\"` } 插入记录到数据库时，默认值 会被用于 填充值为 零值 的字段 注意 像 0、''、false 等零值，不会将这些字段定义的默认值保存到数据库。您需要使用指针类型或 Scanner/Valuer 来避免这个问题，例如： type User struct { gorm.Model Name string Age *int `gorm:\"default:18\"` Active sql.NullBool `gorm:\"default:true\"` } 注意 若要数据库有默认、虚拟/生成的值，你必须为字段设置 default 标签。若要在迁移时跳过默认值定义，你可以使用 default:(-)，例如： type User struct { ID string `gorm:\"default:uuid_generate_v3()\"` // db func FirstName string LastName string Age uint8 FullName string `gorm:\"-\u003e;type:GENERATED ALWAYS AS (concat(firstname,' ',lastname));default:(-);\"` } 使用虚拟/生成的值时，你可能需要禁用它的创建、更新权限，查看 字段级权限 获取详情 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-gorm/:1:4","tags":["Go","gorm"],"title":"Go gorm","uri":"/posts/2024-06-02-go-gorm/"},{"categories":["Go 库文档"],"content":"查询 检测单个对象 GORM 提供了 First、Take、Last 方法，以便从数据库中检索单个对象。当查询数据库时它添加了 LIMIT 1 条件，且没有找到记录时，它会返回 ErrRecordNotFound 错误 // 获取第一条记录（主键升序） db.First(\u0026user) // SELECT * FROM users ORDER BY id LIMIT 1; // 获取一条记录，没有指定排序字段 db.Take(\u0026user) // SELECT * FROM users LIMIT 1; // 获取最后一条记录（主键降序） db.Last(\u0026user) // SELECT * FROM users ORDER BY id DESC LIMIT 1; result := db.First(\u0026user) result.RowsAffected // 返回找到的记录数 result.Error // returns error // 检查 ErrRecordNotFound 错误 errors.Is(result.Error, gorm.ErrRecordNotFound) 如果你想避免ErrRecordNotFound错误，你可以使用Find，比如db.Limit(1).Find(\u0026user)，Find方法可以接受struct和slice的数据。 First, Last方法将按主键排序查找第一/最后一条记录，只有在用struct查询或提供model value时才有效，如果当前model没有定义主键，将按第一个字段排序，例如： var user User var users []User // 可以 db.First(\u0026user) // SELECT * FROM `users` ORDER BY `users`.`id` LIMIT 1 // 可以 result := map[string]interface{}{} db.Model(\u0026User{}).First(\u0026result) // SELECT * FROM `users` ORDER BY `users`.`id` LIMIT 1 // 不行 result := map[string]interface{}{} db.Table(\"users\").First(\u0026result) // 但可以配合 Take 使用 result := map[string]interface{}{} db.Table(\"users\").Take(\u0026result) // 根据第一个字段排序 type Language struct { Code string Name string } db.First(\u0026Language{}) // SELECT * FROM `languages` ORDER BY `languages`.`code` LIMIT 1 用主键检索 如果主键是数值类型，也可以通过 内联条件 传入主键来检索对象。如果主键是 string 类型，要小心避免 SQL 注入，查看 安全 获取详情 db.First(\u0026user, 10) // SELECT * FROM users WHERE id = 10; db.First(\u0026user, \"10\") // SELECT * FROM users WHERE id = 10; db.Find(\u0026users, []int{1,2,3}) // SELECT * FROM users WHERE id IN (1,2,3); 如果主键是像 uuid 这样的字符串，您需要这要写： db.First(\u0026user, \"id = ?\", \"1b74413f-f3b8-409f-ac47-e8c062e3472a\") // SELECT * FROM users WHERE id = \"1b74413f-f3b8-409f-ac47-e8c062e3472a\"; 更新 db.Model(\u0026User{}).Where(\"active = ?\", true).Update(\"name\", \"hello\") ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-gorm/:1:5","tags":["Go","gorm"],"title":"Go gorm","uri":"/posts/2024-06-02-go-gorm/"},{"categories":["Go 库文档"],"content":"Go Goph 模块 github地址：https://github.com/melbahja/goph go开发封装的 ssh client 模块 Features Easy to use and simple API. Supports known hosts by default. Supports connections with passwords. Supports connections with private keys. Supports connections with protected private keys with passphrase. Supports upload files from local to remote. Supports download files from remote to local. Supports connections with ssh agent (Unix systems only). Supports adding new hosts to known_hosts file. Supports file system operations like: Open, Create, Chmod... Supports context.Context for command cancellation. ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-goph/:1:0","tags":["Go","goph","ssh"],"title":"Go goph","uri":"/posts/2024-06-02-go-goph/"},{"categories":["Go 库文档"],"content":"1、安装 go get github.com/melbahja/goph ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-goph/:1:1","tags":["Go","goph","ssh"],"title":"Go goph","uri":"/posts/2024-06-02-go-goph/"},{"categories":["Go 库文档"],"content":"2、使用示例 1）使用ssh 执行命令 package main import ( \"log\" \"fmt\" \"github.com/melbahja/goph\" ) func main() { // Start new ssh connection with private key. auth, err := goph.Key(\"/home/serialt/.ssh/id_rsa\", \"\") if err != nil { log.Fatal(err) } // goph.New 默认使用22端口，如果非22端口，则参考goph.New的实现 client, err := goph.New(\"root\", \"192.1.1.3\", auth) if err != nil { log.Fatal(err) } // Defer closing the network connection. defer client.Close() // Execute your command. out, err := client.Run(\"ls /tmp/\") if err != nil { log.Fatal(err) } // Get your output as []byte. fmt.Println(string(out)) } 2）密钥带密码 auth, err := goph.Key(\"/home/serialt/.ssh/id_rsa\", \"you_passphrase_here\") if err != nil { // handle error } client, err := goph.New(\"root\", \"192.1.1.3\", auth) 3）使用密码连接 auth, err := goph.UseAgent() if err != nil { // handle error } client, err := goph.New(\"root\", \"192.1.1.3\", auth) 4）上传和下载文件 // upload local file to remote err := client.Upload(\"/path/to/local/file\", \"/path/to/remote/file\") // download remote file to local err := client.Download(\"/path/to/remote/file\", \"/path/to/local/file\") 5）执行shell命令 // execute bash commands out, err := client.Run(\"bash -c 'printenv'\") // execute bash command whith timeout context, cancel := context.WithTimeout(ctx, time.Second) defer cancel() // will send SIGINT and return error after 1 second out, err := client.RunContext(ctx, \"sleep 5\") // execute bash command whith env variables out, err := client.Run(`env MYVAR=\"MY VALUE\" bash -c 'echo $MYVAR;'`) 6）使用goph cmd Goph.Cmd struct is like the Go standard os/exec.Cmd. // Get new `Goph.Cmd` cmd, err := client.Command(\"ls\", \"-alh\", \"/tmp\") // or with context: // cmd, err := client.CommandContext(ctx, \"ls\", \"-alh\", \"/tmp\") if err != nil { // handle the error! } // You can set env vars, but the server must be configured to `AcceptEnv line`. cmd.Env = []string{\"MY_VAR=MYVALUE\"} // Run you command. err = cmd.Run() ust like os/exec.Cmd you can run CombinedOutput, Output, Start, Wait, and ssh.Session methods like Signal… 7）使用sftp操作文件系统 sftp, err := client.NewSftp() if err != nil { // handle the error! } file, err := sftp.Create(\"/tmp/remote_file\") file.Write([]byte(`Hello world`)) file.Close() For more file operations see SFTP Docs. ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-goph/:1:2","tags":["Go","goph","ssh"],"title":"Go goph","uri":"/posts/2024-06-02-go-goph/"},{"categories":["Go 库文档"],"content":"3、官方示例 package main import ( \"bufio\" \"context\" \"errors\" \"flag\" \"fmt\" \"log\" \"net\" \"os\" \"strings\" \"time\" \"github.com/melbahja/goph\" \"github.com/pkg/sftp\" \"golang.org/x/crypto/ssh\" \"golang.org/x/crypto/ssh/terminal\" ) // // Run command and auth via password: // \u003e go run main.go --ip 192.168.122.102 --pass --cmd ls // // Run command and auth via private key: // \u003e go run main.go --ip 192.168.122.102 --cmd ls // Or: // \u003e go run main.go --ip 192.168.122.102 --key /path/to/private_key --cmd ls // // Run command and auth with private key and passphrase: // \u003e go run main.go --ip 192.168.122.102 --passphrase --cmd ls // // Run a command and interrupt it after 1 second: // \u003e go run main.go --ip 192.168.122.102 --cmd \"sleep 10\" --timeout=1s // // You can test with the interactive mode without passing --cmd flag. // var ( err error auth goph.Auth client *goph.Client addr string user string port uint key string cmd string pass bool passphrase bool timeout time.Duration agent bool sftpc *sftp.Client ) func init() { flag.StringVar(\u0026addr, \"ip\", \"127.0.0.1\", \"machine ip address.\") flag.StringVar(\u0026user, \"user\", \"root\", \"ssh user.\") flag.UintVar(\u0026port, \"port\", 22, \"ssh port number.\") flag.StringVar(\u0026key, \"key\", strings.Join([]string{os.Getenv(\"HOME\"), \".ssh\", \"id_rsa\"}, \"/\"), \"private key path.\") flag.StringVar(\u0026cmd, \"cmd\", \"\", \"command to run.\") flag.BoolVar(\u0026pass, \"pass\", false, \"ask for ssh password instead of private key.\") flag.BoolVar(\u0026agent, \"agent\", false, \"use ssh agent for authentication (unix systems only).\") flag.BoolVar(\u0026passphrase, \"passphrase\", false, \"ask for private key passphrase.\") flag.DurationVar(\u0026timeout, \"timeout\", 0, \"interrupt a command with SIGINT after a given timeout (0 means no timeout)\") } func VerifyHost(host string, remote net.Addr, key ssh.PublicKey) error { // // If you want to connect to new hosts. // here your should check new connections public keys // if the key not trusted you shuld return an error // // hostFound: is host in known hosts file. // err: error if key not in known hosts file OR host in known hosts file but key changed! hostFound, err := goph.CheckKnownHost(host, remote, key, \"\") // Host in known hosts but key mismatch! // Maybe because of MAN IN THE MIDDLE ATTACK! if hostFound \u0026\u0026 err != nil { return err } // handshake because public key already exists. if hostFound \u0026\u0026 err == nil { return nil } // Ask user to check if he trust the host public key. if askIsHostTrusted(host, key) == false { // Make sure to return error on non trusted keys. return errors.New(\"you typed no, aborted!\") } // Add the new host to known hosts file. return goph.AddKnownHost(host, remote, key, \"\") } func main() { flag.Parse() var err error if agent || goph.HasAgent() { auth, err = goph.UseAgent() } else if pass { auth = goph.Password(askPass(\"Enter SSH Password: \")) } else { auth, err = goph.Key(key, getPassphrase(passphrase)) } if err != nil { panic(err) } client, err = goph.NewConn(\u0026goph.Config{ User: user, Addr: addr, Port: port, Auth: auth, Callback: VerifyHost, }) if err != nil { panic(err) } // Close client net connection defer client.Close() // If the cmd flag exists if cmd != \"\" { ctx := context.Background() // create a context with timeout, if supplied in the argumetns if timeout \u003e 0 { var cancel context.CancelFunc ctx, cancel = context.WithTimeout(ctx, timeout) defer cancel() } out, err := client.RunContext(ctx, cmd) fmt.Println(string(out), err) return } // else open interactive mode. playWithSSHJustForTestingThisProgram(client) } func askPass(msg string) string { fmt.Print(msg) pass, err := terminal.ReadPassword(0) if err != nil { panic(err) } fmt.Println(\"\") return strings.TrimSpace(string(pass)) } func getPassphrase(ask bool) string { if ask { return askPass(\"Enter Private Key Passphrase: \") } return \"\" } func askIsHostTrusted(host string, key ssh.PublicKey) bool { reader := bufio.NewReader(os.Stdin) fmt.Printf(\"Unknown Host: %s \\nFingerprint: %s \\n\", host, ssh.FingerprintSHA256(key)) fmt.Print(\"Would you like ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-goph/:1:3","tags":["Go","goph","ssh"],"title":"Go goph","uri":"/posts/2024-06-02-go-goph/"},{"categories":["Go 库文档"],"content":"Go flag模块 参考链接：https://www.liwenzhou.com/posts/Go/go_flag/ Go语言内置的flag包实现了命令行参数的解析，flag包使得开发命令行工具更为简单。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-flag/:1:0","tags":["Go","flag"],"title":"Go flag","uri":"/posts/2024-06-02-go-flag/"},{"categories":["Go 库文档"],"content":"os.Args 如果你只是简单的想要获取命令行参数，可以像下面的代码示例一样使用os.Args来获取命令行参数。 package main import ( \"fmt\" \"os\" ) //os.Args demo func main() { //os.Args是一个[]string if len(os.Args) \u003e 0 { for index, arg := range os.Args { fmt.Printf(\"args[%d]=%v\\n\", index, arg) } } } 将上面的代码执行go build -o \"args_demo\"编译之后，执行： $ ./args_demo a b c d args[0]=./args_demo args[1]=a args[2]=b args[3]=c args[4]=d os.Args是一个存储命令行参数的字符串切片，它的第一个元素是执行文件的名称。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-flag/:1:1","tags":["Go","flag"],"title":"Go flag","uri":"/posts/2024-06-02-go-flag/"},{"categories":["Go 库文档"],"content":"flag包基本使用 本文介绍了flag包的常用函数和基本用法，更详细的内容请查看官方文档。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-flag/:1:2","tags":["Go","flag"],"title":"Go flag","uri":"/posts/2024-06-02-go-flag/"},{"categories":["Go 库文档"],"content":"导入flag包 import flag ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-flag/:1:3","tags":["Go","flag"],"title":"Go flag","uri":"/posts/2024-06-02-go-flag/"},{"categories":["Go 库文档"],"content":"flag参数类型 flag包支持的命令行参数类型有bool、int、int64、uint、uint64、float float64、string、duration。 flag参数 有效值 字符串flag 合法字符串 整数flag 1234、0664、0x1234等类型，也可以是负数。 浮点数flag 合法浮点数 bool类型flag 1, 0, t, f, T, F, true, false, TRUE, FALSE, True, False。 时间段flag 任何合法的时间段字符串。如”300ms”、”-1.5h”、”2h45m”。 合法的单位有”ns”、”us” /“µs”、”ms”、”s”、”m”、”h”。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-flag/:1:4","tags":["Go","flag"],"title":"Go flag","uri":"/posts/2024-06-02-go-flag/"},{"categories":["Go 库文档"],"content":"定义命令行flag参数 有以下两种常用的定义命令行flag参数的方法。 flag.Type() 基本格式如下： flag.Type(flag名, 默认值, 帮助信息)*Type 例如我们要定义姓名、年龄、婚否三个命令行参数，我们可以按如下方式定义： name := flag.String(\"name\", \"张三\", \"姓名\") age := flag.Int(\"age\", 18, \"年龄\") married := flag.Bool(\"married\", false, \"婚否\") delay := flag.Duration(\"d\", 0, \"时间间隔\") 需要注意的是，此时name、age、married、delay均为对应类型的指针。 flag.TypeVar() 基本格式如下： flag.TypeVar(Type指针, flag名, 默认值, 帮助信息) 例如我们要定义姓名、年龄、婚否三个命令行参数，我们可以按如下方式定义： var name string var age int var married bool var delay time.Duration flag.StringVar(\u0026name, \"name\", \"张三\", \"姓名\") flag.IntVar(\u0026age, \"age\", 18, \"年龄\") flag.BoolVar(\u0026married, \"married\", false, \"婚否\") flag.DurationVar(\u0026delay, \"d\", 0, \"时间间隔\") flag.Parse() 通过以上两种方法定义好命令行flag参数后，需要通过调用flag.Parse()来对命令行参数进行解析。 支持的命令行参数格式有以下几种： -flag xxx （使用空格，一个-符号） --flag xxx （使用空格，两个-符号） -flag=xxx （使用等号，一个-符号） --flag=xxx （使用等号，两个-符号） 其中，布尔类型的参数必须使用等号的方式指定。 Flag解析在第一个非flag参数（单个”-“不是flag参数）之前停止，或者在终止符”–“之后停止。 flag其他函数 flag.Args() ////返回命令行参数后的其他参数，以[]string类型 flag.NArg() //返回命令行参数后的其他参数个数 flag.NFlag() //返回使用的命令行参数个数 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-flag/:1:5","tags":["Go","flag"],"title":"Go flag","uri":"/posts/2024-06-02-go-flag/"},{"categories":["Go 库文档"],"content":"完整示例 定义 func main() { //定义命令行参数方式1 var name string var age int var married bool var delay time.Duration flag.StringVar(\u0026name, \"name\", \"张三\", \"姓名\") flag.IntVar(\u0026age, \"age\", 18, \"年龄\") flag.BoolVar(\u0026married, \"married\", false, \"婚否\") flag.DurationVar(\u0026delay, \"d\", 0, \"延迟的时间间隔\") //解析命令行参数 flag.Parse() fmt.Println(name, age, married, delay) //返回命令行参数后的其他参数 fmt.Println(flag.Args()) //返回命令行参数后的其他参数个数 fmt.Println(flag.NArg()) //返回使用的命令行参数个数 fmt.Println(flag.NFlag()) } 使用 命令行参数使用提示： $ ./flag_demo -help Usage of ./flag_demo: -age int 年龄 (default 18) -d duration 时间间隔 -married 婚否 -name string 姓名 (default \"张三\") 正常使用命令行flag参数： $ ./flag_demo -name 沙河娜扎 --age 28 -married=false -d=1h30m 沙河娜扎 28 false 1h30m0s [] 0 4 使用非flag命令行参数： $ ./flag_demo a b c 张三 18 false 0s [a b c] 3 0 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-flag/:1:6","tags":["Go","flag"],"title":"Go flag","uri":"/posts/2024-06-02-go-flag/"},{"categories":["Go 库文档"],"content":"GO 文件数据库boltdb github地址: https://github.com/etcd-io/bbolt https://github.com/boltdb/bolt 由于作者个人能力有限，宣布不再维护，建议使用社区维护的bbolt 参考：https://zhuanlan.zhihu.com/p/84988890 使用 go get go.etcd.io/bbolt/... ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:0","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"1、介绍 BoltDB是纯Go语言实现的持久化解决方案，保存数据至内存映射文件。称之为持久化解决方案不是数据库，因为数据库这个词有很多额外功能是bolt所不具备的。正是因为缺乏这些功能使得bolt如此优雅、好用。 Bolt就是一个Go包。无需在系统中安装，开始编码前也无需配置，什么都不需要，仅需要go get github.com/boltdb/bolt，然后import “github.com/boltdb/bolt”。 要完全使用bolt的存储功能，只需要一个文件名。无论从开发者或用户视角都感觉不可思议。不知你的感想如何，在我的工作经历中花过很多时间搭建数据库环境，调试配置问题，用户和权限以及其他各种问题，如关系型数据库PostgreSql、Oracle和NoSQL。这些bolt都不需要，没有用户、无需安装，仅一个文件名。这对应用程序的用户来说也是一种恩惠，因为他们也不必为那些麻烦问题而瞎折腾。 Bolt不是关系型数据库。甚至不存储文档，虽然你可以按照这种方式使用它。其仅仅存储键值对…但是如果你不知道这是什么意思或者不知道你如何使用它进行存储，也不用担心。它超级简单，而且非常灵活，让我们来看看。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:1","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"2、使用示例： bolt存储是分组为桶，桶是一组键值对集合的名称，就像Go中的map。桶的名称、键以及值都是[]byte类型。桶可以包括其他桶，也可以通过[]byte类型名称作为key。 Bolt基本上是一组嵌套映射。这种简单性使得它易于使用。不需要设置表、模式、复杂的查询语言。 1）创建和打开一个数据库 package main import ( \"log\" bolt \"go.etcd.io/bbolt\" ) func main() { // Open the my.db data file in your current directory. // It will be created if it doesn't exist. db, err := bolt.Open(\"my.db\", 0600, nil) if err != nil { log.Fatal(err) } defer db.Close() ... } 这里到 db 不支持多链接。这是因为对于 database file 一个链接保持了一个文件锁 file lock。如果并发，后续链接会阻塞。可以为单个链接添加 超时控制 db, err := bolt.Open(\"my.db\", 0600, \u0026bolt.Options{Timeout: 1 * time.Second}) ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:2","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"3、事务 并发读写 同时只能有 一个读写事务 多个只读事务 注意：在事务开始时，会保持一个数据视图 这意味着事务处理过程中不会由于别处更改而改变 线程安全 单个事务和它所创建的所有对象（桶，键）都不是线程安全的。 建议加锁 或者 每一个 goroutine 并发都开启 一个 事务 当然，从 db 这个 bbolt 的顶级结构创建 事务 是 线程安全 的 死锁 前面提到的 读写事务 和 只读事务 拒绝相互依赖。当然也不能在同一个 goroutine 里。 死锁原因是 读写事务 需要周期性重新映射 data 文件（即database）。这在开启只读事务时是不可行的。 读写事务 使用 db.Update开启一个读写事务 err := db.Update(func(tx *bolt.Tx) error{ ··· return nil }) 上文提过，在一个事务中 ，数据视图是一样的。 （详细解释就是，在这个函数作用域中，数据对你呈现最终一致性） 返回值 bboltdb 根据你的返回值判断事务状态，你可以添加任意逻辑并认为出错时返回 return err bboltdb 会回滚，如果 return nil 则提交你的事务。 建议永远检查 Update 的返回值，因为他会返回如 硬盘压力 等造成事务失败的信息（这是在你的逻辑之外的情况） 注意：你自定义返回 error 的 error 信息同样会被传递出来。 只读事务 使用 db.View 来新建一个 只读事务 err := db.View(func(tx *bolt.Tx) error { ··· return nil }) 同上，你会获得一个一致性的数据视图。 当然，只读事务 只能检索信息，不会有任何更改。（btw,但是你可以 copy 一个 database 的副本，毕竟这只需要读数据） 批量读写事务 读写事务 db.Update 最后需要对 database提交更改，这会等待硬盘就绪。 每一次文件读写都是和磁盘交互。这不是一个小开销。 你可以使用 db.Batch 开启一个 批处理事务。他会在最后批量提交（其实是多个 goroutines 开启 db.Batch 事务时有机会合并之后一起提交）从而减小了开销。 ⚠️：db.Batch 只对 goroutine 起效 使用 批处理事务 需要做取舍，用 幂等函数 换取 速度 ⚠️： db.Batch 在一部分事务失败的时候会尝试多次调用那些事务函数，如果不是幂等会造成不可预知的非最终一致性。 例：使用事务外的变量来使你的日志不那么奇怪 var id uint64 err := db.Batch(func(tx *bolt.Tx) error { // Find last key in bucket, decode as bigendian uint64, increment // by one, encode back to []byte, and add new key. ... id = newValue return nil }) if err != nil { return ... } fmt.Println(\"Allocated ID %d\", id) 手动事务 可以手动进行事务的 开启 ，回滚，新建对象，提交等操作。因为本身 db.Update 和 db.View 就是他们的包装 ⚠️：手动事务记得 关闭 （Close） 开启事务使用 db.Begin(bool) 同时参数代表着是否可以写操作。如下： true - 读写事务 false - 只读事务 // Start a writable transaction. tx, err := db.Begin(true) if err != nil { return err } defer tx.Rollback() // Use the transaction... _, err := tx.CreateBucket([]byte(\"MyBucket\")) if err != nil { return err } // Commit the transaction and check for error. if err := tx.Commit(); err != nil { return err } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:3","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"4、存储与buckets bucket 桶是键值对的集合。在一个桶中，键值唯一。 1）创建bucket 使用 Tx.CreateBucket() 和 Tx.CreateBucketIfNotExists() 建立一个新桶（推荐使用第二个） 接受参数是桶的名字 2）删除 使用 Tx.DeleteBucket() 根据桶的名字来删除 示例： func main() { db, err := bbolt.Open(\"./data\", 0666, nil) if err != nil { log.Fatal(err) } defer db.Close() db.Update(func(tx *bbolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(\"MyBucket\")) if err != nil { return fmt.Errorf(\"create bucket: %v\", err) } if err = tx.DeleteBucket([]byte(\"MyBucket\")); err != nil { return err } return nil }) } 2）KV存储 Put: 使用Bucket.Put()来存储键值对，接收两个 []byte 类型的参数 db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(\"MyBucket\")) err := b.Put([]byte(\"answer\"), []byte(\"42\")) return err }) Get: 使用 Bucket.Get() 来查询键值。参数是一个 []byte（别忘了这次我们只是查询，可以使用 只读事务） db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(\"MyBucket\")) v := b.Get([]byte(\"answer\")) fmt.Printf(\"The answer is: %s\\n\", v) return nil }) 细心会注意到，Get是不会返回 error 的，这是因为 Get() 一定能正常工作（除非系统错误），相应的，当返回 nil 时，查询的键值对不存在。 ⚠️：注意 0 长度的值 和 不存在键值对 的行为是不一样的。（一个返回是 nil， 一个不是） func main() { db, err := bolt.Open(\"./data.db\", 0666, nil) if err != nil { log.Fatal(err) } defer db.Close() err = db.Update(func(tx *bolt.Tx) error { b, err := tx.CreateBucketIfNotExists([]byte(\"MyBucket\")) if err != nil { return fmt.Errorf(\"create bucket: %v\", err) } if err = b.Put([]byte(\"answer\"), []byte(\"42\")); err != nil { return err } if err = b.Put([]byte(\"zero\"), []byte(\"\")); err != nil { return err } return nil }) db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(\"MyBucket\")) v := b.Get([]byte(\"noexists\")) fmt.Println(reflect.DeepEqual(v, nil)) // false fmt.Println(v == nil) // true v = b.Get([]byte(\"zero\")) fmt.Println(reflect.DeepEqual(v, nil)) // false fmt.Println(v == nil) // true return nil }) } Delete: 使用 Bucket.Delete() 删除键值对 db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(\"MyBucket\")) fmt.Println(b.Get([]byte(\"answer\"))) err := b.Delete([]byte(\"answer\")) if err != nil { return err } return nil }) ⚠️： Get() 获取到的字节切片值只在当前事务（当前函数作用域）有效，如果要在其他事务中使用需要使用 copy() 将其拷贝到其他的字节切片 Tricks: 桶的自增键 使用 NextSequence()来创建自增键，见下例 // CreateUser saves u to the store. The new user ID is set on u once the data is persisted. func (s *Store) CreateUser(u *User) error { return s.db.Update(func(tx *bolt.Tx) error { // Retrieve the users bucket. // This should be created when the DB is first opened. b := tx.Bucket([]byte(\"users\")) // Generate ID for the user. // This returns an error only if the Tx is closed or not writeable. // That can't happen in an Update() call so I ignore the error check. id, _ := b.NextSequence() u.ID = int(id) // Marshal user data into bytes. buf, err := json.Marshal(u) if err != nil { return err } // Persist bytes to users bucket. return b.Put(itob(u.ID), buf) }) } // itob returns an 8-byte big endian representation of v. func itob(v int) []byte { b := make([]byte, 8) binary.BigEndian.PutUint64(b, uint64(v)) return b } type User struct { ID int ... } 嵌套桶 很简单的，桶可以实现嵌套存储 func (*Bucket) CreateBucket(key []byte) (*Bucket, error) func (*Bucket) CreateBucketIfNotExists(key []byte) (*Bucket, error) func (*Bucket) DeleteBucket(key []byte) error 例子：假设您有一个多租户应用程序，其中根级别存储桶是帐户存储桶。该存储桶内部有一系列帐户的序列，这些帐户本身就是存储桶。在序列存储桶（子桶）中，可能有许多相关的存储桶（Users，Note等）。 // createUser creates a new user in the given account. func createUser(accountID int, u *User) error { // Start the transaction. tx, err := db.Begin(true) if err != nil { return err } defer tx.Rollback() // Retrieve the root bucket for the account. // Assume this has already been created when the account was set up. root := tx.Bucket([]byte(strconv.FormatUint(accountID, 10))) // Setup the users bucket. bkt, err := root.CreateBucketIfNotExists([]byte(\"USERS\")) if err != nil { return err } // Generate an ID for the new user. userID, err := bkt.NextSequence() if err != nil { return err } u.ID = userID // Marshal and save the encoded user. if buf, err := json.Marshal(u); err != nil { return err } else if err := bkt.Put([]byte(strconv.FormatUint(u.ID, 10)),","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:4","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"5、高级用法 boltdb 是一个单一的文件，所以很容易备份。你可以使用Tx.writeto()函数写一致的数据库。如果从只读事务调用这个函数，它将执行热备份，而不会阻塞其他数据库的读写操作。 默认情况下，它将使用一个常规文件句柄，该句柄将利用操作系统的页面缓存。 有关优化大于RAM数据集的信息，请参见Tx文档。 一个常见的用例是在HTTP上进行备份，这样您就可以使用像cURL这样的工具来进行数据库备份： func BackupHandleFunc(w http.ResponseWriter, req *http.Request) { err := db.View(func(tx *bolt.Tx) error { w.Header().Set(\"Content-Type\", \"application/octet-stream\") w.Header().Set(\"Content-Disposition\", `attachment; filename=\"my.db\"`) w.Header().Set(\"Content-Length\", strconv.Itoa(int(tx.Size()))) _, err := tx.WriteTo(w) return err }) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } } 然后您可以使用此命令进行备份： $ curl http://localhost/backup \u003e my.db 或者你可以打开你的浏览器以http://localhost/backup，它会自动下载。 如果你想备份到另一个文件，你可以使用TX.copyfile()辅助功能。 Statistics 数据库对运行的许多内部操作保持一个运行计数，这样您就可以更好地了解发生了什么。通过捕捉两个时间点数据的快照，我们可以看到在这个时间范围内执行了哪些操作。 例如，我们可以用一个 goroutine 里记录统计每一个 10 秒： go func() { // Grab the initial stats. prev := db.Stats() for { // Wait for 10s. time.Sleep(10 * time.Second) // Grab the current stats and diff them. stats := db.Stats() diff := stats.Sub(\u0026prev) // Encode stats to JSON and print to STDERR. json.NewEncoder(os.Stderr).Encode(diff) // Save stats for the next loop. prev = stats } }() 将这些信息通过管道输出到监控也很有用。 Read-Only Mode 可以开启只读模式防止错误更改 db, err := bolt.Open(\"my.db\", 0666, \u0026bolt.Options{ReadOnly: true}) if err != nil { log.Fatal(err) } 现在使用 db.Update() 等开启读写事务 将会阻塞 Mobile Use 移动端支持由 gomobile 工具提供 Create a struct that will contain your database logic and a reference to a *bolt.DB with a initializing constructor that takes in a filepath where the database file will be stored. Neither Android nor iOS require extra permissions or cleanup from using this method. func NewBoltDB(filepath string) *BoltDB { db, err := bolt.Open(filepath+\"/demo.db\", 0600, nil) if err != nil { log.Fatal(err) } return \u0026BoltDB{db} } type BoltDB struct { db *bolt.DB ... } func (b *BoltDB) Path() string { return b.db.Path() } func (b *BoltDB) Close() { b.db.Close() } Database logic should be defined as methods on this wrapper struct. To initialize this struct from the native language (both platforms now sync their local storage to the cloud. These snippets disable that functionality for the database file): Android String path; if (android.os.Build.VERSION.SDK_INT \u003e=android.os.Build.VERSION_CODES.LOLLIPOP){ path = getNoBackupFilesDir().getAbsolutePath(); } else{ path = getFilesDir().getAbsolutePath(); } Boltmobiledemo.BoltDB boltDB = Boltmobiledemo.NewBoltDB(path) iOS - (void)demo { NSString* path = [NSSearchPathForDirectoriesInDomains(NSLibraryDirectory, NSUserDomainMask, YES) objectAtIndex:0]; GoBoltmobiledemoBoltDB * demo = GoBoltmobiledemoNewBoltDB(path); [self addSkipBackupAttributeToItemAtPath:demo.path]; //Some DB Logic would go here [demo close]; } - (BOOL)addSkipBackupAttributeToItemAtPath:(NSString *) filePathString { NSURL* URL= [NSURL fileURLWithPath: filePathString]; assert([[NSFileManager defaultManager] fileExistsAtPath: [URL path]]); NSError *error = nil; BOOL success = [URL setResourceValue: [NSNumber numberWithBool: YES] forKey: NSURLIsExcludedFromBackupKey error: \u0026error]; if(!success){ NSLog(@\"Error excluding %@ from backup %@\", [URL lastPathComponent], error); } return success; } ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:5","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"6、扩展阅读 更多指导 For more information on getting started with Bolt, check out the following articles: Intro to BoltDB: Painless Performant Persistence by Nate Finch. Bolt – an embedded key/value database for Go by Progville ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:6","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"7、与其他数据库的比较 Postgres，MySQL和其他关系数据库 关系数据库将数据组织成行，并且只能通过使用SQL进行访问。这种方法在存储和查询数据方面提供了灵活性，但是在解析和计划SQL语句时也会产生开销。Bolt通过字节切片键访问所有数据。这使得Bolt可以快速地通过键读取和写入数据，但是不提供将值连接在一起的内置支持。 大多数关系数据库（SQLite除外）都是独立于应用程序运行的独立服务器。这使您的系统具有将多个应用程序服务器连接到单个数据库服务器的灵活性，但同时也增加了在网络上序列化和传输数据的开销。Bolt作为应用程序中包含的库运行，因此所有数据访问都必须经过应用程序的过程。这使数据更接近您的应用程序，但限制了对数据的多进程访问。 LevelDB，RocksDB LevelDB及其派生类（RocksDB，HyperLevelDB）与Bolt类似，因为它们是捆绑到应用程序中的库，但是它们的底层结构是日志结构的合并树（LSM树）。LSM树通过使用预写日志和称为SSTables的多层排序文件来优化随机写入。Bolt在内部使用B +树，并且仅使用一个文件。两种方法都需要权衡。 如果您需要较高的随机写入吞吐量（\u003e 10,000 w / sec），或者需要使用旋转磁盘，那么LevelDB可能是一个不错的选择。如果您的应用程序是大量读取或进行大量范围扫描，那么Bolt可能是一个不错的选择。 另一个重要的考虑因素是LevelDB没有事务。它支持键/值对的批量写入，并且支持读取快照，但不能使您安全地执行比较和交换操作。Bolt支持完全可序列化的ACID事务。 LMDB Bolt最初是LMDB的端口，因此在架构上相似。两者都使用B +树，具有ACID语义和完全可序列化的事务，并支持使用单个写入器和多个读取器的无锁MVCC。 这两个项目有些分歧。LMDB专注于原始性能，而Bolt专注于简单性和易用性。例如，出于性能考虑，LMDB允许执行几种不安全的操作，例如直接写入。Bolt选择禁止可能使数据库处于损坏状态的操作。Bolt唯一的例外是DB.NoSync。 API也有一些区别。打开LMDB时需要最大的mmap大小，mdb_env而Bolt会自动处理增量mmap的大小。LMDB使用多个标志来重载getter和setter函数，而Bolt将这些特殊情况拆分为自己的函数。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:7","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"7、注意事项和局限性 选择合适的工具来完成这项工作很重要，而Bolt也不例外。在评估和使用Bolt时，需要注意以下几点： Bolt非常适合读取密集型工作负载。顺序写入性能也很快，但是随机写入可能会很慢。您可以使用DB.Batch()或添加预写日志来帮助缓解此问题。 Bolt在内部使用B + tree，因此可以有很多随机页面访问。与旋转磁盘相比，SSD可以显着提高性能。 尝试避免长时间运行的读取事务。Bolt使用写时复制功能，因此在旧事务使用旧页时无法回收这些旧页。 从Bolt返回的字节片仅在事务期间有效。一旦事务被提交或回滚，它们所指向的内存就可以被新页面重用，或者可以从虚拟内存中取消映射，unexpected fault address访问时会出现恐慌。 Bolt在数据库文件上使用排他写锁定，因此不能被多个进程共享。 使用时要小心Bucket.FillPercent。为具有随机插入的存储桶设置较高的填充百分比将导致数据库的页面利用率非常差。 通常使用较大的水桶。较小的存储桶一旦超过页面大小（通常为4KB），就会导致页面利用率下降。 批量加载大量随机写入新的存储桶可能很慢，因为在提交事务之前页面不会拆分。建议不要在单个事务中将100,000个以上的键/值对随机插入到一个新的存储桶中。 Bolt使用内存映射文件，因此底层操作系统可以处理数据的缓存。通常，操作系统将在内存中缓存尽可能多的文件，并根据需要将内存释放给其他进程。这意味着在使用大型数据库时，Bolt可能会显示很高的内存使用率。但是，这是预料之中的，操作系统将根据需要释放内存。只要Bolt的内存映射适合进程虚拟地址空间，它就可以处理比可用物理RAM大得多的数据库。在32位系统上可能会出现问题。 Bolt数据库中的数据结构是内存映射的，因此数据文件将是特定于字节序的。这意味着您无法将Bolt文件从小字节序计算机复制到大字节序计算机并使其正常工作。对于大多数用户而言，这不是问题，因为大多数现代CPU的字节序都很少。 由于页面在磁盘上的布局方式，Bolt无法截断数据文件并将可用页面返回到磁盘。取而代之的是，Bolt会在其数据文件中维护未使用页面的空闲列表。这些空闲页面可以被以后的事务重用。由于数据库通常会增长，因此这在许多用例中效果很好。但是，请务必注意，删除大块数据将不允许您回收磁盘上的该空间。 有关页面分配的更多信息，请参见此注释。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:1:8","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"阅读资料 对于嵌入式，可序列化的事务性键/值数据库，Bolt是一个相对较小的代码库（\u003c5KLOC），因此对于那些对数据库的工作方式感兴趣的人来说，Bolt可能是一个很好的起点。 最佳起点是Bolt的主要切入点： Open()-初始化对数据库的引用。它负责创建数据库（如果不存在），获得文件的排他锁，读取元页面以及对文件进行内存映射。 DB.Begin()-根据writable参数的值启动只读或读写事务。这需要短暂获得“元”锁以跟踪未结交易。一次只能存在一个读写事务，因此在读写事务期间将获得“ rwlock”。 Bucket.Put()-将键/值对写入存储桶。验证参数之后，使用光标将B +树遍历到将键和值写入的页面和位置。找到位置后，存储桶会将基础页面和页面的父页面具体化为“节点”到内存中。这些节点是在读写事务期间发生突变的地方。提交期间，这些更改将刷新到磁盘。 Bucket.Get()-从存储桶中检索键/值对。这使用光标移动到键/值对的页面和位置。在只读事务期间，键和值数据将作为对基础mmap文件的直接引用返回，因此没有分配开销。对于读写事务，此数据可以引用mmap文件或内存节点值之一。 Cursor-该对象仅用于遍历磁盘页或内存节点的B +树。它可以查找特定的键，移至第一个或最后一个值，也可以向前或向后移动。光标对最终用户透明地处理B +树的上下移动。 Tx.Commit()-将内存中的脏节点和可用页面列表转换为要写入磁盘的页面。然后写入磁盘分为两个阶段。首先，脏页被写入磁盘并fsync()发生。其次，写入具有递增的事务ID的新元页面，然后fsync()发生另一个页面 。这两个阶段的写入操作确保崩溃时会忽略部分写入的数据页，因为指向它们的元页不会被写入。部分写入的元页面是无效的，因为它们是用校验和写入的。 如果您还有其他可能对他人有用的注释，请通过请求请求将其提交。 ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:2:0","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["Go 库文档"],"content":"其他使用Bolt的项目 以下是使用Bolt的公共开源项目的列表： Algernon - A HTTP/2 web server with built-in support for Lua. Uses BoltDB as the default database backend. Bazil - A file system that lets your data reside where it is most convenient for it to reside. bolter - Command-line app for viewing BoltDB file in your terminal. boltcli - the redis-cli for boltdb with Lua script support. BoltHold - An embeddable NoSQL store for Go types built on BoltDB BoltStore - Session store using Bolt. Boltdb Boilerplate - Boilerplate wrapper around bolt aiming to make simple calls one-liners. BoltDbWeb - A web based GUI for BoltDB files. bleve - A pure Go search engine similar to ElasticSearch that uses Bolt as the default storage backend. btcwallet - A bitcoin wallet. buckets - a bolt wrapper streamlining simple tx and key scans. cayley - Cayley is an open-source graph database using Bolt as optional backend. ChainStore - Simple key-value interface to a variety of storage engines organized as a chain of operations. Consul - Consul is service discovery and configuration made easy. Distributed, highly available, and datacenter-aware. DVID - Added Bolt as optional storage engine and testing it against Basho-tuned leveldb. dcrwallet - A wallet for the Decred cryptocurrency. drive - drive is an unofficial Google Drive command line client for *NIX operating systems. event-shuttle - A Unix system service to collect and reliably deliver messages to Kafka. Freehold - An open, secure, and lightweight platform for your files and data. Go Report Card - Go code quality report cards as a (free and open source) service. GoWebApp - A basic MVC web application in Go using BoltDB. GoShort - GoShort is a URL shortener written in Golang and BoltDB for persistent key/value storage and for routing it’s using high performent HTTPRouter. gopherpit - A web service to manage Go remote import paths with custom domains Gitchain - Decentralized, peer-to-peer Git repositories aka “Git meets Bitcoin”. InfluxDB - Scalable datastore for metrics, events, and real-time analytics. ipLocator - A fast ip-geo-location-server using bolt with bloom filters. ipxed - Web interface and api for ipxed. Ironsmith - A simple, script-driven continuous integration (build - \u003e test -\u003e release) tool, with no external dependencies Kala - Kala is a modern job scheduler optimized to run on a single node. It is persistent, JSON over HTTP API, ISO 8601 duration notation, and dependent jobs. Key Value Access Langusge (KVAL) - A proposed grammar for key-value datastores offering a bbolt binding. LedisDB - A high performance NoSQL, using Bolt as optional storage. lru - Easy to use Bolt-backed Least-Recently-Used (LRU) read-through cache with chainable remote stores. mbuckets - A Bolt wrapper that allows easy operations on multi level (nested) buckets. MetricBase - Single-binary version of Graphite. MuLiFS - Music Library Filesystem creates a filesystem to organise your music files. NATS - NATS Streaming uses bbolt for message and metadata storage. Operation Go: A Routine Mission - An online programming game for Golang using Bolt for user accounts and a leaderboard. photosite/session - Sessions for a photo viewing site. Prometheus Annotation Server - Annotation server for PromDash \u0026 Prometheus service monitoring system. reef-pi - reef-pi is an award winning, modular, DIY reef tank controller using easy to learn electronics based on a Raspberry Pi. Request Baskets - A web service to collect arbitrary HTTP requests and inspect them via REST API or simple web UI, similar to RequestBin service Seaweed File System - Highly scalable distributed key~file system with O(1) disk read. stow - a persistence manager for objects backed by boltdb. Storm - Simple and powerful ORM for BoltDB. SimpleBolt - A simple way to use BoltDB. Deals mainly with strings. Skybox Analytics - A standalone funnel analysis tool for web analytics. Scuttlebutt - Uses Bolt to store and process all Twitter mentions of GitHub projects. tentacool - REST api server ","date":"2024-06-02","objectID":"/posts/2024-06-02-go-boltdb/:3:0","tags":["Go","bolt"],"title":"Go boltdb","uri":"/posts/2024-06-02-go-boltdb/"},{"categories":["linux"],"content":"LVM Logical Volume Management 逻辑卷管理 优势： 在线扩展/缩减存储空间/整合琐碎空间 支持快照 Device Mapper设备映射 lvm组织方式： 真实存储设备 --- pv(物理卷) --- vg(卷组) --- lv(逻辑卷) ---- 创建文件系统 --- 挂载使用 ","date":"2024-05-27","objectID":"/posts/2024-05-27-linux-lvm/:1:0","tags":["lvm","linux-lvm"],"title":"lvm","uri":"/posts/2024-05-27-linux-lvm/"},{"categories":["linux"],"content":"相关命令 1、pv(物理卷) 1) 查看物理卷 pvscan 2) 创建物理卷 pvcreate disk/partition 3) 删除物理卷 pvremove pv_name 2、vg(卷组) 1) 查看卷组 [root@node01 ~]# vgscan [root@node01 ~]# vgdisplay vg_name 2) 创建卷组 vgcreate vg_name pv_name pv_name .... 3) 删除卷组 vgremove vg_name 3、lv(逻辑卷) 1) 查看逻辑卷 [root@node01 ~]# lvscan ACTIVE '/dev/centos/swap' [2.00 GiB] inherit ACTIVE '/dev/centos/root' [\u003c17.00 GiB] inherit [root@node01 ~]# lvdisplay /dev/centos/swap 2) 创建逻辑卷 lvcreate -L size -n lv_name vg_name lvcreate -L 400G -n lv01 vg01 3) 删除逻辑卷 lvremove /dev/vg01/lv01 操作过程 # pv 1.创建pv pvcreate /dev/sda6 pvcreate /dev/sda7 2.查询pv pvs pvdisplay # vg 1.创建vg vgcreate vg0 /dev/sda6 /dev/sda7 2.查询vg vgs vgdisplay # lv 1.创建 lvcreate -L 700M -n lv0 vg0 -L size -n name 2.查询 lvs lvdisplay 格式化 mkfs.xfs /dev/vg0/lv0 挂载 mount /dev/vg0/lv0 /mnt/ 示例：扩容跟分区 1、创建物理卷 [root@localhost ~]# pvcreate /dev/sdb Physical volume \"/dev/sdb\" successfully created. [root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 2 2 0 wz--n- 39.49g 0 [root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- \u003c19.00g swap centos -wi-ao---- 508.00m 2、 扩容卷组 [root@localhost ~]# vgextend centos /dev/sdb Volume group \"centos\" successfully extended [root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- \u003c19.00g swap centos -wi-ao---- 508.00m 3、扩展根逻辑卷 [root@localhost ~]# lvextend -l +100%FREE /dev/centos/root Size of logical volume centos/root changed from \u003c19.00 GiB (4863 extents) to \u003c39.00 GiB (9983 extents). Logical volume centos/root successfully resized. [root@localhost ~]# df -Th 文件系统 类型 容量 已用 可用 已用% 挂载点 devtmpfs devtmpfs 2.0G 0 2.0G 0% /dev tmpfs tmpfs 2.0G 0 2.0G 0% /dev/shm tmpfs tmpfs 2.0G 12M 2.0G 1% /run tmpfs tmpfs 2.0G 0 2.0G 0% /sys/fs/cgroup /dev/mapper/centos-root xfs 19G 18G 1.5G 93% / /dev/sr0 iso9660 8.1G 8.1G 0 100% /var/ftp/iso /dev/sda1 xfs 509M 165M 344M 33% /boot tmpfs tmpfs 394M 0 394M 0% /run/user/0 4、同步 [root@localhost ~]# xfs_growfs /dev/centos/root meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=1244928 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=4979712, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 4979712 to 10222592 [root@localhost ~]# df -Th 文件系统 类型 容量 已用 可用 已用% 挂载点 devtmpfs devtmpfs 2.0G 0 2.0G 0% /dev tmpfs tmpfs 2.0G 0 2.0G 0% /dev/shm tmpfs tmpfs 2.0G 12M 2.0G 1% /run tmpfs tmpfs 2.0G 0 2.0G 0% /sys/fs/cgroup /dev/mapper/centos-root xfs 39G 18G 22G 46% / /dev/sr0 iso9660 8.1G 8.1G 0 100% /var/ftp/iso /dev/sda1 xfs 509M 165M 344M 33% /boot tmpfs tmpfs 394M 0 394M 0% /run/user/0 [root@localhost ~]# 扩容 ext2/ext3/ext4 文件系统 resize2fs /dev/vg0/lv0 新建逻辑卷 （1）创建一个指定大小的lv，并指定名字为lv_2 lvcreate -L 2G -n lv_2 vg_1 （2）创建一个占全部卷组大小的lv，并指定名字为lv_3（注意前提是vg并没有创建有lv） lvcreate -l 100%VG -n lv_3 vg_1 （3）创建一个空闲空间80%大小的lv，并指定名字为lv_4(常用) lvcreate -l 80%Free -n lv_4 vg_1 ","date":"2024-05-27","objectID":"/posts/2024-05-27-linux-lvm/:1:1","tags":["lvm","linux-lvm"],"title":"lvm","uri":"/posts/2024-05-27-linux-lvm/"},{"categories":["DevOps"],"content":"钉钉机器人发消息 ","date":"2024-05-14","objectID":"/posts/2024-05-14-dingbot/:1:0","tags":["dingbot"],"title":"dingbot","uri":"/posts/2024-05-14-dingbot/"},{"categories":["DevOps"],"content":"1、签名计算 由于 mac 上的是 BSD 的 date，与 linux 上的 date 不同，在 mac 上使用需要替换为 linux 的 gdate。 #!/usr/bin/env bash ## 需要艾特的人的手机号码，以空格隔开 atMobiles=(13333333333 18888888888) ACCESS_TOKEN=\"fdebf803ece5080bdb432446ef6649e8c371bcxxxxxxxxxxx\" SECRET=\"SEC4622afcfbf51b8e71f0cc22154ba2f6f87xxxxxxxxxxxx\" dingbot() { message=$1 timestamp=$(date +%s%3N) stringtosign=\"${timestamp}\\n${SECRET}\" signdata=$(printf \"${stringtosign}\" | openssl dgst -sha256 -hmac ${SECRET} -binary | base64) sign=$(echo -n \"${signdata}\" | xxd -plain | tr -d '\\n' | sed 's/\\(..\\)/%\\1/g') webhook_url=\"https://oapi.dingtalk.com/robot/send?access_token=${ACCESS_TOKEN}\u0026timestamp=${timestamp}\u0026sign=${sign}\" at_who=$(printf '\"%s\",' \"${atMobiles[@]}\") at_who=${at_who%,} # 移除最后一个逗号 # 构造JSON数据 json_data=$(cat \u003c\u003cEOF { \"at\": { \"atMobiles\": [${at_who}] }, \"msgtype\": \"text\", \"text\": { \"content\": \"${message}\" } } EOF ) curl -s -X POST -H 'Content-Type: application/json' \"${webhook_url}\" -d \"${json_data}\" } dingbot \"你好，这是一个测试消息。\" function dingbotMD(){ title=\"$1\" message=\"$2\" timestamp=$(date +%s%3N) stringtosign=\"${timestamp}\\n${SECRET}\" signdata=$(printf \"${stringtosign}\" | openssl dgst -sha256 -hmac ${SECRET} -binary | base64) sign=$(echo -n \"${signdata}\" | xxd -plain | tr -d '\\n' | sed 's/\\(..\\)/%\\1/g') webhook_url=\"https://oapi.dingtalk.com/robot/send?access_token=${ACCESS_TOKEN}\u0026timestamp=${timestamp}\u0026sign=${sign}\" at_who=$(printf '\"%s\",' \"${atMobiles[@]}\") at_who=${at_who%,} # 移除最后一个逗号 # 构造JSON数据 json_data=$(cat \u003c\u003cEOF { \"msgtype\": \"markdown\", \"markdown\": { \"title\": \"${title}\", \"text\": \"${message}\" } } EOF ) curl -s -X POST -H 'Content-Type: application/json' \"${webhook_url}\" -d \"${json_data}\" } msg=\"$(date)\" dingbotMD \"msg\" \"### 东八区时间：${msg}\" echo ","date":"2024-05-14","objectID":"/posts/2024-05-14-dingbot/:1:1","tags":["dingbot"],"title":"dingbot","uri":"/posts/2024-05-14-dingbot/"},{"categories":["DevOps"],"content":"2、通用版 #!/usr/bin/env bash # *********************************************************************** # Description : Dingbot for shell # Author : serialt # Email : tserialt@gmail.com # FilePath : /shell/DingMsg.sh # Other : # : # # 支持安全类型：【关键字】 和 【加签】 # 依赖命令：curl openssl date echo # # 注意：mac上的date命令是bsd的，与linux上的date不同，获取不到毫秒，不能用于签名计算。 # 或者安装coreutils，使用gdate替换date # # *********************************************************************** ## 钉钉机器人配置 dingbot_secret='SECa87a39d5b80e32xxxxxxxxxxxxxxxxxxxxxxxx' dingbot_url='https://oapi.dingtalk.com/robot/send?access_token=cd316d9df306852b6da7d10xxxxxxxxxxxxxxxxxxxxxxx' ## secret_type keywords || sign ding_secret_type='sign' ## 需要艾特的人的手机号码，以空格隔开 atMobiles=(13333333333 18888888888) ## encode url function url_encode() { t=\"${1}\" if [[ -n \"${1}\" \u0026\u0026 -n \"${2}\" ]];then if ! echo 'xX' | grep -q \"${t}\";then t='x' fi echo -n \"${2}\" | od -t d1 | awk -v a=\"${t}\" '{for (i = 2; i \u003c= NF; i++) {printf(($i\u003e=48 \u0026\u0026 $i\u003c=57) || ($i\u003e=65 \u0026\u0026$i\u003c=90) || ($i\u003e=97 \u0026\u0026 $i\u003c=122) ||$i==45 || $i==46 || $i==95 || $i==126 ?\"%c\" : \"%%%02\"a, $i)}}' else echo -e '$1 and $2 can not empty\\n$1 ==\u003e 'x' or 'X', x ==\u003e lower, X ==\u003e toupper.\\n$2 ==\u003e Strings need to url encode' fi } ## dingbot function dingbot(){ send_strs=\"${1}\" new_url=\"${dingbot_url}\" at_who='' for i in ${atMobiles[*]} do if [ -n \"${at_who}\" ];then at_who=\"${at_who},\\\"${i}\\\"\" else at_who=\"\\\"${i}\\\"\" fi done if [ \"${ding_secret_type}\" == 'keywords' ];then curl -s -X POST -H 'Content-Type: application/json' \"${new_url}\" \\ -d \"{\\\"at\\\":{\\\"atMobiles\\\":[${at_who}]},\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"${send_strs}\\\"}}\" elif [ \"${ding_secret_type}\" == 'sign' ];then timestamp=$(date \"+%s%3N\") dingbot_sign=$(echo -ne \"${timestamp}\\n${dingbot_secret}\" | openssl dgst -sha256 -hmac \"${dingbot_secret}\" -binary | base64) dingbot_sign=$(url_encode 'X' \"${dingbot_sign}\") post_url=\"${dingbot_url}\u0026timestamp=${timestamp}\u0026sign=${dingbot_sign}\" curl -s -X POST -H 'Content-Type: application/json' \"${post_url}\" \\ -d \"{\\\"at\\\":{\\\"atMobiles\\\":[${at_who}]},\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"${send_strs}\\\"}}\" else echo \"secret_type 未知，请检查配置\" fi } msg=\"$(date)\" dingbot \"东八区时间：${msg}\" ","date":"2024-05-14","objectID":"/posts/2024-05-14-dingbot/:1:2","tags":["dingbot"],"title":"dingbot","uri":"/posts/2024-05-14-dingbot/"},{"categories":["DevOps"],"content":"3、其他 shell 版本 #!/usr/bin/env bash info='msg to you' #发送消息 sendMsg(){ token='1e18ffe069052b56f5a0f8fe9b6c058373e7df7ef49dc24baa6xxxxxxxxxxxxxx' curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{'msgtype': 'text','text': {'content': 'msg:\\n$*'}} } main(){ logRotate sendMsg $info } main #!/bin/bash # ****************************************************** # Description : send msg by dingRobot # 使用脚本前请设置钉钉机器人的安全类型，脚本支持关键字和IP # # ****************************************************** logFile='/var/log/dingbot.log' #发送消息 sendMsg(){ local info=$* token='1e18ffe069052b56f5a0f8fe9b6c058373e7df7ef49dc24bacccccccccccc' result=`curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{'msgtype': 'text', 'text': { 'content': '$info' } }\"` [ `echo $result | grep \"errmsg.*ok\"` ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result MessagesType: text [ text: $* ]\" \u003e\u003e $logFile } SendMsgByMD(){ local info=$1 # $info markdown的标题 local infoMsg=$2 # $infoMsg 内容 token='1e18ffe069052b56f5a0f8fe9b6c058373e7df7ef49dc24baa6cccccccccc' result=`curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{ 'msgtype': 'markdown', 'markdown': { 'title':'$info', 'text': '$infoMsg' }, 'at': { 'atMobiles': [ '156xxxx8827', '189xxxx8325' ], 'isAtAll': true } }\"` [ `echo $result | grep \"errmsg.*ok\"` ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result MessagesType: markdown [ title: $info text: $infoMsg ]\" \u003e\u003e $logFile } #main() (sendMsg 'zabbix' )\u0026 (SendMsgByMD 'zabbix' '# send msg')\u0026 exit 55 ","date":"2024-05-14","objectID":"/posts/2024-05-14-dingbot/:1:3","tags":["dingbot"],"title":"dingbot","uri":"/posts/2024-05-14-dingbot/"},{"categories":["DevOps"],"content":"4、python 版 https://github.com/zhuifengshen/DingtalkChatbot ","date":"2024-05-14","objectID":"/posts/2024-05-14-dingbot/:1:4","tags":["dingbot"],"title":"dingbot","uri":"/posts/2024-05-14-dingbot/"},{"categories":["DevOps"],"content":"5、go版 https://github.com/blinkbean/dingtalk ","date":"2024-05-14","objectID":"/posts/2024-05-14-dingbot/:1:5","tags":["dingbot"],"title":"dingbot","uri":"/posts/2024-05-14-dingbot/"},{"categories":["DevOps"],"content":"Publish Terraform Provider https://registry.terraform.io/ 上的provider只能托管在 github 上 ","date":"2024-03-31","objectID":"/posts/2024-03-31-publish-terraform-provider/:1:0","tags":["terraform-registry","hashicorp"],"title":"Publish Provider to Registry","uri":"/posts/2024-03-31-publish-terraform-provider/"},{"categories":["DevOps"],"content":"1、Terraform Registry 官网上注册账号 账号使用 github 登录，设置 github 需要对 terraform registry 的授权 ","date":"2024-03-31","objectID":"/posts/2024-03-31-publish-terraform-provider/:1:1","tags":["terraform-registry","hashicorp"],"title":"Publish Provider to Registry","uri":"/posts/2024-03-31-publish-terraform-provider/"},{"categories":["DevOps"],"content":"2、创建 github project，配置 github action 名字需要符合 terraform-provider-xxxxx，例如 terraform-provider-message， 1）生成 GPG key，用于 provider 签名和验签 [root@dev ~]# gpg --full-generate-key gpg (GnuPG) 2.2.20; Copyright (C) 2020 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (14) Existing key from card Your selection? 1 # 选择RSA RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) 4096 # 输入加密密钥的长度，4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire \u003cn\u003e = key expires in n days \u003cn\u003ew = key expires in n weeks \u003cn\u003em = key expires in n months \u003cn\u003ey = key expires in n years Key is valid for? (0) 0 # 设置密码有效期 Key does not expire at all Is this correct? (y/N) y GnuPG needs to construct a user ID to identify your key. Real name: serialt # 设置密钥的消息 Email address: t@local.com Comment: msg You selected this USER-ID: \"serialt (msg) \u003ct@local.com\u003e\" Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. gpg: key A02032881C9460CE marked as ultimately trusted gpg: revocation certificate stored as '/root/.gnupg/openpgp-revocs.d/16630E5129BFAB582DDFBF71A02032881C9460CE.rev' public and secret key created and signed. pub rsa4096 2021-08-23 [SC] 16630E5129BFAB582DDFBF71A02032881C9460CE uid serialt (msg) \u003ct@local.com\u003e sub rsa4096 2021-08-23 [E] ┌──────────────────────────────────────────────────────┐ │ Please enter the passphrase to │ │ protect your new key │ │ │ │ Passphrase: ________________________________________ │ │ │ │ \u003cOK\u003e \u003cCancel\u003e │ └──────────────────────────────────────────────────────┘ ┌──────────────────────────────────────────────────────┐ │ Please re-enter this passphrase │ │ │ │ Passphrase: ________________________________________ │ │ │ │ \u003cOK\u003e \u003cCancel\u003e │ └──────────────────────────────────────────────────────┘ # 查看所有密钥 gpg -k # 导出密钥 gpg --output public_key.gpg --armor --export 375xxxxx gpg --output private_key.gpg --armor --export-secret-key 375xxxxx 2）github action 需要配置一下 secret TOKEN GPG_PRIVATE_KEY # Terraform Provider release workflow. name: Release # This GitHub action creates a release when a tag that matches the pattern # \"v*\" (e.g. v0.1.0) is created. on: push: tags: - 'v*' # Releases need permissions to read and write the repository contents. # GitHub considers creating releases and uploading assets as writing contents. permissions: contents: write jobs: goreleaser: runs-on: ubuntu-latest steps: - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1 with: # Allow goreleaser to access older tag information. fetch-depth: 0 - uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v5.0.0 with: go-version-file: 'go.mod' cache: true - name: Import GPG key uses: crazy-max/ghaction-import-gpg@01dd5d3ca463c7f10f7f4f7b4f177225ac661ee4 # v6.1.0 id: import_gpg with: gpg_private_key: ${{ secrets.GPG_PRIVATE_KEY }} #passphrase: ${{ secrets.GPG_PRIVATE_PASSPHRASE }} - name: Run GoReleaser uses: goreleaser/goreleaser-action@7ec5c2b0c6cdda6e8bbb49444bc797dd33d74dd8 # v5.0.0 with: args: release --clean env: # GitHub sets the GITHUB_TOKEN secret automatically. GITHUB_TOKEN: ${{ secrets.TOKEN }} GPG_FINGERPRINT: ${{ steps.import_gpg.outputs.fingerprint }} 推送项目到github ","date":"2024-03-31","objectID":"/posts/2024-03-31-publish-terraform-provider/:1:2","tags":["terraform-registry","hashicorp"],"title":"Publish Provider to Registry","uri":"/posts/2024-03-31-publish-terraform-provider/"},{"categories":["DevOps"],"content":"3、Terraform Registry上配置公钥和发布provider 1）导入公钥 https://registry.terraform.io/settings/gpg-keys 2）发布provider https://registry.terraform.io/publish/provider ","date":"2024-03-31","objectID":"/posts/2024-03-31-publish-terraform-provider/:1:3","tags":["terraform-registry","hashicorp"],"title":"Publish Provider to Registry","uri":"/posts/2024-03-31-publish-terraform-provider/"},{"categories":["Network"],"content":"wlan组网 ","date":"2024-03-23","objectID":"/posts/2024-03-24-wlan/:1:0","tags":["network","ap","ac"],"title":"wlan","uri":"/posts/2024-03-24-wlan/"},{"categories":["Network"],"content":"一、概述 无线局域网(Wireless Local Area Networks； WLAN)利用无线技术在空中传输数据、话音和视频信号。作为传统布线网络的一种替代方案或延伸，无线局域网把个人从办公桌边解放了出来，使他们可以随时随地获取信息，提高了员工的办公效率。 WLAN的优点：它能够方便地联网，因为WLAN可以便捷、迅速地接纳新加入的雇员，而不必对网络的用户管理配置进行过多的变动；WLAN在有线网络布线困难的地方比较容易实施，使用WLAN方案，则不必再实施打孔敷线作业，因而不会对建筑设施造成任何损害。 ","date":"2024-03-23","objectID":"/posts/2024-03-24-wlan/:1:1","tags":["network","ap","ac"],"title":"wlan","uri":"/posts/2024-03-24-wlan/"},{"categories":["Network"],"content":"二、802.11基本元素 基本服务器(Basic Service Set)是802.11网络的基本组件，由一组相互通信的工作站所构成。工作站之间的通信在某个模糊地带进行，称为基本服务区域(Basic Service Area)，此区域受限于所使用的无线媒介的传播特性 BSA：BSS的覆盖范围称为基本服务区 BSS分为Independent BSS和Infrastructure BSS两种 独立服务集简称IBSS，工作站之间可以直接通信，但两者间的距离必须在可以通信的范围内。 由于持续时间不长，规模小且目的特殊，IBSS有时称为特设BSS或ad hoc newwork 基础架构模式基本服务集。判断是否为基础结构型网络，只要查看是否有接入点(AP)参与其中 ESS：利用骨干网络将BSS进行连接 SSID：用户的网络名称 BSSID：AP的MAC地址，用来标识AP所管理的BSS ","date":"2024-03-23","objectID":"/posts/2024-03-24-wlan/:1:2","tags":["network","ap","ac"],"title":"wlan","uri":"/posts/2024-03-24-wlan/"},{"categories":["Network"],"content":"三、WLAN拓扑结构 3.1 Ad-Hoc Ad-Hoc拓扑的无线网络由无线工作站组成，用于一台无线工作站和另一台或多台其他无线工作站的直接通讯，该网络无法接入到有线网络中，只能独立使用 3.2 IBSS 由多个AP以及连接他们的分布式系统(DS)组成的基础架构模式网络，也称为扩展服务区(ESS)。扩展服务区内的每个AP都是一个独立的无线网络基础服务区(BSS)，所有AP共享同一个扩展服务区标识符(ESSID) 相同ESSID的无线网络可以进行漫游，不同ESSID的无线网络形成逻辑子网 AP之间使用互相不重叠的信道，AP之间信号覆盖重叠区域为10%-15% 3.3 WDS WDS(Wireless Distribution System无线分布式系统)：通过无线链路链接两个或者多个独立的有线局域网或者无线局域网，组成一个互通的网络 无线WDS技术提高了整个网络结构的灵活性和便捷性 在WDS部署中，网桥组网模式可分为： 点对点(P2P) 点对多点(P2MP) 中继桥接方式 ","date":"2024-03-23","objectID":"/posts/2024-03-24-wlan/:1:3","tags":["network","ap","ac"],"title":"wlan","uri":"/posts/2024-03-24-wlan/"},{"categories":["Network"],"content":"四、AP 4.1 概述 无线局域网的架构主要分为 基于控制器的AP架构(瘦AP，FitAP) 传统的独立AP架构(胖AP，FatAP) 近几年WLAN技术的发展，瘦AP正在迅速替代胖AP模式 4.2 胖AP 除无线接入功能外，一般具备WLAN、LAN两个接口，多支持DHCP服务器、DNS和MAC地址克隆，以及VPN接入、防火墙等安全功能 胖AP也称为独立AP，所有的配置存储于自治型接入点本身，因此设备的管理和配置均由接入点处理。所有加解密和MAC层功能也由自治型接入点完成 胖AP的例子典型的是无线路由器 4.3 瘦AP 无线局域网一体化发展的下一个阶段是集中式WLAN架构。这种模式使用位于网络核心的WLAN控制器，在集中式的无线局域网体系结构中，基于控制器的接入点，也称为轻量型AP 为了实现WLAN网络的快速部署、网络设备的集中管理、精细化的用户管理，相比胖AP方式，企业用户以及运营商更倾向于采用集中控制性WLAN组网(瘦AP+AC) AC和AP之间采用CAPWAP协议 ","date":"2024-03-23","objectID":"/posts/2024-03-24-wlan/:1:4","tags":["network","ap","ac"],"title":"wlan","uri":"/posts/2024-03-24-wlan/"},{"categories":["Network"],"content":"五、CAPWAP简介 CAPWAP(无线接入点控制和配置协议)，用于无线终端接入点(AP)和无线网络控制器(AC)之间的通信和交互，实现AC对其所关联的AP的集中管理和控制 协议内容 AP对AC的自动发现以及AP\u0026AC的状态机运行、维护 AC对AP进行管理、业务配置下发 STA数据封装CAPWAP隧道进行转发 ","date":"2024-03-23","objectID":"/posts/2024-03-24-wlan/:1:5","tags":["network","ap","ac"],"title":"wlan","uri":"/posts/2024-03-24-wlan/"},{"categories":["Network"],"content":"六、AP和AC工作过程 6.1 瘦AP发现AC 6.2 AP和AC详细工作过程 6.2.1 动态发现 AP启动以后会通过DHCP获取IP地址、DNS Server、域名 AP发出L2广播的发现请求报文试图联系一个AC 如果长时间(30秒)没有响应，AP会启动L3发现。AP会从DHCP Server通过Option43获得AC的IP，或者通过Opthion15获得AC的域名，AP向该IP地址(域名)发送请求 接收到发现请求报文的AC会检查该AP是否接入本机的权限，如果有则回应发现响应 AC和AP间建立CAPWAP隧道 6.2.2 CAPWAP隧道建立过程 DHCP CAPWAP隧道建立-Discover AP使用AP发现机制来获取哪些AC可用，决定与最佳AC建立CAPWAP连接。(当AP上已经静态配置了AC，那么就不需要完成AC的发现过程) AP启动CAPWAP协议的发现机制，以单播或广播的形式发送请求报文试图关联AC，AC收到AP的discovery Request以后，会发送一个单播的discovery response给AP，AP可以通过discovery response中所带的AC优先级或者AC上当前AP的个数等，确定与哪个AC建立会话 CAPWAP隧道建立-DTLS(可选) AP根据此IP地址与AC协商，AP接受到响应消息后开始与AC建立CAPWAP隧道，这个阶段可以选择CAPWAP隧道是否采用DTLS加密传输UDP报文 DTLS：Datagram Transport Layer Security(数据报传输层安全协议) CAPWAP隧道建立-Join 在完成DTLS握手后，AC与AP开始建立控制隧道，在建立控制隧道的交互过程中，AC回应的Join Response报文中会携带用户配置的升级版本号，握手报文间隔/超时时间，控制报文优先级等信息。AC会检查AP的当前版本，如果AP的版本无法与AC要求的相匹配，AP和AC会进入Image Data状态做固件升级，以此来更新AP的版本，如果AP的版本符合要求，则进入Configuration状态 CAPWAP隧道建立-Configure 将入Configure状态后为了做AP的现有配置和AC设定配置的匹配检查，AP发送Configuration Request到AC，该信息中包含现有AP的配置，当AP当前配置与AC要求不符时，AC通过Configuration Response通知AP CAPWAP隧道建立-data check 进入run状态，他们之间会发送keeplive报文来维护数据隧道 七、综合实验 7.1 实验组网 7.2 实验配置 7.2.1 瘦AP配置 1、划分vlan10 20，vlan10用于管理，vlan20用于业务 2、LSW4的配置 \u003cHuawei\u003eundo terminal monitor \u003cHuawei\u003esys [Huawei]vlan batch 10 20 [Huawei]int g0/0/2 [Huawei-GigabitEthernet0/0/2]port link-type trunk [Huawei-GigabitEthernet0/0/2]port trunk allow-pass vlan 10 20 [Huawei-GigabitEthernet0/0/2]port trunk pvid vlan 10 [Huawei-GigabitEthernet0/0/3]int g0/0/1 [Huawei-GigabitEthernet0/0/1]port link-type trunk [Huawei-GigabitEthernet0/0/1]port trunk allow-pass vlan 10 20 3、LSW3的配置 [Huawei]int g0/0/1 [Huawei-GigabitEthernet0/0/1]port link-type trunk [Huawei-GigabitEthernet0/0/1]port trunk allow-pass vlan 10 20 [Huawei-GigabitEthernet0/0/1]int g0/0/3 [Huawei-GigabitEthernet0/0/3]port link-type trunk [Huawei-GigabitEthernet0/0/3]port trunk allow-pass vlan 10 20 4、AC配置 [AC6005]vlan batch 10 20 [AC6005-GigabitEthernet0/0/1]port link-type trunk [AC6005-GigabitEthernet0/0/1]port trunk allow-pass vlan 10 20 [AC6005-GigabitEthernet0/0/1]q //配置dhcp [AC6005]dhcp enable [AC6005]int Vlanif 10 [AC6005-Vlanif10]ip address 10.1.10.1 24 [AC6005-Vlanif10]dhcp select interface [AC6005-Vlanif10]int vlanif 20 [AC6005-Vlanif20]ip address 10.1.20.1 24 [AC6005-Vlanif20]dhcp select interface [AC6005-Vlanif20]q //在AC上配置AP上线 //创建AP组，用于将相同配置的AP加入到同一AP组 [AC6005]wlan [AC6005-wlan-view]ap-group name ap-group1 [AC6005-wlan-ap-group-ap-group1]q //创建域管理模板，在域管理模板配置AC的国家码并在AP组下引用管理模块 [AC6005-wlan-view]regulatory-domain-profile name defult [AC6005-wlan-regulate-domain-defult]country-code cn [AC6005-wlan-regulate-domain-defult]q [AC6005-wlan-view]ap-group name ap-group1 [AC6005-wlan-ap-group-ap-group1]regulatory-domain-profile default Warning: Modifying the country code will clear channel, power and antenna gain c onfigurations of the radio and reset the AP. Continue?[Y/N]:y [AC6005-wlan-ap-group-ap-group1]q [AC6005-wlan-view]q //配置AC源接口 [AC6005]capwap source int Vlanif 10 //查看AP2的MAC地址，并记录下来 [AC6005]wlan [AC6005-wlan-view]ap auth-mode mac-auth [AC6005-wlan-view]ap-id 0 ap-mac [ap2的mac地址] [AC6005-wlan-ap-0]ap-name area_1 [AC6005-wlan-ap-0]ap-group ap-group1 [AC6005-wlan-ap-0]q //配置WLAN业务参数，配置WPA-WPA2+PSK+AES [AC6005]wlan [AC6005-wlan-view]security-profile name wlan-net [AC6005-wlan-sec-prof-wlan-net]security wpa-wpa2 psk pass-phrase 12345678 aes Warning: The current password is too simple. For the sake of security, you are a dvised to set a password containing at least two of the following: lowercase let ters a to z, uppercase letters A to Z, digits, and special characters. Continue? [Y/N]:y [AC6005-wlan-sec-prof-wlan-net]q //创建名为\"wlan-net\"的SSID，并配置SSID名称为\"wlan-net\" [AC6005-wlan-view]ssid-profile name wlan-net [AC6005-wlan-ssid-prof-wlan-net]ssid wlan-net Info: This operation may take a few seconds, please wait.done. [AC6005-wlan-ssid-prof-wlan-net]q //创建名为\"wlan-net\"的VAP模板，配置业务数据转发模式，业务VLAN，并且引用安全模板和SSID [AC6005-wlan-view]vap-profile name wlan-net //配置直接转发 [AC6005-wlan-vap-prof-wlan","date":"2024-03-23","objectID":"/posts/2024-03-24-wlan/:1:6","tags":["network","ap","ac"],"title":"wlan","uri":"/posts/2024-03-24-wlan/"},{"categories":["Network"],"content":"路由交换基础配置 设备名修改 \u003cHuawei\u003e system-view [Huawei] sysname Server [Server] undo sysname [Huawei] 查看配置 # 查看当前配置 display this # 查看当前所有配置 display current-configuration 禁用ftp功能 \u003cHuawei\u003e system-view [Huawei] ftp server enable [Huawei] undo ftp server 删除port版定的ip [Huawei]interface g0/0/1 [Huawei-GigabitEthernet0/0/1]ip address 192.168.1.1 24 [Huawei-GigabitEthernet0/0/1]undo ip address 配置时间 display clock 查看当前时间 clock timezone 设置所在时区 clock datetime 设置当前时间和日期 clock daylight-saving-time 设置采用夏时制 配置标题消息 # 配置登录前显示的标题信息 [Huawei] header login information \"welcome to huawei\" # 配置登录后显示的标题信息 [Huawei] header shell information \"Please do not reboot the device\" 配置路由器接口设置IP地址 \u003cHuawei\u003e system-view [Huawei] intface GigabitEthernet0/0/1 [Huawei-GigabitEthernet0/0/1] ip address 192.168.10.2 255.255.255.0 [Huawei-GigabitEthernet0/0/1]display ip interface brief # 显示当前接口信息 ****** Interface IP Address/Mask Physical Protocol GigabitEthernet0/0/1 192.168.10.2/24 down down [Huawei-GigabitEthernet0/0/1]display this # 显示当前配置 Telnet配置 # 开启telnet 服务 telnet server enable # 查看状态 display telnet server status # 进入VTY配置模式 user-interface vty 0 4 # 配置支持Telnet或SSH协议 protocol inbound telnet/ssh # 配置认证模式 authentication-mode password/aaa # 配置认证密码 set authentication password cipher huawei # 配置用户级别 user privilege level 15 # 配置最大VTY会话数量 user-interface maximum-vty 15 # 进入AAA配置模式 aaa # 创建用户和密码 local-user wakin password cipher huawei # 配置用户级别 local-user wakin privilege level 15 # 配置用户可用服务 local-user wakin service-type telnet #查看用户界面占用情况: display users \u003cHuawei\u003esystem-view [Huawei]telnet server enable [Huawei]aaa [Huawei-aaa]loc-user huawei password irreversible-cipher Huawei@123 [Huawei-aaa]local-user huawei privilege level 15 [Huawei-aaa]local-user huawei service-type telnet [Huawei-aaa]quit [Huawei]user-interface vty 0 4 [Huawei]authentication-mode aaa 路由设置 # 显示路由表 display ip routing-table # 静态路由 # ip route-static 目标网络 掩码 下一跳 ip route-static 192.168.1.0 24 10.1.12.2 # 缺省路由 # ip route-static 0.0.0.0 下一跳地址 ip route-static 0.0.0.0 10.1.12.3 # 浮动静态路由：通过调整优先级，实现路由的备份（即：主备备份）。 [RTA]ip route-static 20.0.0.0 30 10.1.1.2 [RTA]ip route-static 20.0.0.0 30 10.1.2.2 preference 70 # 防止路由环回 [RTB]ip route-static 10.1.0.0 16 null0 开启ssh [R1]public-key local create rsa The range of public key modulus is (512 ~ 2048). If the key modulus is greater than 512, it will take a few minutes. Press CTRL+C to abort. Input the modulus length [default = 1024]: Generating Keys... .. Create the key pair successfully. [R1]ssh server enable # 进入 VTY 视图，配置验证模式为 scheme，设置用户权限为 Level-15，并配置协议为 ssh [R1]user-interface vty 0 4 [R1-line-vty0-4]authentication-mode scheme [R1-line-vty0-4]user-role level-15 [R1-line-vty0-4]protocol inbound ssh # 创建用于登录验证的用户，配置密码，配置用户权限为 Level-15，服务类型为 ssh [R1]local-user wangdaye class manage New local user added. [R1-luser-manage-wangdaye]password simple 123456 [R1-luser-manage-wangdaye]service-type ssh [R1-luser-manage-wangdaye]authorization-attribute user-role level-15 ","date":"2024-03-23","objectID":"/posts/2024-03-24-route-switch-base/:1:0","tags":["network"],"title":"Route\u0026Swich 基础","uri":"/posts/2024-03-24-route-switch-base/"},{"categories":["Network"],"content":"vlan # 传教vlan [SW1]vlan 10 [SW1-vlan10]vlan 20 # 把交换机的口加到vlan中 [SW1]int g1/0/2 [SW1-GigabitEthernet1/0/2]port access vlan 10 [SW1]int g1/0/3 [SW1-GigabitEthernet1/0/3]port access vlan 20 # 设置trunk口 [SW1]int g1/0/1 [SW1-GigabitEthernet1/0/1]port link-type trunk [SW1-GigabitEthernet1/0/1]port trunk permit vlan 10 20 单臂路由 [SW1]vlan 10 [SW1]vlan 20 [SW1]int g1/0/2 [SW1-GigabitEthernet1/0/2]port access vlan 10 [SW1]int g1/0/3 [SW1-GigabitEthernet1/0/3]port access vlan 20 [SW1]int g1/0/1 [SW1-GigabitEthernet1/0/1]port link-type trunk [SW1-GigabitEthernet1/0/1]port trunk permit vlan 10 20 [R1]int g0/0.1 [R1-GigabitEthernet0/0.1]vlan-type dot1q vid 10 [R1-GigabitEthernet0/0.1]ip add 192.168.1.254 24 [R1]int g0/0.2 [R1-GigabitEthernet0/0.2]vlan-type dot1q vid 20 [R1-GigabitEthernet0/0.2]ip add 192.168.2.254 24 [R1]dis ip routing-table Destinations : 16 Routes : 16 Destination/Mask Proto Pre Cost NextHop Interface 0.0.0.0/32 Direct 0 0 127.0.0.1 InLoop0 127.0.0.0/8 Direct 0 0 127.0.0.1 InLoop0 127.0.0.0/32 Direct 0 0 127.0.0.1 InLoop0 127.0.0.1/32 Direct 0 0 127.0.0.1 InLoop0 127.255.255.255/32 Direct 0 0 127.0.0.1 InLoop0 192.168.1.0/24 Direct 0 0 192.168.1.254 GE0/0.1 192.168.1.0/32 Direct 0 0 192.168.1.254 GE0/0.1 192.168.1.254/32 Direct 0 0 127.0.0.1 InLoop0 192.168.1.255/32 Direct 0 0 192.168.1.254 GE0/0.1 192.168.2.0/24 Direct 0 0 192.168.2.254 GE0/0.2 192.168.2.0/32 Direct 0 0 192.168.2.254 GE0/0.2 192.168.2.254/32 Direct 0 0 127.0.0.1 InLoop0 192.168.2.255/32 Direct 0 0 192.168.2.254 GE0/0.2 224.0.0.0/4 Direct 0 0 0.0.0.0 NULL0 224.0.0.0/24 Direct 0 0 0.0.0.0 NULL0 255.255.255.255/32 Direct 0 0 127.0.0.1 InLoop0 [R1] 三层交换机做路由 [SW1]vlan 10 [SW1-vlan10]vlan 20 [SW1]int g1/0/1 [SW1-GigabitEthernet1/0/1]port access vlan 10 [SW1]int g1/0/2 [SW1-GigabitEthernet1/0/2]port access vlan 20 [SW1]int vlan 10 [SW1-Vlan-interface10]ip add 192.168.1.254 24 [SW1]int vlan 20 [SW1-Vlan-interface20]ip add 192.168.2.254 24 [SW1]dis ip routing-table Destinations : 16 Routes : 16 Destination/Mask Proto Pre Cost NextHop Interface 0.0.0.0/32 Direct 0 0 127.0.0.1 InLoop0 127.0.0.0/8 Direct 0 0 127.0.0.1 InLoop0 127.0.0.0/32 Direct 0 0 127.0.0.1 InLoop0 127.0.0.1/32 Direct 0 0 127.0.0.1 InLoop0 127.255.255.255/32 Direct 0 0 127.0.0.1 InLoop0 192.168.1.0/24 Direct 0 0 192.168.1.254 Vlan10 192.168.1.0/32 Direct 0 0 192.168.1.254 Vlan10 192.168.1.254/32 Direct 0 0 127.0.0.1 InLoop0 192.168.1.255/32 Direct 0 0 192.168.1.254 Vlan10 192.168.2.0/24 Direct 0 0 192.168.2.254 Vlan20 192.168.2.0/32 Direct 0 0 192.168.2.254 Vlan20 192.168.2.254/32 Direct 0 0 127.0.0.1 InLoop0 192.168.2.255/32 Direct 0 0 192.168.2.254 Vlan20 224.0.0.0/4 Direct 0 0 0.0.0.0 NULL0 224.0.0.0/24 Direct 0 0 0.0.0.0 NULL0 255.255.255.255/32 Direct 0 0 127.0.0.1 InLoop0 [SW1] DHCP # 开启dhcp [R1]dhcp enable [R1]dhcp server ip-pool 1 [R1-dhcp-pool-1]network 192.168.1.0 mask 255.255.255.0 [R1-dhcp-pool-1]gateway-list 192.168.1.254 [R1-dhcp-pool-1]dns-list 202.103.24.68 202.103.0.117 # 设置专用地址段，要求不能用于自动分配 [R1]dhcp server forbidden-ip 192.168.1.10 192.168.1.20 ","date":"2024-03-23","objectID":"/posts/2024-03-24-route-switch-base/:1:1","tags":["network"],"title":"Route\u0026Swich 基础","uri":"/posts/2024-03-24-route-switch-base/"},{"categories":["DevOps"],"content":"OpenConnect 参考文档 https://github.com/huataihuang/cloud-atlas-draft/blob/master/security/vpn/openconnect/deploy_ocserv_vpn_server_on_ubuntu.md https://www.cnblogs.com/grafin/p/17785264.html https://cn.linux-console.net/?p=22087 OpenConnect起源于对Cisco AnyConnect VPN客户端的开源替代方案的需求。Cisco AnyConnect是一款商业VPN解决方案，用于建立安全的远程连接。然而，由于其闭源和商业性质，社区对于一个开源的替代品的需求逐渐增加。OpenConnect的发展旨在填补这一空白，为用户提供一个自由、灵活且安全的VPN连接选项。 工作原理 OpenConnect的工作原理基于与Cisco AnyConnect服务器建立的安全连接。它使用SSL和DTLS协议进行身份验证和加密通信。用户首先提供所需的连接参数，例如服务器地址、用户名和密码。然后，OpenConnect使用这些参数与服务器进行握手和认证。一旦身份验证成功，VPN连接将建立起来，用户可以通过加密通道安全地传输数据。 软件分为客户端和服务端： 服务端：ocserv 客户端：openconnect 客户端支持的vpn服务有 Cisco AnyConnect SSL VPN Juniper Network Connect GlobalProtect SSL VPN F5 BIG-IP SSL VPN FortiGate SSL VPN Array Networks SSL VPN Set VPN protocol: --protocol=anyconnect Compatible with Cisco AnyConnect SSL VPN, as well as ocserv (default) --protocol=nc Compatible with Juniper Network Connect --protocol=gp Compatible with Palo Alto Networks (PAN) GlobalProtect SSL VPN --protocol=pulse Compatible with Pulse Connect Secure SSL VPN --protocol=f5 Compatible with F5 BIG-IP SSL VPN --protocol=fortinet Compatible with FortiGate SSL VPN --protocol=array Compatible with Array Networks SSL VPN ","date":"2024-03-23","objectID":"/posts/2024-03-21-openconnect/:1:0","tags":["OpenConnect","vpn"],"title":"OpenConnect","uri":"/posts/2024-03-21-openconnect/"},{"categories":["DevOps"],"content":"一、部署 1、安装 ocserv RHEL 系列 ocserv 已经在 epel 仓库中提供了，所以可以直接通过 yum 安装 [root@dev ~]# yum install epel-release # gnutls-utils 包含证书的制作工具 certtool [root@dev ~]# yum install ocserv gnutls-utils 2、生成证书 [root@dev ~]# mkdir /opt/anyconnect [root@dev ~]# cd /opt/anyconnect/ # 生成 CA 证书 [root@dev ~]# certtool --generate-privkey --outfile ca-key.pem cat \u003eca.tmpl \u003c\u003cEOF cn = \"VPN CA\" organization = \"Local Corp\" serial = 1 expiration_days = 36500 ca signing_key cert_signing_key crl_signing_key EOF [root@dev ~]# certtool --generate-self-signed --load-privkey ca-key.pem \\ --template ca.tmpl --outfile ca-cert.pem # 复制 CA 证书到 ocserv 配置目录中 [root@dev ~]# cp ca-key.pem /etc/ocserv/ # 创建服务端证书 [root@dev ~]# certtool --generate-privkey --outfile server-key.pem [root@dev ~]# cat \u003eserver.tmpl \u003c\u003cEOF cn = \"VPN server\" organization = \"Local\" serial = 2 expiration_days = 3650 encryption_key signing_key tls_www_server EOF [root@dev ~]# certtool --generate-certificate --load-privkey server-key.pem \\ --load-ca-certificate ca-cert.pem --load-ca-privkey ca-key.pem \\ --template server.tmpl --outfile server-cert.pem [root@dev ~]# cp server-cert.pem server-key.pem /etc/ocserv/ 3、配置ocserv /etc/ocserv/ocserv.conf #ocserv支持多种认证方式，这是自带的密码认证，使用ocpasswd创建密码文件 #ocserv还支持证书认证，可以通过Pluggable Authentication Modules (PAM)使用radius等认证方式 auth = \"plain[passwd=/etc/ocserv/ocpasswd]\" #指定替代的登录方式，这里使用证书登录作为第二种登录方式 #指定替代的登录方式，这里使用证书登录作为第二种登录方式 #enable-auth = \"certificate\" #tcp和udp端口 tcp-port = 44333 udp-port = 44333 #运行用户和组 run-as-user = ocserv run-as-group = ocserv # socket文件 socket-file = /var/run/ocserv.sock #证书路径 server-cert = /etc/ocserv/server-cert.pem server-key = /etc/ocserv/server-key.pem #ca路径 ca-cert = /etc/ocserv/ca-cert.pem # 开启lz4压缩 compression = true # 隔离工作，默认不动 isolate-workers = true # 最大客户端数量，0表示无限数量 max-clients = 16 # 同一用户可以同时登陆的客户端数量 max-same-clients = 5 # 默认不动 rate-limit-ms = 100 # 服务器统计重置时间，不动 server-stats-reset-time = 604800 # 保持连接，每隔多少秒向客户端发送连接数据包，防止断线。 # IOS系统5分钟会关闭后台数据通讯，然后就会断线。 # 因此将keepalive和mobile-dpd设置成200秒 keepalive = 200 dpd = 90 mobile-dpd = 200 # udp端口无传输25秒后转成tcp端口 switch-to-tcp-timeout = 25 # 启用MTU转发以优化性能 try-mtu-discovery = true # 空闲断开时间，如果想无限期连接，注释这两行 # idle-timeout=1200 # mobile-idle-timeout=2400 # 仅使用TLS1.2以上版本 cert-user-oid = 0.9.2342.19200300.100.1.1 tls-priorities = \"NORMAL:%SERVER_PRECEDENCE:%COMPAT:-RSA:-VERS-SSL3.0:-ARCFOUR-128:-VERS-TLS1.0:-VERS-TLS1.1\" # 认证超时时间 auth-timeout = 240 # 最小重新认证时间 min-reauth-time = 300 max-ban-score = 80 ban-reset-time = 1200 cookie-timeout = 324000 deny-roaming = false rekey-time = 172800 rekey-method = ssl use-occtl = true pid-file = /var/run/ocserv.pid device = vpns predictable-ips = true # 默认域名，修改为你的域名或ip地址，这个设置没有任何作用 default-domain = xxx.com:4433 # 配置自定义私有IP地址范围(vpn客户端)，注释默认的两行 #ipv4-network = 192.168.1.0 #ipv4-netmask = 255.255.255.0 ipv4-network = 10.70.25.0 ipv4-netmask = 255.255.255.0 # 以VPN隧道传输所有DNS查询 tunnel-all-dns = true # 更改DNS服务器(国内服务器就填写国内dns) dns = 8.8.8.8 dns = 1.1.1.1 # 允许思科客户端连接 cisco-client-compat = true # 以下路由表不通过VPN隧道，直接本地网络连接 # 一定要添加自己服务器的ip地址，否则连上VPN后打不开自己的网站 no-route = x.x.x.x/255.255.255.255 #只允许访问下面的网段(推送的路由) route = 192.168.0.0/255.255.0.0 route = 172.16.0.0/255.255.0.0 4、创建用户 #username为你要添加的用户名 [root@dev ~]# ocpasswd -c /etc/ocserv/ocpasswd username # 检查内核转发 [root@dev ~]# cat /proc/sys/net/ipv4/ip_forward # 开启内核转发 [root@dev ~]# echo \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf [root@dev ~]# sysctl -p # 配置iptables规则(不需要配置) # 对指定的表 table 进行操作，添加一个规则，把192.168.111.0的流量指定到ens36出去 iptables -t nat -A POSTROUTING -s 192.168.111.0 -o ens36 -j MASQUERADE iptables -A FORWARD -i vpns+ -j ACCEPT iptables -A FORWARD -o vpns+ -j ACCEPT # 保存路由表 iptables-save \u003e /etc/sysconfig/iptables # 放行端口(firewalld配置) firewall-cmd --permanent --add-port=44333/tcp firewall-cmd --permanent --add-port=44333/udp firewall-cmd --add-masquerade --permanent #必须配置，重要 firewall-cmd --reload 5、测试 测试服务启动 [root@dev ~]# ocserv -c /etc/ocserv/ocserv.conf -f -d 10 启动服务 [root@dev ~]# systemctl enable ocserv [root@dev ~]# systemctl start ","date":"2024-03-23","objectID":"/posts/2024-03-21-openconnect/:1:1","tags":["OpenConnect","vpn"],"title":"OpenConnect","uri":"/posts/2024-03-21-openconnect/"},{"categories":["DevOps"],"content":"K3s 证书 k3s 根CA证书默认10年，签署的证书有效期默认1年，在到期前的90天内需要重启，重启后会自动轮转证书。 参考文档： https://forums.rancher.cn/t/k3s-ca-10/331 https://blog.starudream.cn/2023/07/21/k3s-client-cert-extend/ https://forums.rancher.cn/t/k3s-ca-10/331/37 https://github.com/qkboy/k3s/tree/v1.29.0%2Bk3s1-longcert https://docs.k3s.io/zh/cli/certificate#%E8%BD%AE%E6%8D%A2%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%81%E4%B9%A6 https://www.linuxfly.org/post/733/ ","date":"2024-03-21","objectID":"/posts/2024-03-11-k3s-cert/:0:0","tags":["k3s cert"],"title":"k3s-cert","uri":"/posts/2024-03-11-k3s-cert/"},{"categories":["DevOps"],"content":"一、手动轮转证书 1、检查证书有效期 # server for i in `ls /var/lib/rancher/k3s/server/tls/*.crt`; do echo $i; openssl x509 -enddate -noout -in $i; done # agent for i in `ls /var/lib/rancher/k3s/agent/*.crt`; do echo $i; openssl x509 -enddate -noout -in $i; done 2、设置环境变量 echo CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=\"3600\" \u003e\u003e /etc/default/k3s 3、轮转证书 server # 停止 K3s systemctl stop k3s # 轮换证书 k3s certificate rotate # 启动 K3s systemctl start k3s agent systemctl restart k3s-agent 4、检查证书有效期 for i in `ls /var/lib/rancher/k3s/server/tls/*.crt`; do echo $i; openssl x509 -enddate -noout -in $i; done kubectl get secret -n kube-system k3s-serving -o jsonpath='{.data.tls\\.crt}' | base64 -d | openssl x509 -noout -text | grep Not ","date":"2024-03-21","objectID":"/posts/2024-03-11-k3s-cert/:1:0","tags":["k3s cert"],"title":"k3s-cert","uri":"/posts/2024-03-11-k3s-cert/"},{"categories":["DevOps"],"content":"二、修改源码方式 k3s 是引用dynamiclistener 这个库来生成证书的，可以修改源码实现百年证书 ","date":"2024-03-21","objectID":"/posts/2024-03-11-k3s-cert/:2:0","tags":["k3s cert"],"title":"k3s-cert","uri":"/posts/2024-03-11-k3s-cert/"},{"categories":["DevOps"],"content":"三、自定义证书 k3s 官方有提供脚本用于在创建集群前先创建证书 wget https://raw.githubusercontent.com/k3s-io/k3s/master/contrib/util/generate-custom-ca-certs.sh sed -ri 's/7300/36500/g' generate-custom-ca-certs.sh sed -ri 's/3700/36500/g' generate-custom-ca-certs.sh echo CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=\"36500\" \u003e /etc/default/k3s bash generate-custom-ca-certs.sh curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn INSTALL_K3S_EXEC=\"--disable=traefik --disable=servicelb --kube-proxy-arg proxy-mode=ipvs --write-kubeconfig ~/.kube/config --write-kubeconfig-mode 644 \" sh -s - --docker check for i in `ls /var/lib/rancher/k3s/server/tls/*.crt`; do echo $i; openssl x509 -enddate -noout -in $i; done kubectl get secret -n kube-system k3s-serving -o jsonpath='{.data.tls\\.crt}' | base64 -d | openssl x509 -noout -text | grep Not ","date":"2024-03-21","objectID":"/posts/2024-03-11-k3s-cert/:3:0","tags":["k3s cert"],"title":"k3s-cert","uri":"/posts/2024-03-11-k3s-cert/"},{"categories":["DevOps"],"content":"四、RBAC 管理 1、创建证书和签名请求 [root@dev ~]# openssl genrsa -out dev.key 2048 [root@dev ~]# openssl req -new -key dev.key -out dev.csr -subj \"/CN=dev/O=dev\" 2、创建 csr ，请求签名 [root@dev ~]# cat \u003c\u003cEOF | kubectl apply -f - apiVersion: certificates.k8s.io/v1 kind: CertificateSigningRequest metadata: name: dev spec: groups: - system:authenticated request: $(cat dev.csr | base64 | tr -d '\\n') signerName: kubernetes.io/kube-apiserver-client usages: - client auth EOF [root@dev ~]# kubectl get csr [root@dev ~]# kubectl certificate approve dev [root@dev ~]# kubectl get csr dev -o jsonpath='{.status.certificate}' | base64 -d \u003e dev.crt 3、生成证书 # 复制一份当前的证书作为模板 [root@dev ~]# cp ~/.kube/config local-config [root@dev ~]# kubectl config set-credentials default --client-key=dev.key --client-certificate=dev.crt --embed-certs=true --kubeconfig=local-config [root@dev ~]# kubectl config set-context default --cluster=default --user=default --kubeconfig=local-config 证书有效期默认是一年 4、rbac 配置 https://github.com/serialt/terraform-module-k8s-rbac rbac（用于测试） [root@dev ~]# cat \u003e rbac.yaml \u003c\u003cEOF apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: default name: dev rules: - apiGroups: [\"\"] #core api组 resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: dev namespace: default #授权的命名空间为default subjects: - kind: User name: dev # 绑定dev用户 apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: dev #绑定Role apiGroup: rbac.authorization.k8s.io EOF kubectl apply -f rbac.yaml [root@dev ~]# export KUBECONFIG=local-config [root@dev ~]#kubectl get pod NAME READY STATUS RESTARTS AGE myapp-deployment-6587ffc4b-ws4hm 1/1 Running 2 27d myapp-deployment-6587ffc4b-zx8g2 1/1 Running 1 27d [root@master-01 user]# kubectl get ns Error from server (Forbidden): namespaces is forbidden: User \"dev\" cannot list resource \"namespaces\" in API group \"\" at the cluster scope [root@dev ~]# kubectl get svc Error from server (Forbidden): services is forbidden: User \"dev\" cannot list resource \"services\" in API group \"\" in the namespace \"default\" ","date":"2024-03-21","objectID":"/posts/2024-03-11-k3s-cert/:4:0","tags":["k3s cert"],"title":"k3s-cert","uri":"/posts/2024-03-11-k3s-cert/"},{"categories":["DevOps"],"content":"Terraform Registry Mirror terraform 的 provider 托管在海外，使用时候会经常因为网络问题导致下载失败，terraform 官方有 Provider Network Mirror Protocol，支持使用本地文件和 Static Website，制作方法都依赖于terraform providers mirror 命令获取到的资源。 ","date":"2024-03-17","objectID":"/posts/2024-03-17-tf-mirror-registery/:1:0","tags":["terraform-registry","hashicorp"],"title":"Terraform Registry Mirror","uri":"/posts/2024-03-17-tf-mirror-registery/"},{"categories":["DevOps"],"content":"1、制作离线 provider 资源 在当前目录下生成 provider.tf 文件 terraform { required_providers { docker = { source = \"kreuzwerker/docker\" version = \"2.20.3\" } } } 创建存储的目录，并下载 provider # 下载当前版 terraform 架构的 provider 到 provider 目录，可以用 -platform=OS_ARCH 指定架构 [serialt@Sugar tf-demo]🐳 mkdir providers terraform providers mirror providers # 下载 darwin_arm64 linux_amd64 [serialt@Sugar tf-demo]🐳 terraform providers mirror -platform=linux_amd64 providers [serialt@Sugar tf-demo]🐳 terraform providers mirror -platform=darwin_arm64 providers [serialt@Sugar tf-demo]🐳 tree providers providers └── registry.terraform.io └── kreuzwerker └── docker ├── 2.20.3.json ├── index.json ├── terraform-provider-docker_2.20.3_darwin_arm64.zip └── terraform-provider-docker_2.20.3_linux_amd64.zip 3 directories, 4 files ","date":"2024-03-17","objectID":"/posts/2024-03-17-tf-mirror-registery/:1:1","tags":["terraform-registry","hashicorp"],"title":"Terraform Registry Mirror","uri":"/posts/2024-03-17-tf-mirror-registery/"},{"categories":["DevOps"],"content":"2、本地文件镜像 配置插件缓存目录 export TF_PLUGIN_CACHE_DIR=/home/user/.terraform.d/plugin-cache 配置 ~/.terraformrc provider_installation { filesystem_mirror { path = \"/home/user/tf-demo/providers\" include = [\"*/*/*\"] } direct { exclude = [\"*/*/*\"] } } [serialt@Sugar tf-ccc]🐳 terraform init Initializing the backend... Initializing provider plugins... - Finding kreuzwerker/docker versions matching \"2.20.3\"... - Installing kreuzwerker/docker v2.20.3... - Installed kreuzwerker/docker v2.20.3 (unauthenticated) Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run \"terraform init\" in the future. ╷ │ Warning: Incomplete lock file information for providers │ │ Due to your customized provider installation methods, Terraform was forced to │ calculate lock file checksums locally for the following providers: │ - kreuzwerker/docker │ │ The current .terraform.lock.hcl file only includes checksums for │ darwin_arm64, so Terraform running on another platform will fail to install │ these providers. │ │ To calculate additional checksums for another platform, run: │ terraform providers lock -platform=linux_amd64 │ (where linux_amd64 is the platform to generate) ╵ Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. ","date":"2024-03-17","objectID":"/posts/2024-03-17-tf-mirror-registery/:1:2","tags":["terraform-registry","hashicorp"],"title":"Terraform Registry Mirror","uri":"/posts/2024-03-17-tf-mirror-registery/"},{"categories":["DevOps"],"content":"3、网络镜像 nginx配置文件 server { server_name tf-mirror.local.com; listen 80; return 301 https://$server_name$request_uri; } server{ server_name tf-mirror.local.com; listen 443 ssl; charset utf-8; gzip on; gzip_min_length 1K; gzip_comp_level 4; gzip_buffers 32 4K; gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; gzip_vary on; add_header Strict-Transport-Security \"max-age=31536000; includeSubDomians;proload\" always; root /data/terraform-mirror/; index index.html index.htm; try_files $uri $uri/ /index.html; client_max_body_size 20m; access_log /var/log/nginx/tf-mirror.local.com.log main; error_log /var/log/nginx/tf-mirror.local.com-err.log; ssl_certificate /etc/nginx/cert_files/local.com.crt; ssl_certificate_key /etc/nginx/cert_files/local.com.key; } 上传下载的 provider 资源到 web 根目录 例如：/data/terraform-mirror/ [serialt@Sugar tf-ccc]🐳 scp -r ./providers local.com:/data/terraform-mirror/ 启动nginx服务 配置~/.terraformrc文件 provider_installation { network_mirror { url = \"https://tf-mirror.local.com/providers/\" } } [serialt@Sugar tf-ccc]🐳 terraform init Initializing the backend... Initializing provider plugins... - Finding latest version of hashicorp/random... - Installing hashicorp/random v3.6.0... - Installed hashicorp/random v3.6.0 (verified checksum) Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run \"terraform init\" in the future. Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. ","date":"2024-03-17","objectID":"/posts/2024-03-17-tf-mirror-registery/:1:3","tags":["terraform-registry","hashicorp"],"title":"Terraform Registry Mirror","uri":"/posts/2024-03-17-tf-mirror-registery/"},{"categories":["DevOps"],"content":"4、基于脚本下载 provider 离线资源 https://github.com/serialt/terraform-registry-mirror 要求： terraform jq 1）修改下载的平台和架构 sed -ri PLATFORMS=\"linux_amd64 darwin_amd64 darwin_arm64\" sed -ri '/^PLATFORMS=/cPLATFORMS=\"linux_amd64 darwin_amd64 darwin_arm64\"' bin/mirror.sh sed -ri '/^PLATFORMS=/cPLATFORMS=\"linux_amd64 darwin_amd64 darwin_arm64\"' bin/core.sh 2）下载 terraform bin/core.sh terraform.json 3）下载 provider # 下载单个 bin/core.sh ./providers/aws.json # 下载多个 mirror(){ action=$1 providers=`ls ./providers` for i in ${providers};do bash ./bin/${action} ./providers/${i} done } mirror mirror.sh # mirror updater.sh ","date":"2024-03-17","objectID":"/posts/2024-03-17-tf-mirror-registery/:1:4","tags":["terraform-registry","hashicorp"],"title":"Terraform Registry Mirror","uri":"/posts/2024-03-17-tf-mirror-registery/"},{"categories":["DevOps"],"content":"Packer 参考链接： https://developer.hashicorp.com/packer/docs?product_intent=packer https://blog.k8s.li/packer-vsphere-example.html https://cloud.tencent.com/developer/article/1474736 https://blog.csdn.net/weixin_45941099/article/details/123838526 https://github.com/serialt/packer-demo https://lonegunmanb.github.io/packer-handbook/ ","date":"2024-03-16","objectID":"/posts/2024-03-15-packer/:1:0","tags":["packer","hashicorp"],"title":"Packer","uri":"/posts/2024-03-15-packer/"},{"categories":["DevOps"],"content":"介绍： Packer是用一个配置文件，在多种云计算平台上创建完全一致镜像的开源工具。Packer是由HashiCorp在2013年左右推出的。Packer可以在各种主流操作系统上运行，可以高速、并行在多种云平台上创建镜像。Packer并不能取代puppet或者Chef之类的主机配置工具，而是互为补充-Packer在创建镜像时，可以调用这些工具在基础镜像上安装、配置软件。 镜像是指一个预先安装了软件、配置好了的操作系统，这个镜像可以被用开快速创建云主机。每个云平台通常有不同的镜像格式。 Packer解决什么问题 使用预先准备好的镜像有很多好处，但是很多人都不太愿意使用这种方式，原因是创建和管理镜像实在是太复杂了。所以在Packer出现之前，镜像都是人工在云平台上搭建一个操作系统，然后通过云平台的功能转换成镜像而创建的，这对运维团队的速度影响很大，因此大家都不怎么使用镜像。 Packer的出现解决了这些问题。Packer只是一个命令行工具，易于通过终端使用，也可以很简单的放到自动化工具里边，用来自动创建任何类型的主机镜像。 使用Packer的好处 快速的基础架构实施：Packer创建的镜像可以让运维人员几秒钟内创建一个预先配置好的云主机，而不是几分钟甚至几个小时。这一好处不但对生产环境，也对测试及开发环境有益。 多平台兼容：由于Packer可以为多个平台创建完全一致的镜像，你可以在腾讯云上运行生产环境，在自己的私有云里边运行测试环境，在自己的vmware虚拟机里运行开发环境。而每个环境都完全一致。 提高稳定性：Packer在创建镜像时安装并配置软件。安装或者配置步骤中的问题会在这时候发现，而不是在穿件云主机的时候。 提高可测试性：镜像创建完成后，可以很快的启动一个云主机并对其进行测试。如果测试通过，那就可以相信，通过这个镜像创建的云主机都会通过测试。 ","date":"2024-03-16","objectID":"/posts/2024-03-15-packer/:1:1","tags":["packer","hashicorp"],"title":"Packer","uri":"/posts/2024-03-15-packer/"},{"categories":["DevOps"],"content":"具体用例 在持续开发、持续交付Pipeline里使用Packer Packer是用命令行驱动的，而且不需要很多资源。因此可以很容易把Packer放到持续交付的pipeline里，创建镜像。在持续交付随后的步骤中，可以对此镜像进行测试，看基础设施的变化是不是能够通过测试。如果测试通过，那就可以相信在这一镜像基础上搭建的云主机也会工作。这对基础设施变化的稳定性和可测试性提供了基础。 保证开发与生产环境的一致性 Packer可以让开发与生产环境尽量一致。由于Packer可以为多个平台创建完全一致的镜像，你可以在腾讯云上运行生产环境，在自己的私有云里边运行测试环境，在自己的vmware虚拟机里运行开发环境。而每个环境都完全一致。把这一用例与前边的持续交付结合在一起，用户可以保障开发环境与生产环境尽量一致，从而减少出问题的可能。 ","date":"2024-03-16","objectID":"/posts/2024-03-15-packer/:1:2","tags":["packer","hashicorp"],"title":"Packer","uri":"/posts/2024-03-15-packer/"},{"categories":["DevOps"],"content":"build过程 Packer使用hcl和json文件的模板将配置携带到各种任务中。 核心任务是Build 。 在此阶段，Packer正在使用Builders为单个平台创建机器映像。 例如。 Qemu Builder创建一个kvm / xen虚拟机映像。 下一阶段是配置。 在此任务中， 预配器 （如ansible或shell脚本）在计算机映像内执行任务。 完成后， 后处理器将处理最终任务。 例如压缩虚拟映像或将其导入特定的应用程序。 packer模板：一个 hcl template file 包含： builders (必需) description (可选) variables (可选) min_packer_version (可选) provisioners (可选) post-processors(可选) ","date":"2024-03-16","objectID":"/posts/2024-03-15-packer/:1:3","tags":["packer","hashicorp"],"title":"Packer","uri":"/posts/2024-03-15-packer/"},{"categories":["DevOps"],"content":"示例 1、docker镜像打包 基于 ubuntu 2204 生成自定义镜像，并导出到 ubuntu.image.tar [root@dev docker]# cat docker.pkr.hcl packer { required_plugins { docker = { version = \"\u003e= 0.0.7\" source = \"github.com/hashicorp/docker\" } } } variable \"msg\" { type = string default = \"build image\" } source \"docker\" \"app\" { image = \"ubuntu:22.04\" commit = \"true\" } build { name = \"build image\" sources = [\"source.docker.app\"] provisioner \"shell\" { environment_vars = [ \"FOO=hello world\", ] inline = [ \"echo Adding file to Docker Container\", \"echo \\\"FOO is $FOO\\\" \u003e example.txt\", ] } provisioner \"shell\" { inline = [\"echo This provisioner runs last ${var.msg} \"] } post-processor \"docker-tag\" { repository = \"docker.io/serialt/ubuntu-packer\" tags = [\"app\", \"packer-app\"] only = [\"docker.app\"] } } RHEL系列系统中已经有packer命令，在下载 hashicorp packer 后为了防止冲突，可以将 hashicorp 的 packer 改名为 packer.io # 安装 docker的插件 packer.io plugins install github.com/hashicorp/docker # 自动补全 packer.io -autocomplete-install # 列出已经安装的插件 [root@dev docker]# packer.io --version 1.9.1 [root@dev docker]# packer.io plugins installed /root/.config/packer/plugins/github.com/hashicorp/docker/packer-plugin-docker_v1.0.7_x5.0_linux_amd64 /root/.config/packer/plugins/github.com/hashicorp/qemu/packer-plugin-qemu_v1.0.8_x5.0_linux_amd64 /root/.config/packer/plugins/github.com/hashicorp/qemu/packer-plugin-qemu_v1.0.9_x5.0_linux_amd64 /root/.config/packer/plugins/github.com/hashicorp/ansible/packer-plugin-ansible_v1.1.0_x5.0_linux_amd64 # 打包镜像 [root@dev docker]# packer.io build . build image.docker.app: output will be in this color. ==\u003e build image.docker.app: Creating a temporary directory for sharing data... ==\u003e build image.docker.app: Pulling Docker image: ubuntu:22.04 build image.docker.app: 22.04: Pulling from library/ubuntu build image.docker.app: Digest: sha256:77906da86b60585ce12215807090eb327e7386c8fafb5402369e421f44eff17e build image.docker.app: Status: Image is up to date for ubuntu:22.04 build image.docker.app: docker.io/library/ubuntu:22.04 ==\u003e build image.docker.app: Starting docker container... build image.docker.app: Run command: docker run -v /root/.config/packer/tmp2973759040:/packer-files -d -i -t --entrypoint=/bin/sh -- ubuntu:22.04 build image.docker.app: Container ID: 7d3c046baf8524135b2ac56470943d872f52c9890f75a1fa47cd26f1548fd008 ==\u003e build image.docker.app: Using docker communicator to connect: 172.17.0.8 ==\u003e build image.docker.app: Provisioning with shell script: /tmp/packer-shell3125516653 build image.docker.app: Adding file to Docker Container ==\u003e build image.docker.app: Provisioning with shell script: /tmp/packer-shell1890782291 build image.docker.app: This provisioner runs last build image ==\u003e build image.docker.app: Committing the container build image.docker.app: Image ID: sha256:1e5475a585ac3894ab4890a8901babc0f190388a5dfab28b1c0a35a4eb2d2ff6 ==\u003e build image.docker.app: Killing the container: 7d3c046baf8524135b2ac56470943d872f52c9890f75a1fa47cd26f1548fd008 ==\u003e build image.docker.app: Running post-processor: (type docker-tag) build image.docker.app (docker-tag): Tagging image: sha256:1e5475a585ac3894ab4890a8901babc0f190388a5dfab28b1c0a35a4eb2d2ff6 build image.docker.app (docker-tag): Repository: docker.io/serialt/ubuntu-packer:app build image.docker.app (docker-tag): Tagging image: sha256:1e5475a585ac3894ab4890a8901babc0f190388a5dfab28b1c0a35a4eb2d2ff6 build image.docker.app (docker-tag): Repository: docker.io/serialt/ubuntu-packer:packer-app Build 'build image.docker.app' finished after 6 seconds 607 milliseconds. ==\u003e Wait completed after 6 seconds 607 milliseconds ==\u003e Builds finished. The artifacts of successful builds are: --\u003e build image.docker.app: Imported Docker image: sha256:1e5475a585ac3894ab4890a8901babc0f190388a5dfab28b1c0a35a4eb2d2ff6 --\u003e build image.docker.app: Imported Docker image: docker.io/serialt/ubuntu-packer:packer-app with tags docker.io/serialt/ubuntu-packer:app docker.io/serialt/ubuntu-packer:packer-app [root@dev docker]# ","date":"2024-03-16","objectID":"/posts/2024-03-15-packer/:1:4","tags":["packer","hashicorp"],"title":"Packer","uri":"/posts/2024-03-15-packer/"},{"categories":["DevOps"],"content":"2、Mac 上构建 VMware Fusion 镜像 https://github.com/serialt/packer-demo 基于 vagrant 构建 rockylinux iso # 安装 vagrant brew tap hashicorp/tap brew install hashicorp/tap/hashicorp-vagrant # 安装 vagrant-vmware-desktop # https://developer.hashicorp.com/vagrant/docs/providers/vmware/installation vagrant plugin install vagrant-vmware-desktop # 安装插件 [sugar@dev docker]# packer init . # 格式化代码 [sugar@dev docker]# packer fmt . [sugar@dev docker]# packer build -only=vmware-iso.rockylinux-9-aarch64 . [sugarSugar rockylinux]🐳 packer build -only=vmware-iso.rockylinux-9-aarch64 . Warning: Your vmx data contains the following variable(s), which Packer normally sets when it generates its own default vmx template. This may cause your build to fail or behave unpredictably: virtualHW.version on rockylinux-9-vagrant.pkr.hcl line 115: (source code not available) vmware-iso.rockylinux-9-aarch64: output will be in this color. ==\u003e vmware-iso.rockylinux-9-aarch64: Retrieving ISO ==\u003e vmware-iso.rockylinux-9-aarch64: Trying https://mirror.sjtu.edu.cn/rocky/9.3/isos/aarch64/Rocky-9.3-aarch64-boot.iso ==\u003e vmware-iso.rockylinux-9-aarch64: Trying https://mirror.sjtu.edu.cn/rocky/9.3/isos/aarch64/Rocky-9.3-aarch64-boot.iso?checksum=sha256%3Ae23f647456234d11d08eea5071c8d6dc56981ec54fa2da3a6b696adbf5543453 ==\u003e vmware-iso.rockylinux-9-aarch64: https://mirror.sjtu.edu.cn/rocky/9.3/isos/aarch64/Rocky-9.3-aarch64-boot.iso?checksum=sha256%3Ae23f647456234d11d08eea5071c8d6dc56981ec54fa2da3a6b696adbf5543453 =\u003e /Users/serialt/.cache/packer/b49961728ad30951d1cbcb3007deff311f5c929d.iso ==\u003e vmware-iso.rockylinux-9-aarch64: Configuring output and export directories... ==\u003e vmware-iso.rockylinux-9-aarch64: Creating required virtual machine disks ==\u003e vmware-iso.rockylinux-9-aarch64: Building and writing VMX file ==\u003e vmware-iso.rockylinux-9-aarch64: Starting HTTP server on port 8963 ==\u003e vmware-iso.rockylinux-9-aarch64: Starting virtual machine... vmware-iso.rockylinux-9-aarch64: The VM will be run headless, without a GUI. If you want to vmware-iso.rockylinux-9-aarch64: view the screen of the VM, connect via VNC with the password \"GsYgoysa\" to vmware-iso.rockylinux-9-aarch64: vnc://127.0.0.1:5938 ==\u003e vmware-iso.rockylinux-9-aarch64: Connecting to VNC... ==\u003e vmware-iso.rockylinux-9-aarch64: Waiting 10s for boot... ==\u003e vmware-iso.rockylinux-9-aarch64: Typing the boot command over VNC... ==\u003e vmware-iso.rockylinux-9-aarch64: Waiting for SSH to become available... ==\u003e vmware-iso.rockylinux-9-aarch64: Connected to SSH! ==\u003e vmware-iso.rockylinux-9-aarch64: Provisioning with Ansible... vmware-iso.rockylinux-9-aarch64: Setting up proxy adapter for Ansible.... ==\u003e vmware-iso.rockylinux-9-aarch64: Executing Ansible: ansible-playbook -e packer_build_name=\"rockylinux-9-aarch64\" -e packer_builder_type=vmware-iso -e packer_http_addr=172.16.1.1:8963 --ssh-extra-args '-o IdentitiesOnly=yes' --extra-vars packer_provider=vmware-iso -e ansible_ssh_private_key_file=/var/folders/vm/zlhwbdyj2031f088_w9q3f8w0000gn/T/ansible-key3377589468 -i /var/folders/vm/zlhwbdyj2031f088_w9q3f8w0000gn/T/packer-provisioner-ansible4016248806 /Users/serialt/github/packer/rockylinux/ansible/*****-box.yml vmware-iso.rockylinux-9-aarch64: vmware-iso.rockylinux-9-aarch64: PLAY [RockyLinux Vagrant Box] ************************************************** vmware-iso.rockylinux-9-aarch64: vmware-iso.rockylinux-9-aarch64: TASK [Gathering Facts] ********************************************************* vmware-iso.rockylinux-9-aarch64: ok: [default] vmware-iso.rockylinux-9-aarch64: vmware-iso.rockylinux-9-aarch64: TASK [cleanup_vm : Upgrade packages] ******************************************* vmware-iso.rockylinux-9-aarch64: ok: [default] vmware-iso.rockylinux-9-aarch64: vmware-iso.rockylinux-9-aarch64: TASK [cleanup_vm : Install python3-libselinux] ********************************* vmware-iso.rockylinux-9-aarch64: ok: [default] vmware-iso.rockylinux-9-aarch64: vmware-iso.rockylinux-9-aarch64: TASK [cleanup_vm : Install epel] ****************","date":"2024-03-16","objectID":"/posts/2024-03-15-packer/:1:5","tags":["packer","hashicorp"],"title":"Packer","uri":"/posts/2024-03-15-packer/"},{"categories":["DevOps"],"content":"3、linux 上构建qemu镜像 [root@dev cloud-images]# packer.io build -var qemu_binary=\"/usr/libexec/qemu-kvm\" -only=qemu.almalinux-8-gencloud-x86_64 . qemu.almalinux-8-gencloud-x86_64: output will be in this color. ==\u003e qemu.almalinux-8-gencloud-x86_64: Retrieving ISO ==\u003e qemu.almalinux-8-gencloud-x86_64: Trying https://mirror.sjtu.edu.cn/almalinux/8.8/isos/x86_64/AlmaLinux-8.8-x86_64-boot.iso ==\u003e qemu.almalinux-8-gencloud-x86_64: Trying https://mirror.sjtu.edu.cn/almalinux/8.8/isos/x86_64/AlmaLinux-8.8-x86_64-boot.iso?checksum=sha256%3A016e59963c2c3bd4c99c18ac957573968e23da51131104568fbf389b11df3e05 ==\u003e qemu.almalinux-8-gencloud-x86_64: https://mirror.sjtu.edu.cn/almalinux/8.8/isos/x86_64/AlmaLinux-8.8-x86_64-boot.iso?checksum=sha256%3A016e59963c2c3bd4c99c18ac957573968e23da51131104568fbf389b11df3e05 =\u003e /root/.cache/packer/cd61467f6ca2d6762e243b18a2705c8b210e11aa.iso ==\u003e qemu.almalinux-8-gencloud-x86_64: Starting HTTP server on port 8889 ==\u003e qemu.almalinux-8-gencloud-x86_64: Found port for communicator (SSH, WinRM, etc): 2564. ==\u003e qemu.almalinux-8-gencloud-x86_64: Looking for available port between 5900 and 6000 on 127.0.0.1 ==\u003e qemu.almalinux-8-gencloud-x86_64: Starting VM, booting from CD-ROM qemu.almalinux-8-gencloud-x86_64: The VM will be run headless, without a GUI. If you want to qemu.almalinux-8-gencloud-x86_64: view the screen of the VM, connect via VNC without a password to qemu.almalinux-8-gencloud-x86_64: vnc://127.0.0.1:5955 ==\u003e qemu.almalinux-8-gencloud-x86_64: Waiting 10s for boot... ==\u003e qemu.almalinux-8-gencloud-x86_64: Connecting to VM via VNC (127.0.0.1:5955) ==\u003e qemu.almalinux-8-gencloud-x86_64: Typing the boot commands over VNC... qemu.almalinux-8-gencloud-x86_64: Not using a NetBridge -- skipping StepWaitGuestAddress ==\u003e qemu.almalinux-8-gencloud-x86_64: Using SSH communicator to connect: 127.0.0.1 ==\u003e qemu.almalinux-8-gencloud-x86_64: Waiting for SSH to become available... ==\u003e qemu.almalinux-8-gencloud-x86_64: Connected to SSH! ==\u003e qemu.almalinux-8-gencloud-x86_64: Provisioning with Ansible... qemu.almalinux-8-gencloud-x86_64: Setting up proxy adapter for Ansible.... qemu.almalinux-8-gencloud-x86_64: Executing Ansible Galaxy qemu.almalinux-8-gencloud-x86_64: Starting galaxy role install process qemu.almalinux-8-gencloud-x86_64: [WARNING]: The requirements file '/opt/packer/cloud- qemu.almalinux-8-gencloud-x86_64: - downloading role 'vbox_guest', owned by ezamriy qemu.almalinux-8-gencloud-x86_64: images/ansible/requirements.yml' contains collections which will be ignored. To qemu.almalinux-8-gencloud-x86_64: install these collections run 'ansible-galaxy collection install -r' or to qemu.almalinux-8-gencloud-x86_64: install both at the same time run 'ansible-galaxy install -r' without a custom qemu.almalinux-8-gencloud-x86_64: install path. qemu.almalinux-8-gencloud-x86_64: - downloading role from https://github.com/ezamriy/ansible-role-vbox_guest/archive/v0.2.0.tar.gz qemu.almalinux-8-gencloud-x86_64: [ERROR]: failed to download the file: The read operation timed out qemu.almalinux-8-gencloud-x86_64: [WARNING]: - ezamriy.vbox_guest was NOT installed successfully. qemu.almalinux-8-gencloud-x86_64: ERROR! - you can use --ignore-errors to skip failed roles and finish processing the list. ==\u003e qemu.almalinux-8-gencloud-x86_64: Provisioning step had errors: Running the cleanup provisioner, if present... ==\u003e qemu.almalinux-8-gencloud-x86_64: Deleting output directory... Build 'qemu.almalinux-8-gencloud-x86_64' errored after 17 minutes 14 seconds: Error executing Ansible: Error executing Ansible Galaxy: Non-zero exit status: exit status 1 ==\u003e Wait completed after 17 minutes 14 seconds ==\u003e Some builds didn't complete successfully and had errors: --\u003e qemu.almalinux-8-gencloud-x86_64: Error executing Ansible: Error executing Ansible Galaxy: Non-zero exit status: exit status 1 ==\u003e Builds finished but no artifacts were created. [root@dev cloud-images]# [root@dev cloud-images]# [root@dev cloud-images]# ","date":"2024-03-16","objectID":"/posts/2024-03-15-packer/:1:6","tags":["packer","hashicorp"],"title":"Packer","uri":"/posts/2024-03-15-packer/"},{"categories":["Go 库文档"],"content":"Go embed 实现将文件打包到Go程序中 参考链接：https://juejin.cn/post/7103539856805986334 Go是一门编译型语言，编译后生成的二进制文件可以直接在对应的操作系统直接运行，我们编译出来的程序一般都是一个二进制文件，但是在实际的使用过程中，除了二进制文件，我们还需要一些配置文件或者一些静态的文件，如Html，CSS，等文件。如果我们可以将这些文件在编译的时候，就一同打包到我们的二进制中，那是一件很每秒的事情，也能降低使用方的门槛~ Go在1.16中提供了go:embed的功能，有了他，就可以实现将一些文件嵌入到我们的打包程序中。 ","date":"2024-03-16","objectID":"/posts/2024-03-15-go-embed/:1:0","tags":["Go","embed"],"title":"Go Embed","uri":"/posts/2024-03-15-go-embed/"},{"categories":["Go 库文档"],"content":"牛刀小试 准备一个文件hello.txt,里面内容为 hello go:embed 项目的文件路径如下 - hello.txt - hello_embed.go - hello_embed_test.go hello_embed.go import ( _ \"embed\" ) //go:embed hello.txt var hello string func ReadHelloTxt() string { return hello } 测试方法 import \"testing\" func Test(t *testing.T) { t.Log(ReadHelloTxt()) } 通过运行测试用例，控制台输出了hello.txt中的文本内容 === RUN Test hello_embed_test.go:6: hello go:embed --- PASS: Test (0.00s) PASS ok gotest 0.124s 注意事项 1）//go:embed 文件名，注释后面不能加空格，否则失效，有的小伙伴喜欢在注释后面加一个空格，但是如果是在此处加的话，形如：// go:embed 这样会导致embed失效 2）我们需要导入embed的包才能使用，即 import _ \"embed\" 3）要读取的文件或者文件夹只能在当前目录或者当前目录的子目录，不能是其他目录，否则会执行报错~ ","date":"2024-03-16","objectID":"/posts/2024-03-15-go-embed/:1:1","tags":["Go","embed"],"title":"Go Embed","uri":"/posts/2024-03-15-go-embed/"},{"categories":["Go 库文档"],"content":"go:embed 可以嵌入的内容\u0026注意事项 1）对于单个文件，支持嵌入为字符串或者字节切片 2）对于多个文件，支持嵌入文件系统embed.FS 3）只能嵌入为 string，byte slice和embed.FS三种类型，这三种类型的别名或者类型命名都不可以 ","date":"2024-03-16","objectID":"/posts/2024-03-15-go-embed/:1:2","tags":["Go","embed"],"title":"Go Embed","uri":"/posts/2024-03-15-go-embed/"},{"categories":["Go 库文档"],"content":"嵌入为字符串或者字节切片 //go:embed hello.txt var hello string //go:embed hello.txt var helloRaw []byte ","date":"2024-03-16","objectID":"/posts/2024-03-15-go-embed/:1:3","tags":["Go","embed"],"title":"Go Embed","uri":"/posts/2024-03-15-go-embed/"},{"categories":["Go 库文档"],"content":"嵌入为embed.FS文件系统 嵌入为文件系统，这个功能在嵌入为多个文件或者嵌入的是文件夹的时候，非常实用。 //go:embed hello.txt var helloFS embed.FS func ReadHelloFS() string { data, _ := helloFS.ReadFile(\"hello.txt\") return string(data) } 嵌入多个文件 新增hello_1.txt文件在我们项目中 - hello.txt - hello_1.txt - hello_embed.go - hello_embed_test.go 嵌入多个文件的写法有很多，比如: 使用多个go:embed //go:embed hello.txt var hello string //go:embed hello_1.txt var hello1 string 使用文件系统 //go:embed hello.txt //go:embed hello_1.txt var hello embed.FS func main() { data, _ := helloFS.ReadFile(\"hello.txt\") fmt.Println(string(data)) data1, _ := helloFS.ReadFile(\"hello.txt\") fmt.Println(string(data1)) } 写到一行 //go:embed hello_1.txt hello.txt var hello embed.FS ","date":"2024-03-16","objectID":"/posts/2024-03-15-go-embed/:1:4","tags":["Go","embed"],"title":"Go Embed","uri":"/posts/2024-03-15-go-embed/"},{"categories":["Go 库文档"],"content":"文件夹嵌入 在我们的项目中增加一个文件夹，并将刚才的文本文件放到文件夹中 cmd - p |- hello.txt |- hello_1.txt - hello_embed.go - hello_embed_test.go 我们可以通过嵌入文件夹的形式将P文件夹中以及子文件夹全部嵌入到我们的项目中,这里使用的是相对路径 //go:embed p var helloFS embed.FS func main() { data, _ := helloFS.ReadFile(\"p/hello.txt\") fmt.Println(string(data)) data1, _ := helloFS.ReadFile(\"p/hello.txt\") fmt.Println(string(data1)) } ","date":"2024-03-16","objectID":"/posts/2024-03-15-go-embed/:1:5","tags":["Go","embed"],"title":"Go Embed","uri":"/posts/2024-03-15-go-embed/"},{"categories":["Go 库文档"],"content":"模糊匹配 go:embed指令中可以只写文件夹名称，次文件夹中除了.或者_开头的文件和文件夹都会嵌入到程序中，并且子文件夹也会被递归的嵌入，形成一个文件系统。 如果想嵌入.或者_开头的文件或者文件夹，我们可以通过使用*,比如：go:embed p/*,注意，*不具有递归性，所以子文件夹下面的.或者_不会被嵌入 文件过滤 go:embed还支持文件前缀过滤的功能，比如我们想嵌入所有拓展名是.txt的文件到程序中，我们可以这样写 //go:embed p var helloFS embed.FS func main() { data, _ := helloFS.ReadFile(\"p/hello.txt\") fmt.Println(string(data)) data1, _ := helloFS.ReadFile(\"p/hello.txt\") fmt.Println(string(data1)) } ","date":"2024-03-16","objectID":"/posts/2024-03-15-go-embed/:1:6","tags":["Go","embed"],"title":"Go Embed","uri":"/posts/2024-03-15-go-embed/"},{"categories":["DevOps"],"content":"Terraform Harbor 管理 provider.tf terraform { required_providers { harbor = { source = \"goharbor/harbor\" version = \"3.10.9\" } } } # set env # HARBOR_USERNAME # HARBOR_PASSWORD provider \"harbor\" { url = var.harbor.url insecure = var.harbor.insecure } user.tf resource \"harbor_user\" \"upload\" { admin = true comment = \"用于镜像上传和下载使用\" email = \"tf@local.com\" full_name = \"app\" username = \"app\" password = \"xxxxxx*****\" } image.tf resource \"harbor_registry\" \"hk_harbor\" { access_id = \"app\" access_secret = \"xxxxxxx********\" description = \"harbor hk\" endpoint_url = \"https://harbor-kh.local.com\" insecure = true name = \"hk_harbor\" provider_name = \"harbor\" } replication.tf resource \"harbor_replication\" \"hk\" { action = \"push\" deletion = false dest_namespace = \"sugar\" dest_namespace_replace = 0 enabled = true name = \"hk-sugar\" description = \"sync image to hk harbor\" override = true registry_id = harbor_registry.hk_harbor.registry_id schedule = \"event_based\" filters { name = \"sugar/*\" } } ","date":"2024-03-09","objectID":"/posts/2024-03-09-tf-harbor/:0:0","tags":["TF Harbor"],"title":"TF Harbor","uri":"/posts/2024-03-09-tf-harbor/"},{"categories":["DevOps"],"content":"Terraform 代码片段 ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:0","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"1、变量控制代码是否启用 module \"istio\" { count = var.istio.enabled ? 1 : 0 source = \"xxxxxx\" } ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:1","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"2、state文件中获取数据 state文件中需要有output，才能使用 data \"terraform_remote_state\" \"global\" { backend = \"local\" config = { path = \"../../global/terraform.tfstate\" } } data \"terraform_remote_state\" \"global\" { backend = \"http\" config = { address = \"http://git.local.com/api/v4/projects/111/terraform/state/xxxstatefile\" } } locals { domain = data.terraform_remote_state.global.outputs.domain 」 ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:2","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"3、获取terraform当前执行的目录 resource \"null_resource\" \"pwd\" { triggers = { always_run = \"${uuid()}\" } provisioner \"local-exec\" { command = \"echo ${path.cwd} \u003e\u003e somefile.txt\" } } ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:3","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"4、for_each 循环 resource \"tencentcloud_dnspod_record\" \"domain_record_dnspod\" { for_each = { for k, v in var.domain_record : k =\u003e { type = v.type, record = v.record, sub_domain = v.sub_domain, domain = v.domain, record_line = v.record_line } } domain = each.value.domain record_line = each.value.record_line record_type = each.value.type value = each.value.record sub_domain = each.value.sub_domain } resource \"xxxxx\" \"xxxx\" { for_each = {for k,v in var.ack_nodes: k =\u003e v if !contains(keys(v), \"hello\")} ***** } ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:4","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"5、contains # 如果 var.hello.world 有world这个key，就使用对应的值，否则就使用 github 这个默认值 resource \"xxxx\" \"xxx\" { name = contains(keys(var.hello), \"world\") ? var.hello.world:\"github\" age = var.age \u003e 50 ? var.age : 18 } ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:5","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"6、merge data \"aliyun_images_image\" \"image\" { for_each = merge(var.ack_nodes, var.ecs) name_regex = contains(keys(var.ack_nodes), each.key) ? \"Ubuntu 20.*bit$\":\"${each.value.os}.*bit$\" architecture = \"x86\" visibility = \"public\" most_recent = true } ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:6","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"7、concat 拼接和合并多个list member_names = [] member_names = concat( [for i in nexus_repository_npm_proxy.proxy: i.name], [nexus_repository_npm_hosted.local.name], ) terraform 内置函数 https://whyliyi.github.io/2020/01/29/terraform-%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0(Built-in-functions).html 可以使用 terraform console 进行调试 # max/min：取最大/最小 \u003e max(100,1) 100 \u003e min(12, 54, 3) 3 # abs：取数字的绝对值 \u003e abs(23) 23 \u003e abs(0) 0 \u003e abs(-12.4) 12.4 # ceil：上取整 \u003e ceil(5) 5 \u003e ceil(5.1) 6 # floor：下取整 \u003e floor(5) 5 \u003e floor(4.9) 4 # log： 取对数 \u003e log(16, 2) 4 # parseint：将字符串转换成对应进制的数字 \u003e parseint(\"100\", 10) 100 \u003e parseint(\"FF\", 16) 255 \u003e parseint(\"-10\", 16) -16 \u003e parseint(\"1011111011101111\", 2) 48879 # pow：求幂 \u003e pow(3, 2) 9 # signum：求符号 \u003e signum(-13) -1 \u003e signum(0) 0 \u003e signum(344) 1 #### 字符串函数 # chomp：删除换行符 \u003e chomp(\"hello\\n\\n\") hello # format：格式化字符串 \u003e format(\"Hello, %s!\", var.name) Hello, Valentina! # formatlist：格式化字符串列表 \u003e formatlist(\"%s, %s!\", \"Salutations\", [\"Valentina\", \"Ander\", \"Olivia\", \"Sam\"]) [ \"Salutations, Valentina!\", \"Salutations, Ander!\", \"Salutations, Olivia!\", \"Salutations, Sam!\", ] # indent：多行字符串缩进指定字符串数 \u003e \" items: %{indent(2, \"[\\n foo,\\n bar,\\n]\\n\")}\" items: [ foo, bar, ] # join：用指定分隔符连接列表中的字符串 \u003e join(\", \", [\"foo\", \"bar\", \"baz\"]) foo, bar, baz # split：按照指定分隔符分割字符串 \u003e split(\"+\", \"1+2+3\") [1, 2, 3,] # lower：字符串转化为全小写 # upper：字符串转化为全大写 # regex：按照正则表达式匹配字符串，并且返回第一个匹配成功的子字符串 \u003e regex(\"[a-z]+\", \"53453453.345345aaabbbccc23454\") aaabbbccc # regexall：按照正则表达式匹配字符串，并返回匹配的子字符串列表 \u003e regexall(\"[a-z]+\", \"1234abcd5678efgh9\") [ \"abcd\", \"efgh\", ] # replace：替换字符串中符合条件的子字符串 \u003e replace(\"1 + 2 + 3\", \"+\", \"-\") 1 - 2 - 3 # strrev：字符串逆序 \u003e strrev(\"hello\") olleh # substr：字符串分片 \u003e substr(\"hello world\", 1, 4) ello # title：单词的首字母大写 \u003e title(\"hello world\") Hello World # trim：删除字符串首尾指定字符串 \u003e trim(\"?!hello?!\", \"!?\") hello # trimprefix：删除字符串指定前缀 \u003e trimprefix(\"helloworld\", \"hello\") world # trimsuffix：删除字符串指定后缀 \u003e trimsuffix(\"helloworld\", \"world\") hello # trimspace：删除前后空格 \u003e trimspace(\" hello\\n\\n\") hello ##### 类型转换函数 # tobool：转换成bool类型，仅仅是true、false、”true”、”false”可以转换 # tolist：将参数转化成列表类型 \u003e tolist([\"a\", \"b\", 3]) [ \"a\", \"b\", \"3\", ] # tomap：转换成map类型 \u003e tomap({\"a\" = \"foo\", \"b\" = true}) { \"a\" = \"foo\" \"b\" = \"true\" } # tonumber：转换成数字 \u003e tonumber(1) 1 \u003e tonumber(\"1\") 1 \u003e tonumber(\"no\") Error: Invalid function argument # toset：转换成set类型 \u003e toset([\"c\", \"b\", \"b\", 3]) [ \"b\", \"c\", \"3\", ] # tostring：转换成字符串类型, 只对string、number、bool类型有效 \u003e tostring(\"hello\") hello \u003e tostring(1) 1 \u003e tostring(true) true \u003e tostring([]) Error: Invalid function argument # try：计算所有的表达式，并返回第一个计算成功的结果，并且不会抛出任何错误 \u003e local.foo { \"bar\" = \"baz\" } \u003e try(local.foo.bar, \"fallback\") baz \u003e try(local.foo.boop, \"fallback\") fallback # chunklist 分片 chunklist(list, chunk_size) \u003e chunklist([\"a\", \"b\", \"c\", \"d\", \"e\"], 2) [ [ \"a\", \"b\", ], [ \"c\", \"d\", ], [ \"e\", ], ] # coalesce 返回第一个不为空的元素 \u003e coalesce(\"a\", \"b\") a \u003e coalesce([\"\", \"b\"]...) b # coalescelist 返回第一个不为空的list \u003e coalescelist([\"a\", \"b\"], [\"c\", \"d\"]) [ \"a\", \"b\", ] \u003e coalescelist([], [\"c\", \"d\"]) [ \"c\", \"d\", ] # compact 返回非空的全部元素 \u003e compact([\"a\", \"\", \"b\", null, \"c\"]) [ \"a\", \"b\", \"c\", ] # concat 合并多个list \u003e concat([\"a\", \"\"], [\"b\", \"c\"]) [ \"a\", \"\", \"b\", \"c\", ] # contains 判断是否包含 contains(list, value) # distinct 转换为字典，去重 \u003e distinct([\"a\", \"b\", \"a\", \"c\", \"d\", \"b\"]) [ \"a\", \"b\", \"c\", \"d\", ] # element 取list 中的索引元素 element(list, index) \u003e element([\"a\", \"b\", \"c\"], 1) b #大于索引的时候取第一个元素 \u003e element([\"a\", \"b\", \"c\"], 3) a \u003e element([\"a\", \"b\", \"c\"], length([\"a\", \"b\", \"c\"])-1) c # flatten 扁平化合并 \u003e flatten([[\"a\", \"b\"], [], [\"c\"]]) [\"a\", \"b\", \"c\"] \u003e flatten([[[\"a\", \"b\"], []], [\"c\"]]) [\"a\", \"b\", \"c\"] # lookup 查找 lookup(map, key, default) \u003e lookup({a=\"ay\", b=\"bee\"}, \"a\", \"what?\") ay \u003e lookup({a=\"ay\", b=\"bee\"}, \"c\", \"what?\") what? # range range(max) range(start, limit) range(start, limit, step) \u003e range(3) [ 0, 1, 2, ] \u003e range(1, 4) [ 1, 2, 3, ] \u003e range(1, 8, 2) [ 1, 3, 5, 7, ] # reverse 反转 \u003e reverse([1, 2, 3]) [ 3, 2, 1, ] # setintersection 获取重复的元素 \u003e setintersection([\"a\", \"b\"], [\"b\", \"c\"], [\"b\", \"d\"]) [ \"b\", ] # setunion set 联合 \u003e setunion([\"a","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:7","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"其他 减小 terraform 项目目录体积 目录中 provider 的二进制包占主要，在分发项目到其它 Arch 和 OS 的机器运行的时候，可以先将 provider目录删除，然后在压缩并进行分发。 ","date":"2024-02-25","objectID":"/posts/2024-02-25-tf-code/:0:8","tags":["tf code"],"title":"tf-code","uri":"/posts/2024-02-25-tf-code/"},{"categories":["DevOps"],"content":"KtConnect 官方文档：https://alibaba.github.io/kt-connect/#/zh-cn/guide/quickstart 简单示例： apiVersion: v1 kind: Service metadata: name: myapp spec: type: ClusterIP selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 80 --- apiVersion: apps/v1 kind: Deployment metadata: name: myapp labels: app: myapp spec: replicas: 2 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: nginx image: nginx ports: - containerPort: 80 resources: requests: cpu: 100m memory: 100Mi limits: cpu: 100m memory: 100Mi sudo ktctl connect -c ~/.kube/config ktctl 会在 default namespace 里启动一个 pod 用于转发流量，这样本地就可以像在集群中一样，访问里面的服务。 ","date":"2024-01-29","objectID":"/posts/2024-01-29-ktconnect/:0:0","tags":["ktconnect"],"title":"ktconnect","uri":"/posts/2024-01-29-ktconnect/"},{"categories":["DevOps"],"content":"alpine 虚拟机安装 ","date":"2024-01-22","objectID":"/posts/2024-01-22-alpine-vm/:0:0","tags":["alpine-vm"],"title":"Alpine vm","uri":"/posts/2024-01-22-alpine-vm/"},{"categories":["DevOps"],"content":"使用alpine-vm iso 文件进行安装 参考文档： https://www.qunniao.net/1408.html https://wener.me/notes/os/alpine/intro https://blog.xiaohack.org/4674.html https://tonylee.name/Alpine-Linux-4f1cbdb482754c65a61e7f08e9691234 关闭交换分区减小镜像大小： vi /sbin/setup-alpine # 在 setup-disk 增加参数关闭交换分区 setup-disk -s 0 alpine 3.19 镜像可以最小达到123M 官方 下载页 列了几种类型的镜像, 所有镜像的构建脚本位于 alpinelinux/alpine-iso. TIPS 做安装盘建议选择 EXTENDED, 在不需要 setup-repository 的前提下也能够安装到硬盘. 仓库镜像中也能下载系统镜像 v3.10/releases STANDARD 标准镜像 镜像较少, 安装需要网络连接 EXTENDED 扩展镜像 附带了常用包, 安装不需要网络连接; 适用于路由和服务器 VANILLA 未 Hardened 的镜像 自 3.8 开始，已经没有 hardened 的内核了 VIRTUAL 适用于虚拟机的镜像 XEN 适用于 XEN 虚拟化的镜像 MINI ROOT FILESYSTEM 最小根目录系统 适用于容器和 chroot RASPBERRY PI 树莓派系统 GENERIC ARM 通用 ARM 系统 ","date":"2024-01-22","objectID":"/posts/2024-01-22-alpine-vm/:1:0","tags":["alpine-vm"],"title":"Alpine vm","uri":"/posts/2024-01-22-alpine-vm/"},{"categories":["DevOps"],"content":"alpine arm64 安装docker failed to start daemon: Devices cgroup isn't mounted echo 'none /sys/fs/cgroup cgroup defaults 0 0' \u003e\u003e /etc/fstab mount -a ","date":"2024-01-22","objectID":"/posts/2024-01-22-alpine-vm/:2:0","tags":["alpine-vm"],"title":"Alpine vm","uri":"/posts/2024-01-22-alpine-vm/"},{"categories":["DevOps"],"content":"Python 自签名证书 mozilla 维护者一个公共ca的文件，在使用http客户端使用自签名证书的时候可以把对应的文件合并然后再导入，示例代码： requirements.txt certifi==2023.11.17 urllib3==2.1.0 #!/usr/bin/env python3 # coding=utf-8 # *********************************************************************** # Description : Blue Planet # Author : serialt # Created Time : 2024-01-15 20:12:32 # Last modified : 2024-01-16 20:35:00 # FilePath : /urlib3/lib.py # Other : # : # # # # *********************************************************************** import os import urllib3 import certifi pablic_ca = 'pub_ca.crt' def load_ca(path): if not os.path.exists(pablic_ca): mozilla_ca = certifi.where() with open(pablic_ca, \"a\")as pub_ca: # get cert from certifi m_ca = open(mozilla_ca) m_ca_data = m_ca.read() pub_ca.write(m_ca_data) m_ca.close() # get cert from ca_path ca_files = os.listdir(path) for file in ca_files: if not os.path.isdir(file): fl = open(path+'/'+file) data = fl.read() fl.close() pub_ca.write('\\n'+data) pub_ca.close() # Creating a PoolManager instance for sending requests. http = urllib3.PoolManager( cert_reqs=\"CERT_REQUIRED\", maxsize=10, ca_certs=pablic_ca, ) # Sending a GET request and getting back response as HTTPResponse object. resp = http.request(\"GET\", \"http://httpbin.org/get\") # Print the returned data. print(resp.data) load_ca('ca') ","date":"2024-01-16","objectID":"/posts/2024-01-15-python-cert/:0:0","tags":["python-cert"],"title":"Python Cert","uri":"/posts/2024-01-15-python-cert/"},{"categories":["DevOps"],"content":"Terraform Registry ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:0:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"一、Registry 协议 文档地址：https://developer.hashicorp.com/terraform/internals/provider-registry-protocol # list可用的provider curl 'https://registry.terraform.io/v1/providers/hashicorp/random/versions' { \"versions\": [ { \"version\": \"2.0.0\", \"protocols\": [\"4.0\", \"5.1\"], \"platforms\": [ {\"os\": \"darwin\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"arm\"}, {\"os\": \"windows\", \"arch\": \"amd64\"} ] }, { \"version\": \"2.0.1\", \"protocols\": [\"5.2\"], \"platforms\": [ {\"os\": \"darwin\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"amd64\"}, {\"os\": \"linux\", \"arch\": \"arm\"}, {\"os\": \"windows\", \"arch\": \"amd64\"} ] } ] } # find provider package curl 'https://registry.terraform.io/v1/providers/hashicorp/random/2.0.0/download/linux/amd64' { \"protocols\": [\"4.0\", \"5.1\"], \"os\": \"linux\", \"arch\": \"amd64\", \"filename\": \"terraform-provider-random_2.0.0_linux_amd64.zip\", \"download_url\": \"https://releases.hashicorp.com/terraform-provider-random/2.0.0/terraform-provider-random_2.0.0_linux_amd64.zip\", \"shasums_url\": \"https://releases.hashicorp.com/terraform-provider-random/2.0.0/terraform-provider-random_2.0.0_SHA256SUMS\", \"shasums_signature_url\": \"https://releases.hashicorp.com/terraform-provider-random/2.0.0/terraform-provider-random_2.0.0_SHA256SUMS.sig\", \"shasum\": \"5f9c7aa76b7c34d722fc9123208e26b22d60440cb47150dd04733b9b94f4541a\", \"signing_keys\": { \"gpg_public_keys\": [ { \"key_id\": \"51852D87348FFC4C\", \"ascii_armor\": \"-----BEGIN PGP PUBLIC KEY BLOCK-----\\nVersion: GnuPG v1\\n\\nmQENBFMORM0BCADBRyKO1MhCirazOSVwcfTr1xUxjPvfxD3hjUwHtjsOy/bT6p9f\\nW2mRPfwnq2JB5As+paL3UGDsSRDnK9KAxQb0NNF4+eVhr/EJ18s3wwXXDMjpIifq\\nfIm2WyH3G+aRLTLPIpscUNKDyxFOUbsmgXAmJ46Re1fn8uKxKRHbfa39aeuEYWFA\\n3drdL1WoUngvED7f+RnKBK2G6ZEpO+LDovQk19xGjiMTtPJrjMjZJ3QXqPvx5wca\\nKSZLr4lMTuoTI/ZXyZy5bD4tShiZz6KcyX27cD70q2iRcEZ0poLKHyEIDAi3TM5k\\nSwbbWBFd5RNPOR0qzrb/0p9ksKK48IIfH2FvABEBAAG0K0hhc2hpQ29ycCBTZWN1\\ncml0eSA8c2VjdXJpdHlAaGFzaGljb3JwLmNvbT6JATgEEwECACIFAlMORM0CGwMG\\nCwkIBwMCBhUIAgkKCwQWAgMBAh4BAheAAAoJEFGFLYc0j/xMyWIIAIPhcVqiQ59n\\nJc07gjUX0SWBJAxEG1lKxfzS4Xp+57h2xxTpdotGQ1fZwsihaIqow337YHQI3q0i\\nSqV534Ms+j/tU7X8sq11xFJIeEVG8PASRCwmryUwghFKPlHETQ8jJ+Y8+1asRydi\\npsP3B/5Mjhqv/uOK+Vy3zAyIpyDOMtIpOVfjSpCplVRdtSTFWBu9Em7j5I2HMn1w\\nsJZnJgXKpybpibGiiTtmnFLOwibmprSu04rsnP4ncdC2XRD4wIjoyA+4PKgX3sCO\\nklEzKryWYBmLkJOMDdo52LttP3279s7XrkLEE7ia0fXa2c12EQ0f0DQ1tGUvyVEW\\nWmJVccm5bq25AQ0EUw5EzQEIANaPUY04/g7AmYkOMjaCZ6iTp9hB5Rsj/4ee/ln9\\nwArzRO9+3eejLWh53FoN1rO+su7tiXJA5YAzVy6tuolrqjM8DBztPxdLBbEi4V+j\\n2tK0dATdBQBHEh3OJApO2UBtcjaZBT31zrG9K55D+CrcgIVEHAKY8Cb4kLBkb5wM\\nskn+DrASKU0BNIV1qRsxfiUdQHZfSqtp004nrql1lbFMLFEuiY8FZrkkQ9qduixo\\nmTT6f34/oiY+Jam3zCK7RDN/OjuWheIPGj/Qbx9JuNiwgX6yRj7OE1tjUx6d8g9y\\n0H1fmLJbb3WZZbuuGFnK6qrE3bGeY8+AWaJAZ37wpWh1p0cAEQEAAYkBHwQYAQIA\\nCQUCUw5EzQIbDAAKCRBRhS2HNI/8TJntCAClU7TOO/X053eKF1jqNW4A1qpxctVc\\nz8eTcY8Om5O4f6a/rfxfNFKn9Qyja/OG1xWNobETy7MiMXYjaa8uUx5iFy6kMVaP\\n0BXJ59NLZjMARGw6lVTYDTIvzqqqwLxgliSDfSnqUhubGwvykANPO+93BBx89MRG\\nunNoYGXtPlhNFrAsB1VR8+EyKLv2HQtGCPSFBhrjuzH3gxGibNDDdFQLxxuJWepJ\\nEK1UbTS4ms0NgZ2Uknqn1WRU1Ki7rE4sTy68iZtWpKQXZEJa0IGnuI2sSINGcXCJ\\noEIgXTMyCILo34Fa/C6VCm2WBgz9zZO8/rHIiQm1J5zqz0DrDwKBUM9C\\n=LYpS\\n-----END PGP PUBLIC KEY BLOCK-----\", \"trust_signature\": \"\", \"source\": \"HashiCorp\", \"source_url\": \"https://www.hashicorp.com/security.html\" } ] } } ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:1:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"二、Cache Terraform Registry ​ 在执行terraform init 的时候，terraform cli 会从官方的Registry查找和下载对应的provider，小的provider几M，大的可能几百M，而且如果当执行plan或apply出现问题需要重新执行init，可能需要多次请求registry，这对网络的速度和稳定性要求比较高。因此，基于官方的 Provider Registry Protocol 和 Remote Service，可以开发一个简单的cli缓存和提供Registry服务。 ​ ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:2:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"1、terraform下载provider原理 ​ 当执行terraform init 后，terraform cli 会根据 tf文件中定义的provider去向 registry.terraform.io 发起GET请求，例如：tf文件中有使用hashicorp/random，terraform cli 会发出Get请求 https://registry.terraform.io/v1/providers/hashicorp/random/versions，请求到数据后再跟tf文件中定义的版本判断一致后获取要下载的provider package 包的信息，例如：https://registry.terraform.io/v1/providers/hashicorp/random/2.0.0/download/linux/amd64，返回的数据中有provider的下载地址、provide的hash值和用于验证provider签名的公钥，由hashicorp维护的provider package会存放在releases.hashicorp.com中，而由第三方开发者维护的只能使用github托管，要求代码必须是开源的，且repo的命名格式符合 terraform-provider-ssh。 ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:2:1","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"2、缓存加速原理 ~/.terraformrc文件中可以可以配置镜像，例如： host \"registry.terraform.io\" { services = { \"modules.v1\" = \"http://127.0.0.1:9090/pub/v1/modules/\", \"providers.v1\" = \"http://127.0.0.1:9090/v1/providers/\" } } 当执行terraform init的时候，访问 registry.terraform.io/v1/providers/ 会被替换为http://127.0.0.1:9090/v1/providers/ ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:2:2","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"三、基于nexus存储provider ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:3:0","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"1、下载数据并同步到nexus 配置文件格式 storage: type: nexus nexus: url: http://nexus.local.com repo: terraform tf: providerLast: 2 provider: - \"hashicorp/random\" - \"hashicorp/aws\" - \"hashicorp/tls\" - \"hashicorp/dns\" providerOS: - linux - darwin providerArch: - amd64 - arm64 providerVersion: hashicorp/random: - \"3.6.0\" - \"3.3.2\" loafoe/ssh: - \"2.5.0\" # 获取provider的版本，把这个文件上传到nexus，路径: hashicorp/random/versions curl 'https://registry.terraform.io/v1/providers/hashicorp/random/versions' # 获取到版本信息后请求下载的provider package 信息 ,下载里面的文件，并把对应的链接信修改为nexus中的地址 curl https://registry.terraform.io/v1/providers/hashicorp/random/2.0.0/download/linux/amd64' # 下载上一步获取到的原始 provider pcakge 链接中的文件，把文件上传到nexus ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:3:1","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"2、实现Provider Registry Protocol 根据 Provider Registry Protocol实现一个私有的registry，根据请求来的信息去请求nexus上的对应数据，把数据返回给terraform cli , terraform cli 会自己从接收到的数据去从nexus下载对应版本的provider。 ","date":"2024-01-14","objectID":"/posts/2024-01-14-terraform-registry/:3:2","tags":["terraform-registry"],"title":"Terraform Registry","uri":"/posts/2024-01-14-terraform-registry/"},{"categories":["DevOps"],"content":"Vault 参考链接：https://thiscute.world/posts/experience-of-vault/#%E4%B8%80vault-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5 介绍 Vault 是 hashicorp 推出的 secrets 管理、加密即服务与权限管理工具。它的功能简介如下： 1）secrets 管理：支持保存各种自定义信息、自动生成各类密钥，vault 自动生成的密钥还能自动轮转(rotate) 2）认证方式：支持接入各大云厂商的账号体系（比如阿里云RAM子账号体系）或者 LDAP 等进行身份验证，不需要创建额外的账号体系。 3）权限管理：通过 policy，可以设定非常细致的 ACL 权限。 4）密钥引擎：也支持接管各大云厂商的账号体系（比如阿里云RAM子账号体系），实现 API Key 的自动轮转。 5）支持接入 kubernetes rbac 认证体系，通过 serviceaccount+role 为每个 Pod 单独配置认证角色。 6）支持通过 sidecar/init-container 将 secrets 注入到 pod 中，或者通过 k8s operator 将 vault 数据同步到 k8s secrets 中 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:0:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"一、Vault 基础概念 ​ 几乎所有的 Vault 组件都被统称为「屏障（Barrier）」。Vault 可以简单地被划分为存储后端（Storage Backend）、屏障（Barrier）和 HTTP/S API 三个部分。 ​ Vault，翻译成中文就是金库。类比银行金库，「屏障」就是用于保护金库的合金大门和钢筋混凝土，存储后端和客户端之间的所有数据流动都需要经过它。「屏障」确保只有加密数据会被写入存储后端，加密数据在经过「屏障」被读出的过程中被验证与解密。和银行金库的大门非常类似，「屏障」也必须先解封，才能解密存储后端中的数据。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、数据存储及加密解密 存储后端（Storage Backend）: Vault 自身不存储数据，因此需要为它配置一个存储后端。 存储后端是不受信任的，只用于存储加密数据。 初始化（Initialization）: Vault 在首次启动时需要初始化，这一步生成一个加密密钥（Encryption Key）用于加密数据，加密完成的数据才能被保存到存储后端。 解封（Unseal）: Vault 启动后，因为不知道加密密钥所以无法解密数据，这种状态被形象得称作已封印（Sealed）。在解封前 Vault 无法进行任何操作。 加密密钥被主密钥（Master Key）保护，我们必须提供主密钥才能解密出 Vault 的加密密钥，从而完成解封操作。 默认情况下，Vault 使用沙米尔密钥分割算法 将主密钥分割成五个分割密钥（Key Shares），必须要提供其中任意三个分割密钥才能重建出主密钥，完成解封操作。 分割密钥的总数，以及重建主密钥最少需要的分割密钥数量，都是可以调整的。 沙米尔密钥分割算法也可以关闭，这样主密钥将被直接提供给管理员，管理员可直接使用它进行解封操作。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2. 认证系统及权限系统 在解封完成后，Vault 就可以开始处理请求了。 HTTP 请求进入后的整个处理流程都由 vault core 管理，core 会强制进行 ACL 检查，并确保审计日志(audit logging)完成记录。 客户端首次连接 vault 时，需要先完成身份认证，vault 的 auth methods 模块有很多身份认证方法可选： 1）用户友好的认证方法，适合管理员使用：username/password、云服务商、ldap，在创建 user 的时候，需要为 user 绑定 policy，给予合适的权限。 2）应用友好的方法，适合应用程序使用：public/private keys、tokens、kubernetes、jwt身份验证请求流经 core 并进入 auth methods，auth methods 确定请求是否有效并返回「关联策略(policies)」的列表。 ACL 策略由 policy store 负责管理与存储，由 core 进行 ACL 检查。 ACL 的默认行为是拒绝，这意味着除非明确配置 policy 允许某项操作，否则该操作将被拒绝。在通过 auth methods 完成了身份认证，并且返回的关联策略也没毛病之后，token store 将会生成并管理一个新的凭证（token）， 这个 token 会被返回给客户端，用于进行后续请求。类似 web 网站的 cookie，token 也都存在一个租期（lease）或者说有效期，这加强了安全性。token 关联了相关的策略 policies，这些策略将被用于验证请求的权限。 请求经过验证后，将被路由到 secret engine。如果 secret engine 返回了一个 secret（由 vault 自动生成的 secret）， core 会将其注册到 expiration manager，并给它附加一个 lease ID。lease ID 被客户端用于更新(renew)或吊销(revoke)它得到的 secret. 如果客户端允许租约(lease)到期，expiration manager 将自动吊销这个 secret. core 还负责处理审核代理 audit broker的请求及响应日志，将请求发送到所有已配置的审核设备 audit devices. 不过默认情况下这个功能貌似是关闭的。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"3. Secret Engine Secret Engine 是保存、生成或者加密数据的组件，它非常灵活。 有的 Secret Engines 只是单纯地存储与读取数据，比如 kv 就可以看作一个加密的 Redis。 而其他的 Secret Engines 则连接到其他的服务并按需生成动态凭证。 还有些 Secret Engines 提供「加密即服务(encryption as a service)」的能力，如 transit、证书管理等。 常用的 engine 举例： 1）AliCloud Secrets Engine: 基于 RAM 策略动态生成 AliCloud Access Token，或基于 RAM 角色动态生成 AliCloud STS 凭据，Access Token 会自动更新(Renew)，而 STS 凭据是临时使用的，过期后就失效了。 2）kv: 键值存储，可用于存储一些静态的配置。它一定程度上能替代掉携程的 Apollo 配置中心。 3）Transit Secrets Engine: 提供加密即服务的功能，它只负责加密和解密，不负责存储。主要应用场景是帮 app 加解密数据，但是数据仍旧存储在 MySQL 等数据库中。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:1:3","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"二、部署 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、docker-compose version: '3.3' services: vault: image: vault:1.12.3 container_name: vault ports: - \"8200:8200\" restart: always volumes: - ./logs:/vault/logs - ./file:/vault/date - ./config.hcl:/vault/config/config.hcl #- ./certs:/certs # vault 需要锁定内存以防止敏感值信息被交换(swapped)到磁盘中 # 为此需要添加如下 capability cap_add: - IPC_LOCK entrypoint: vault server -config /vault/config/config.hcl config.hcl 内容如下： # 单机版 ui = true listener \"tcp\" { tls_disable = 1 address = \"[::]:8200\" cluster_address = \"[::]:8201\" } storage \"file\" { path = \"/vault/data\" } ui = true // 使用文件做数据存储（单节点） storage \"raft\" { path = \"/vault/date\" node_id = \"node1\" } listener \"tcp\" { address = \"[::]:8200\" tls_disable = \"true\" } api_addr = \"http://0.0.0.0/8200\" // ha 访问入口，不能写0.0.0.0 cluster_addr = \"http://172.16.78.161:8201\" ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2、初始化 # 设置vault地址 [root@sugar vault]# export VAULT_ADDR='http://127.0.0.1:8200' # 复制命令到宿主机 [root@sugar vault]# docker cp vault:/bin/vault /usr/local/bin/vault [root@sugar vault]# chmod +x /usr/local/bin/vault [root@sugar vault]# vault operator init vault operator init Unseal Key 1: aTpDcs5FQ1GzklifRwYCKdLPHpCUvNm9EGhZ0NH8Ut0p Unseal Key 2: 33V89ljeUr23AQpBgDANgFRzft+8f7E5KRXPDjsFpOG2 Unseal Key 3: OwfbdEA481baX8TZ0/kT49dBFg6ArXboVapBAd1y0fqk Unseal Key 4: DD1Lp86WGqVq+18LwUdGPxb6cquTjSz/yAIc9fkYNzF9 Unseal Key 5: FrqRqQSlhb/sjj7h9Pcau5eqrB/rxtkFBbBJSfuv48IM Initial Root Token: hvs.FTcALTSfrVuw9On8B2g2JQIl Vault initialized with 5 key shares and a key threshold of 3. Please securely distribute the key shares printed above. When the Vault is re-sealed, restarted, or stopped, you must supply at least 3 of these keys to unseal it before it can start servicing requests. Vault does not store the generated root key. Without at least 3 keys to reconstruct the root key, Vault will remain permanently sealed! It is possible to generate new unseal keys, provided you have a quorum of ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"3、解封 [root@sugar vault]# vault operator unseal aTpDcs5FQ1GzklifRwYCKdLPHpCUvNm9EGhZ0NH8Ut0p Key Value --- ----- Seal Type shamir Initialized true Sealed true Total Shares 5 Threshold 3 Unseal Progress 1/3 Unseal Nonce 8d5a33c3-bff5-e407-eb13-15c1457bdb63 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft HA Enabled true [root@sugar vault]# vault operator unseal OwfbdEA481baX8TZ0/kT49dBFg6ArXboVapBAd1y0fqk Key Value --- ----- Seal Type shamir Initialized true Sealed true Total Shares 5 Threshold 3 Unseal Progress 2/3 Unseal Nonce 8d5a33c3-bff5-e407-eb13-15c1457bdb63 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft HA Enabled true [root@sugar vault]# vault operator unseal 'FrqRqQSlhb/sjj7h9Pcau5eqrB/rxtkFBbBJSfuv48IM' Key Value --- ----- Seal Type shamir Initialized true Sealed false Total Shares 5 Threshold 3 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft Cluster Name vault-cluster-8257ffed Cluster ID 2eccf238-400e-1ba5-f491-321c1388c826 HA Enabled true HA Cluster n/a HA Mode standby Active Node Address \u003cnone\u003e Raft Committed Index 31 Raft Applied Index 31 [root@sugar vault]# vault status Key Value --- ----- Seal Type shamir Initialized true Sealed false Total Shares 5 Threshold 3 Version 1.12.3 Build Date 2023-02-02T09:07:27Z Storage Type raft Cluster Name vault-cluster-8257ffed Cluster ID 2eccf238-400e-1ba5-f491-321c1388c826 HA Enabled true HA Cluster https://192.168.10.161:8201 HA Mode active Active Since 2023-03-07T12:11:38.884017872Z Raft Committed Index 36 Raft Applied Index 36 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:3","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"4、登录测试 # export VAULT_TOKEN='hvs.FTcALTSfrVuw9On8B2g2JQIl' [root@jenkins116 vault]# vault login Token (will be hidden): WARNING! The VAULT_TOKEN environment variable is set! The value of this variable will take precedence; if this is unwanted please unset VAULT_TOKEN or update its value accordingly. Success! You are now authenticated. The token information displayed below is already stored in the token helper. You do NOT need to run \"vault login\" again. Future Vault requests will automatically use this token. Key Value --- ----- token hvs.FTcALTSfrVuw9On8B2g2JQIl token_accessor vkDaIsiPx3w9JEpUWv9NRnQm token_duration ∞ token_renewable false token_policies [\"root\"] identity_policies [] policies [\"root\"] ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:2:4","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"三、策略与授权 参考链接：https://zhuanlan.zhihu.com/p/370343645 ​ Vault模拟了一个文件系统，Vault中所有的信息，包括机密、配置等，都是依照各自的路径来使用的。使用Vault策略，我们可以使用声明式的语法来赋予或者禁止对特定路径的特定操作。Vault的策略默认情况下是拒绝一切访问的，所以一个空的策略不会赋予对系统的任何访问权限。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、策略语法 策略使用HCL或是JSON语法编写，描述了一个人类用户或是应用程序允许访问Vault中哪些路径。 一个简单的例子，赋予对secret/foo路径的读权限： path \"secret/foo\" { capabilities = [\"read\"] } 当这个策略被附加到一个令牌后，该令牌可以读取secret/foo，然而无法修改或删除secret/foo，因为没有授予其相关能力（Capability）。由于策略系统是默认拒绝的，所以令牌在Vault中没有其他权限。 另一个更加丰富的策略，包含注释： # This section grants all access on \"secret/*\". Further restrictions can be # applied to this broad policy, as shown below. path \"secret/*\" { capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\"] } # Even though we allowed secret/*, this line explicitly denies # secret/super-secret. This takes precedence. path \"secret/super-secret\" { capabilities = [\"deny\"] } # Policies can also specify allowed, disallowed, and required parameters. Here # the key \"secret/restricted\" can only contain \"foo\" (any value) and \"bar\" (one # of \"zip\" or \"zap\"). path \"secret/restricted\" { capabilities = [\"create\"] allowed_parameters = { \"foo\" = [] \"bar\" = [\"zip\", \"zap\"] } } 策略基于路径匹配来验证一个请求所需要的能力。一个策略路径可以精准匹配一个确切的路径，或者可以使用*模式指定前缀匹配： # Permit reading only \"secret/foo\". An attached token cannot read \"secret/food\" # or \"secret/foo/bar\". path \"secret/foo\" { capabilities = [\"read\"] } # Permit reading everything under \"secret/bar\". An attached token could read # \"secret/bar/zip\", \"secret/bar/zip/zap\", but not \"secret/bars/zip\". path \"secret/bar/*\" { capabilities = [\"read\"] } # Permit reading everything prefixed with \"zip-\". An attached token could read # \"secret/zip-zap\" or \"secret/zip-zap/zong\", but not \"secret/zip/zap path \"secret/zip-*\" { capabilities = [\"read\"] } 另外，路径当中可以使用+代表路径中一个段内任意长度的字符（从Vault 1.1开始支持）： # Permit reading the \"teamb\" path under any top-level path under secret/ path \"secret/+/teamb\" { capabilities = [\"read\"] } # Permit reading secret/foo/bar/teamb, secret/bar/foo/teamb, etc. path \"secret/+/+/teamb\" { capabilities = [\"read\"] } Vault模拟了一个文件系统，所有的操作都对应了一个路径，以及对应的能力，即使是Vault内部的核心配置信息也挂载于sys/路径下。策略可以定义一个令牌对这些路径和能力的访问权限。 Vault采用一组具有优先级的判定规则来决定最为具体的路径匹配。如果一个匹配模式被多个策略使用并能匹配上给定路径，Vault会取其能力的并集。如果一个路径能被多个策略定义的不同的匹配模式所匹配，那么只有最高优先级的匹配会被采用。 假设对给定路径P，存在两条策略都能够匹配，它们的路径匹配模式分别是P1和P2，Vault采用如下优先级规则： 1）如果P1中第一个+或是*出现的位置早于P2，那么采用P2 2）如果P1以*结尾，而P2不是，那么采用P2 3）如果P1包含更多的+段，那么采用P2 4）如果P1更短，那么采用P2 5）如果P1得到的字典序更小，那么采用P2 举个例子，给定两个路径：secret/*和secret/+/+/foo/*，由于第一个通配符的位置相同（都在secret/之后），并且都以*结尾，而后者拥有更多的通配符段（多了两个+/段），所以结果是使用secret/*路径模式的策略。 需要注意的是，*与正则表达式中的同符号并不同义，Vault仅允许*出现在模式的末尾。 如果赋予了list能力，需要注意的是因为list操作总是作用于一个路径前缀上，所以策略定义的路径匹配模式必须使用前缀匹配（即以*结尾）。 能力（Capabilites） 除了路径匹配模式以外，每条规则都必须指定一个或多个能力来定义细颗粒度的允许-禁止规则。能力永远以一个字符串列表的形式定义，哪怕只有一个能力。 需要注意的是，我们在下面列出能力的同时，也会给出该能力相对应的HTTP动词。当编写策略时，可以先查阅相关HTTP API文档了解路径信息以及相关HTTP动词，然后映射到策略定义中的能力。虽然映射关系并不是严格的1:1，但它们通常非常相似地匹配。 create(POST/PUT)——允许在指定路径创建数据。只有很少的Vault部件会区分create和update，所以大多数操作同时需要create以及update能力。需要区分二者的部分会在相关文档中说明。 read(GET)——允许读取指定路径的数据 update(POST/PUT)——允许修改指定路径的数据。对多数Vault部件来说，这隐含了在指定位置创建初始值的能力 delete(DELETE)——允许删除指定路径的数据 list(LIST)——允许罗列指定路径的所有值。要注意的是，经由list操作返回的键是未经策略过滤的。请勿在键名中编码敏感信息。不是所有后端都支持list操作 下面的能力并无对应的HTTP动词： sudo——允许访问需要根权限保护的路径。除非拥有sudo能力，否则令牌被禁止与这些路径交互（对这种路径的操作可能同时需要其他能力，例如read或delete） 例如，修改审计日志后端配置就需要令牌具有sudo特权。 deny——不允许访问。该定义总是优先于其他能力定义，包括sudo，只要能力中存在deny，就不允许执行任何操作 需要注意的是，上述的能力映射到的是HTTP动词而非实际底层执行的操作，这通常会使人感到困惑。举个例子，通过Vault的数据库机密引擎创建一个数据库用户名密码，底层实际执行的操作是创建，但对应的HTTP动词却是GET，所以要在对应路径上配置read能力。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2、细颗粒度控制 除却以上标准的能力，Vault还提供了对指定路径的更细颗粒度的权限控制。与路径相关联的功能优先于对参数的控制。 1）参数限制 需要首先说明，Version 2的kv机密引擎不支持参数限制，所以以下例子均假设secret/路径挂载的是Version 1的kv机密引擎。 Vault中的数据以键值对的形式表达：key=value。Vault策略可以进一步限制对指定路径下特定键和值的访问。这些可选的细颗粒度控制项有： required_parameters——一组必须指定的参数： # This requires the user to create \"secret/foo\" with a parameter named # \"bar\" and \"baz\". path \"secret/foo\" { capabilities = [\"create\"] required_parameters = [\"bar\", \"baz\"] } 上述例子中，用户想要在secret/foo下创建数据，必须包含名为bar和baz的参数。 allowed_parameters——针对指定路径允许操作的键值对的白名单。值为空白列表则代表允许使用任意值： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". It cannot contain any other parameters, but \"bar\" can contain # any value. path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [] } } 上述例子允许在secret/foo下创建键为bar，值为任意值的数据。 给定非空列表值则意味着只能使用列表中限定的值： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". It cannot contain any other parameters, and \"bar\" can only # contain the values \"zip\" or \"zap\". path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"zip\", \"zap\"] } } 上述例子允许在secret/foo下创建键为bar，值为zip或zap的数据。 如果指定了任意的键，那么所有未被指定的键都会被拒绝，除非同时指定了*参数为空列表，这就允许修改其他任意键数据。被指定的键仍然受到给定的值列表的限制： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". The parameter \"bar\" can only contain the values \"zip\" or \"zap\", # but any other parameters may be created with any value. path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"zip\", \"zap\"] \"*\" = [] } } 上述例子中，只限制对bar的值必须是zip或zap，对其他键的值则没有任何限制，可以创建任意键。 重要的一点是，使用*可能会造成意外的后果： # This allows the user to create or update \"secret/foo\" with a parameter # named \"bar\". The values passed to parameter \"bar\" must start with \"baz/\" # so values like \"baz/quux\" are fine. However, values like # \"baz/quux,wibble,wobble,wubble\" would also be accepted. The API that # underlies \"secret/foo\" might allow comma delimited values for the \"bar\" # parameter, and if it did, specifying a value like # \"baz/quux,wibble,wobble,wubble\" would result in 4 different values getting # passed along. Seeing values like \"wibble\" or \"wobble\" getting passed to # \"secret/foo\" might surprise someone that expected the allowed_parameters # constraint to only allow values starting with \"baz/\". path \"secret/foo\" { capabilities = [\"create\", \"update\"] allowed_parameters = { \"bar\" = [\"baz/*\"] } } 在上面的例子中，我们限制对secret/foo只能写入键为bar的数据，并且值必须以baz/为前缀。比如bar=baz/quux这样的数据就是合法的。问题是，我们也可以把值设置成baz/quux,wibble,wobble,wubble，Vault会接纳这种带有分隔符的值，而这样的值可能会被应用程序解析为长度为4的列表，这样的话我们可能会惊讶地发现即使我们限制了bar的值必须以baz/为前缀，仍然读取到了诸如wibble这样的值。 denied_parameters——键值对的黑名单，优先级高于allowed_parameters。 设置值为空列表会导致拒绝对对应键的任意修改。 # This allows the user to create \"secret/foo\" with any parameters not # named \"bar\". path \"secret/foo\" { capabilities = [\"create\"] denied_parameters = { \"bar\" = [] } } 上面的例子禁止在secret/foo下创建键为bar的任意键值对。 如果对denied_parameters赋值一个非空列表，会导致禁止参数的值包含列表中的任意元素： # This allows the user to create \"secret/foo\" with a parameter named # \"bar\". It can contain any other parameters, but \"bar\" cannot contain # the values \"zip\" or \"zap\". path \"secret/foo\" { capabilities = [\"create\"] denied_parameters = { \"bar\" = [\"zip\", \"zap\"] } } 上述例子禁止设置secret/foo的bar的值为zip或是zap。 设置denied_parameters的键为*，则禁止操作任意键： # This allows the user to create \"secret/foo\", but it cannot have any # parameters. path \"secret/foo\" { capabilities = [\"create\"] denied_parameters = { \"*\" = [] } } 如果denied_parameters配置了任意键，那么默认所有未被指定的键都是允许操作的，除非另有显式的allowed_parameters配置。 参数限制中的值也支持前缀与后缀表示： path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"foo-*\"] } } 上面的例子规定对secret/foo，只能创建键为bar，值以foo-为前缀的键值对。 path \"secret/foo\" { capabilities = [\"create\"] allowed_parameters = { \"bar\" = [\"*-foo\"] } } 而上面的例子则是限制值必须以-foo为后缀。 2）限制响应封装的有效期 Vault可以设置响应封装机制。我们可以在策略中使用相关参数限制客户端可以申请的响应封装的有效期时限，精确到秒。我们可以通过s、m或是h后缀来代表秒、分钟和小时。 在实践中，为特定路径指定值为一秒的min_wrapping_ttl可以达到强制必须以响应封装的形式返回相应路径数据的目的。 min_wrapping_ttl——客户端可以指定的响应封装有效期的最小值，如果设置该值，则强制必须以响应封装的形式返回相应路径的数据 max_wrapping_ttl——允","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"3、内建策略 Vault有两个内建策略：default和root。本节来讨论下这两个内建策略。 1）Default策略 default策略是一个无法删除的Vault内建策略。默认情况下，它被附加到所有令牌上，但可以通过使用身份验证方式创建令牌时显式排除之。 该策略包含了基础的功能，例如准许令牌查询有关自身的数据以及使用**Cubbyhole数据**。然而，Vault并不限制该策略的内容，你可以根据需要修改它。Vault永远不会覆盖你的设置。如果你想把default策略同步到最新的Vault版本的默认值，只要用新版Vault执行vault server -dev启动一个测试服务，读取它的default策略内容，然后写回到原来的Vault服务的default策略即可： $ vault read sys/policy/default Key Value --- ----- name default rules # Allow tokens to look up their own properties path \"auth/token/lookup-self\" { capabilities = [\"read\"] } # Allow tokens to renew themselves path \"auth/token/renew-self\" { capabilities = [\"update\"] } # Allow tokens to revoke themselves path \"auth/token/revoke-self\" { capabilities = [\"update\"] } # Allow a token to look up its own capabilities on a path path \"sys/capabilities-self\" { capabilities = [\"update\"] } # Allow a token to look up its own entity by id or name path \"identity/entity/id/{{identity.entity.id}}\" { capabilities = [\"read\"] } path \"identity/entity/name/{{identity.entity.name}}\" { capabilities = [\"read\"] } # Allow a token to look up its resultant ACL from all policies. This is useful # for UIs. It is an internal path because the format may change at any time # based on how the internal ACL features and capabilities change. path \"sys/internal/ui/resultant-acl\" { capabilities = [\"read\"] } # Allow a token to renew a lease via lease_id in the request body; old path for # old clients, new path for newer path \"sys/renew\" { capabilities = [\"update\"] } path \"sys/leases/renew\" { capabilities = [\"update\"] } # Allow looking up lease properties. This requires knowing the lease ID ahead # of time and does not divulge any sensitive information. path \"sys/leases/lookup\" { capabilities = [\"update\"] } # Allow a token to manage its own cubbyhole path \"cubbyhole/*\" { capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\"] } # Allow a token to wrap arbitrary values in a response-wrapping token path \"sys/wrapping/wrap\" { capabilities = [\"update\"] } # Allow a token to look up the creation time and TTL of a given # response-wrapping token path \"sys/wrapping/lookup\" { capabilities = [\"update\"] } # Allow a token to unwrap a response-wrapping token. This is a convenience to # avoid client token swapping since this is also part of the response wrapping # policy. path \"sys/wrapping/unwrap\" { capabilities = [\"update\"] } # Allow general purpose tools path \"sys/tools/hash\" { capabilities = [\"update\"] } path \"sys/tools/hash/*\" { capabilities = [\"update\"] } # Allow checking the status of a Control Group request if the user has the # accessor path \"sys/control-group/request\" { capabilities = [\"update\"] } 创建令牌时排除default策略： $ vault token create -no-default-policy 或是调用API： $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"no_default_policy\": \"true\"}' \\ https://vault.hashicorp.rocks/v1/auth/token/create 根策略 root策略是一个无法删除也无法修改的Vault内建策略。任何关联了该策略的用户都将是根用户。根用户可以在Vault内执行任意操作，强烈建议在生产环境中使用Vault前首先吊销所有的根令牌。 每当Vault服务被首次初始化时，都会创建一个根用户。这个根用户是用来执行Vault的初始化配置的。配置完成后，应创建并使用由细颗粒度策略约束的用户并启用身份认证方式，然后吊销根令牌。 要吊销根令牌可以使用命令行： $ vault token revoke \"\u003ctoken\u003e\" 或是通过HTTP API： $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"token\": \"\u003ctoken\u003e\"}' \\ https://vault.hashicorp.rocks/v1/auth/token/revoke ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:3:3","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"四、vault cli使用 显示所有策略 $ vault read sys/policy 上传并创建策略 $ vault policy write policy-name policy-file.hcl # http $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"policy\":\"path \\\"...\\\" {...} \"}' \\ https://vault.hashicorp.rocks/v1/sys/policy/policy-name # 这两个例子里，策略的名称都是 policy-name。你可以把策略名理解成指向策略规则的指针。令牌通过策略名关联相关策略规则。 更新策略 $ vault write my-existing-policy updated-policy.json # http $ curl \\ --request POST \\ --header \"X-Vault-Token: ...\" \\ --data '{\"policy\":\"path \\\"...\\\" {...} \"}' \\ https://vault.hashicorp.rocks/v1/sys/policy/my-existing-policy 删除策略 $ vault delete sys/policy/policy-name # http $ curl \\ --request DELETE \\ --header \"X-Vault-Token: ...\" \\ https://vault.hashicorp.rocks/v1/sys/policy/policy-name # 删除是一个幂等操作。删除一个不存在的策略不会导致Vault返回错误。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:4:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"五、用户权限管理 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:5:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"1、关联策略 Vault可以通过身份认证方式登录时自动在令牌上关联一组策略，相关配置随具体的身份认证方式类型而不同。简单起见，我们演示一下Vault内建的userpass认证方式。 Vault管理员或是安全团队成员可以用如下命令行创建一个关联了一组策略的用户： # 开启用户登录 vault auth enable userpass # http 方式开启 $ curl \\ --request DELETE \\ --header \"X-Vault-Token: ...\" \\ https://vault.hashicorp.rocks/v1/sys/policy/policy-name curl -XPOST -s -H \"X-Vault-Token: xxxxx\" \"http://vault.local.com/v1/sys/auth/userpass\" -d'{\"type\": \"userpass\"}' # 创建sethvargo用户，并设置密码和策略 $ vault write auth/userpass/users/sethvargo \\ password=\"s3cr3t!\" \\ policies=\"dev-readonly,logs\" 用户可以用命令行执行身份认证，获取令牌： $ vault login -method=\"userpass\" username=\"sethvargo\" Password (will be hidden): ... 如果用户名密码正确，Vault会创建一个令牌，将预设的策略附加在令牌上，然后返回给用户。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:5:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"2、创建令牌时附加策略 可以在通过命令行创建令牌时关联策略： $ vault token create -policy=dev-readonly -policy=logs 子令牌可以关联一组父令牌拥有的策略的子集。根用户可以分派任意策略。 一旦令牌被签发，其关联的策略无法再被修改。必须吊销旧令牌并申请新令牌才能得到更新后的关联策略。 然而，令牌关联的策略内容是实时解析的，也就是说，如果更新了策略内容，附加此策略的令牌下次的请求就会按照新策略内容进行权限检查。 ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:5:2","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"六、terraform 管理 terraform { required_providers { vault = { source = \"hashicorp/vault\" } } } provider \"vault\" { address = var.vault-init.url token = var.vault-init.token } resource \"vault_mount\" \"secret_path\" { for_each = var.vault-init.secret_path path = each.value.path type = each.value.type description = each.value.description options = { version = \"1\" } } resource \"vault_policy\" \"policy\" { for_each = var.vault-init.policy name = each.key policy = each.value.policy } resource \"vault_auth_backend\" \"userpass\" { type = \"userpass\" } resource \"vault_generic_endpoint\" \"create_user\" { for_each = var.vault-init.userlist path = \"auth/userpass/users/${each.key}\" ignore_absent_fields = true data_json = jsonencode(each.value) depends_on = [ vault_auth_backend.userpass, vault_policy.policy ] } resource \"vault_generic_secret\" \"secret_value\" { for_each = var.vault-init.secret_value path = \"${each.value.path}/${each.key}\" data_json = jsonencode(each.value.data) depends_on = [ vault_mount.secret_path, vault_policy.policy ] } variable \"vault-init\" { type = any default = { url = null token = null secret_path = {} userlist = {} policy = {} secret_value = {} } } tfvars vault-init = { url = \"http://127.0.0.1:8200\" token = \"cccccccccc\" secret_path = { p2 = { path = \"Monitor\" type = \"kv\" description = \"Metrics/Tracing/Logs\" }, p5 = { path = \"APP\" type = \"kv\" description = \"Gitea/Gitlab\" } } policy = { admin = { policy = \u003c\u003cEOT path \"cubbyhole/*\" { capabilities = [\"deny\"] } path \"sys/auth\" { capabilities = [\"read\"] } path \"auth/userpass/users/*\" { capabilities = [\"list\", \"read\", \"update\"] } path \"Monitor/+\" { capabilities = [\"read\", \"list\"] } path \"APP/+\" { capabilities = [\"read\", \"list\", \"update\", \"patch\"] } path \"APP/+/+\" { capabilities = [\"read\", \"list\"] } EOT }, user = { policy = \u003c\u003cEOT path \"cubbyhole/*\" { capabilities = [\"deny\"] } path \"Hardware/+\" { capabilities = [\"deny\"] } path \"Monitor/+\" { capabilities = [\"read\", \"list\"] } EOT } } userlist = { user = { username = \"user\", password = \"hello_world\", policies = [\"user\"] }, admin = { username = \"admin\", password = \"hello_world\", policies = [\"admin\"] } } secret_value = { Grafana = { path = \"Monitor\" data = { \"External Address\"= \"http://grafana.local.com\", \"Password\"= \"CvcTKkm4xxxxxxxxx\", \"Username\"= \"admin\" } } } } ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:6:0","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["DevOps"],"content":"Terraform vault unseal vault 官方支持的自动 unseal 依赖于第三方服务，除此以外可以使用 vault cli 和 http 方式解封。 基于 scottwinkler/shell，通过执行命令进行 vault 的初始化和 unseal terraform { required_providers { helm = { source = \"hashicorp/helm\" } shell = { source = \"scottwinkler/shell\" version = \"1.7.10\" } } } module \"vault\" { count = var.vault.enabled ? 1 : 0 source = \"xxxx\" xxxxx } resource \"shell_script\" \"vault_init\" { count = var.vault.enabled ? 1 : 0 lifecycle_commands { create = \u003c\u003cEOF sleep 50 kubectl -n ${module.vault[0].namespace} exec vault-0 -- vault operator init -key-shares=6 -key-threshold=3 -format=json EOF delete = \"\" } environment = { KUBECONFIG = var.kubeconfig } depends_on = [ module.vault, ] } resource \"shell_script\" \"vault_unseal\" { count = var.vault.enabled ? 1 : 0 lifecycle_commands { create = \u003c\u003cEOF kubectl -n ${module.vault[0].namespace} exec vault-0 -- vault operator unseal ${jsondecode(shell_script.vault_init[0].output.unseal_keys_b64)[0]} kubectl -n ${module.vault[0].namespace} exec vault-0 -- vault operator unseal ${jsondecode(shell_script.vault_init[0].output.unseal_keys_b64)[1]} kubectl -n ${module.vault[0].namespace} exec vault-0 -- vault operator unseal ${jsondecode(shell_script.vault_init[0].output.unseal_keys_b64)[2]} EOF delete = \"\" } environment = { KUBECONFIG = var.kubeconfig } depends_on = [module.vault] } ","date":"2024-01-07","objectID":"/posts/2024-01-07-vault/:6:1","tags":["vault"],"title":"Vault","uri":"/posts/2024-01-07-vault/"},{"categories":["Database"],"content":"SQL Server docker run -e \"ACCEPT_EULA=Y\" -e \"SA_PASSWORD=Y.sa123456\" -p 1433:1433 --name mssql2022 -d mcr.microsoft.com/mssql/server:2022-latest 其中 sa123456 为 SQL Server sa 用户的密码，SA_PASSWORD=Y.sa123456 为密码，要求是最少8位的强密码，要有大写字母，小写字母，数字以及特殊符号， ","date":"2023-12-27","objectID":"/posts/2023-12-27-mssql/:0:0","tags":["db","sqlserver","mssql"],"title":"SQL Server","uri":"/posts/2023-12-27-mssql/"},{"categories":["DevOps"],"content":"k3s 参考链接： https://www.escapelife.site/posts/754ba85c.html ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:0:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"一、简介 K3s 是一个轻量级的 Kubernetes 发行版，它针对边缘计算、物联网等场景进行了高度优化。 CNCF 认证的 Kubernetes 发行版 支持 X86_64, ARM64, ARMv7 平台 单一进程包含 Kubernetes master，kubelet 和 containerd K3s 有以下增强功能： 打包为单个二进制文件 把 K8S 相关的组件，比如 kube-api/ kube-manager 都打包到同一个二进制文件里面，这样的话，只需要启动这个文件就可以快速的启动对应的组件。 使用基于 sqlite3 的默认存储机制 同时支持使用 etcd3、MySQL 和 PostgreSQL 作为存储机制。 默认情况下是安全的 在 K3s 中有一个默认的证书管理机制(默认一年有效期)，也有一个可以轮转证书的功能(就是在小于九十天之内重启 K3s 的话，就会自动续一年)。 功能强大的 batteries-included 功能 就是虽然有些服务本身这个二进制文件并没有提供，但是可以通过内置的服务，将配置文件放到指定的目录下面，就可以在启动的时候一并将该服务启动或替换默认组件。 所有 K8S control-plane 组件都封装在单个二进制文件和进程中 因为封装在二进制文件中，所以启动的时候只有一个进程。好处在于只需要管理这个单一进程就可以了，同时也具备操作复杂集群的能力。 最大程度减轻了外部依赖性 即稍新一点的 Linux 内核就可以了(需要 kernel 和 cgroup 挂载)。 之所以叫做 K3S 是因为希望安装的 K8S 在内存占用方面只是一半的大小，而一半大的东西就是一个 5 个字母的单词，简写为 K3S。 生命周期 同时支持 3 个 K8s 版本，支持的生命周期与 K8s 相同 可以参考: Kubernetes 版本及版本偏差支持策略 进行学习 更新周期 当 K8s 更新新版本后，一般 K3s 在一周内同步更新 可以通过 这个链接 获取 latest/stable/testing 版本 我们默认安装的是 stable 版本，可以运行通过命令进行查看 命名规范 v1.20.4+k3s1: v1.20.4 为 K8s 版本，k3s1 为补丁版本 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:1:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"二、单机部署 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:2:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"1、在线部署 curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_SELINUX_WARN=false INSTALL_K3S_MIRROR=cn INSTALL_K3S_EXEC=\"--write-kubeconfig ~/.kube/config --write-kubeconfig-mode 644 \" sh - # token存放在/var/lib/rancher/k3s/server/node-token # cat /var/lib/rancher/k3s/server/node-token curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://172.16.1.164:6443 K3S_TOKEN=K105b756f7f9ce7b0d7f776405cc197e74fa5002701ac76dc63edd57dce8cd272ba::server:a61905854a82cc9280a3ac57ccd649d5 sh - ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:2:1","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"2、离线部署 1）下载k3s二进制包、镜像和安装脚本 二进制包：https://github.com/rancher/k3s/releases 镜像：https://github.com/k3s-io/k3s/releases 部署脚本：https://github.com/k3s-io/k3s/blob/master/install.sh RHEL系列需要安装selinux：https://github.com/k3s-io/k3s-selinux/releases 一下以 Rocky 9 arm64 为示例 # download wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-arm64 wget https://github.com/k3s-io/k3s-selinux/releases/download/v1.4.stable.1/k3s-selinux-1.4-1.el9.noarch.rpm wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-airgap-images-arm64.tar.gz # wget https://get.k3s.io -o ./install.sh # wget http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh wget https://raw.githubusercontent.com/k3s-io/k3s/master/install.sh # set k3s cp ./k3s /usr/local/bin/ chmod 755 /usr/local/bin/k3s # set images tar -xf k3s-airgap-images-$ARCH.tar.gz mkdir -p /var/lib/rancher/k3s/agent/images/ cp ./k3s-airgap-images-$ARCH.tar /var/lib/rancher/k3s/agent/images/ # install selinux and set system yum -y localinstall k3s-selinux-.rpm systemctl stop firewalld systemctl disable firewalld setenforce 0 sed -ri '/^SELINUX=/cSELINUX=disabled' /etc/selinux/config # install k3s INSTALL_K3S_SKIP_DOWNLOAD=true INSTALL_K3S_MIRROR=cn INSTALL_K3S_SELINUX_WARN=true INSTALL_K3S_SKIP_SELINUX_RPM=true INSTALL_K3S_EXEC=\"--write-kubeconfig ~/.kube/config --write-kubeconfig-mode 644 \" ./install.sh # 其他节点加入 # token存放在/var/lib/rancher/k3s/server/node-token # cat /var/lib/rancher/k3s/server/node-token INSTALL_K3S_SKIP_DOWNLOAD=true INSTALL_K3S_MIRROR=cn INSTALL_K3S_SELINUX_WARN=false K3S_URL=https://172.16.1.5:6443 K3S_TOKEN=K101e11731af882398bc6757080f0d8e4b46f8cdb2a17a2edfce54d7971cb3411d1::server:81ee583304cc2b38bf15190298403d34 ./install.sh ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:2:2","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"二、高级配置 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"1、设置节点hostname 集群中不能有共同的主机名，如果hostname有相同，则需要在加入集群时设置一下主机名 # 为每个节点指定主机名 curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ K3S_NODE_NAME=\"k3s2\" INSTALL_K3S_MIRROR=cn \\ K3S_URL=https://192.168.64.3:6443 K3S_TOKEN=xxx sh - # 为每个节点指定主机名 curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn K3S_URL=https://192.168.64.3:6443 \\ K3S_TOKEN=xxx sh -s - --node-name k3s2 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:1","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"2、可用环境变量 Environment Variable Description INSTALL_K3S_SKIP_DOWNLOAD 如果设置为 “true “将不会下载 K3s 的哈希值或二进制。 INSTALL_K3S_SYMLINK 默认情况下，如果路径中不存在命令，将为 kubectl、crictl 和 ctr 二进制文件创建符号链接。如果设置为’skip’将不会创建符号链接，而’force’将覆盖。 INSTALL_K3S_SKIP_ENABLE 如果设置为 “true”，将不启用或启动 K3s 服务。 INSTALL_K3S_SKIP_START 如果设置为 “true “将不会启动 K3s 服务。 INSTALL_K3S_VERSION 从 Github 下载 K3s 的版本。如果没有指定，将尝试从\"stable\"频道下载。 INSTALL_K3S_BIN_DIR 安装 K3s 二进制文件、链接和卸载脚本的目录，或者使用/usr/local/bin作为默认目录。 INSTALL_K3S_BIN_DIR_READ_ONLY 如果设置为 true 将不会把文件写入INSTALL_K3S_BIN_DIR，强制设置INSTALL_K3S_SKIP_DOWNLOAD=true。 INSTALL_K3S_SYSTEMD_DIR 安装 systemd 服务和环境文件的目录，或者使用/etc/systemd/system作为默认目录。 INSTALL_K3S_EXEC 带有标志的命令，用于在服务中启动 K3s。如果未指定命令，并且设置了K3S_URL，它将默认为“agent”。如果未设置K3S_URL，它将默认为“server”。要获得帮助，请参考此示例。 INSTALL_K3S_NAME 要创建的 systemd 服务名称，如果以服务器方式运行 k3s，则默认为’k3s’；如果以 agent 方式运行 k3s，则默认为’k3s-agent’。如果指定了服务名，则服务名将以’k3s-‘为前缀。 INSTALL_K3S_TYPE 要创建的 systemd 服务类型，如果没有指定，将默认使用 K3s exec 命令。 INSTALL_K3S_SELINUX_WARN 如果设置为 true，则在没有找到 k3s-selinux 策略的情况下将继续。 INSTALL_K3S_SKIP_SELINUX_RPM 如果设置为 “true “将跳过 k3s RPM 的自动安装。 INSTALL_K3S_CHANNEL_URL 用于获取 K3s 下载网址的频道 URL。默认为 https://update.k3s.io/v1-release/channels 。 INSTALL_K3S_CHANNEL 用于获取 K3s 下载 URL 的通道。默认值为 “stable”。选项包括：stable, latest, testing。 K3S_CONFIG_FILE 指定配置文件的位置。默认目录为/etc/rancher/k3s/config.yaml。 K3S_TOKEN 用于将 server 或 agent 加入集群的共享 secret。 K3S_TOKEN_FILE 指定 cluster-secret,token 的文件目录。 ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:2","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"3、k3s安装参数设置 # 使用docker作为容器运行时 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--docker\" sh - # 指定运行时工具 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--container-runtime-endpoint containerd\" \\ sh - # 设置私有镜像仓库配置文件 # 默认配置文件: /etc/rancher/k3s/registries.yaml $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--private-registry xxx\" \\ sh - # 针对多网卡主机安装K3s集群 # 默认多网卡会使用默认网关的那个卡 $ rout -n # K3s server $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--node-ip=192.168.100.100\" \\ sh - # K3s agent $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ K3S_URL=https://192.168.99.211:6443 K3S_TOKEN=xxx \\ INSTALL_K3S_EXEC=\"--node-ip=192.168.100.100\" \\ sh - # --tls-san # 在TLS证书中添加其他主机名或IP作为主机备用名称 # 即在公网环境下允许通过公网IP访问控制、操作远程集群 # 或者部署多个Server并使用LB进行负责，就需要保留公网地址 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC=\"--tls-san 1.1.1.1\" \\ sh - # 获取配置 $ kubectl get secret k3s-serving -n kube-system -o yaml # 然后本机复制公网主节点对应的yaml文件即可本地操作了 $ scp ci@1.1.1.1:/etc/rancher/k3s/k3s.yaml ~/.kube/config # 修改启动的服务对应配置(调整节点的启动的最大Pod数量) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--kubelet-arg=max-pods=200' \\ sh - # 修改启动的服务对应配置(使用ipvs作为服务调度工具) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--kube-proxy-arg=proxy-mode=ipvs' \\ sh - # 修改启动的服务对应配置(调整服务启动的端口范围) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--kube-apiserver-arg=service-node-port-range=40000-50000' \\ sh - # kubelet-arg --kubelet-arg # kube-apiserver --kube-apiserver-arg # kube-proxy-arg --kube-proxy-arg # kube-proxy-arg --kube-proxy-arg=proxy-mode=ipvs # --data-dir # 修改K3s数据存储目录 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--data-dir=/opt/k3s-data' \\ sh - # 禁用组件 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--disable traefik' \\ sh - # 自己加自己需要的服务 $ ls /var/lib/rancher/k3s/server/manifests $ kubectl get pods -A | grep traefik # 添加label和taint标识 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--node-label foo=bar,hello=world \\ --node-taint key1=value1:NoExecute' sh - # 查看一下 $ kubectl describe nodes K3s Server/Agent - 数据库选项 # 指定数据源名称 # 标志位: --datastore-endpoint\u0026nbsp;value # 环境变量: K3S_DATASTORE_ENDPOINT $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--datastore-endpoint\u0026nbsp;etcd' \\ sh - # cron规范中的快照间隔时间 # --etcd-snapshot-schedule-cron\u0026nbsp;value $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--etcd-snapshot-schedule-cron *\u0026nbsp;*/5\u0026nbsp;*\u0026nbsp;*\u0026nbsp;*' \\ sh - ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:3","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"4、网络选项配置 默认情况下，K3s 将以 flannel 作为 CNI 运行，使用 VXLAN 作为默认后端，CNI 和默认后端都可以通过参数修改。要启用加密，请使用下面的 IPSec 或 WireGuard 选项。 # 默认安装K3s之后的网络配置 $ sudo cat /var/lib/rancher/k3s/agent/etc/flannel/net-conf.json { \"Network\": \"10.42.0.0/16\", \"EnableIPv6\": false, \"EnableIPv4\": true, \"IPv6Network\": \"::/0\", \"Backend\": { \"Type\": \"vxlan\" } } CLI Flag 和 Value 描述 --flannel-backend=vxlan 使用 VXLAN 后端(默认) --flannel-backend=host-gw 使用 host-gw 后端 --flannel-backend=ipsec 使用 IPSEC 后端；对网络流量进行加密 --flannel-backend=wireguard 使用 WireGuard 后端；对网络流量进行加密 1）配置 Flannel 选项 这样，我就可以在安装 K3s 或者之后修改对应配置文件，来修改 Flannel 默认的后端网络配置选项(重启会覆盖不生效)了。下面，我们演示下，如何修改为 host-gw 模式。 # 主节点 # flannel-backend使用host-gw # 该模式会把对端主机的IP当做默认网管(多Server情况) $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn \\ INSTALL_K3S_EXEC='--flannel-backend=host-gw' \\ sh - # 工作节点 $ curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | \\ INSTALL_K3S_MIRROR=cn K3S_URL=https://192.168.100.100:6443 \\ K3S_TOKEN=xxx sh - # 默认的路由信息 $ route -n 0.0.0.0 172.16.64.1 0.0.0.0 UG 100 0 0 enp0s2 10.42.1.0 172.16.64.9 255.255.255.0 UG 0 0 0 enp0s2 # 查看配置之后的网络配置 $ sudo cat /var/lib/rancher/k3s/agent/etc/flannel/net-conf.json { \"Network\": \"10.42.0.0/16\", \"Backend\": { \"Type\": \"host-gw\" } } ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:4","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"5、镜像仓库设置 K3s 默认使用 containerd 作为容器运行时，所以在 docker 上配置镜像仓库是不生效的。K3s 镜像仓库配置文件由两大部分组成：mirrors 和 configs。 Mirrors 是一个用于定义专用镜像仓库的名称和 endpoint 的指令 Configs 部分定义了每个 mirror 的 TLS 和证书配置 对于每个 mirror，你可以定义 auth 和 / 或 tls K3s registry 配置目录为： /etc/rancher/k3s/registries.yaml。K3s 启动时会检查 /etc/rancher/k3s/ 中是否存在 registries.yaml 文件，并指示 containerd 使用文件中定义的镜像仓库。如果你想使用一个私有的镜像仓库，那么你需要在每个使用镜像仓库的节点上以 root 身份创建这个文件。 请注意，server 节点默认是可以调度的。如果你没有在 server 节点上设置污点，那么将在它们上运行工作负载，请确保在每个 server 节点上创建 registries.yaml 文件。 containerd 使用了类似 K8S 中 svc 与 endpoint 的概念，svc 可以理解为访问名称，这个名称会解析到对应的 endpoint 上。也可以理解 mirror 配置就是一个反向代理，它把客户端的请求代理到 endpoint 配置的后端镜像仓库。mirror 名称可以随意填写，但是必须符合 IP 或域名的定义规则。并且可以配置多个 endpoint，默认解析到第一个 endpoint，如果第一个 endpoint 没有返回数据，则自动切换到第二个 endpoint，以此类推。 # /etc/rancher/k3s/registries.yaml # 同时可以设置多个mirrors地址 # 可以对mirrors设置权限和证书 mirrors: \"172.31.6.200:5000\": endpoint: - \"http://172.31.6.200:5000\" - \"http://x.x.x.x:5000\" - \"http://y.y.y.y:5000\" \"rancher.ksd.top:5000\": endpoint: - \"http://172.31.6.200:5000\" \"docker.io\": endpoint: - \"https://fogjl973.mirror.aliyuncs.com\" - \"https://registry-1.docker.io\" configs: \"172.31.6.200:5000\": auth: username: admin password: Harbor@12345 tls: cert_file: /home/ubuntu/harbor2.escapelife.site.cert key_file: /home/ubuntu/harbor2.escapelife.site.key ca_file: /home/ubuntu/ca.crt # 镜像都是从同一个仓库获取到的 $ sudo systemctl restart k3s.service $ sudo crictl pull 172.31.6.200:5000/library/alpine $ sudo crictl pull rancher.ksd.top:5000/library/alpine 这里我们介绍下，如何使用 TLS 配置。 # 证书颁发机构颁发的证书 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: \"harbor.escapelife.site\": endpoint: - \"https://harbor.escapelife.site\" configs: \"harbor.escapelife.site\": auth: username: admin password: Harbor@12345 EOF $ sudo systemctl restart k3s # 自签名证书 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: \"harbor2.escapelife.site\": endpoint: - \"https://harbor2.escapelife.site\" configs: \"harbor2.escapelife.site\": auth: username: admin password: Harbor@12345 tls: cert_file: /home/ubuntu/harbor2.escapelife.site.cert key_file: /home/ubuntu/harbor2.escapelife.site.key ca_file: /home/ubuntu/ca.crt EOF $ sudo systemctl restart k3s # 不使用TLS证书 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: \"docker.io\": endpoint: - \"https://fogjl973.mirror.aliyuncs.com\" - \"https://registry-1.docker.io\" EOF $ sudo systemctl restart k3s K3s 将会在 /var/lib/rancher/k3s/agent/etc/containerd/config.toml 中为 containerd 生成 config.toml。如果要对这个文件进行高级设置，你可以在同一目录中创建另一个名为 config.toml.tmpl 的文件，此文件将会代替默认设置。 # 可用示例 # mkdir -p /etc/rancher/k3s cat \u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: docker.io: endpoint: - \"https://docker.mirrors.sjtug.sjtu.edu.cn\" - \"https://docker.nju.edu.cn\" quay.io: endpoint: - \"https://quay.nju.edu.cn\" gcr.io: endpoint: - \"https://gcr.nju.edu.cn\" ghcr.io: endpoint: - \"https://ghcr.nju.edu.cn\" nvcr.io: endpoint: - \"https://ngc.nju.edu.cn\" EOF systemctl restart k3s # 完整示例 $ cat \u003e\u003e /etc/rancher/k3s/registries.yaml mirrors: \"harbor.escapelife.site\": endpoint: - \"https://harbor.escapelife.site\" \"harbor2.escapelife.site\": endpoint: - \"https://harbor2.escapelife.site\" \"172.31.19.227:5000\": endpoint: - \"http://172.31.19.227:5000\" \"docker.io\": endpoint: - \"https://fogjl973.mirror.aliyuncs.com\" - \"https://registry-1.docker.io\" configs: \"harbor.escapelife.site\": auth: username: admin password: Harbor@12345 \"harbor2.escapelife.site\": auth: username: admin password: Harbor@12345 tls: cert_file: /home/ubuntu/harbor2.escapelife.site.cert key_file: /home/ubuntu/harbor2.escapelife.site.key ca_file: /home/ubuntu/ca.crt ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:5","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"6、证书管理 参考链接：https://blog.starudream.cn/2023/07/21/k3s-client-cert-extend/ 默认情况下，K3s 的证书在 12 个月内过期。如果证书已经过期或剩余的时间不足 90 天，则在 K3s 重启时轮换证书。 # 查询K3s证书过期时间 $ for i in `ls /var/lib/rancher/k3s/server/tls/*.crt`; \\ do \\ echo $i;\\ openssl x509 -enddate -noout -in $i; \\ done # 修改系统时间为证书过期前90天或证书过期后 $ timedatectl set-ntp no $ date -s 20220807 # 重启K3s服务 $ service k3s restart k3s 默认的根证书签发 十年，客户端证书签发 一年。 经常需要重新签发客户端证书，可以通过修改 k3s 的环境变量来延长客户端证书的有效期。 新增 /etc/default/k3s 文件，并添加以下内容： CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=\"3650\" 该变量在 k3s server 重新签发证书时有效，或者在安装之前设置。 # 轮换证书 k3s certificate rotate # 启动 K3s systemctl start k3s ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:3:6","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"三、多master高可用生产级别部署—在线版 https://kube-vip.io/docs/usage/k3s/ https://zhuanlan.zhihu.com/p/651292552 HA + kube-vip ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:4:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"1、配置内核参数 [root@k8s-m1 ~]# cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf # https://github.com/moby/moby/issues/31208 # ipvsadm -l --timout # 修复ipvs模式下长连接timeout问题 小于900即可 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.ip_forward = 1 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 # 要求iptables不对bridge的数据进行处理 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.netfilter.nf_conntrack_max = 2310720 fs.inotify.max_user_watches=89100 fs.may_detach_mounts = 1 fs.file-max = 52706963 fs.nr_open = 52706963 vm.swappiness = 0 vm.overcommit_memory=1 vm.panic_on_oom=0 EOF 加载内核参数 [root@k8s-m1 ~]# sysctl -p ipvs配置 [root@k8s-m1 ~]# yum install ipset ipvsadm -y [root@k8s-m1 ~]# cat \u003e/etc/modules-load.d/ipvs.conf\u003c\u003cEOF ip_vs # 负载均衡调度算法-最少连接 ip_vs_lc # 负载均衡调度算法-加权最少连接 ip_vs_wlc # 负载均衡调度算法-轮询 ip_vs_rr # 负载均衡调度算法-加权轮询 ip_vs_wrr # 源地址散列调度算法 ip_vs_sh nf_conntrack br_netfilter EOF [root@k8s-m1 ~]# systemctl restart systemd-modules-load.service 查看加载情况 [root@k8s-m1 ~]# lsmod | grep -e ip_vs -e nf_conntrack -e br_netfilter systemctl stop firewalld systemctl disable firewalld setenforce 0 sed -ri '/^SELINUX=/cSELINUX=disabled' /etc/selinux/config 换源 sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/rocky|g' \\ -i.bak \\ /etc/yum.repos.d/rocky-extras.repo \\ /etc/yum.repos.d/rocky.repo 自签名ca [可选] mkdir -p /var/lib/rancher/k3s/server/tls cd /var/lib/rancher/k3s/server/tls openssl genrsa -out client-ca.key 2048 openssl genrsa -out server-ca.key 2048 openssl genrsa -out request-header-ca.key 2048 openssl req -x509 -new -nodes -key client-ca.key -sha256 -days 3650 -out client-ca.crt -addext keyUsage=critical,digitalSignature,keyEncipherment,keyCertSign -subj '/CN=k3s-client-ca' openssl req -x509 -new -nodes -key server-ca.key -sha256 -days 3650 -out server-ca.crt -addext keyUsage=critical,digitalSignature,keyEncipherment,keyCertSign -subj '/CN=k3s-server-ca' openssl req -x509 -new -nodes -key request-header-ca.key -sha256 -days 3650 -out request-header-ca.crt -addext keyUsage=critical,digitalSignature,keyEncipherment,keyCertSign -subj '/CN=k3s-request-header-ca' 设置k3s续签的证书有效期 echo \"CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=3650\" \u003e /etc/default/k3s # 或者 #echo \"CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=3650\" \u003e /etc/sysconfig/k3s ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:4:1","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"2、安装kube-vip 操作过程：首先生成一个用于部署在 K3s 集群中的 kube-vip Manifest，然后再启动一个高可用的 K3s 集群，启动 K3s 集群时会自动部署 kube-vip 的 Manifest 文件，从而通过 kube-vip 实现控制平面的高可用。 # 创建manifests目录 mkdir -p /var/lib/rancher/k3s/server/manifests/ # 获取 kube-vip RBAC 清单 # kube-vip 在 K3s 下作为 DaemonSet 运行，我们需要 RBAC 资源来确保 ServiceAccount 存在并进行绑定，来确保它具有与 API 服务器通信所需的权限。 curl https://kube-vip.io/manifests/rbac.yaml \u003e /var/lib/rancher/k3s/server/manifests/kube-vip-rbac.yaml 生成kube-vip DaemonSet Manifest export VIP=172.16.1.222 # 设置虚拟 IP 用于访问控制平面的地址 export INTERFACE=ens160 # 设置控制平面所在主机的网卡名称 KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r \".[0].name\") # 获取 kube-vip 版本 alias kube-vip=\"docker run --network host --rm ghcr.io/kube-vip/kube-vip:$KVVERSION\" # 针对 docker 环境设置别名 # 创建 kube-vip 清单 kube-vip manifest daemonset \\ --interface $INTERFACE \\ --address $VIP \\ --inCluster \\ --taint \\ --controlplane \\ --services \\ --arp \\ --leaderElection \u003e /var/lib/rancher/k3s/server/manifests/kube-vip.yaml 文件内容 apiVersion: v1 kind: ServiceAccount metadata: name: kube-vip namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" name: system:kube-vip-role rules: - apiGroups: [\"\"] resources: [\"services\", \"services/status\", \"nodes\", \"endpoints\"] verbs: [\"list\",\"get\",\"watch\", \"update\"] - apiGroups: [\"coordination.k8s.io\"] resources: [\"leases\"] verbs: [\"list\", \"get\", \"watch\", \"update\", \"create\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: system:kube-vip-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-vip-role subjects: - kind: ServiceAccount name: kube-vip namespace: kube-system --- apiVersion: apps/v1 kind: DaemonSet metadata: creationTimestamp: null name: kube-vip-ds namespace: kube-system spec: selector: matchLabels: name: kube-vip-ds template: metadata: creationTimestamp: null labels: name: kube-vip-ds spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node-role.kubernetes.io/master operator: Exists - matchExpressions: - key: node-role.kubernetes.io/control-plane operator: Exists containers: - args: - manager env: - name: vip_arp value: \"true\" - name: port value: \"6443\" - name: vip_interface value: ens160 - name: vip_cidr value: \"32\" - name: cp_enable value: \"true\" - name: cp_namespace value: kube-system - name: vip_ddns value: \"false\" - name: svc_enable value: \"true\" - name: vip_leaderelection value: \"true\" - name: vip_leaseduration value: \"5\" - name: vip_renewdeadline value: \"3\" - name: vip_retryperiod value: \"1\" - name: address value: 172.16.1.222 # image: ghcr.io/kube-vip/kube-vip:v0.6.0 image: ghcr.nju.edu.cn/kube-vip/kube-vip:v0.6.0 imagePullPolicy: Always name: kube-vip resources: {} securityContext: capabilities: add: - NET_ADMIN - NET_RAW - SYS_TIME hostNetwork: true serviceAccountName: kube-vip tolerations: - effect: NoSchedule operator: Exists - effect: NoExecute operator: Exists updateStrategy: {} status: currentNumberScheduled: 0 desiredNumberScheduled: 0 numberMisscheduled: 0 numberReady: 0 3、安装HA K3s集群 K3s 支持多种 HA 安装方式，本次示例采用嵌入式 ETCD 的方式搭建高可用的 K3s 集群，这样集群中就存在了 3 个控制平面，然后通过 kube-vip 实现这些控制平面的高可用。 安装 K3s 时需要指定 --tls-san 参数，这样 K3s 就会使用 kube-vip 虚拟 IP 地址生成 API 服务器证书。 master节点上 第一个server curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn INSTALL_K3S_EXEC=\" --cluster-init --tls-san 172.16.1.222 --disable=traefik --disable servicelb --kube-proxy-arg proxy-mode=ipvs --write-kubeconfig ~/.kube/config --write-kubeconfig-mode 644 \" sh - # 查看token cat /var/lib/rancher/k3s/server/token 其他server curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_TOKEN=K107f47359a4c5125056975c2bb8e4bee90a099366efa61e207092782f19f209abd::server:83a5baabf15d41e9cdf1de4a84b5367f INSTALL_K3S_EXEC=\" --server https://172.16.1.164:6443 --tls-san 172.16.1.2","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:4:2","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"四、多master高可用生产级别部署—离线版 # download wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-arm64 wget https://github.com/k3s-io/k3s/releases/download/v1.28.4%2Bk3s2/k3s-airgap-images-arm64.tar.gz # 下载rpm包 wget https://github.com/k3s-io/k3s-selinux/releases/download/v1.4.stable.1/k3s-selinux-1.4-1.el9.noarch.rpm yum -y localinstall k3s-selinux-1.4-1.el9.noarch.rpm --downloadonly --downloaddir=./k3s-rpm yum -y install ipvsadm ipset --downloadonly --downloaddir=./k3s-rpm # 下载安装脚本 # wget https://get.k3s.io -o ./install.sh # wget http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh wget https://raw.githubusercontent.com/k3s-io/k3s/master/install.sh #分发到所有节点 # set k3s cp ./k3s /usr/local/bin/ chmod 755 /usr/local/bin/k3s # set images tar -xf k3s-airgap-images-$ARCH.tar.gz mkdir -p /var/lib/rancher/k3s/agent/images/ cp ./k3s-airgap-images-$ARCH.tar /var/lib/rancher/k3s/agent/images/ systemctl stop firewalld systemctl disable firewalld setenforce 0 sed -ri '/^SELINUX=/cSELINUX=disabled' /etc/selinux/config # 内核参数设置 cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf # https://github.com/moby/moby/issues/31208 # ipvsadm -l --timout # 修复ipvs模式下长连接timeout问题 小于900即可 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.ip_forward = 1 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 # 要求iptables不对bridge的数据进行处理 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.netfilter.nf_conntrack_max = 2310720 fs.inotify.max_user_watches=89100 fs.may_detach_mounts = 1 fs.file-max = 52706963 fs.nr_open = 52706963 vm.swappiness = 0 vm.overcommit_memory=1 vm.panic_on_oom=0 EOF sysctl -p cat \u003e/etc/modules-load.d/ipvs.conf\u003c\u003cEOF ip_vs # 负载均衡调度算法-最少连接 ip_vs_lc # 负载均衡调度算法-加权最少连接 ip_vs_wlc # 负载均衡调度算法-轮询 ip_vs_rr # 负载均衡调度算法-加权轮询 ip_vs_wrr # 源地址散列调度算法 ip_vs_sh nf_conntrack br_netfilter EOF systemctl restart systemd-modules-load.service lsmod | grep -e ip_vs -e nf_conntrack -e br_netfilter # 设置续签时间 echo \"CATTLE_NEW_SIGNED_CERT_EXPIRATION_DAYS=3650\" \u003e /etc/default/k3s # 设置镜像加速 mkdir -p /etc/rancher/k3s cat \u003e /etc/rancher/k3s/registries.yaml \u003c\u003cEOF mirrors: docker.io: endpoint: - \"https://docker.mirrors.sjtug.sjtu.edu.cn\" - \"https://docker.nju.edu.cn\" quay.io: endpoint: - \"https://quay.nju.edu.cn\" gcr.io: endpoint: - \"https://gcr.nju.edu.cn\" ghcr.io: endpoint: - \"https://ghcr.nju.edu.cn\" nvcr.io: endpoint: - \"https://ngc.nju.edu.cn\" EOF 第一个server # 配置kube-vip mkdir -p /var/lib/rancher/k3s/server/manifests/ cat \u003e kube-vip.yaml \u003c\u003cEOF apiVersion: v1 kind: ServiceAccount metadata: name: kube-vip namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" name: system:kube-vip-role rules: - apiGroups: [\"\"] resources: [\"services\", \"services/status\", \"nodes\", \"endpoints\"] verbs: [\"list\",\"get\",\"watch\", \"update\"] - apiGroups: [\"coordination.k8s.io\"] resources: [\"leases\"] verbs: [\"list\", \"get\", \"watch\", \"update\", \"create\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: system:kube-vip-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-vip-role subjects: - kind: ServiceAccount name: kube-vip namespace: kube-system --- apiVersion: apps/v1 kind: DaemonSet metadata: creationTimestamp: null name: kube-vip-ds namespace: kube-system spec: selector: matchLabels: name: kube-vip-ds template: metadata: creationTimestamp: null labels: name: kube-vip-ds spec: affinity: nodeAffinity: requ","date":"2023-12-16","objectID":"/posts/2023-12-16-k3s/:5:0","tags":["k3s","k8s"],"title":"k3s","uri":"/posts/2023-12-16-k3s/"},{"categories":["DevOps"],"content":"Ansible handbook ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:0:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"一、ansible配置 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:1:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"1、ansible.cfg https://ansible-tran.readthedocs.io/en/latest/docs/intro_configuration.html * ANSIBLE_CONFIG (一个环境变量) * ansible.cfg (位于当前目录中) * .ansible.cfg (位于家目录中) * /etc/ansible/ansible.cfg 生成ansible的配置文件 $ ansible-config init --disabled \u003e ~/.ansible.cfg 使用环境变量关闭Key验证提示 $ export ANSIBLE_HOST_KEY_CHECKING=False 可使用的模板 [defaults] interpreter_python = auto #interpreter_python = /usr/bin/python3 host_key_checking=False #inventory=~/.ansible/hosts private_key_file=/path/to/file.pem remote_user = root sudo_user=root ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:1:1","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"2、hosts 写法一 node1.ansible.com node2.ansible.com 192.168.1.1 写法二 [webserver] 192.168.10.1 192.168.10.2 [dbserver] 192.168.20.1 192.168.20.2 注意：如果主机建未做ssh互信，则可以按以下写法 # 连续IP [test1] name1 ansible_ssh_host=192.168.1.[20:50] ansible_ssh_user=\"root\" ansible_ssh_pass=\"1234\" ansible_ssh_port=22 ansible_ssh_private_key_file=~/.ssh/id_rsa # 带参数 [test1] name1 ansible_ssh_host=192.168.1.[20:50] [test1:vars] ansible_ssh_user=root ansible_ssh_pass=\"1234\" testvar=\"test\" host文件常用变量 ansible_ssh_host #用于指定被管理的主机的真实IP ansible_ssh_port #用于指定连接到被管理主机的ssh端口号，默认是22 ansible_ssh_user #ssh连接时默认使用的用户名 ansible_ssh_pass #ssh连接时的密码 ansible_sudo_pass #使用sudo连接用户时的密码 ansible_sudo_exec #如果sudo命令不在默认路径，需要指定sudo命令路径 ansible_ssh_private_key_file #秘钥文件路径，秘钥文件如果不想使用ssh-agent管理时可以使用此选项 ansible_shell_type #目标系统的shell的类型，默认sh ansible_connection #SSH 连接的类型： local , ssh , paramiko，在 ansible 1.2 之前默认是 paramiko ，后来智能选择，优先使用基于 ControlPersist 的 ssh （支持的前提） ansible_python_interpreter #用来指定python解释器的路径，默认为/usr/bin/python 同样可以指定ruby 、perl 的路径 ansible_*_interpreter #其他解释器路径，用法与ansible_python_interpreter类似，这里\"*\"可以是ruby或才perl等 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:1:2","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"二、playbook示例 - hosts: rocky become: yes become_user: root roles: #- role: serialt.centos_init - role: repo vars: elrepo_install: False - role: serialt.os_init vars: login_info: \" Welcome to local OPS\" fail2ban_ignore_ip: \"\" ssh_key_message: \"t@local.com\" - role: python - role: serialt.docker vars: docker_insecure_registries: [\"repo.local.com\"] # - role: serialt.chrony #- role: serialt.kernel # - role: zabbix-server 补充 # 本地执行 - name: check | 发布文件是否存在。 shell: \"ls {{ deploy_file }}\" connection: local # 判断 - name: Create software directory. file: path: \"{{ software_files_path }}\" state: directory connection: local when: not go_file_result.stat.exists # 串行执行 - hosts: server1 become: yes gather_facts: yes serial: 1 tasks: - YOUR TASKS HERE - hosts: serialt become: yes become_user: root vars: go_version: \"1.20.2\" tasks: - name: check | 发布文件是否存在。 shell: \"ls {{ deploy_file }}\" connection: local ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:2:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"三、公钥受信 ad hoc ansible add-public-key -m authorized_key -a \"user=root state=present key='{{ lookup('file', '/home/root/.ssh/id_rsa.pub') }}'\" playbook - hosts: add-public-key gather_facts: false tasks: - name: Add local public key to remote hosts. authorized_key: user: sugar key: \"{{ lookup('file', '/Users/serialt/.ssh/id_rsa.pub') }}\" state: present hosts [add-public-key] 172.16.78.53 ansible_connection=ssh ansible_ssh_user=\"sugar\" ansible_ssh_pass=\"ubuntu\" ; 172.25.70.2 ansible_connection=ssh ansible_ssh_user=\"root\" ansible_ssh_pass=\"redhat\" ; 172.25.70.3 ansible_connection=ssh ansible_ssh_user=\"sugar\" ansible_ssh_pass=\"redhat\" ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:2:1","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"四、模块简介 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:0","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"ping 检测被管理端是否在线 ad-hoc [root@localhost test]# ansible k8s -m ping 192.168.122.100 | SUCCESS =\u003e { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } playbook # ping模块没有参数 [root@localhost test]# cat ping.yaml - hosts: k8s user: root gather_facts: false tasks: - name: test ping ping: ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:1","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"shell 在被管理端执行命令，支持重定向和管道 ad-hoc [root@localhost test]# ansible k8s -m shell -a \" uptime\" 192.168.122.100 | CHANGED | rc=0 \u003e\u003e 11:11:05 up 25 days, 1:14, 2 users, load average: 0.31, 0.44, 0.39 # 参数 chdir=\u003cDirectory\u003e playbook [root@localhost test]# cat shell.yaml - hosts: k8s user: root gather_facts: false tasks: - name: test shell shell: date \u0026\u0026 pwd args: chdir: /tmp/ - name: Run expect to wait for a successful PXE boot via out-of-band CIMC shell: | set timeout 300 spawn ssh admin@{{ cimc_host }} expect \"password:\" send \"{{ cimc_password }}\\n\" expect \"\\n{{ cimc_name }}\" send \"connect host\\n\" expect \"pxeboot.n12\" send \"\\n\" exit 0 args: executable: /usr/bin/expect delegate_to: localhost ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:2","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"copy 拷贝ansible管理端的文件到远程主机的指定位置 常见参数： 参数 取值 默认值 说明 dest string null 指明拷贝文件的目标目录位置，使用绝对路径，如果源是目录，则目标也要是目录,如果目标文件已存在，会覆盖原有内容 src string null 指明本地路径下的某个文件，可以使用相对路径和绝对路径，支持直接指定目录，如果源是目录，则目标也要是目录 mode 权限位 无 指明复制时，目标文件的权限 owner string null 指明复制时，目标文件的属主 group string null 指明复制时，目标文件的属组 content string null 指明复制到目标主机上的内容，不能与src一起使用，相当于复制content指明的数据，到目标文件中 [root@localhost test]# ansible k8s -m copy -a \"src=/etc/hosts dest=/tmp/\" 192.168.122.100 | CHANGED =\u003e { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": true, \"checksum\": \"42d592f8ed1579880187c900197e1edd09688992\", \"dest\": \"/tmp/hosts\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"f4c82671111086eb6fa6d869e80e1128\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 803, \"src\": \"/root/.ansible/tmp/ansible-tmp-1608693775.8-22394-277593855767937/source\", \"state\": \"file\", \"uid\": 0 } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:3","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"fetch 从远程主机拉取文件到本地（ 一般情况下，只会从一个远程节点拉取数据） 常见参数： 参数 取值 默认值 说明 dest string null 从远程主机上拉取的文件存放在本地的位置，一般只能是目录 src string null 指明远程主机上要拉取的文件，只能是文件，不能是目录 [root@master ~]# ansible test -m fetch -a 'src=/etc/passwd dest=/tmp' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"checksum\": \"974b44c114ecbd71bdee11e09a9bc14c9b0395bd\", \"dest\": \"/tmp/192.168.100.102/etc/passwd\", \"md5sum\": \"01d72332a8d9737631212995fe1494f4\", \"remote_checksum\": \"974b44c114ecbd71bdee11e09a9bc14c9b0395bd\", \"remote_md5sum\": null } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:4","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"cron 管理计划任务 常见参数 参数 取值 默认值0 说明 minute 0-59, * , * / 2 * 指明计划任务的分钟 hour 0-23, * , * / 2 * day 1-31 * month 1-12 * weekday 0-6 * reboot yes | no null 指明计划任务执行的时间为每次重启之后 name string null 给该计划任务取个名称,必须要给明。每个任务的名称不能一样 job string null 执行的任务是什么，当state=present时才有意义 state present | absent present 表示这个任务是创建还是删除，present表示创建，absent表示删除，默认是present [root@master ~]# ansible test -m cron -a 'minute=*/5 name=Ajob job=\"/usr/sbin/ntpdate 172.16.8.100 \u0026\u003e /dev/null\" state=present' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"envs\": [], \"jobs\": [ \"Ajob\" ] } [root@master ~]# ansible test -m shell -a 'crontab -l' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e #Ansible: Ajob */5 * * * * /usr/sbin/ntpdate 172.16.8.100 \u0026\u003e /dev/null [root@master ~]# ansible test -m cron -a 'minute=*/5 name=Ajob job=\"/usr/sbin/ntpdate 172.16.8.100 \u0026\u003e /dev/null\" state=absent' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"envs\": [], \"jobs\": [] } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:5","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"file 用于设定远程主机上的文件属性 常见参数: 参数 取值 默认值 说明 path string null 指明对哪个文件修改其属性 src string null 指明path=指明的文件是软链接文件，其对应的源文件是谁，必须要在state=link时才有用 state directory | link| absent null 表示创建的文件是目录还是软链接 owner string null 指明文件的属主 mode 权限位 无 指明文件的权限 使用示例： 创建软链接的用法： src= path= state=link 修改文件属性的用法： path= owner= mode= group= 创建目录的用法： path= state=directory 删除文件： path= state=absent [root@ansible etc]# ansible testsrv -m file -a \"path=/tmp/1.txt mode=600 owner=root group=nobody\" [root@ansible ~]# ansible testsrv -m file -a \"path=/tmp/bb mode=777 recurse=yes\" 创建软链接 [root@master ~]# ansible test -m file -a 'src=/etc/passwd path=/tmp/passwd.link state=link' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"dest\": \"/tmp/passwd.link\", \"gid\": 0, \"group\": \"root\", \"mode\": \"0777\", \"owner\": \"root\", \"size\": 11, \"src\": \"/etc/passwd\", \"state\": \"link\", \"uid\": 0 } 删除文件 [root@master ~]# ansible test -m file -a 'path=/tmp/cc.txt state=absent' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"path\": \"/tmp/cc.txt\", \"state\": \"absent\" } 修改文件属性 [root@master ~]# ansible test -m file -a 'path=/tmp/bb.txt mode=700 owner=root group=nobody' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"gid\": 99, \"group\": \"nobody\", \"mode\": \"0700\", \"owner\": \"root\", \"path\": \"/tmp/bb.txt\", \"size\": 14, \"state\": \"file\", \"uid\": 0 } [root@master ~]# ansible test -m shell -a 'ls -l /tmp/bb.txt' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e -rwx------ 1 root nobody 14 Dec 2 2016 /tmp/bb.txt 创建目录 [root@master ~]# ansible test -m file -a 'path=/tmp/bj state=directory' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"gid\": 0, \"group\": \"root\", \"mode\": \"0755\", \"owner\": \"root\", \"path\": \"/tmp/bj\", \"size\": 4096, \"state\": \"directory\", \"uid\": 0 } 删除目录 [root@master ~]# ansible test -m file -a 'path=/tmp/bj state=absent' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"path\": \"/tmp/bj\", \"state\": \"absent\" } [root@master ~]# ansible test -m shell -a 'ls -l /tmp' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e total 16 -rw-r--r-- 1 root root 0 Dec 2 2016 aa.txt drwx------ 2 root root 4096 Dec 2 13:41 ansible_twMJYb -rwx------ 1 root nobody 14 Dec 2 2016 bb.txt -rw-r--r-- 1 root root 158 Dec 2 2016 hosts -rw------- 1 nobody nobody 947 Dec 2 2016 passwd lrwxrwxrwx 1 root root 11 Dec 2 13:35 passwd.link -\u003e /etc/passwd -rw------- 1 root root 0 Dec 2 00:58 yum.log ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:6","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"hostsname 管理远程主机的主机名 参数： name= 指明主机名 [root@master ~]# ansible test -m shell -a 'hostname' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e node1.ansible.com [root@master ~]# ansible test -m hostname -a 'name=node2.ansible.com' 192.168.100.102 | SUCCESS =\u003e { \"ansible_facts\": { \"ansible_domain\": \"ansible.com\", \"ansible_fqdn\": \"node2.ansible.com\", \"ansible_hostname\": \"node2\", \"ansible_nodename\": \"node2.ansible.com\" }, \"changed\": true, \"name\": \"node2.ansible.com\" } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:7","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"yum 基于yum机制，对远程主机管理程序包 常用参数： 参数 取值 默认值 说明 name string null 指明程序包的名称，可以带上版本号，不指明版本，就是默认最新版本 state present|lastest|absent null 指明对程序包执行的操作，present表示安装程序包，latest表示安装最新版本的程序包，absent表示卸载程序包 disablerepo yes|no null 在用yum安装时，临时禁用某个仓库，仓库的ID enablerepo yes|no null 在用yum安装时，临时启用某个仓库,仓库的ID conf_file= string null 指明yum运行时采用哪个配置文件，而不是使用默认的配置文件 disable_gpg_check yes|no null 是否启用gpg-check # 卸载软件包: [root@master ~]# ansible test -m yum -a 'name=httpd state=absent' [root@master ~]# ansible test -m shell -a 'rpm -q httpd' # 安装软件包: [root@master ~]# ansible test -m yum -a 'name=httpd state=present' [root@ansible ~]# ansible 192.168.122.102 -m yum -a \"name=ftp state=present disablerepo=zabbix\" [root@ansible_server ~]# ansible test_server -m yum -a \"name=zabbix-agent state=present enablerepo=zabbix3.2 disablerepo=zabbix\" # 更新软件 [root@ansible_server ~]# ansible test_server -m yum -a \"name=zabbix-agent state=latest\" palybook - hosts: all tasks: - name: yum yum: name: \"{{ item }}\" state: present with_items: - git - httpd - mysql ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:8","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"yum_repository 管理远程主机上的 yum 仓库 常用参数： 参数 取值 默认值 说明 name string null 必须参数，用于指定要操作的唯一的仓库ID，也就是”.repo”配置文件中每个仓库对应的”中括号”内的仓库ID baseurl string null 用于设置 yum 仓库的 baseurl description string null 用于设置仓库的注释信息，也就是”.repo”配置文件中每个仓库对应的”name字段”对应的内容 file string null 用于设置仓库的配置文件名称，即设置”.repo”配置文件的文件名前缀，在不使用此参数的情况下，默认以 name 参数的仓库ID作为”.repo”配置文件的文件名前缀，同一个”.repo” 配置文件中可以存在多个 yum 源 enabled string yes 用于设置是否激活对应的 yum 源，此参数默认值为 yes，表示启用对应的 yum 源，设置为 no 表示不启用对应的 yum 源 gpgcheck string no 用于设置是否开启 rpm 包验证功能，默认值为 no，表示不启用包验证，设置为 yes 表示开启包验证功能 gpgcakey string null 当 gpgcheck 参数设置为 yes 时，需要使用此参数指定验证包所需的公钥 state present present 当值设置为 absent 时，表示删除对应的 yum 源 [root@ansible-manager ~]# ansible ansible-demo3 -m yum_repository -a 'name=aliEpel description=\"alibaba EPEL\" baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/' ansible-demo3 | SUCCESS =\u003e { \"changed\": true, \"repo\": \"aliEpel\", \"state\": \"present\" } 配置postgresql 清华源 [root@localhost test]# cat yum_repo.yaml - hosts: 127.0.0.1 user: root gather_facts: false tasks: - name: config postgresql with tsinghua yum_repository: file: postgresql-10 name: postgresql description: postgresql-10 tsinghua baseurl: https://mirrors.tuna.tsinghua.edu.cn/postgresql/repos/yum/10/redhat/rhel-7-x86_64/ enabled: yes gpgcheck: no [root@localhost yum.repos.d]# cat postgresql-10.repo [postgresql] baseurl = https://mirrors.tuna.tsinghua.edu.cn/postgresql/repos/yum/10/redhat/rhel-7-x86_64/ enabled = 1 gpgcheck = 0 name = postgresql-10 tsinghua ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:9","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"service 管理远程主机上的服务的模块 常用参数： 参数 取值 默认值 说明 name string null 被管理的服务名称(/etc/init.d) state started|stopped|restarted started 启动或关闭或重起 enabled yes|no no 设定该服务开机自启动 [root@master ~]# ansible test -m service -a 'name=nginx state=started' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"name\": \"nginx\", \"state\": \"started\" } [root@master ~]# ansible test -m shell -a 'service nginx status' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e nginx (pid 4054) is running... [root@master ~]# [root@master ~]# ansible test -m service -a 'name=nginx state=stopped' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"name\": \"nginx\", \"state\": \"stopped\" } [root@master ~]# ansible test -m shell -a 'service nginx status' 192.168.100.102 | FAILED | rc=3 \u003e\u003e nginx is stopped [root@master ~]# ansible test -m service -a 'name=nginx state=started enabled=yes runlevel=2345' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"enabled\": true, \"name\": \"nginx\", \"state\": \"started\" } [root@master ~]# ansible test -m shell -a 'chkconfig --list nginx' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e nginx 0:off 1:off 2:on 3:on 4:on 5:on 6:off ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:10","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"systemd 管理被控制主机的systemd服务 常见参数： 参数 取值 默认值 说明 daemon_reload yes|no 无 重启守护进程，与其他systemd参数排斥 name string null 被管理的服务名 enabled yes|no null 服务设置为开机自启 state reloaded|restarted|started|stopped null 服务状态 [root@localhost test]# cat daemon_reload.yaml - hosts: 127.0.0.1 user: root gather_facts: false tasks: - name: daemon reload systemd: daemon_reload: yes [root@localhost test]# cat nginx.yaml - hosts: 127.0.0.1 user: root gather_facts: false tasks: - name: daemon reload systemd: name: nginx enabled: yes state: restarted ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:11","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"git 管理git服务模块 常见参数： 参数 取值 默认值 说明 bare yes|no no 建立裸仓库，用于服务器端git仓库存储 clone yes|no yes 本地镜像仓库不存在则clone depth 数字 null clone时克隆的commit深度，1表示只克隆最新一次提交，默认null dest string null clone出的仓库存储的路径，仅当clone=no时不用设置 force yes|no no 强制 remote string null 远程仓库的名称，默认是origin repo string null 远程仓库的地址 version string null checkout的版本，支持分支、tag、hash archive string null clone后的压缩文件存储文件，支持格式zip、tar.gz、tar、tgz - hosts: 127.0.0.1 user: root gather_facts: false vars: - GIT_REPO: git@serialt.io:sugars/sugars_backend.git - SRC_HASH: 4949e0b60be3f6a80826d3e02exxxxxxxxxxxx tasks: - name: clone a git repo git: repo: \"{{ item.repo }}\" version: \"{{ item.hash }}\" dest: /tmp/serialt_backend with_items: - {repo: \"{{ GIT_REPO }}\",hash: \"{{ SRC_HASH }}\" } ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:12","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"supervisorctl 管理supervisorctl服务 常见参数： 参数 取值 默认值 说明 config string null supervisor配置文件路径 name string null supervisord program的名字，支持program和program组 state string nul 可选present, started, stopped, restarted, absent, signalled supervisorctl_path string null supervisorctl命令的路径 EXAMPLES: # Manage the state of program to be in 'started' state. - supervisorctl: name: my_app state: started # Manage the state of program group to be in 'started' state. - supervisorctl: name: 'my_apps:' state: started # Restart my_app, reading supervisorctl configuration from a specified file. - supervisorctl: name: my_app state: restarted config: /var/opt/my_project/supervisord.conf # Restart my_app, connecting to supervisord with credentials and server URL. - supervisorctl: name: my_app state: restarted username: test password: testpass server_url: http://localhost:9001 # Send a signal to my_app via supervisorctl - supervisorctl: name: my_app state: signalled signal: USR1 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:13","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"pip 管理python库依赖模块 常见参数： 参数 取值 默认值 说明 chdir string null 执行时的路径 name string null pip安装的包名 requirements string null 安装依赖的包文件 executable string null 安装依赖包时使用的python路径 state string present 依赖包的状态，absent, forcereinstall, latest, present，默认present virtualenv string null 所使用的虚拟环境目录 virtualenv_command string null 创建虚拟环境的命令 virtualenv_python string null 虚拟环境的python版本 extra_args= string null 附加参数，可以用来指定所使用的安装源 [root@localhost test]# cat pip.yaml - hosts: 192.168.100.105 user: root gather_facts: false tasks: - name: install python venv pip: requirements: /tmp/requirements.txt state: present virtualenv: /tmp/serialt_venv/ ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:14","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"archive 压缩文件模块 常用参数： 参数 取值 默认值 说明 dest string null 文件归档后的压缩包文件名，当 path中有多个文件或目录时，需提供 dest 参数 exclude_path string null 排除的path format string gz 支持bz2, gz, tar, xz, zip，默认gz path string null 要压缩的路径 remove bool False 删除源文件 EXAMPLES: - name: Compress directory /path/to/foo/ into /path/to/foo.tgz archive: path: /path/to/foo dest: /path/to/foo.tgz - name: Compress regular file /path/to/foo into /path/to/foo.gz and remove it archive: path: /path/to/foo remove: yes - name: Create a zip archive of /path/to/foo archive: path: /path/to/foo format: zip - name: Create a bz2 archive of multiple files, rooted at /path archive: path: - /path/to/foo - /path/wong/foo dest: /path/file.tar.bz2 format: bz2 - name: Create a bz2 archive of a globbed path, while excluding specific dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/bar - /path/to/foo/baz format: bz2 - name: Create a bz2 archive of a globbed path, while excluding a glob of dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/ba* format: bz2 - name: Use gzip to compress a single archive (i.e don't archive it first with tar) archive: path: /path/to/foo/single.file dest: /path/file.gz format: gz - name: Create a tar.gz archive of a single file. archive: path: /path/to/foo/single.file dest: /path/file.tar.gz format: gz force_archive: true RETURN VALUES: - name: Create a zip archive of /path/to/foo archive: path: /path/to/foo format: zip - name: Create a bz2 archive of multiple files, rooted at /path archive: path: - /path/to/foo - /path/wong/foo dest: /path/file.tar.bz2 format: bz2 - name: Create a bz2 archive of a globbed path, while excluding specific dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/bar - /path/to/foo/baz format: bz2 - name: Create a bz2 archive of a globbed path, while excluding a glob of dirnames archive: path: - /path/to/foo/* dest: /path/file.tar.bz2 exclude_path: - /path/to/foo/ba* format: bz2 - name: Use gzip to compress a single archive (i.e don't archive it first with tar) archive: path: /path/to/foo/single.file dest: /path/file.gz format: gz - name: Create a tar.gz archive of a single file. archive: path: /path/to/foo/single.file dest: /path/file.tar.gz format: gz force_archive: true ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:15","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"unarchive 参数 取值 默认值 说明 creates string null 文件名，当它已经存在时，这个步骤将不会被运行 copy yes / no yes 拷贝的文件从ansible主机复制到远程主机，no在远程主机上寻找src源文件解压 src string null tar源路径，可以是ansible主机上的路径，也可以是远程主机上的路径，如果是远程主机上的路径，则需设置copy=no dest string null 远程主机上的目标绝对路径 mode 数字 无 设置解压缩后的文件权限 exec 无 无 列出需要排除的目录和文件 owner string 无 解压后文件或目录的属主 group srting 无 解压后的目录或文件的属组 EXAMPLES: - name: Extract foo.tgz into /var/lib/foo unarchive: src: foo.tgz dest: /var/lib/foo - name: Unarchive a file that is already on the remote machine unarchive: src: /tmp/foo.zip dest: /usr/local/bin remote_src: yes - name: Unarchive a file that needs to be downloaded (added in 2.0) unarchive: src: https://example.com/example.zip dest: /usr/local/bin remote_src: yes - name: Unarchive a file with extra options unarchive: src: /tmp/foo.zip dest: /usr/local/bin extra_opts: - --transform - s/^xxx/yyy/ ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:16","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"uri 用于请求某个网页 常见参数： 参数 取值 默认值 说明 body raw null 当body_format设置为json时的键值对 body_format string raw 数据格式，form-urlencoded, json, raw method string GET 指明请求的方法，如GET、POST, PUT, DELETE, HEAD dest string null 下载文件的路径 force bool False force_basic_auth headers method 指明请求的方法，如GET、POST, PUT, DELETE, HEAD return_content bool False url string null url_password 如果请求的url需要认证，则填写认证的密码 url_username 如果请求的url需要认证，则填写用户名 [root@master ~]# ansible test -m url -a 'url=http://192.168.100.102/index.html' 192.168.100.102 | SUCCESS =\u003e { \"accept_ranges\": \"bytes\", \"changed\": false, \"connection\": \"close\", \"content_length\": \"612\", \"content_type\": \"text/html\", \"date\": \"Fri, 02 Dec 2016 06:31:58 GMT\", \"etag\": \"\\\"571f8501-264\\\"\", \"last_modified\": \"Tue, 26 Apr 2016 15:10:57 GMT\", \"msg\": \"OK (612 bytes)\", \"redirected\": false, \"server\": \"nginx/1.10.0\", \"status\": 200, \"url\": \"http://192.168.100.102/index.html\" } [root@master ~]# EXAMPLES: - name: Check that you can connect (GET) to a page and it returns a status 200 uri: url: http://www.example.com - name: Check that a page returns a status 200 and fail if the word AWESOME is not in the page contents uri: url: http://www.example.com return_content: yes register: this failed_when: \"'AWESOME' not in this.content\" - name: Create a JIRA issue uri: url: https://your.jira.example.com/rest/api/2/issue/ user: your_username password: your_pass method: POST body: \"{{ lookup('file','issue.json') }}\" force_basic_auth: yes status_code: 201 body_format: json - name: Login to a form based webpage, then use the returned cookie to access the app in later tasks uri: url: https://your.form.based.auth.example.com/index.php method: POST body_format: form-urlencoded body: name: your_username password: your_password enter: Sign in status_code: 302 register: login - name: Login to a form based webpage using a list of tuples uri: url: https://your.form.based.auth.example.com/index.php method: POST body_format: form-urlencoded body: - [ name, your_username ] - [ password, your_password ] - [ enter, Sign in ] status_code: 302 register: login - name: Connect to website using a previously stored cookie uri: url: https://your.form.based.auth.example.com/dashboard.php method: GET return_content: yes headers: Cookie: \"{{ login.set_cookie }}\" - name: Queue build of a project in Jenkins uri: url: http://{{ jenkins.host }}/job/{{ jenkins.job }}/build?token={{ jenkins.token }} user: \"{{ jenkins.user }}\" password: \"{{ jenkins.password }}\" method: GET force_basic_auth: yes status_code: 201 - name: POST from contents of local file uri: url: https://httpbin.org/post method: POST src: file.json - name: POST from contents of remote file uri: url: https://httpbin.org/post method: POST src: /path/to/my/file.json remote_src: yes - name: Pause play until a URL is reachable from this host uri: url: \"http://192.0.2.1/some/test\" follow_redirects: none method: GET register: _result until: _result.status == 200 retries: 720 # 720 * 5 seconds = 1hour (60*60/5) delay: 5 # Every 5 seconds # There are issues in a supporting Python library that is discussed in # https://github.com/ansible/ansible/issues/52705 where a proxy is defined # but you want to bypass proxy use on CIDR masks by using no_proxy - name: Work around a python issue that doesn't support no_proxy envvar uri: follow_redirects: none validate_certs: false timeout: 5 url: \"http://{{ ip_address }}:{{ port | default(80) }}\" register: uri_data failed_when: false changed_when: false vars: ip_address: 192.0.2.1 environment: | { {% for no_proxy in (lookup('env', 'no_proxy') | regex_replace('\\s*,\\s*', ' ') ).split() %} {% if no_proxy | regex_search('\\/') and no_proxy | ipaddr('net') != '' and no_proxy | ipaddr('net') != false and ip_address | ipaddr(no_proxy) is not none and ip_address | ipaddr(no_proxy) != false %} 'no_proxy': '{{ ip_address }}' {% elif no_proxy | regex_search(':') != '' and no_proxy | regex_search(':') != false and no_proxy == ip_address + ':' + (port | default(80)) %} 'no_proxy': '{{ ip_address }","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:17","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"group 用来添加或删除远端主机的用户组 常见参数： 参数 取值 默认值 说明 name string null state string present gid int null GID system bool False 创建系统用户 [root@master ~]# ansible test -m group -a 'name=hr gid=2000 state=present' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"gid\": 2000, \"name\": \"hr\", \"state\": \"present\", \"system\": false } [root@master ~]# ansible test -m shell -a 'tail -1 /etc/group' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e hr❌2000: ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:18","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"user 管理远程主机上的用户的账号 常见参数： 参数 取值 默认值 说明 name string null 指明要管理的账号名称 state string present 指明是创建账号还是删除账号，present表示创建，absent表示删除 system bool False 指定系统用户 uid int null 用户的uid shell string null shell类型 home string null 家目录位置 group string null 指明用户的基本组 groups string null 指明用户的附加组 move_home bool False 当home设定了家目录，如果要创建的家目录已存在，是否将已存在的家目录进行移动 password string null 指明用户的密码，最好使用加密好的字符串 comment string null 指明用户的注释信息 remove bool null 当state=absent时，也就是删除用户时，是否要删除用户的而家目录 [root@master ~]# ansible test -m user -a 'name=martin group=hr groups=shichang uid=500 shell=/bin/bash home=/home/martin comment=\"martin user\"' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"comment\": \"martin user\", \"createhome\": true, \"group\": 2000, \"groups\": \"shichang\", \"home\": \"/home/martin\", \"name\": \"martin\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 500 } [root@master ~]# ansible test -m shell -a 'grep \"martin:\" /etc/passwd' 192.168.100.102 | SUCCESS | rc=0 \u003e\u003e martin❌500:2000:martin user:/home/martin:/bin/bash [root@master ~]# ansible test -m user -a 'name=martin state=absent remove=yes' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"force\": false, \"name\": \"martin\", \"remove\": true, \"state\": \"absent\" } EXAMPLES: - name: Add the user 'johnd' with a specific uid and a primary group of 'admin' user: name: johnd comment: John Doe uid: 1040 group: admin - name: Add the user 'james' with a bash shell, appending the group 'admins' and 'developers' to the user's gro user: name: james shell: /bin/bash groups: admins,developers append: yes - name: Remove the user 'johnd' user: name: johnd state: absent remove: yes - name: Create a 2048-bit SSH key for user jsmith in ~jsmith/.ssh/id_rsa user: name: jsmith generate_ssh_key: yes ssh_key_bits: 2048 ssh_key_file: .ssh/id_rsa - name: Added a consultant whose account you want to expire user: name: james18 shell: /bin/zsh groups: developers expires: 1422403387 - name: Starting at Ansible 2.6, modify user, remove expiry time user: name: james18 expires: -1 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:19","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"script 将管理端的某个脚本，移动到远端主机(不需要指明传递到远端主机的哪个路径下，系统会自动移动，然后执行)， 一般是自动移动到远端主机的/root/.ansible/tmp目录下，然后自动给予其权限，然后再开个子shell然后运行脚本，运行完成后删除脚本 [root@master ~]# ansible test -m script -a '/root/1.sh' 192.168.100.102 | SUCCESS =\u003e { \"changed\": true, \"rc\": 0, \"stderr\": \"\", \"stdout\": \"\", \"stdout_lines\": [] } [root@master ~]# ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:20","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"setup 可收集远程主机的facts变量的信息，相当于收集了目标主机的相关信息(如内核版本、操作系统信息、cpu、…)，保存在ansible的内置变量中，之后我们有需要用到时，直接调用变量即可 [root@master ~]# ansible test -m setup 192.168.100.102 | SUCCESS =\u003e { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ \"192.168.100.102\" ], \"ansible_all_ipv6_addresses\": [ \"fe80::20c:29ff:fe0c:5ab9\" ], \"ansible_architecture\": \"x86_64\", \"ansible_bios_date\": \"05/20/2014\", \"ansible_bios_version\": \"6.00\", ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:21","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"template 基于模板方式，生成一个模板文件，复制到远程主机，让远程主机基于模板，生成符合远程主机自身的文件 注意：此模块不能在命令行使用，只能用在playbook中 常见参数： src= 指明管理端本地的模板文件的目录 dest= 指明将模板文件拷贝到远程主机的哪个目录下 owner= 指明拷贝到远程主机的文件的属主 group= 指明拷贝到远程主机的文件的属组 mode= 指明拷贝到远程主机的文件的权限 [root@master ~]# cat temp.txt this is {{ ansible_hostname }} [root@master ~]# cat test.yml - hosts: 192.168.10.202 remote_user: root tasks: - name: test template template: src=/root/temp.txt dest=/tmp [root@master ~]# ansible-playbook test.yml PLAY [192.168.10.202] ********************************************************** TASK [setup] ******************************************************************* ok: [192.168.10.202] TASK [test template module] **************************************************** changed: [192.168.10.202] PLAY RECAP ********************************************************************* 192.168.10.202 : ok=2 changed=1 unreachable=0 failed=0 [root@master ~]# ansible 192.168.10.202 -m shell -a 'cat /tmp/temp.txt' 192.168.10.202 | SUCCESS | rc=0 \u003e\u003e this is agent202 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:22","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"script script 模块可以在远程主机上执行 ansible 管理主机上的脚本，也就是说，脚本一直存在于 ansible 管理主机本地，不需要手动拷贝到远程主机后再执行。 常用参数： chdir：执行脚本时所在的目录 creates：使用此参数指定一个远程主机中的文件，当指定的文件存在时，就不执行对应脚本 removes：使用此参数指定一个远程主机中的文件，当指定的文件不存在时，就不执行对应脚本 示例： - name: Run a script with arguments (free form) script: /some/local/script.sh ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:23","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"lineinfile 参数 取值 默认值 说明 path string null 操作的文件 line string null 替换的内容 regexp string null 匹配表达式 state present|absent present insertafter string 无 插入到匹配行后 insertbefore string 无 插入匹配行前 backup yes|no 无 改变前备份 示例：开启selinux - name: Ensure SELinux is set to enforcing mode lineinfile: path: /etc/selinux/config regexp: '^SELINUX=' line: SELINUX=enforcing - name: Make sure group wheel is not in the sudoers configuration lineinfile: path: /etc/sudoers state: absent regexp: '^%wheel' - name: Replace a localhost entry with our own lineinfile: path: /etc/hosts regexp: '^127\\.0\\.0\\.1' line: 127.0.0.1 localhost owner: root group: root mode: '0644' ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:24","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"fail 参数 取值 默认值 说明 msg string null 满足条件执行时输出的信息 - fail: msg: The system may not be provisioned according to the CMDB status. when: cmdb_status != \"to-be-staged\" ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:25","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"stat 检查文件或文件系统的状态，对于Windows目标，则使用win_stat模块 参数 取值 默认值 说明 path string null 文件或目录的路径，必选参数 checksum_algorithm string sha1 计算文件的算法，可选md5, sha1, sha224, sha256, sha384, sha512 stat模块的返回值 返回值 取值 exists bool path str mode str isdir bool islnk bool uid int gid int size int inode int lnk_source str md5 str 使用示例 - stat: path: /etc/foo.conf register: st - fail: msg: \"Whoops! file ownership has changed\" when: st.stat.pw_name != 'root' - stat: path: /path/to/something register: sym - debug: msg: \"islnk isn't defined (path doesn't exist)\" when: sym.stat.islnk is not defined - debug: msg: \"islnk is defined (path must exist)\" when: sym.stat.islnk is defined - debug: msg: \"Path exists and is a symlink\" when: sym.stat.islnk is defined and sym.stat.islnk - debug: msg: \"Path exists and isn't a symlink\" when: sym.stat.islnk is defined and sym.stat.islnk == False - stat: path: /path/to/something register: p - debug: msg: \"Path exists and is a directory\" when: p.stat.isdir is defined and p.stat.isdir # Don't do checksum - stat: path: /path/to/myhugefile get_checksum: no # Use sha256 to calculate checksum - stat: path: /path/to/something checksum_algorithm: sha256 ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:26","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"pause 暂停一段时间等待终端输入 参数 取值 默认值 说明 echo bool yes 是否输出键盘的输入值 minutes string null 暂停多少分钟 prompt string null 打印一串信息提示用户操作 seconds string null 暂停多少秒 pause模块的返回值 返回值 取值 delta string echo bool start string stdout string stop string user_input string 使用示例 - name: Pause for 5 minutes to build app cache pause: minutes: 5 - name: Pause until you can verify updates to an application were successful pause: - name: A helpful reminder of what to look out for post-update pause: prompt: \"Make sure org.foo.FooOverload exception is not present\" - name: Did you Backup DB pause: prompt=\"Did you commit it? Enter to continue or CTRL-C to quit.\" - name: Pause to get some sensitive input pause: prompt: \"Enter a secret\" echo: no ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:27","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"六、变量 # 使用文件进行传参数 ansible-playbook site.yml -i hosts -e @env.yaml ","date":"2023-12-04","objectID":"/posts/2023-12-4-ansible-handbook/:3:28","tags":["ansible"],"title":"Ansible handbook","uri":"/posts/2023-12-4-ansible-handbook/"},{"categories":["DevOps"],"content":"Gitlab ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:0:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"版本介绍 gitlab分社区版和企业版，与其他企业版软件不同的是，社区版和企业版都不收费，都可以免费使用 官方文档：https://docs.gitlab.com/ ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:1:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"授权模式 GitLab基于开源核心模型 (open core model)。即以为着Gitlab有两个版本：社区版Community Edition 和 企业版Enterprise Edition。 GitLab 社区版是MIT许可的open source。 GitLab 企业版基于社区版：使用了同样的内核，但是添加了额外的功能、特性。 这是在所有权授权下。 对于所有的版本：Gitlab 所有的 javascript 源码 都是 open source 的。Gtilab 开发的所有的 javascript code 都是 MIT 授权许可。 企业版虽然是免费使用，但免费但功能跟社区版一致。 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:1:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"一、部署 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:2:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"1、包部署 1）下载安装包 清华源：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce 南京大学镜像：https://mirrors.nju.edu.cn/gitlab-ce/ gitlab安装包比较大，建议先下载到本地再安装 [root@gitlab3 ~]# ls anaconda-ks.cfg gitlab-ce-12.9.7-ce.0.el7.x86_64.rpm [root@gitlab3 ~]# yum -y localinstall gitlab-ce-12.9.7-ce.0.el7.x86_64.rpm 2）配置gitlab gitlab使用chef进行安装，配置文件为/etc/gitlab/gitlab.rb # 配置访问地址 [root@gitlab3 ~]# vim /etc/gitlab/gitlab.rb 29 external_url 'http://gitlab.example.com' # 配置通知邮箱 # 官方邮箱配置示例：https://docs.gitlab.com/omnibus/settings/smtp.html [root@gitlab1 ~]# vim /etc/gitlab/gitlab.rb gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = \"smtphz.qiye.163.com\" gitlab_rails['smtp_port'] = 994 gitlab_rails['smtp_user_name'] = \"cccccc@163.com\" gitlab_rails['smtp_password'] = \"xxxxxxxxxx\" gitlab_rails['smtp_domain'] = \"qiye.163.com\" gitlab_rails['smtp_authentication'] = \"login\" gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['smtp_tls'] = true user['git_user_email'] = \"cccc@163.com\" gitlab_rails['gitlab_email_from'] = 'cccc@163.com' gitlab_rails['gitlab_email_reply_to'] = 'cccc@163.com' # 配置重启服务 [root@gitlab1 ~]# gitlab-ctl stop [root@gitlab1 ~]# gitlab-ctl reconfigure [root@gitlab1 ~]# gitlab-ctl restart # 测试邮件发送 [root@gitlab1 ~]# gitlab-rails console Notify.test_email('t@local.com','gitlab','this is test').deliver_now 邮箱 主题 内容 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:2:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"2、docker部署 使用docker部署时建议先修改ssh端口，预留22给gitlab docker run \\ -p 443:443 -p 80:80 -p 22:22 \\ --name gitlab \\ --volume /data/gitlab/config:/etc/gitlab \\ --volume /data/gitlab/logs:/var/log/gitlab \\ --volume /data/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:13.12.9-ce.0 docker-compose version: '3' services: gitlab: image: gitlab/gitlab-ce:13.12.9-ce.0 container_name: gitlab restart: always privileged: true environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url = \"http://git.local.com\" ports: - '80:80' - '443:443' - '2222:22' volumes: - '/dataDisk/gitlab/config:/etc/gitlab' - '/dataDisk/gitlab/logs:/var/log/gitlab' - '/dataDisk/gitlab/data:/var/opt/gitlab' ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:2:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"二、配置 1、gitlab修改url （如果是迁移或者重新配置） 1）修改gitlab的配置文件 [root@gitlab1 ~]# vim /etc/gitlab/gitlab.rb 30 external_url 'http://192.168.100.103' #修改为域名或者IP 2）修改git clone的路径 查看gitlab.yml软连接的路径 [root@gitlab1 ~]# cd /opt/gitlab/embedded/service/gitlab-rails/config lrwxrwxrwx 1 root root 43 Jun 19 15:23 gitlab.yml -\u003e /var/opt/gitlab/gitlab-rails/etc/gitlab.yml [root@gitlab1 config]# vim /var/opt/gitlab/gitlab-rails/etc/gitlab.yml 10 ## GitLab settings 11 gitlab: 12 ## Web server settings (note: host is the FQDN, do not include http://) 13 host: 192.168.100.103 #gitlab登陆后访问的路径 14 port: 80 15 https: false ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:3:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"三、gitlab-runner ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"1、包安装 1）下载和安装 [root@gitlab1 ~]# yum -y install https://mirror.nju.edu.cn/gitlab-runner/yum/el8-x86_64/gitlab-runner-14.8.3-1.x86_64.rpm [root@gitlab1 ~]# yum -y install git 2）注册gitlab-runner [root@gitlab1 ~]# gitlab-runner register \\ --non-interactive \\ --executor \"shell\" \\ --url \"http://192.168.23.100/\" \\ --registration-token \"JRzzw2j1Ji6aBjwvkxAv\" \\ --description \"xxxxx-devops-runner\" \\ --tag-list \"build,deploy,runner-shell,runner\" \\ --run-untagged=\"true\" \\ --locked=\"false\" \\ --access-level=\"not_protected\" 会要求输入gitlab的url和Token. 查找过程如下： 进入仓库-\u003esettings-\u003eCI/CD，找到Runner Settings这一项，点击Expend,即可在Setup a specific Runner manually这项中找到。 注册完后查看runner状态 进入仓库-\u003esettings-\u003eCI/CD，找到Runner Settings这一项，点击Expend,即可看到Gitlab-Runenr的运行状态 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"2、docker安装 version: \"3\" services: gitrunner: image: 'gitlab/gitlab-runner:ubuntu-v15.8.3' container_name: \"gitlab-runner\" restart: always command: \"run --user=root --working-directory=/home/gitlab-runner\" volumes: - '/data/gitlab-runner/config:/etc/gitlab-runner' - '/data/gitlab-runner/cache:/tmp/cache' # - '/data/gitlab-runner/ssl:/etc/gitlab-runner/certs/' - '/usr/bin/docker:/usr/bin/docker' - '/var/run/docker.sock:/var/run/docker.sock' 注册 docker exec -it gitlab-runner gitlab-runner register --non-interactive --executor \"shell\" --url \"http://local.com\" --registration-token \"XmWa6cccc-ccccccc\" --description \"runner\" --tag-list \"docker-runner,gitlab-runner-shell,runner\" --run-untagged=\"true\" --locked=\"false\" --access-level=\"not_protected\" runner in docker docker exec -it gitlab-runner gitlab-runner register --non-interactive --executor \"docker\" --docker-image=debian:11 --url \"http://local.com\" --registration-token \"XmWa6cccc-ccccccc\" --description \"docker-runner\" --tag-list \"docker-runner,gitlab-runner-docker\" --run-untagged=\"true\" --locked=\"false\" --access-level=\"not_protected\" ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"3、.gitlab-ci.yml 模版 default: image: 'centos:7' before_script: - echo Hello World after_script: - echo end tags: gitlab-runner-shell # 指定gitlab runner 的tag cache: paths: [vendor/] DEPLOY_VARIABLE: \"default-deploy\" variables: IMAGE: name/${CI_PROJECT_NAMESPACE}-${CI_PROJECT_NAME} workflow: rules: - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH variables: DEPLOY_VARIABLE: \"deploy-production\" # Override globally-defined DEPLOY_VARIABLE - if: $CI_COMMIT_REF_NAME =~ /feature/ variables: IS_A_FEATURE: \"true\" # Define a new variable. - when: always stages: - test - build - package - deploy - cleanup test_all: image: \"pymicro\" pull_policy: if-not-present stage: test services: - name: my-postgres:11.7 alias: db-postgres pull_policy: if-not-present entrypoint: [\"/usr/local/bin/db-postgres\"] command: [\"start\"] veriables: MYSQL_DATABASE: db MYSQL_ROOT_PASSWORD: password allow_failure: true # job 允许失败 before_script: - 'command -v ssh-agent \u003e/dev/null || ( apt-get update -y \u0026\u0026 apt-get install openssh-client -y )' - eval $(ssh-agent -s) - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add - - mkdir -p ~/.ssh - chmod 700 ~/.ssh - echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" \u003e ~/.ssh/config' script: - flake8 app - pytest tests after_script: - execute this after my script # 执行命令 build_image: image: name docker:17.11 pull_policy: always # if-not-present #entrypoint: [\"echo hellow-world\"] #覆盖 entrypoint命令 # command: [\"start\"] 覆盖command命令 stage: build services: - name: my-postgres:11.7 alias: db-postgres entrypoint: [\"/usr/local/bin/db-postgres\"] command: [\"start\"] variables: DOCKER_HOST: tcp://dockerd:2375 # 缓存 binaries 中以 .apk 和 .config 文件结尾的所有文件： cache: key: binaries-cache paths: - binaries/*.apk - .config only: - master tags: - build script: - | docker build -t ${IMAGE_TAG} -f Dockerfile . docker push ${IMAGE_TAG} package_app: stage: build rules: - if: $CI_COMMIT_MESSAGE =~ /build-app-a/ variables: GITLAB_app_NAME: gitea-drone - if: $CI_COMMIT_MESSAGE =~ /build-app-b/ variables: GITLAB_app_NAME: gitea-drone-b - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"' changes: - Dockerfile when: manual allow_failure: true - if: $CI_PIPELINE_SOURCE == \"merge_request_event\" changes: paths: - Dockerfile - exists: - Dockerfile before_script: - hello script: - echo \"${GITLAB_app_NAME}\" after_script: - echo \"world\" allow_failure: exit_codes: - 137 - 255 # 当Gemfile.lock有变化时候，重新生成缓存 cache: key: files: - Gemfile.lock - package.json paths: - vendor/ruby - node_modules last-job: stage: .post script: - echo \"This job runs in the .post stage, after all other stages.\" deploy_production: stage: deploy variables: GIT_STRATEGY: none needs: - job: test-job2 optional: true - job: test-job1 # only/except only: # - master - main - /^issue-.*$/ - merge_requests - tags variables: - $RELEASE == \"staging\" refs: - branches changes: - Dockerfile - docker/scripts/ allow_failure: true when: manual tags: - deploy-production script: - kubectl set image deploy/myproject \"app=${IMAGE_TAG}\" --record cache: untracked: true # 来缓存 Git 仓库中所有未跟踪的文件 paths: - binaries/ cleanup_job: stage: cleanup script: - cleanup after jobs when: always 内置变量，参考地址：https://docs.gitlab.cn/jh/ci/variables/predefined_variables.html 变量 GitLab Runner 描述 CHAT_CHANNEL 10.6 all 触发 ChatOps 命令的源聊天频道。 CHAT_INPUT 10.6 all 使用 ChatOps 命令传递的附加参数。 CHAT_USER_ID 14.4 all 触发 ChatOps 命令的用户的聊天服务用户 ID。 CI all 0.4 适用于在 CI/CD 中执行的所有作业。可用时为 true。 CI_API_V4_URL 11.7 all GitLab API v4 根 URL。 CI_BUILDS_DIR all 11.10 执行构建的顶级目录。 CI_COMMIT_AUTHOR 13.11 all Name \u003cemail\u003e 格式的提交作者。 CI_COMMIT_BEFORE_SHA 11.2 all 出现在分支或标签上的上一个最新提交。在合并请求的流水线中总是 0000000000000000000000000000000000000000。 CI_COMMIT_BRANCH 12.6 0.5 提交分支名称。在分支流水线中可用，包括默认分支的流水线。在合并请求流水线或标签流水线中不可用。 CI_COMMIT_DESCRIPTION 10.8 all 提交的描述。如果标题短于 100 个字符，则消息没有第一行。 CI_COMMIT_MESSAGE 10.8 all 完整的提交消息。 CI_COMMIT_REF_NAME 9.0 all 为其构建项目的分支或标签名称。 CI_COMMIT_REF_PROTECTED 11.11 all 如果作业正在运行以获取受保护的 ref 为 true 。 CI_COMMIT_REF_SLUG 9.0 all CI_COMMIT_REF_NAME 小写，缩短为 63 字节，除了 0-9 和 a-z 之外的所有内容都替换为 -。没有前","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:4:3","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"四、备份与恢复 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:5:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"1、备份 [root@gitlab1 ~]# gitlab-rake gitlab:backup:create 使用以上命令会在/var/opt/gitlab/backups目录下创建一个名称类似为1530156812_2018_06_28_10.8.4_gitlab_backup.tar的压缩包, 这个压缩包就是Gitlab整个的完整部分, 其中开头的1530156812_2018_06_28_10.8.4是备份创建的日期 ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:5:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"2、数据恢复 [root@gitlab1 ~]# gitlab-ctl stop unicorn [root@gitlab1 ~]# gitlab-ctl stop sidekiq 备份文件增加777权限，并且文件需要存放在/var/opt/gitlab/backups里 [root@gitlab1 ~]# gitlab-rake gitlab:backup:restore BACKUP=1530156812_2018_06_28_10.8.4 # 输入两次yes 启动服务 [root@gitlab1 ~]# gitlab-ctl restart ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:5:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"五、升级 gitlab的跨版本升级需要升级中间多个小版本，为了方便升级，可以基于docker升级。 version: '3' services: gitlab: image: gitlab/gitlab-ce:12.9.7-ce.0 container_name: gitlab restart: always privileged: true environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url = \"http://git.local.com\" ports: - '80:80' - '443:443' - '2222:22' volumes: - '/dataDisk/gitlab/config:/etc/gitlab' - '/dataDisk/gitlab/logs:/var/log/gitlab' - '/dataDisk/gitlab/data:/var/opt/gitlab' networks: - gitlab networks: gitlab: ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:0","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"数据备份 # 备份产生目录 /var/opt/gitlab/backups/ gitlab-rake gitlab:backup:create # 容器备份 sudo docker exec -t gitlab gitlab-rake gitlab:backup:create ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:1","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"迁移 ### 配置文件说明 # 原本： /etc/gitlab/gitlab.rb # 容器： /data/gitlab/config/gitlab.rb # 授权备份文件 scp 1586766848_2020_04_13_10.3.3_gitlab_backup.tar root@10.0.0.2:/var/opt/gitlab/backups/ chown 777 /var/opt/gitlab/backups/1586766848_2020_04_13_10.3.3_gitlab_backup.tar # 加载备份路径 默认 /var/opt/gitlab/backups vim /data/gitlab/config/gitlab.rb gitlab_rails['backup_path'] = \"/var/opt/gitlab/backups\" gitlab_rails['backup_archive_permissions'] = 0644 gitlab_rails['backup_keep_time'] = 864000 # 重载配置 docker exec -t gitlab gitlab-ctl reconfigure # 停止数据库进程 docker exec -t gitlab gitlab-ctl status docker exec -t gitlab gitlab-ctl stop puma docker exec -t gitlab gitlab-ctl stop sidekiq docker exec -t gitlab gitlab-ctl status # 恢复备份文件 （输入两次yes） docker exec -ti gitlab bash docker exec -t gitlab gitlab-rake gitlab:backup:restore BACKUP=1586766848_2020_04_13_10.3.3 gitlab-backup restore BACKUP=11493107454_2018_04_25_10.6.4-ce # 重启与检测 docker exec -t gitlab gitlab-ctl restart docker exec -t gitlab gitlab-rake gitlab:check SANITIZE=true ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:2","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["DevOps"],"content":"可能出现的问题： 公钥不受信任，要么按提示需要输入yes，要么把config也进行迁移 ssh -T git@local.com ","date":"2023-12-04","objectID":"/posts/2023-12-4-gitlab/:6:3","tags":["gitlab","git"],"title":"Gitlab","uri":"/posts/2023-12-4-gitlab/"},{"categories":["Go基础"],"content":"通道 channel ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:0:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"介绍 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"概括 Go语言设计团队的首任负责人Rob Pike对并发编程的一个建议是不要让计算通过共享内存来通讯，而应该让它们通过通讯来共享内存。 通道机制就是这种哲学的一个设计结果。（在Go编程中，我们可以认为一个计算就是一个协程。） 通过共享内存来通讯和通过通讯来共享内存是并发编程中的两种编程风格。 当通过共享内存来通讯的时候，我们需要一些传统的并发同步技术（比如互斥锁）来避免数据竞争。 Go提供了一种独特的并发同步技术来实现通过通讯来共享内存。此技术即为通道。 我们可以把一个通道看作是在一个程序内部的一个先进先出（FIFO：first in first out）数据队列。 一些协程可以向此通道发送数据，另外一些协程可以从此通道接收数据。 随着一个数据值的传递（发送和接收），一些数据值的所有权从一个协程转移到了另一个协程。 当一个协程发送一个值到一个通道，我们可以认为此协程释放了（通过此发送值可以访问到的）一些值的所有权。 当一个协程从一个通道接收到一个值，我们可以认为此协程获取了（通过此接受值可以访问到的）一些值的所有权。 当然，在通过通道传递数据的时候，也可能没有任何所有权发生转移。 所有权发生转移的值常常被传递的值所引用着，但有时候也并非如此。 在Go中，数据所有权的转移并非体现在语法上，而是体现在逻辑上。 Go通道可以帮助程序员轻松地避免数据竞争，但不会防止程序员因为犯错而写出错误的并发代码的情况发生。 尽管Go也支持几种传统的数据同步技术，但是只有通道为一等公民。 通道是Go中的一种类型，所以我们可以无需引进任何代码包就可以使用通道。 几种传统的数据同步技术提供在sync和sync/atomic标准库包中。 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:1","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"通道类型和值 和数组、切片以及映射类型一样，每个通道类型也有一个元素类型。 一个通道只能传送它的（通道类型的）元素类型的值。 通道可以是双向的，也可以是单向的。 字面形式chan T表示一个元素类型为T的双向通道类型。 编译器允许从此类型的值中接收和向此类型的值中发送数据。 字面形式chan\u003c- T表示一个元素类型为T的单向发送通道类型。 编译器不允许从此类型的值中接收数据。 字面形式\u003c-chan T表示一个元素类型为T的单向接收通道类型。 编译器不允许向此类型的值中发送数据。 双向通道chan T的值可以被隐式转换为单向通道类型chan\u003c- T和\u003c-chan T，但反之不行（即使显式也不行）。 类型chan\u003c- T和\u003c-chan T的值也不能相互转换。 通道类型的零值也使用预声明的nil来表示。 一个非零通道值必须通过内置的make函数来创建。 比如make(chan int, 10)将创建一个元素类型为int的通道值。 第二个参数指定了欲创建的通道的容量。此第二个实参是可选的，它的默认值为0。 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:2","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"通道操作 // 定义一个 channel var ch = make(chan struct{}) // 关闭 channel close(ch) // 传入数据 ch \u003c- struct{}{} // 接受数据 \u003c-ch msg \u003c-ch // 查询 channel容量 cap(ch) // 查询 channel 长度 len(ch) ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:3","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"操作 channel channel有三类： 零值（nil）通道； 非零值但已关闭的通道； 非零值并且尚未关闭的通道。 下表简单地描述了三种通道操作施加到三类通道的结果。 操作 一个零值nil通道 一个非零值但已关闭的通道 一个非零值且尚未关闭的通道 关闭 产生恐慌 产生恐慌 成功关闭(C) 发送数据 永久阻塞 产生恐慌 阻塞或者成功发送(B) 接收数据 永久阻塞 永不阻塞(D) 阻塞或者成功接收(A) 对于上表中的五种未打上标的情形，规则很简单： 关闭一个nil通道或者一个已经关闭的通道将产生一个恐慌。 向一个已关闭的通道发送数据也将导致一个恐慌。 向一个nil通道发送数据或者从一个nil通道接收数据将使当前协程永久阻塞。 示例： package main import ( \"fmt\" \"time\" ) func main() { c := make(chan int) // 一个非缓冲通道 go func(ch chan\u003c- int, x int) { time.Sleep(time.Second) // \u003c-ch // 此操作编译不通过 ch \u003c- x*x // 阻塞在此，直到发送的值被接收 }(c, 3) done := make(chan struct{}) go func(ch \u003c-chan int) { n := \u003c-ch // 阻塞在此，直到有值发送到c fmt.Println(n) // 9 // ch \u003c- 123 // 此操作编译不通过 time.Sleep(time.Second) done \u003c- struct{}{} }(c) \u003c-done // 阻塞在此，直到有值发送到done fmt.Println(\"bye\") } 一场永不休场的足球比赛： package main import ( \"fmt\" \"time\" ) func main() { var ball = make(chan string) kickBall := func(playerName string) { for { fmt.Print(\u003c-ball, \"传球\", \"\\n\") time.Sleep(time.Second) ball \u003c- playerName } } go kickBall(\"张三\") go kickBall(\"李四\") go kickBall(\"王二麻子\") go kickBall(\"刘大\") ball \u003c- \"裁判\" // 开球 var c chan bool // 一个零值nil通道 \u003c-c // 永久阻塞在此 } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:1:4","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"通道遍历 ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:2:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"for-range for-range循环控制流程也适用于通道。 此循环将不断地尝试从一个通道接收数据，直到此通道关闭并且它的缓冲队列为空为止。 和应用于数组/切片/映射的for-range语法不同，应用于通道的for-range语法中最多只能出现一个循环变量，此循环变量用来存储接收到的值。 for v := range aChannel { // 使用v } // 等价于 for { v, ok = \u003c-aChannel if !ok { break } // 使用v } for x := range c { time.Sleep(time.Second) fmt.Println(x) } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:2:1","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"select-case Go中有一个专门为通道设计的select-case分支流程控制语法。 此语法和switch-case分支流程控制语法很相似。 比如，select-case流程控制代码块中也可以有若干case分支和最多一个default分支。 但是，这两种流程控制也有很多不同点。在一个select-case流程控制中， select关键字和{之间不允许存在任何表达式和语句。 fallthrough语句不能被使用. 每个case关键字后必须跟随一个通道接收数据操作或者一个通道发送数据操作。 通道接收数据操作可以做为源值出现在一条简单赋值语句中。 以后，一个case关键字后跟随的通道操作将被称为一个case操作。 所有的非阻塞case操作中将有一个被随机选择执行（而不是按照从上到下的顺序），然后执行此操作对应的case分支代码块。 在所有的case操作均为阻塞的情况下，如果default分支存在，则default分支代码块将得到执行； 否则，当前协程将被推入所有阻塞操作中相关的通道的发送数据协程队列或者接收数据协程队列中，并进入阻塞状态。 按照上述规则，一个不含任何分支的select-case代码块select{}将使当前协程处于永久阻塞状态。 // default分支将铁定得到执行，因为两个case分支后的操作均为阻塞的。 package main import \"fmt\" func main() { var c chan struct{} // nil select { case \u003c-c: // 阻塞操作 case c \u003c- struct{}{}: // 阻塞操作 default: fmt.Println(\"Go here.\") } } 下面这个例子中实现了尝试发送（try-send）和尝试接收（try-receive）。 它们都是用含有一个case分支和一个default分支的select-case代码块来实现的。 package main import \"fmt\" func main() { c := make(chan string, 2) trySend := func(v string) { select { case c \u003c- v: default: // 如果c的缓冲已满，则执行默认分支。 } } tryReceive := func() string { select { case v := \u003c-c: return v default: return \"-\" // 如果c的缓冲为空，则执行默认分支。 } } trySend(\"Hello!\") // 发送成功 trySend(\"Hi!\") // 发送成功 trySend(\"Bye!\") // 发送失败，但不会阻塞。 // 下面这两行将接收成功。 fmt.Println(tryReceive()) // Hello! fmt.Println(tryReceive()) // Hi! // 下面这行将接收失败。 fmt.Println(tryReceive()) // - } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:2:2","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"使用示例： ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:3:0","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"使用通道实现通知 向一个通道发送一个值来实现单对单通知 package main import ( \"crypto/rand\" \"fmt\" \"os\" \"sort\" ) func main() { values := make([]byte, 32 * 1024 * 1024) if _, err := rand.Read(values); err != nil { fmt.Println(err) os.Exit(1) } done := make(chan struct{}) // 也可以是缓冲的 // 排序协程 go func() { sort.Slice(values, func(i, j int) bool { return values[i] \u003c values[j] }) done \u003c- struct{}{} // 通知排序已完成 }() // 并发地做一些其它事情... \u003c- done // 等待通知 fmt.Println(values[0], values[len(values)-1]) } 从一个通道接收一个值来实现单对单通 package main import ( \"fmt\" \"time\" ) func main() { done := make(chan struct{}) // 此信号通道也可以缓冲为1。如果这样，则在下面 // 这个协程创建之前，我们必须向其中写入一个值。 go func() { fmt.Print(\"Hello\") // 模拟一个工作负载。 time.Sleep(time.Second * 2) // 使用一个接收操作来通知主协程。 \u003c- done }() done \u003c- struct{}{} // 阻塞在此，等待通知 fmt.Println(\" world!\") } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:3:1","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["Go基础"],"content":"使当前协程永久阻塞 可以用一个无分支的select流程控制代码块使当前协程永久处于阻塞状态。 这是select流程控制的最简单的应用。 事实上，上面很多例子中的for {time.Sleep(time.Second)}都可以换为select{}。 package main import \"runtime\" func DoSomething() { for { // 做点什么... runtime.Gosched() // 防止本协程霸占CPU不放 } } func main() { go DoSomething() go DoSomething() select{} } ","date":"2023-12-01","objectID":"/posts/2023-12-2-go-channel/:3:2","tags":["go-channel","channel"],"title":"Go channel","uri":"/posts/2023-12-2-go-channel/"},{"categories":["DevOps"],"content":"Gorm gen 参考链接： https://nickxu.me/2023/03/29/GORM%E7%9A%84GEN%E6%A8%A1%E5%BC%8F%E5%88%9D%E4%B8%8A%E6%89%8B/ https://www.liwenzhou.com/posts/Go/gen/ 示例代码： https://github.com/serialt/genc Gen是一个基于GORM的安全ORM框架，其主要通过代码生成方式实现GORM代码封装。使用Gen框架能够自动生成Model结构体和类型安全的CRUD代码，极大提升CRUD效率。 ","date":"2023-11-28","objectID":"/posts/2023-11-28-gorm-gen/:0:0","tags":["gorm","gorm-gen"],"title":"Gorm gen","uri":"/posts/2023-11-28-gorm-gen/"},{"categories":["DevOps"],"content":"Gen介绍 Gen是由字节跳动无恒实验室与GORM作者联合研发的一个基于GORM的安全ORM框架，主要通过代码生成方式实现GORM代码封装。 Gen框架在GORM框架的基础上提供了以下能力： 基于原始SQL语句生成可重用的CRUD API 生成不使用interface{}的100%安全的DAO API 依据数据库生成遵循GORM约定的结构体Model 支持GORM的所有特性 简单来说，使用Gen框架后我们无需手动定义结构体Model，同时Gen框架也能帮我们生成类型安全的CRUD代码。 更多详细介绍请查看Gen官方文档。 此外，Facebook开源的ent也是社区中常用的类似框架，大家可按需选择使用。 ","date":"2023-11-28","objectID":"/posts/2023-11-28-gorm-gen/:1:0","tags":["gorm","gorm-gen"],"title":"Gorm gen","uri":"/posts/2023-11-28-gorm-gen/"},{"categories":["DevOps"],"content":"Gen 使用 go get grom.io/gen 在项目根目录新建 model文件夹，然后创建 model.go package model type Student struct { Id int Name string TeacherID int } type Teacher struct { Id int Name string // has many Student []Student } 然后使用go 生成代码 创建cmd/gen/generate.go package main import ( \"github.com/root/genc/model\" \"gorm.io/gen\" ) //// Dynamic SQL //type Querier interface { // // SELECT * FROM @@table WHERE name = @name{{if role !=\"\"}} AND role = @role{{end}} // FilterWithNameAndRole(name, role string) ([]gen.T, error) //} func main() { g := gen.NewGenerator(gen.Config{ OutPath: \"../../query\", Mode: gen.WithoutContext | gen.WithDefaultQuery | gen.WithQueryInterface, // generate mode }) // gormdb, _ := gorm.Open(mysql.Open(\"root:@(127.0.0.1:3306)/demo?charset=utf8mb4\u0026parseTime=True\u0026loc=Local\")) //g.UseDB(gormdb) // reuse your gorm db // Generate basic type-safe DAO API for struct `model.User` following conventions g.ApplyBasic(model.Student{}, model.Teacher{}) // Generate Type Safe API with Dynamic SQL defined on Querier interface for `model.User` and `model.Company` //g.ApplyInterface(func(Querier) {}, model.User{}, model.Company{}) // Generate the code g.Execute() } 运行命令 go run cmd/gen/generate.go [root@Sugar genc]🐳 go run cmd/gen/generate.go 2023/11/28 01:10:21 Start generating code. 2023/11/28 01:10:21 generate query file: /Users/root/github/genc/query/students.gen.go 2023/11/28 01:10:21 generate query file: /Users/root/github/genc/query/teachers.gen.go 2023/11/28 01:10:21 generate query file: /Users/root/github/genc/query/gen.go 2023/11/28 01:10:21 Generate code done. server main文件 cmd/sugar/sugar.go package main import ( \"fmt\" \"github.com/glebarez/sqlite\" \"github.com/root/genc/model\" \"github.com/root/genc/query\" \"gorm.io/gorm\" \"gorm.io/gorm/schema\" ) func main() { // dsn := \"root:12345678@tcp(127.0.0.1:3306)/gorm_learning?charset=utf8mb4\u0026parseTime=True\u0026loc=Local\" db, err := gorm.Open(sqlite.Open(\"test.db\"), \u0026gorm.Config{ DisableForeignKeyConstraintWhenMigrating: true, NamingStrategy: schema.NamingStrategy{ SingularTable: true, // 设置创建表名时不使用复数 }, }) if err != nil { panic(err) } err = db.AutoMigrate(\u0026model.Student{}, \u0026model.Teacher{}) if err != nil { panic(err) } query.SetDefault(db) // 增 student1 := model.Student{Name: \"student1\"} student2 := model.Student{Name: \"student2\"} student3 := model.Student{Name: \"student3\"} _ = query.Student.Create(\u0026student1, \u0026student2, \u0026student3) teacher1 := model.Teacher{Name: \"teacher1\"} _ = query.Teacher.Create(\u0026teacher1) // 删 _, _ = query.Student.Where(query.Student.Id.Eq(3)).Delete() // 改 _, _ = query.Student.Where(query.Student.Id.Eq(2)).Update(query.Student.Name, \"student2_new\") // 查 student, _ := query.Student.Where(query.Student.Id.Eq(1)).Take() teacher, _ := query.Teacher.Where(query.Teacher.Id.Eq(1)).Take() fmt.Println(student) // {1 student1 0} fmt.Println(teacher) // {1 teacher1 []} // 关联 _ = query.Teacher.Student.Model(\u0026teacher1).Append(\u0026student1, \u0026student2) teacher, _ = query.Teacher.Preload(query.Teacher.Student).Where(query.Teacher.Id.Eq(1)).Take() fmt.Println(teacher) // {1 teacher1 [{1 student1 1} {2 student2_new 1}]} fmt.Println(query.Student.TableName()) fmt.Println(query.Teacher.TableName()) } 运行主服务 [root@Sugar genc]🐳 go run cmd/sugar/main.go \u0026{1 student1 1} \u0026{1 teacher1 []} \u0026{1 teacher1 [{1 student1 1} {2 student2_new 1}]} student teacher 更新字段使用对比 GLOBAL_DB.Model(\u0026Student{}).Where(\"ID = ?\", 2).Update(\"Name\", \"student2_new\") query.Student.Where(query.Student.Id.Eq(2)).Update(query.Student.Name, \"student2_new\") ","date":"2023-11-28","objectID":"/posts/2023-11-28-gorm-gen/:2:0","tags":["gorm","gorm-gen"],"title":"Gorm gen","uri":"/posts/2023-11-28-gorm-gen/"},{"categories":["DevOps"],"content":"Shell handbok ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:0:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"一、特殊符号 参考链接: https://blog.csdn.net/jiezi2016/article/details/79649382 https://blog.csdn.net/wangzhaotongalex/article/details/73321766 介绍下Shell中的${}、##和%%使用范例，本文给出了不同情况下得到的结果。 假设定义了一个变量为： 代码如下: file=/dir1/dir2/dir3/my.file.txt 可以用${ }分别替换得到不同的值： ${file#*/}：删掉第一个 / 及其左边的字符串：dir1/dir2/dir3/my.file.txt ${file##*/}：删掉最后一个 / 及其左边的字符串：my.file.txt ${file#*.}：删掉第一个 . 及其左边的字符串：file.txt ${file##*.}：删掉最后一个 . 及其左边的字符串：txt ${file%/*}：删掉最后一个 / 及其右边的字符串：/dir1/dir2/dir3 ${file%%/*}：删掉第一个 / 及其右边的字符串：(空值) ${file%.*}：删掉最后一个 . 及其右边的字符串：/dir1/dir2/dir3/my.file ${file%%.*}：删掉第一个 . 及其右边的字符串：/dir1/dir2/dir3/my 记忆的方法为： # 是 去掉左边（键盘上#在 $ 的左边） %是去掉右边（键盘上% 在$ 的右边） 单一符号是最小匹配；两个符号是最大匹配 ${file:0:5}：提取最左边的 5 个字节：/dir1 ${file:5:5}：提取第 5 个字节右边的连续5个字节：/dir2 也可以对变量值里的字符串作替换： ${file/dir/path}：将第一个dir 替换为path：/path1/dir2/dir3/my.file.txt ${file//dir/path}：将全部dir 替换为 path：/path1/path2/path3/my.file.txt $*与$@ $*和$@都表示传递给函数或脚本的所有参数，不被双引号“”包含时，都以$1 $2 …$n的形式输出所有参数。 当它们被双引号“”包含时，“$*”会将所有的参数作为一个整体，以“$1 $2 …$n”的形式输出所有参数；“$@”会将各个参数分开，以“$1” “$2”…”$n”的形式输出所有参数。 ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:1:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"二、重定向与变量 cat \u003e\u003etest.txt \u003c\u003c EOF 1、安装kvm 2、卸载kvm 3、安装python EOF $0 shell脚本的名字 $n 第n个参数 $# 获取参数的个数 $* 所有参数 $@ 所有参数 两者区别： \"$*\"会把所有位置参数当成一个整体（或者说当成一个单词），如果没有位置参数，则\"$*\"为空，如果有两个位置参数并且IFS为空格时，\"$*\"相当于\"$1 $2\" \"$@\" 会把所有位置参数当成一个单独的字段，如果没有位置参数（$#为0），则\"$@\"展开为空（不是空字符串，而是空列表），如果存在一个位置参数，则\"$@\"相当于\"$1\"，如果有两个参数，则\"$@\"相当于\"$1\" \"$2\"等等 $? 用于记录上一条命令的执行状态 0---255 0：执行成功 $$ 获取当前执行Shell脚本的进程号（PID） $! 获取上一个在后台工作的进程的进程号 $_ 获取在此之前执行的命令或脚本的最后一个参数 特殊扩展变量 可以man bash 命令，然后搜索\"Parameter Expansion\"来查找相关的内容帮助 ${parameter:-word} 如果parameter的变量值为空或没赋值，则返回word字符串并代替变量的值（变量没定义，返回备用的值，防止变量为空或没定义报错） ${parameter:=word} 如果parameter的变量值为空或没赋值，。。。同上，（变量没定义为防止出错，找的备胎变量） ${parameter:?word} 如果parameter的变量值为空或者没赋值，word字符串就作为标准错误输出，否则出书变量的值（捕捉由于变量未定义导致的错误，并退出） ${parameter:+word} 若果parameter的变量值为空或者未赋值，则什么都不做，否则word字符串将代替变量的值。 ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:2:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"三、判断 条件判断 -z 判断字符串是否为空串 -n 字符段长度是否非零的 如果结果为真值 返回值为0 如果结果为假值 -eq 等于 -gt 大于 -lt 小于 -ge 大于等于 -le 小于等于 -ne 不等于 根据文件类型判断 -d 文件存在且必须是目录 -e 文件存在，不判断文件类型 -f 文件存在且是标准普通文件 -h 文件存在且是软连接，同 -L -r 文件存在且可读 -w 文件存在且可写 -x 文件存在且可执行 -s 文件存在且至少有一个字符 双目表达式 单目表达式， 所有的单目表达式都可以使用!表示取反 [ ! -f file_name ] if标准写法 if 条件; then 操作语句 操作语句 .... else 操作语句 操作语句 fi [ file1 -ef file2 ] 两个文件有相同的设备编号和inode编号 (判断硬链接) if [ 'a' != 'b'];then echo 'a' fi 以上可以简写为: [ 'a' != 'b' ] \u0026\u0026 echo 'a' case 语法 read -p \"Enter string: \" str_01 case $str_01 in linux|Linux) echo \"CentOS\" ;; windows|Windows) echo \"Microsoft\" ;; *) echo \"Other\" ;; esac for 循环 # 普通循环 sum=0 for i in `seq 100`; do let sum=$sum+$i done echo $sum # 类C写法 for ((i=1;i\u003c8;i++));do cmd1 done while循环 while 条件; do 操作语句 操作语句 存在一条可以改变条件真假的语句 done until循环 当条件为假时才循环 until 条件测试 ;do cmd1 done 数组与循环 # ca.crt /etc/openvpn/easy-rsa/pki # server.crt /etc/openvpn/easy-rsa/pki/issued # user.crt /etc/openvpn/easy-rsa/pki/issued # user.key /etc/openvpn/easy-rsa/pki/private # ca.key /etc/openvpn/easy-rsa/pki/private # ta.key /etc/openvpn/easy-rsa # 定义用户 accounts=( client2,用户2 client3,用户3 client4,用户4 ) OPENVPN_DIR=\"/etc/openvpn\" EASY_RSA_DIR=\"/etc/openvpn/easy-rsa\" # 分配好的证书 OVPN_DIR=\"/tmp/openvpn\" # 创建key # $1 用户证书名 create_key(){ [[ ! -f ${EASY_RSA_DIR}/easyrsa ]] \u0026\u0026 exit 55 cd ${EASY_RSA_DIR}/ \u0026\u0026 ./easyrsa build-client-full $1 nopass } # $1 用户名 create_ovpn(){ [[ ! -f ${OVPN_DIR} ]] \u0026\u0026 mkdir -p ${OVPN_DIR} cat \u003e ${OVPN_DIR}/$1.ovpn \u003c\u003c EOF client dev tun proto tcp remote vpn.local.com 50000 resolv-retry infinite nobind persist-key persist-tun remote-cert-tls server cipher AES-256-CBC comp-lzo verb 3 EOF } # $1 用户名 insert_file(){ ca=`cat ${EASY_RSA_DIR}/pki/ca.crt` user_crt=`cat ${EASY_RSA_DIR}/pki/issued/$1.crt` user_key=`cat ${EASY_RSA_DIR}/pki/private/$1.key` ta=`cat ${EASY_RSA_DIR}/ta.key` cat \u003e\u003e ${OVPN_DIR}/$1.ovpn \u003c\u003c EOF \u003cca\u003e ${ca} \u003c/ca\u003e \u003ccert\u003e ${user_crt} \u003c/cert\u003e \u003ckey\u003e ${user_key} \u003c/key\u003e key-direction 1 \u003ctls-auth\u003e ${ta} \u003c/tls-auth\u003e EOF } ## main for aobj in ${accounts[@]} do arr=(${aobj//,/ }) actName=${arr[0]} chineseName=${arr[1]} create_ovpn ${actName} create_key ${actName} insert_file ${actName} done ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:3:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"四、高级语法 可选参数 while getopts \"🅰️b:c:\" opt do case $opt in a) echo \"参数a的值$OPTARG\" ;; b) echo \"参数b的值$OPTARG\" ;; c) echo \"参数c的值$OPTARG\" ;; ?) echo \"未知参数\" exit 1;; esac done ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:4:0","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"sed d 删除符合条件的行 # sed '1,2d' /etc/inittab 删除文件中包含oot的行 # sed '/oot/d' /etc/fstab 删除第1行及其后2行 # sed '1,+2d' /etc/fstab 删除第1行 # sed '1d' /etc/fstab 删除以/开头的行 # sed '/^\\//d' /etc/fstab a \\string 在符合条件的行后追加新行，string为追加的内容 在以/开头的行后面追加# hello world # sed '/^\\//a \\# hello world' /etc/fstab 在以/开头的行后面追加两行内容，分别为# hello worl # hello linux # sed '/^\\//a \\# hello world\\n# hello linux' /etc/fstab i \\string 在符合条件的行前添加新行，string为追加的内容 在文件第1行添加# hello world # sed '1i \\# hello world' /etc/fstab c \\string 替换指定行的内容 将文件中最后一行内容替换为End Of File # sed '$c \\End Of File' /1.txt # sed '7c \\SELINUX=disabled' /etc/sysconfig/selinux # 当有hello的行，将被替换成hello=world # sed -r \"/hello/c \\hello=world\" exmaple.txt ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:4:1","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"awk # awk -F: '/^r/{print $1}' /etc/passwd ","date":"2023-11-24","objectID":"/posts/2023-11-24-shell-handbook/:4:2","tags":["shell","shell-handbook"],"title":"Shell handbook","uri":"/posts/2023-11-24-shell-handbook/"},{"categories":["DevOps"],"content":"switch-case语法 shell 语法 case 变量 in 取值1) 操作语句 操作语句 ;; 取值2) 操作语句 操作语句 ;; 取值3) 操作语句 操作语句 ;; *) 操作语句 操作语句 ;; esac # example read -p \"Enter string: \" str_01 case $str_01 in linux|Linux) echo \"CentOS\" ;; windows|Windows) echo \"Microsoft\" ;; *) echo \"Other\" ;; esac go func testSwitch3() { switch n := 7; n { case 1, 3, 5, 7, 9: fmt.Println(\"奇数\") case 2, 4, 6, 8: fmt.Println(\"偶数\") default: fmt.Println(n) } } func switchDemo1() { finger := 3 switch finger { case 1: fmt.Println(\"大拇指\") case 4: fmt.Println(\"无名指\") case 5: fmt.Println(\"小拇指\") default: fmt.Println(\"无效的输入！\") } } python 3.10及以后 match term: case pattern-1: action-1 case pattern-2: action-2 case pattern-3: action-3 case _: action-default lang = input(\"What's the programming language you want to learn? \") match lang: case \"Python\": print(\"You can become a Data Scientist\") case \"go\": print(\"You can become a Blockchain developer\") case \"Java\": print(\"You can become a mobile app developer\") case _: print(\"The language doesn't matter, what matters is solving problems.\") ","date":"2023-11-24","objectID":"/posts/2023-11-24-switch-case/:0:0","tags":["switch","case","switch-case"],"title":"switch-case handbook","uri":"/posts/2023-11-24-switch-case/"},{"categories":["DevOps"],"content":"Ansible Module 参考链接：https://ansible.leops.cn/dev/modules/ 1、自定义模块开发 该模块的目的是在远程主机上将远程源文件复制到远程目标文件 #!/usr/bin/python # -*- coding: utf-8 -*- # Copyright: (c) 2020, lework # GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt) ANSIBLE_METADATA = {'metadata_version': '1.0', 'status': ['preview'], 'supported_by': 'community'} DOCUMENTATION = ''' --- module: remote_copy short_description: Copy a file on the remote host version_added: \"2.9\" description: - The remote_copy module copies a file on the remote host from a given source to a provided destination. options: source: description: - Path to a file on the source file on the remote host required: true dest: description: - Path to the destination on the remote host for the copy required: true author: - \"Lework\" ''' EXAMPLES = ''' # Example from Ansible Playbooks - name: backup a config file remote_copy: source: /tmp/foo dest: /tmp/bar ''' RETURN = ''' source: description: Path to a file on the source file on the remote host type: str returned: success sample: \"/path/to/file.name\" dest: description: Path to the destination on the remote host for the copy type: string returned: success sample: \"/path/to/destination.file\" ''' import os import shutil from ansible.module_utils.basic import AnsibleModule def main(): module_args = dict( source=dict(required=True, type='str'), dest=dict(required=True, type='str') ) result = dict( changed=False, source='', dest='' ) module = AnsibleModule( argument_spec=module_args, supports_check_mode=True ) if module.check_mode: module.exit_json(**result) if not os.path.isfile(module.params['source']): module.fail_json(msg='The '+ module.params['source'] +' file was not found', **result) try: shutil.copy(module.params['source'], module.params['dest']) except Exception as e: module.fail_json(msg=e, **result) result['source'] = module.params['source'] result['dest'] = module.params['dest'] if os.path.isfile(module.params['dest']): result['changed'] = True remote_facts = {'rc_source': module.params['source'], 'rc_dest': module.params['dest'] } result['ansible_facts'] = remote_facts module.exit_json(**result) if __name__ == '__main__': main() ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-ansible-module/:0:0","tags":["python-ansible","ansible-module"],"title":"Python ansible module","uri":"/posts/2023-11-22-python-ansible-module/"},{"categories":["DevOps"],"content":"Python 基础 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:0:0","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"一、基础语法 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:0","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"1、输出语句的使用 1）引号的使用 \u003e\u003e\u003e print ('hello world') hello world \u003e\u003e\u003e print (\"hello world\") hello world \u003e\u003e\u003e 2）三引号: 输出多行内容 \u003e\u003e\u003e print (\"\"\"abc ... cdc ... ddd ... ccc ... fff\"\"\") abc cdc ddd ccc fff 注释符：# python2与python3的区别 print语法不同，python3需要加() python2默认使用的字符集ASCII码, # encoding: utf8。python3默认使用的字符集Unicode 2）输出变量 username = \"root\" password = \"redhat\" print(username) print(\"my name is \", username, \"my password is\", password) print(\"my name is \" + username + \"my password is \" + password) #只适用于字符串 3）格式化输出 \u003e\u003e\u003e username = \"root\" \u003e\u003e\u003e password = \"redhat\" \u003e\u003e\u003e print(\"my name is %s\" % username ) my name is root \u003e\u003e\u003e print(\"my name is '%s'\" % username) my name is 'root' \u003e\u003e\u003e print(\"my name is %s, my password is %s\" % (username, password)) my name is root, my password is redhat 常用的格式化字符 %s 字符串 通用 %d 数字，整数 number_01 = 123 number_02 = \"456\" number_03 = 3.9415 print(\"It is %d\" % number_01) print(\"It is %d\" % number_03) %f 浮点数，小数 number_01 = 123 number_02 = 3.948915 number_03 = 3.9489151111111111 print(\"It is %f\" % number_01) print(\"It is %f\" % number_02) print(\"It is %f\" % number_03) print(\"It is %.2f\" % number_02) %% 输出%本身 number = 50 # This is 50% print(\"This is %d%%\" % number) username = \"root\" password = \"redhat\" sql_01 = \"select * from tb01 where username='%s' and password='%s'\" % (username, password) print(sql_01) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:1","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"2、变量定义 变量名称规范： 字母、数字、下划线_ 只能以字母、下划线_开头 不能与python关键字冲突。（print if for while else ） #交互式变量赋值 username = input(\"输入用户名： \") #注意： #返回的结果是字符串 print(\"用户名： %s\" % username) 删除变量 name = \"Martin\" print(name) del name print(name) python变量与其他语言不同之处 弱类型 地址引用类型 number_01 = 10 number_02 = 10 print(id(number_01)) print(id(number_02)) number_01 = 100 number_02 = number_01 print(id(number_01)) print(id(number_02)) 内置函数 id() 返回变量的内存地址 type() 返回变量的类型 内存使用机制 每个变量定义后，会在内存中开辟一段空间，这段空间对应存在一个引用计数器，变量被调用一次，引用计数器会自动增加；当python解释器检测到一段内存的引用计数器为0后，会自动清理该内存 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:2","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"3、变量的类型 数字 字符串 列表 元组 字典 集合 Bytes ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:3","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"4、运算 #数学运算符 \u003e\u003e\u003e a = 10 \u003e\u003e\u003e b = 4 \u003e\u003e\u003e a + b 14 \u003e\u003e\u003e a - b 6 \u003e\u003e\u003e a * b 40 \u003e\u003e\u003e a ** b 10000 \u003e\u003e\u003e \u003e\u003e\u003e a / b 2.5 \u003e\u003e\u003e a // b 2 \u003e\u003e\u003e a % b 2 \u003e\u003e\u003e a = 10 \u003e\u003e\u003e a = a + 1 \u003e\u003e\u003e a 11 \u003e\u003e\u003e a += 1 \u003e\u003e\u003e a 12 \u003e\u003e\u003e #比较运算符 ==, !=, \u003e, \u003e=, \u003c=, \u003c 逻辑运算符 and, or, not \u003e\u003e\u003e a = 10 \u003e\u003e\u003e \u003e\u003e\u003e \u003e\u003e\u003e a \u003e 20 and 1 \u003c 2 False \u003e\u003e\u003e \u003e\u003e\u003e a \u003e 20 or 1 \u003c 2 True \u003e\u003e\u003e \u003e\u003e\u003e not a \u003e 20 True \u003e\u003e\u003e 数制转换 \u003e\u003e\u003e a = 10 \u003e\u003e\u003e bin(a) '0b1010' \u003e\u003e\u003e oct(a) '0o12' \u003e\u003e\u003e hex(a) '0xa' \u003e\u003e\u003e #生成随机数的模块 \u003e\u003e\u003e import random \u003e\u003e\u003e random.randint(0, 10) 7 \u003e\u003e\u003e random.randint(0, 10) 9 \u003e\u003e\u003e random.randint(0, 10) 2 \u003e\u003e\u003e random.randint(0, 10) 3 \u003e\u003e\u003e random.randint(0, 10) 6 示例：四则运算 number_01 = int(input(\"输入第1个数字： \")) number_02 = int(input(\"输入第2个数字： \")) print(\"%s + %s = %s\" % (number_01, number_02, number_01 + number_02)) print(\"%s - %s = %s\" % (number_01, number_02, number_01 - number_02)) print(\"%s * %s = %s\" % (number_01, number_02, number_01 * number_02)) print(\"%s / %s = %s\" % (number_01, number_02, number_01 / number_02)) print(\"%s // %s = %s\" % (number_01, number_02, number_01 // number_02)) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:4","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"5、逻辑控制语句 同级代码要有相同缩进，默认4个空格 条件判断 — if if 条件: 操作语句 操作语句 if 1 \u003c 2: print(\"AAA\") print(\"BBB\") # 只要数字不等于0，条件为真 number = 10 if number: print(\"AAA\") print(\"BBB\") number = 10 if not number: print(\"AAA\") print(\"BBB\") # True, False 首字母全是大写 if True: print(\"AAA\") if …. else number = 100 if number \u003c 20: print(\"AAAA\") else: print(\"BBBB\") if … elif … elif …. else number = int(input(\"Enter number: \")) if number \u003e 10: print(\"AAA\") elif number \u003e 30: print(\"BBBB\") elif number \u003e 40: print(\"CCCC\") else: print(\"DDDD\") 嵌套if age = int(input(\"输入你的年龄： \")) if age \u003c= 18: gender = input(\"输入你的性别： \") if gender == \"M\": print(\"准备入队\") else: print(\"睡吧\") else: print(\"回家洗洗睡吧\") 循环 for while for循环： for 变量 in 取值: 操作语句 操作语句 for i in range(5): print(\"第%s次循环开始\" % i) print(\"第%s次循环结束\" % i) print(\"-----------------\") 中断循环： #break 中断整体循环 for i in range(5): print(\"第%s次循环开始\" % i) if i == 3: break print(\"第%s次循环结束\" % i) print(\"-----------------\") continue 中断本次循环 for i in range(5): print(\"第%s次循环开始\" % i) if i == 3: continue print(\"第%s次循环结束\" % i) print(\"-----------------\") 示例：斐波那契数列 length=int(input(\"input length:\")) i=0 j=1 tmp=1 for n in range(length): print( tmp,\" \",end=) tmp = i + j i = j j = tmp print() while循环 while 条件: 操作语句 操作语句 i = 1 while i \u003c= 4: print(\"第%s次循环开始\" % i) print(\"第%s次循环结束\" % i) print(\"-----------------\") i += 1 while True: 操作语句 操作语句 示例： 实现数制转换 import sys number = int(input(\"输入数字： \")) menu = \"\"\" 1、二进制 2、八进制 3、十六进制 4、退出 输入你的选择：d \"\"\" ''' 循环判断用户的选择，根据不同的选择做不同的响应 ''' while True: choice = int(input(menu)) if choice == 1: print(\"数字%s的二进制形式：%s\" % (number, bin(number))) elif choice == 2: print(\"数字%s的八进制形式：%s\" % (number, oct(number))) elif choice == 3: print(\"数字%s的十六进制形式：%s\" % (number, hex(number))) else: print(\"谢谢\") sys.exit() pass: 占位符 #!/usr/bin/python import time for i in range(5): print i if i == 1: pass ---- 代码桩 if之间不能空代码可以用pass占位 if i == 2: continue if i == 3: break print \"#\"*10 else: print \"END\" for j in range(2): print \"---\u003e\",j [root@server python]# python dic.py 0 ########## 1 ########## 2 3 ---\u003e 0 ---\u003e 1 结束执行 [root@server python]# cat dic.py #!/usr/bin/python for i in range(10): print i if i == 5: exit() [root@server python]# python dic.py 0 1 2 3 4 5 switch语句 switch语句用于编写多分支结构的程序,类似与if… elif… else语句 switch语句表达的分支结构比if… elif… else语句表达的更清晰,代码可读性更高，但是python并没有提供switch语句 python可以通过字典实现switch语句的功能 实现方法分为两步 首先：定义一个字典，其次,调用字典的get()获取相应的表达式xxxxxxxxxx [root@www python]# cat test.py #!/usr/bin/bash #coding:utf8 from __future__ import division def jia(x,y): return x+y def jian(x,y): return x-y def cheng(x,y): return x*y def chu(x,y): return x/y def operator(x,o,y): if o == \"+\": print jia(x,y) elif o == \"-\": print jian(x,y) elif o == \"*\": print cheng(x,y) elif o == \"/\": print chu(x,y) else: pass operator(2,\"/\",4) #!/usr/bin/bash #coding:utf8 from __future__ import division def jia(x,y): return x+y def jian(x,y): return x-y def cheng(x,y): return x*y def chu(x,y): return x/y operator = {\"+\":jia,\"-\":jian,\"*\":cheng,\"/\":chu} print operator [\"/\"](3,2) 示例： 写一个卖水果的菜单(有菜单),再将他转换为switch格式 menu=\"\"\" 1、apple 2、banala 3、orange \"\"\" fuirt={1:['apple',5],2:['banala',3],3:['orange',7]} print(fuirt[1]) while True: print(menu) tmp=int(input(\"请输入要查询价格的水果:\")) print(\"%s的价格是 %s 元/斤\"%(fuirt[tmp][0],fuirt[tmp][1])) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:5","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"六、函数 1、格式 未定义返回值 \u003e\u003e\u003e def fun(): ... print (\"a\") \u003e\u003e\u003e var=fun() a \u003e\u003e\u003e print (var) None 定义返回值 \u003e\u003e\u003e def fun(): ... return \"ok\" ... ... \u003e\u003e\u003e var=fun() \u003e\u003e\u003e print (var) ok 2、默认值 #!/usr/bin/python # -*- coding: UTF-8 -*- #可写函数说明 def printinfo( name, age = 35 ): \"打印任何传入的字符串\" print \"Name: \", name print \"Age \", age return #调用printinfo函数 printinfo( age=50, name=\"miki\" ) printinfo( name=\"miki\" ) 3、不定长参数 #!/usr/bin/python # -*- coding: UTF-8 -*- # 可写函数说明 def printinfo( arg1, *vartuple ): \"打印任何传入的参数\" print \"输出: \" print arg1 for var in vartuple: print var return # 调用printinfo 函数 printinfo( 10 ) printinfo( 70, 60, 50 ) ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:6","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"七、模块 搜索路径是一个解释器会先进行搜索的所有目录的列表。如想要导入模块 support.py，需要把命令放在脚本的顶端： # support.py def print_func( par ): print \"Hello : \", par return # test.py #!/usr/bin/python # -*- coding: UTF-8 -*- # 导入模块 import support # 现在可以调用模块里包含的函数了 support.print_func(\"sugar\") Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下： ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:7","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"八、面向对象 定义类与实例化 class Ren: name = \"人\" def run(self): print(\"跑步\") cmd = Ren() print(cmd) 私有属性与方法 在属性或者方法前加__的，即表示该方法和属性为私有类外不可调用 #!/usr/bin/python # -*- coding: UTF-8 -*- class Employee: '所有员工的基类' empCount = 0 def __init__(self, name, salary): self.name = name self.salary = salary Employee.empCount += 1 def displayCount(self): print \"Total Employee %d\" % Employee.empCount def displayEmployee(self): print \"Name : \", self.name, \", Salary: \", self.salary 类的继承 #!/usr/bin/python # -*- coding: UTF-8 -*- class Parent: # 定义父类 parentAttr = 100 def __init__(self): print \"调用父类构造函数\" def parentMethod(self): print '调用父类方法' def setAttr(self, attr): Parent.parentAttr = attr def getAttr(self): print \"父类属性 :\", Parent.parentAttr class Child(Parent): # 定义子类 def __init__(self): print \"调用子类构造方法\" def childMethod(self): print '调用子类方法' c = Child() # 实例化子类 c.childMethod() # 调用子类的方法 c.parentMethod() # 调用父类方法 c.setAttr(200) # 再次调用父类的方法 - 设置属性值 c.getAttr() # 再次调用父类的方法 - 获取属性值 方法重写 #!/usr/bin/python # -*- coding: UTF-8 -*- class Parent: # 定义父类 def myMethod(self): print '调用父类方法' class Child(Parent): # 定义子类 def myMethod(self): print '调用子类方法' c = Child() # 子类实例 c.myMethod() # 子类调用重写方法 ","date":"2023-11-22","objectID":"/posts/2023-11-22-python-basic/:1:8","tags":["python","python-basic"],"title":"Python basic","uri":"/posts/2023-11-22-python-basic/"},{"categories":["DevOps"],"content":"Terraform handbook 参考链接：https://blog.gmem.cc/terraform ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:0:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"一、简介 Terraform用于实现基础设施即代码（infrastructure as code）—— 通过代码（配置文件）来描述基础设施的拓扑结构，并确保云上资源和此结构完全对应。Terraform有三个版本，我们主要关注Terraform CLI。 Terraform CLI主要包含以下组件： 命令行前端 Terraform Language（以下简称TL，衍生自HashiCorp配置语言HCL）编写的、描述基础设施拓扑结构的配置文件。配置文件的组织方式是模块。本文使用术语“配置”（Configuration）来表示一整套描述基础设施的Terraform配置文件 针对各种云服务商的驱动（Provider），实现云资源的创建、更新和删除 云上资源不单单包括基础的IaaS资源，还可以是DNS条目、SaaS资源。事实上，通过开发Provider，你可以用Terraform管理任何资源。 Terraform会检查配置文件，并生成执行计划。计划描述了那些资源需要被创建、修改或删除，以及这些资源之间的依赖关系。Terraform会尽可能并行的对资源进行变更。当你更新了配置文件后，Terraform会生成增量的执行计划。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:1:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"二、命令行 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"1、安装命令行 直接到https://www.terraform.io/downloads.html下载，存放到$PATH下即可。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:1","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"2、基本特性 1）切换工作目录 使用选项 -chdir=DIR 2）Shell自动补全 使用 terraform -install-autocomplete安装自动完成脚本，使用 terraform -uninstall-autocomplete删除自动完成脚本。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:2","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"3、资源地址 很多子命令接受资源地址参数，下面是一些例子： # 资源类型.资源名 aws_instance.foo # 资源类型.资源列表名[索引] aws_instance.bar[1] # 子模块foo的子模块bar中的 module.foo.module.bar.aws_instance.baz ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:3","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"4、配置文件 配置文件的路径可以通过环境变量 TF_CLI_CONFIG_FILE设置。非Windows系统中， $HOME/.terraformrc为默认配置文件路径。配置文件语法类似于TF文件： # provider缓存目录 plugin_cache_dir = \"$HOME/.terraform.d/plugin-cache\" # disable_checkpoint = true # 存放凭证信息，包括模块仓库、支持远程操作的系统的凭证 credentials \"app.terraform.io\" { token = \"xxxxxx.atlasv1.zzzzzzzzzzzzz\" } # 改变默认安装逻辑 provider_installation { # 为example.com提供本地文件系统镜像，这样安装example.com/*/*的provider时就不会去网络上请求 # 默认路径是： # ~/.terraform.d/plugins/${host_name}/${namespace}/${type}/${version}/${target} # 例如： # ~/.terraform.d/plugins/hashicorp.com/edu/hashicups/0.3.1/linux_amd64/terraform-provider-hashicups_v0.3.1 filesystem_mirror { path = \"/usr/share/terraform/providers\" include = [\"example.com/*/*\"] } direct { exclude = [\"example.com/*/*\"] } # Terraform会在terraform init的时候，校验Provider的版本和checksum。Provider从Registry或者本地 # 目录下载Provider。当我们开发Provider的时候，常常需要方便的测试临时Provider版本，这种Provider还 # 没有关联版本号，也没有在Registry中注册Chencksum # 为了简化开发，可以配置dev_overrides，它能覆盖所有配置的安装方法 dev_overrides { \"hashicorp.com/edu/hashicups-pf\" = \"$(go env GOBIN)\" } } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:4","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"5、init 配置工作目录，为使用其它命令做好准备。 Terraform命令需要在一个编写了Terraform配置文件的目录（配置根目录）下执行，它会在此目录下存储设置、缓存插件/模块，以及（默认使用Local后端时）存储状态数据。此目录必须进行初始化。 初始化后，会生成以下额外目录/文件： .terraform目录，用于缓存provider和模块 如果使用Local后端，保存状态的terraform.tfstate文件。如果使用多工作区，则是terraform.tfstate.d目录。 对配置的某些变更，需要重新运行初始化，包括provider需求的变更、模块源/版本约束的变更、后端配置的变更。需要重新初始化时，其它命令可能会无法执行并提示你进行初始化。 命令 terraform get可以仅仅下载依赖的模块，而不执行其它init子任务。 运行 terraform init -upgrade会强制拉取最新的、匹配约束的版本并更新依赖锁文件。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:5","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"6、validate 校验配置是否合法。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:6","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"7、plan 显示执行计划，即当前配置将请求（结合state）哪些变更。Terraform的核心功能时创建、修改、删除基础设施对象，使基础设施的状态和当前配置匹配。当我们说运行Terraform时，主要是指plan/apply/destroy这几个命令。 terraform plan命令评估当前配置，确定其声明的所有资源的期望状态。然后比较此期望状态和真实基础设施的当前状态。它使用state来确定哪些真实基础设施对象和声明资源的对应关系，并且使用provider的API查询每个资源的当前状态。当确定到达期望状态需要执行哪些变更后，Terraform将其打印到控制台，它并不会执行任何实际的变更操作。 计划模式 plan命令支持两种备选的工作模式： 销毁模式：创建一个计划，其目标是销毁所有当前存在于配置中的远程对象，留下一个空白的state。对应选项 -destroy 仅刷新模式：创建一个计划，其目标仅仅是更新state和根模块的输出值，以便和从Terraform之外对基础设施对象的变更匹配。对应选项 -refresh-only 指定输入变量 使用选项 -var ‘NAME=VALUE’可以指定输入变量，该选项可以使用多次。 使用选项 -var-file=FILENAME可以从文件读取输入变量，某些文件会自动读取 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:7","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"8、apply 应用执行计划，创建、更新设施对象。 apply会做plan的任何事情，并在其基础上，直接执行变更操作。默认情况下，apply即席的执行一次plan，你也可以直接使用已保存的plan 命令格式： terraform apply [options] [plan file] 自动确认 选项 -auto-approve可以自动确认并执行所需操作，不需要人工确认。 使用已有计划 如果指定plan file参数，则读取先前保存的计划并执行。 计划模式 支持plan命令中关于计划模式的选项。 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:2:8","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"三、TF语言 ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:0","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"1、块 配置文件由若干块（Block）组成，块的语法如下： # Block header, which identifies a block \u003cBLOCK TYPE\u003e \"\u003cBLOCK LABEL\u003e\" \"\u003cBLOCK LABEL\u003e\" \"...\" { # Block body \u003cIDENTIFIER\u003e = \u003cEXPRESSION\u003e # Argument } 块是一个容器，它的作用取决于块的类型。块常常用来描述某个资源的配置。 取决于块的类型，标签的数量可以是0-N个。对于resource块，标签数量为两个。某些特殊的块，可能支持任意数量的标签。某些内嵌的块，例如network_interface，则不支持标签。 块体中可以包含若干参数（Argument），或者其它内嵌的块。参数用于将一个表达式分配到一个标识符，常常对应某个资源的一条属性。表达式可以是字面值，或者引用其它的值，正是这种引用让Terraform能够识别资源依赖关系。 直接位于配置文件最外层的块，叫做顶级块（Top-level Block），Terraform支持有限种类的顶级块。大部分Terraform特性，例如resource，基于顶级块实现。 下面是一个例子： resource \"aws_vpc\" \"main\" { cidr_block = var.base_cidr_block } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:1","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"2、数据类型 类型 说明 string Unicode字符序列，基本形式 “hello” number 数字，形式 6.02 bool true或 false list/tuple 一系列的值，形式 [“us-west-1a”, “us-west-1c”] map/object 键值对，形式 {name = “Mabel”, age = 52} ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:2","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"3、空值 空值使用 null表示。 4、字符串和模板 转义字符 \\n 换行 \\r 回车 \\t 制表 \\\" 引号 \\\\ 反斜杠 \\uNNNN Unicode字符 \\UNNNNNNNN Unicode字符 注意，在Heredoc中反斜杠不用于转义，可以使用： $${ 字符串插值标记${ %%{ 模板指令标记%{ 支持unix风格的字符串 block { value = \u003c\u003cEOT hello world EOT } block { value = \u003c\u003c-EOT hello world EOT } 要将对象转换为JSON或YAML，可以调用函数： example = jsonencode({ a = 1 b = \"hello\" }) ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:3","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"5、操作符 逻辑操作符： ! \u0026\u0026 || 算数操作符： * / % + - 比较操作符： \u003e, \u003e=, \u003c, \u003c= ==, != 条件表达式 condition ? true_val : false_val var.a != \"\" ? var.a : \"default-a\" for表达式 使用for表达式可以通过转换一种复杂类型输出，生成另一个复杂类型结果。输入中的每个元素，可以对应结果的0-1个元素。任何表达式可以用于转换，下面是使用upper函数将列表转换为大写： [for s in var.list : upper(s)] 输入类型 作为for表达式的输入的类型可以是list / set / tuple / map / object。可以为for声明两个临时符号，前一个表示index或key： [for k, v in var.map : length(k) + length(v)] 结果类型 结果的类型取决于包围for表达式的定界符： [] 表示生成的结果是元组 {} 表示生成的结果是object，你必须使用 =\u003e符号： {for s in var.list : s =\u003e upper(s)} 输入过滤 包含一个可选的if子句可以对输入元素进行过滤： [for s in var.list : upper(s) if s != \"\"] 示例： variable \"users\" { type = map(object({ is_admin = boolean })) } locals { admin_users = { for name, user in var.users : name =\u003e user if user.is_admin } } splat表达式 splat表达式提供了更简单语法，在某些情况下代替for表达式： [for o in var.list : o.id] # 等价于 var.list[*].id [for o in var.list : o.interfaces[0].name] # 等价于 var.list[*].interfaces[0].name 可选object属性 variable \"with_optional_attribute\" { type = object({ a = string # 必须属性 b = optional(string) # 可选属性 }) } 版本约束 版本约束是一个特殊的字符串值，在引用module、使用provider时，或者通过terraform块的required_version时，需要用到版本约束： # 版本范围区间 version = \"\u003e= 1.2.0, \u003c 2.0.0\" # 操作符 = 等价于无操作符，限定特定版本 != 排除特定版本 \u003e \u003e= \u003c \u003c= 限制版本范围 ~\u003e 允许最右侧的版本号片段的变化 depends_on 该元参数用于处理隐含的资源/模块依赖，这些依赖无法通过分析Terraform配置文件得到。从0.13版本开始，该元参数可用于模块。之前的版本仅仅用于资源。 depends_on的值是一个列表，其元素具必须是其它资源的引用，不支持任意表达式。 depends_on应当仅仅用作最后手段，避免滥用。 resource \"aws_iam_role\" \"example\" { name = \"example\" assume_role_policy = \"...\" } # 这个策略允许运行在EC2中的实例访问S3 API resource \"aws_iam_role_policy\" \"example\" { name = \"example\" role = aws_iam_role.example.name policy = jsonencode({ \"Statement\" = [{ \"Action\" = \"s3:*\", \"Effect\" = \"Allow\", }], }) } resource \"aws_iam_instance_profile\" \"example\" { # 这是可以自动分析出的依赖 role = aws_iam_role.example.name } resource \"aws_instance\" \"example\" { ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" # 这是可以自动分析出的依赖，包括传递性依赖 iam_instance_profile = aws_iam_instance_profile.example # 如果这个实例中的程序需要访问S3接口，我们需要用元参数显式的声明依赖 # 从而分配策略 depends_on = [ aws_iam_role_policy.example, ] } count 默认情况下，一个resource块代表单个云上基础设施对象。如果你想用一个resource块生成多个类似的资源，可以用count或for_each参数。 设置了此元参数的上下文中，可以访问名为 count的变量，它具有属性 index，为从0开始计数的资源实例索引。 示例： resource \"aws_instance\" \"server\" { # 创建4个类似的实例 count = 4 ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" tags = { # 实例的索引作为tag的一部分 Name = \"Server ${count.index}\" } } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:4","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"for_each 如果资源的规格几乎完全一致，可以用count，否则，需要使用更加灵活的for_each元参数。 for_each的值必须是一个映射或set(string)，你可以在上下文中访问 each对象， 它具有 key和 value两个属性，如果for_each的值是集合，则key和value相等。示例： resource \"azurerm_resource_group\" \"rg\" { for_each = { a_group = \"eastus\" another_group = \"westus2\" } # 对于每个键值对都会生成azurerm_resource_group资源 name = each.key location = each.value } resource \"aws_iam_user\" \"the-accounts\" { # 数组转换为集合 for_each = toset( [\"Todd\", \"James\", \"Alice\", \"Dottie\"] ) name = each.key } variable \"vpcs\" { # 这里定义了map类型的变量，并且限定了map具有的键 type = map(object({ cidr_block = string })) } # 创建多个VPC资源 resource \"aws_vpc\" \"example\" { for_each = var.vpcs cidr_block = each.value.cidr_block } # 上述资源作为下面那个for_each的值 # 创建对应数量的网关资源 resource \"aws_internet_gateway\" \"example\" { # 为每个VPC创建一个网关 # 资源作为值 for_each = aws_vpc.example # 映射的值，在这里是完整的VPC对象 vpc_id = each.value.id } # 输出所有VPC ID output \"vpc_ids\" { value = { for k, v in aws_vpc.example : k =\u003e v.id } # 显式依赖网关资源，确保网关创建后，输出才可用 depends_on = [aws_internet_gateway.example] } ","date":"2023-11-22","objectID":"/posts/2023-11-22-terraform-handbook/:3:5","tags":["tf","terraform"],"title":"Terraform handbook","uri":"/posts/2023-11-22-terraform-handbook/"},{"categories":["DevOps"],"content":"Timezone 参考链接： https://bbs.huaweicloud.com/blogs/detail/243151 http://www.timeofdate.com/timezone/abbr/all ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:0:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"一、设置时区 timedatectl set-timezone Asia/Shanghai ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:1:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"二、时区详细 ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"1、概念 ​ 在以前全球国家都处于农业社会的时候，人们通过每天观察太阳的位置来决定时间，这就使得不同经度的地方有不同的时间。当时人们旅行主要靠走和马匹，不同地方时间不一致的问题没有那么突出。但是到了十九世纪随着火车的发明，人们一天旅行的距离一下子延长了很多，到不同的地方因此迫切需要一个通用的方法把各个地方的时间统一起来。1853年8月12日，美国东部罗德岛州，两辆火车迎头相撞，14人因此死亡。事故的原因在今天看来难以置信——两车工程师的手表差了2分钟。 1863年，首次使用时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。 1870年代加拿大铁路工程师弗莱明首次提出全世界按统一标准划分时区。 1883年11月18日，美国铁路部门正式实施五个时区。 1884年华盛顿子午线国际会议正式通过采纳这种时区划分，称为世界标准时制度。因此，世界标准时区的诞生同其它全球标准一样也是有一个缓慢的发展过程。 ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:1","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"2、通用名词解释 时区 ：时区是地球上的区域使用同一个时间定义。以前，人们通过观察太阳的位置（时角）决定时间，这就使得不同经度的地方的时间有所不同（地方时）。1863年，首次使用时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。世界各个国家位于地球不同位置上，因此不同国家，特别是东西跨度大的国家日出、日落时间必定有所偏差。这些偏差就是所谓的时差。 格林尼治标准时间： GMT（Greenwich Mean Time）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义为在那里通过的经线。由于地球在它的椭圆轨道里的运动速度不均匀，地球每天的自转是有些不规则的，而且正在缓慢减速。所以，格林尼治时间已经不再被作为标准时间使用。 世界协调时间 ：UTC（Coordinated Universal Time）是经过平均太阳时(以格林威治时间GMT为准)、地轴运动修正后的新时标以及以「秒」为单位的国际原子时所综合精算而成的时间。UTC比GMT来得更加精准。对于现行表款来说，GMT与UTC的功能与精确度是没有差别的。 夏日节约时间 ：DST（Daylight Saving Time）又称日光节约时制，在英国称为夏令时间(Summer Time)。是一种为节约能源而人为规定地方时间的制度，在这一制度实行期间所采用的统一时间称为“夏令时间”。一般在天亮较早的夏季人为将时间调快一小时，可以使人早起早睡，减少照明量，以充分利用光照资源，从而节约照明用电。各个采纳夏时制的国家规定不同。 时区表示法 如果时间是以协调世界时（UTC）表示，则在时间后面直接加上一个“Z”（不加空格）。“Z”是协调世界时中0时区的标志。因此，“09:30 UTC”就写作“09:30Z”或是“0930Z”。“14:45:15 UTC”则为“14:45:15Z”或“144515Z”。UTC时间也被叫做祖鲁时间，因为在北约音标字母中用“Zulu”表示“Z”。 UTC偏移量 ：UTC偏移量是协调世界时（UTC）和特定地点的日期与时间差异，其单位为小时和分钟。它通常以 ±[hh]:[mm]、±[hh][mm]、或 ±[hh]的格式显示。所以，如果被描述的时间比UTC早一小时（例如柏林的冬季时间），UTC的偏移量将是”+01:00”、”+0100”、或简单显示为”+01”。 ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:2","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"3、linux时区存储位置 为了避免因国家或地区问题，一般时区设置是以城市为标准 [root@sugar2 Asia]# pwd /usr/share/zoneinfo/Asia [root@sugar2 Asia]# ls Aden Baku Colombo Ho_Chi_Minh Kashgar Magadan Pyongyang Singapore Ujung_Pandang Almaty Bangkok Dacca Hong_Kong Kathmandu Makassar Qatar Srednekolymsk Ulaanbaatar Amman Barnaul Damascus Hovd Katmandu Manila Qostanay Taipei Ulan_Bator Anadyr Beirut Dhaka Irkutsk Khandyga Muscat Qyzylorda Tashkent Urumqi Aqtau Bishkek Dili Istanbul Kolkata Nicosia Rangoon Tbilisi Ust-Nera Aqtobe Brunei Dubai Jakarta Krasnoyarsk Novokuznetsk Riyadh Tehran Vientiane Ashgabat Calcutta Dushanbe Jayapura Kuala_Lumpur Novosibirsk Saigon Tel_Aviv Vladivostok Ashkhabad Chita Famagusta Jerusalem Kuching Omsk Sakhalin Thimbu Yakutsk Atyrau Choibalsan Gaza Kabul Kuwait Oral Samarkand Thimphu Yangon Baghdad Chongqing Harbin Kamchatka Macao Phnom_Penh Seoul Tokyo Yekaterinburg Bahrain Chungking Hebron Karachi Macau Pontianak Shanghai Tomsk Yerevan ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:2:3","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["DevOps"],"content":"三、时区简写 UTC GMT SGT 新加坡时间 Singapore（CST时间有多个地区相同的名字） HKT 香港时间 Hongkong Asia/Hong_Kong ","date":"2023-11-20","objectID":"/posts/2023-11-20-timezone/:3:0","tags":["timezone","tz"],"title":"Timezone","uri":"/posts/2023-11-20-timezone/"},{"categories":["Other"],"content":"电脑一键恢复： Dell： F12 –\u003e Supportassist OS Recovery MSI：F3 Huawei: F10 Mac: 长按电源键直到Option出现（m系列mac） 联想：https://robotrs.lenovo.com.cn/ZmptY2NtYW5hZ2Vy/p4data/Rdata/Rfiles/OKR.html ","date":"2023-11-20","objectID":"/posts/2023-11-20-pc/:0:0","tags":["recovery","pc"],"title":"Recovery","uri":"/posts/2023-11-20-pc/"},{"categories":["Other"],"content":"ventoy ","date":"2023-11-20","objectID":"/posts/2023-11-20-pc/:1:0","tags":["recovery","pc"],"title":"Recovery","uri":"/posts/2023-11-20-pc/"},{"categories":["Other"],"content":"1、使用说明 ventoy下载链接： 官方：https://www.ventoy.net/cn/download.html 国内镜像：https://mirror.nju.edu.cn/github-release/ventoy/Ventoy/ 下载解压后执行Ventoy2Disk https://www.ventoy.net/cn/doc_secure.html ","date":"2023-11-20","objectID":"/posts/2023-11-20-pc/:1:1","tags":["recovery","pc"],"title":"Recovery","uri":"/posts/2023-11-20-pc/"},{"categories":["DevOps"],"content":"Git使用规范 一、commit \u003ctype\u003e(scope): \u003csubject\u003e Header \u003cBLANK LINE\u003e \u003cbody\u003e Body \u003cBALNK LINE\u003e \u003cfooter\u003e Footer commit message包含Header、Body、Footer三个部分，其中Header是必须的 Header 用于说明commit的类型 feat：新功能 fix：BUG修复 docs：对文档或说明的改变 revert：revert之前的commit ","date":"2023-11-19","objectID":"/posts/2023-11-19-git-to-use/:0:0","tags":["git-branch","branch","dev"],"title":"Git-to-use","uri":"/posts/2023-11-19-git-to-use/"},{"categories":["DevOps"],"content":"二、分支命名规范 master：长期分支，与生产环境发布的代码保持同步，每个commit就是一个发布版本 develop：长期分支，用于汇总各分支代码 release-*：短期分支，每个版本的测试阶段和发布阶段时使用的分支 hotfix-*：短期分支，用于生产环境发生问题时，用来解决问题而拉取的分支，进行修改bug feature-*：短期分支，用于开发新功能 格式为： release-6.5.0 hotfix-6.5.0 feature-6.5.0 feature-somesymbol ","date":"2023-11-19","objectID":"/posts/2023-11-19-git-to-use/:0:1","tags":["git-branch","branch","dev"],"title":"Git-to-use","uri":"/posts/2023-11-19-git-to-use/"},{"categories":["DevOps"],"content":"三、保护分支 1、master和develop为保护分支（protect branch）只有管理员有权操作。 master分支的每一个commit对应一个tag（发布的版本） 2、release-*分支时在develop合并feature分支后，拉出的新分支，release分支一定是要从develop拉出的新分支，用户测试以及pre上线，期间产生的bug都在release分支上提交，在pre上测试通过后再发布生产环境，然后再将release分支合并到develop和master分支，并在master上新建tag 3、hotfix分支是生产环境发生问题，从master的commit或tag中拉出的分支，经过测试和发布后分别合到develop和master分支。 ","date":"2023-11-19","objectID":"/posts/2023-11-19-git-to-use/:0:2","tags":["git-branch","branch","dev"],"title":"Git-to-use","uri":"/posts/2023-11-19-git-to-use/"},{"categories":["DevOps"],"content":"SVN ","date":"2023-11-18","objectID":"/posts/2023-11-18-svn/:1:0","tags":["svn","vcs","dev"],"title":"svn","uri":"/posts/2023-11-18-svn/"},{"categories":["DevOps"],"content":"介绍： 代码版本管理工具 能记住本版修改的情况 查看所有的修改记录 恢复到任何历史版本 恢复已经删除的文件 svn与git相比的优势: 使用简单、上手快 目录权限控制，企业安全必备 子目录checkout，减少不必要的文件检出 缺点： svc是集中到版本库控制，需要依赖于中央版本控制服务，git是分布式的，可以独立工作 主要应用: 开发人员代码版本管理 重要文件的存储 关系内部文件共享 windows客户端：TortoiseSVN ","date":"2023-11-18","objectID":"/posts/2023-11-18-svn/:1:1","tags":["svn","vcs","dev"],"title":"svn","uri":"/posts/2023-11-18-svn/"},{"categories":["DevOps"],"content":"安装 基于centos7 1、安装svn [root@localhost ~]# yum -y install svn 2、创建svn版本库 创建版本库目录 [root@localhost /]# mkdir -p /svn/repos [root@localhost /]# svnadmin create /svn/repos 3、配置svn [root@localhost repos]# ll total 8 drwxr-xr-x 2 root root 54 Jun 13 21:47 conf drwxr-sr-x 6 root root 233 Jun 13 21:47 db -r--r--r-- 1 root root 2 Jun 13 21:47 format drwxr-xr-x 2 root root 231 Jun 13 21:47 hooks drwxr-xr-x 2 root root 41 Jun 13 21:47 locks -rw-r--r-- 1 root root 229 Jun 13 21:47 README.txt 1）conf目录 [root@localhost conf]# ll total 12 -rw-r--r-- 1 root root 1080 Jun 13 21:47 authz -rw-r--r-- 1 root root 309 Jun 13 21:47 passwd -rw-r--r-- 1 root root 3090 Jun 13 21:47 svnserve.conf authz：负责账号权限的管理，控制账号是否读写权限 passwd：负责账号和密码的用户名单管理 svnserve.conf：svn服务器配置文件 2）authz配置文件 [root@localhost conf]# vim authz [repos:/] # / 表示根目录 ，既/svn/repos cccc = rw # rw表示seialt用户拥有读写权限 abc = rw # 组设置 [groups] # harry_and_sally = harry,sally # harry_sally_and_joe = harry,sally,\u0026joe iso = zhang,wang test = li # [/foo/bar] # harry = rw # \u0026joe = r # * = [repos:/iso] jk = rw [repos:/data] @iso = rw # [repository:/baz/fuz] # @harry_and_sally = rw # * = r [repos:/] cccc = rw abc = rw 3）passwd文件 [root@localhost conf]# vim passwd [users] # harry = harryssecret # sally = sallyssecret cccc = 123456 abc = 123 4）svnserve.conf文件 [root@localhost conf]# vim svnserve.conf [root@localhost conf]# vim svnserve.conf 19 anon-access = none 20 auth-access = write 27 password-db = passwd 34 authz-db = authz 39 realm = cccc anon-access = none：表示禁止匿名用户访问。 auth-access = write：表示授权用户拥有读写权限。 password-db = passswd：指定用户名口令文件，即 passwd 文件。 authz-db = authz：指定权限配置文件，即 authz 文件。 realm = cccc：指定认证域，即/svn/repos目录。 4、启动svn [root@localhost conf]# svnserve -d -r /svn [root@localhost conf]# ps -ef | grep svn root 10923 1 0 22:49 ? 00:00:00 svnserve -d -r /repo root 10925 1396 0 22:49 pts/0 00:00:00 grep --color=auto svn [root@localhost conf]# ss -anpl | grep svn tcp LISTEN 0 7 *:3690 *:* users:((\"svnserve\",pid=10923,fd=3)) [root@localhost conf]# 5、连接 [root@localhost conf]# svn co svn://127.0.0.1/repos Authentication realm: \u003csvn://127.0.0.1:3690\u003e /repos Password for 'root': Authentication realm: \u003csvn://127.0.0.1:3690\u003e /repos Username: cccc Password for 'cccc': ----------------------------------------------------------------------- ATTENTION! Your password for authentication realm: \u003csvn://127.0.0.1:3690\u003e /repos can only be stored to disk unencrypted! You are advised to configure your system so that Subversion can store passwords encrypted, if possible. See the documentation for details. You can avoid future appearances of this warning by setting the value of the 'store-plaintext-passwords' option to either 'yes' or 'no' in '/root/.subversion/servers'. ----------------------------------------------------------------------- Store password unencrypted (yes/no)? yes Checked out revision 0. [root@localhost conf]# 6、使用sasldb加密密码文件 说明：Linux下使用svnserve的SASL认证能解决这个问题，subversion1.5以上的版本默认装了sasl认证，解决svnserve密码文件passwd是明文的问题，生成一个sasl认证的密码文件sasldb。 1）修改conf/svnserve.conf文件 [sasl] use-sasl = true min-encryption = 128 max-encryption = 256 注释：# password-db = passwd这行保持注释掉的状态，不使用passwd文件。变量 min-encryption 和 max-encryption 控制服务器所需要的加密强度。要完全禁用加密，就将这 2 个变量的值都设为 0。要启用简单的数据校验(例如，为了防止篡改和保证数据的完整，不加密)，就将这 2 个值都设为 1。如果你想允许(但不强制)加密，将最小值设为 0，最大值设为任意位数。要强制加密，将这 2 个值设为大于 1 的数字。在前面的例子中，我们要求客户端至少进行 128 位加密，但是不大于 256 位加密。 2）新建svn.conf文件 一般放在/usr/Lib/sasl2或者/etc/sasl2，内容如下 pwcheck_method: auxprop auxprop_plugin: sasldb sasldb_path: /svn/repo/cccc/sasldb mech_list: DIGEST-MD5 注释：pwcheck_method指明检查的方法，这里是“auxprop ”，这个pwcheck_method还对应了如启动一个代理作为认证服务等方式，而现在的意思就是使用本文件说的方式去检查。然后我们指明auxprop_plugin为sasldb，也就是使用一个文件存放用户名密码，也就是/home/svn/svnjiami/sasldb,其它的认证信息存放plugin还有sql和ldapdb。而mech_list指明了认证信息传递机制。 3）重启svn 如果 svnserve 已经在运行，你需要重启服务，并确保它读取了更新后的配置参数 killall svnserve //停止svnserve服务 svnserve –d –r /svn/repos //启动svnserve服务 4）创建加密后的用户和密码 saslpasswd2 -c -f /svn/repo/cccc/sasldb -u cccc cccc # –u [svnserve.conf里面配置的realm名字] [username] -p \u003cpw //新建用户，可修改用户用","date":"2023-11-18","objectID":"/posts/2023-11-18-svn/:1:2","tags":["svn","vcs","dev"],"title":"svn","uri":"/posts/2023-11-18-svn/"},{"categories":["DevOps"],"content":"Git ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:0:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"一、git基本使用 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、commit [root@node01 project]# git add 1.txt [root@node01 project]# git commit -m \"create new 1.txt\" [master (root-commit) 3e8ce87] create new 1.txt 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 1.txt ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"2、diff文件 [root@node01 project]# git diff 1.txt diff --git a/1.txt b/1.txt index e69de29..21d56a0 100644 --- a/1.txt +++ b/1.txt @@ -0,0 +1 @@ +1111111111111111 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:2","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"3、版本回退 在进行版本回退时，使用HEAD代表当前版本，HEAD^ 代表上一个版本，HEAD^^代表上上个版本，还可以使用HEAD~10代表前10个版本 [root@node01 project]# git reset --hard HEAD^ HEAD is now at fdf9d68 add new 1111 [root@node01 project]# [root@node01 project]# cat 1.txt 1111111111111111 [root@node01 project]# 也可以使用如下命令格式: [root@node01 project] git reset --hard \u003ccommit_id\u003e [root@node01 project]# git reflog 1.txt fdf9d68 HEAD@{0}: reset: moving to HEAD^ 996cc77 HEAD@{1}: commit: add new 222 fdf9d68 HEAD@{2}: commit: add new 1111 3e8ce87 HEAD@{3}: commit (initial): create new 1.txt [root@node01 project]# [root@node01 project]# git reset --hard 996cc77 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:3","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"4、撤销更改 1）对于尚未添加到暂存区的修改，可直接通过编辑原文件或者使用git checkout -- \u003cfile\u003e的方式进行撤销 [root@node01 project]# git checkout -- 1.txt [root@node01 project]# git status # On branch master nothing to commit, working directory clean 2）对于已经添加到暂存区，但还没有git commit的修改，可使用git reset HEAD \u003cfile\u003e的方式撤销 [root@node01 project]# vim 1.txt [root@node01 project]# git add 1.txt [root@node01 project]# git status # On branch master # Changes to be committed: # (use \"git reset HEAD \u003cfile\u003e...\" to unstage) # # modified: 1.txt # [root@node01 project]# git reset HEAD 1.txt Unstaged changes after reset: M 1.txt [root@node01 project]# git status # On branch master # Changes not staged for commit: # (use \"git add \u003cfile\u003e...\" to update what will be committed) # (use \"git checkout -- \u003cfile\u003e...\" to discard changes in working directory) # # modified: 1.txt # no changes added to commit (use \"git add\" and/or \"git commit -a\") [root@node01 project]# git checkout -- 1.txt [root@node01 project]# git status # On branch master nothing to commit, working directory clean [root@node01 project]# cat 1.txt 1111111111111111 22222222222222222 3333333333333 3）对于已经添加到暂存区，并已经提交的修改可通过git reset –hard \u003ccommit_id\u003e的方式进行撤销 [root@node01 project]# vim 1.txt [root@node01 project]# git add 1.txt [root@node01 project]# git commit -m \"add new 44444444\" [master 240af53] add new 44444444 1 file changed, 1 insertion(+) [root@node01 project]# git reflog 1.txt 240af53 HEAD@{0}: commit: add new 44444444 5424335 HEAD@{1}: commit: add new 333333 996cc77 HEAD@{2}: reset: moving to 996cc77 3e8ce87 HEAD@{3}: reset: moving to 3e8ce87 996cc77 HEAD@{4}: reset: moving to 996cc77 fdf9d68 HEAD@{5}: reset: moving to HEAD^ 996cc77 HEAD@{6}: commit: add new 222 fdf9d68 HEAD@{7}: commit: add new 1111 3e8ce87 HEAD@{8}: commit (initial): create new 1.txt [root@node01 project]# [root@node01 project]# [root@node01 project]# git reset --hard 5424335 HEAD is now at 5424335 add new 333333 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:1:4","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"二、git配置 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、配置基本信息 [root@localhost srv]# git config --global user.name 'sugar' [root@localhost srv]# git config --global user.email 't@local.com' [root@localhost srv]# git config --global color.ui true #配置显示的颜色，方便看到更改的信息 [root@localhost srv]# git config --global core.ignorecase false # 配置大小写敏感，git默认大小写不敏感 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"2、gitconfig配置文件 [user] name = sugar email = t@local.com # signingkey = DCE96Cxxxxxxxxxxxxxxxxxxxxxxxx #[commit] # gpgsign = true # ~/github/ 目录下的项目使用~/github/.gitconfig下的gitconfig配置文件 [includeIf \"gitdir:~/github/\"] path = ~/github/.gitconfig [includeIf \"gitdir:~/my-prod/\"] path = ~/my-prod/.gitconfig [init] defaultBranch = main [color] ui = true [alias] lg = log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u003c%an\u003e%Creset' --abbrev-commit [alias] # status st = status ss = status --short --branch # stash sh = stash shp = stash pop shl = stash list shs = stash save sha = stash apply std = stash drop # branch br = branch bra = branch -a brm = branch -m co = checkout cob = checkout -b sw = switch swc = switch -c # remote ra = remote add rao = remote add origin ru = remote set-url ruo = remote set-url origin rv = remote -v # fetch fe = fetch fep = fetch -p fo = fetch origin fop = fetch origin -p # merge mr = merge mnc = merge --no-commit # msq = merge --squash # commit cm = commit -m # config user and mail user = config user.name mail = config user.email [url \"git@github.com:username\"] insteadOf = https://github.com/username # 强制https转ssh协议 [url \"ssh://git@local.com/\"] insteadOf = https://local.com/ [core] excludesfile = ~/.gitignore_global autocrlf = input quotepath = false ignorecase = false editor = vim # sshCommand = ssh -i ~/.ssh/id_rsa -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no [i18n \"commit\"] encoding = utf-8 [i18n] logoutputencoding = utf-8 [http \"https://github.com\"] proxy = socks5://127.0.0.1:8888 [http] proxy = http://127.0.0.1:8889 [https] proxy = http://127.0.0.1:8889 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:2","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"3、windows上终端打开出现乱码 cmd配置 git config --global core.quotepath false git config --global gui.encoding utf-8 git config --global i18n.commit.encoding utf-8 git config --global i18n.logoutputencoding utf-8 # bash 环境下 export LESSCHARSET=utf-8 # cmd环境下： set LESSCHARSET=utf-8 powershell配置 git config --global core.quotepath false git config --global gui.encoding utf-8 git config --global i18n.commit.encoding utf-8 git config --global i18n.logoutputencoding utf-8 $env:LESSCHARSET='utf-8' git bash sugar@sugar MINGW64 /e/Desktop/company/github (master) $ cat /etc/bash.bashrc alias ls='ls -F --color --show-control-chars' NOW_DIR=\"E:\\Desktop\" cd ${NOW_DIR} export LESSCHARSET=utf-8 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:2:3","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"三、分支管理 git版本库所有的操作都是运行在分支上，git仓库创建时会建立默认的分支，名称为master；所有的操作都在master分支上进行 在对版本库中的文件进行操作时，可以创建不同的分支，不同的操作运行在不同的分支上，不同分支上的操作不会相互干扰，操作进行完成后，可以合并不同分支上的操作 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:3:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、创建分支 [root@node01 project]# git checkout -b game Switched to a new branch 'game' [root@node01 project]# [root@node01 project]# git branch dev * game master 1）远程chekout到本地 [root@node01 project]# git checkout origin/develop -b develop 2）删除分支 # 删除本地分支 [root@node01 project]# git branch -d release-1.1.0 # 强制删除 [root@node01 project]# git branch -D release-1.1.0 # 删除远程分支 [root@node01 project]# git push origin --delete release-1.1.0 或者 [root@node01 project]# git push origin :release-1.1.0 3）根据hash值进行checkout git checkout d21a8c517ca3xxxxxxxxxxxxxxxxxxxxxxxxxxx 4）分支合并 切换到准备合并后的分支，合并其他分支到当前分支 [root@node01 project]# git merge dev Updating bb6fb7a..d83dae8 Fast-forward 1.txt | 2 ++ 1 file changed, 2 insertions(+) ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:3:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"四、tag管理 打标签，用于仓库某个提交打上标签，以表示其特殊性。比较有代表性的是人们会使用这个功能来标记发布结点（ v1.0 、 v2.0 等等） 1、查看本地已有标签 [root@localhost github_web]# git tag 4.101.0 4.103.0 4.103.1 列出所有标签 -l或者--list，指定某些提交信息-l \"v4.4*\" 2、创建tag Git 支持两种标签： 轻量标签（lightweight） 附注标签（annotated）。 轻量标签很像一个不会改变的分支——它只是某个特定提交的引用。 而附注标签是存储在 Git 数据库中的一个完整对象， 它们是可以被校验的，其中包含打标签者的名字、电子邮件地址、日期时间， 此外还有一个标签信息，并且可以使用 GNU Privacy Guard （GPG）签名并验证。 通常会建议创建附注标签，这样你可以拥有以上所有信息。但是如果你只是想用一个临时的标签， 或者因为某些原因不想要保存这些信息，那么也可以用轻量标签。 附属标签： git tag -a v1.4 -m \"my version 1.4\" 查看详细信息 git show v1.4 输出显示了打标签者的信息、打标签的日期时间、附注信息，然后显示具体的提交信息。 轻量标签: 另一种给提交打标签的方式是使用轻量标签。 轻量标签本质上是将提交校验和存储到一个文件中——没有保存任何其他信息。 创建轻量标签，不需要使用 -a、-s 或 -m 选项，只需要提供标签名字： $ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息： $ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u003ct@local.com\u003e Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number 后期打标签 git tag -a v1.2 9fceb02 共享标签 默认情况下，git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样——你可以运行 git push origin \u003ctagname\u003e。 $ git push origin v1.5 Counting objects: 14, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (14/14), 2.05 KiB | 0 bytes/s, done. Total 14 (delta 3), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.5 -\u003e v1.5 如果想要一次性推送很多标签，也可以使用带有 --tags 选项的 git push 命令。 这将会把所有不在远程仓库服务器上的标签全部传送到那里。 $ git push origin --tags Counting objects: 1, done. Writing objects: 100% (1/1), 160 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.4 -\u003e v1.4 * [new tag] v1.4-lw -\u003e v1.4-lw 3、删除标签 要删除掉你本地仓库上的标签，可以使用命令 git tag -d \u003ctagname\u003e。 例如，可以使用以下命令删除一个轻量标签： $ git tag -d v1.4-lw Deleted tag 'v1.4-lw' (was e7d5add) 注意上述命令并不会从任何远程仓库中移除这个标签，你必须用 git push \u003cremote\u003e :refs/tags/\u003ctagname\u003e 来更新你的远程仓库： 方法一：git push \u003cremote\u003e :refs/tags/\u003ctagname\u003e $ git push origin :refs/tags/v1.4-lw To /git@github.com:username/project.git - [deleted] v1.4-lw 上面这种操作的含义是，将冒号前面的空值推送到远程标签名，从而高效地删除它。 方法二：直接删除远程标签 $ git push origin --delete \u003ctagname\u003e 4、检出标签 检出标签为一个分支，格式为git checkout -b branch_name tag_name git checkout -b version2 v2.0.0 5、.git 目录 ├── HEAD ├── branches ├── config ├── description ├── hooks │ ├── pre-commit.sample │ ├── pre-push.sample │ └── ... ├── info │ └── exclude ├── objects │ ├── info │ └── pack └── refs ├── heads └── tags config （配置）该文件包含你的仓库配置，比如远程的 url ，你的邮箱和用户名等。每次你在控制台使用 git config… 都会对这里产生影响。 description（描述）供 gitweb ( github 的一种前身) 使用，显示仓库的描述。 hooks (钩子)这是一个有趣的特性。 Git 提供了一套脚本，可以在每个有意义的 Git 阶段自动运行。这些被称为钩子的脚本可以在提交 (commit)、变基 (rebase)、拉取 ( pull ) 操作的前后运行。脚本命预示着它的执行时机。如我们可以编写 pre-push 的作为钩子，进行推送代码前的检查。 info (信息)你可以将不想被 git 管理的文件记录到 .gitignore 文件中。排除文件的意思是不想共享这个文件。例如你不想共享你的 IDE 自定义配置，将其添加到 .gitignore 文件中即可。 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:4:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"五、cherry-pick 参考：https://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html 对于多分支的代码库，将代码从一个分支转移到另一个分支是常见需求。 这时分两种情况。一种情况是，你需要另一个分支的所有代码变动，那么就采用合并（git merge）。另一种情况是，你只需要部分代码变动（某几个提交），这时可以采用 Cherry pick。 1、基本语法 git cherry-pick命令的作用，就是将指定的提交（commit）应用于其他分支。 $ git cherry-pick \u003ccommitHash\u003e 上面命令就会将指定的提交commitHash，应用于当前分支。这会在当前分支产生一个新的提交，当然它们的哈希值会不一样。 举例来说，代码仓库有master和feature两个分支。 a - b - c - d Master \\ e - f - g Feature 现在将提交f应用到master分支。 # 切换到 master 分支 $ git checkout master # Cherry pick 操作 $ git cherry-pick f 上面的操作完成以后，代码库就变成了下面的样子。 a - b - c - d - f Master \\ e - f - g Feature 从上面可以看到，master分支的末尾增加了一个提交f。 git cherry-pick命令的参数，不一定是提交的哈希值，分支名也是可以的，表示转移该分支的最新提交。 $ git cherry-pick feature 上面代码表示将feature分支的最近一次提交，转移到当前分支。 操作示例： [sugar@centos-7 git-test]$ git log -1 commit dcf3a215fd6ba3288ad21584d2112bdab5a713b4 Author: sugar \u003ccccc@gmail.com\u003e Date: Sun Sep 12 14:29:26 2021 +0800 feat: v1 version 1s add [sugar@centos-7 git-test]$ git checkout master Switched to branch 'master' [sugar@centos-7 git-test]$ git log commit 31da420cc2d2ae6094f88e368a72f0353541d89f Author: sugar \u003ccccc@gmail.com\u003e Date: Sun Sep 12 14:25:43 2021 +0800 feat: 第一此增加 [sugar@centos-7 git-test]$ git cherry-pick dcf3a215fd6ba3288ad21584d2112bdab5a713b4 [master fa78bb0] feat: v1 version 1s add 1 file changed, 2 insertions(+), 1 deletion(-) [sugar@centos-7 git-test]$ ls cccc.txt [sugar@centos-7 git-test]$ git log -1 commit fa78bb090d3221ba2ff9cae59efa1f8691677115 Author: sugar \u003ccccc@gmail.com\u003e Date: Sun Sep 12 14:29:26 2021 +0800 feat: v1 version 1s add 2、转移多个commit Cherry pick 支持一次转移多个提交 [sugar@centos-7 git-test]$ git cherry-pick \u003cHashA\u003e \u003cHashB\u003e 连续提交多个commit # 提交A到B的commit，但不包含A；提交A必须早于提交B，否则命令将失败，但不会报错。 [sugar@centos-7 git-test]$ git cherry-pick A..B # 提交A到B的commit，包含A [sugar@centos-7 git-test]$ git cherry-pick A^..B 3、参数 git cherry-pick命令的常用配置项如下。 （1）-e，--edit 打开外部编辑器，编辑提交信息。 （2）-n，--no-commit 只更新工作区和暂存区，不产生新的提交。 （3）-x 在提交信息的末尾追加一行(cherry picked from commit ...)，方便以后查到这个提交是如何产生的。 （4）-s，--signoff 在提交信息的末尾追加一行操作者的签名，表示是谁进行了这个操作。 （5）-m parent-number，--mainline parent-number 如果原始提交是一个合并节点，来自于两个分支的合并，那么 Cherry pick 默认将失败，因为它不知道应该采用哪个分支的代码变动。 -m配置项告诉 Git，应该采用哪个分支的变动。它的参数parent-number是一个从1开始的整数，代表原始提交的父分支编号。 $ git cherry-pick -m 1 \u003ccommitHash\u003e 上面命令表示，Cherry pick 采用提交commitHash来自编号1的父分支的变动。 一般来说，1号父分支是接受变动的分支（the branch being merged into），2号父分支是作为变动来源的分支（the branch being merged from）。 4、代码冲突 如果操作过程中发生代码冲突，Cherry pick 会停下来，让用户决定如何继续操作。 1）--contine 用户解决代码冲突后，第一步将修改的文件重新加入暂存区（git add .），第二步使用下面的命令，让 Cherry pick 过程继续执行。 $ git cherry-pick --continue 2）--abort 发生代码冲突后，放弃合并，回到操作前的样子。 3）--quit 发生代码冲突后，退出 Cherry pick，但是不回到操作前的样子。 5、转移到另外一个仓库 Cherry pick 也支持转移另一个代码库的提交，方法是先将该库加为远程仓库。 # 添加一个远程仓库 $ git remote add target git://gitUrl # 将远程仓库的代码抓取到本地 $ git fetch target # 检查一下要从远程仓库转移的提交，获取它的哈希值 $ git log target/master # 使用git cherry-pick命令转移提交 $ git cherry-pick \u003ccommitHash\u003e ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:5:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"六、合并commit 在使用 Git 作为版本控制的时候，我们可能会由于各种各样的原因提交了许多临时的 commit，而这些 commit 拼接起来才是完整的任务。那么我们为了避免太多的 commit 而造成版本控制的混乱，通常我们推荐将这些 commit 合并成一个。 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"1、查看提交历史 $ git log commit 3ca6ec340edc66df13423f36f52919dfa3...... commit 1b4056686d1b494a5c86757f9eaed844...... commit 53f244ac8730d33b353bee3b24210b07...... commit 3a4226b4a0b6fa68783b07f1cee7b688....... ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:1","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"2、git rebase 想要合并1-3条，有两个方法 1）从HEAD版本开始往过去数3个版本 $ git rebase -i HEAD~3 2）指名要合并的版本之前的版本号 $ git rebase -i 3a4226b 请注意3a4226b这个版本是不参与合并的，只是把它当做一个坐标 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:2","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"3、选择要合并的提交 p是保留，s是合并 1）执行了rebase命令之后，会弹出一个窗口，头几行如下： pick 3ca6ec3 '注释**********' pick 1b40566 '注释*********' pick 53f244a '注释**********' 2）将pick改为squash或者s,之后保存并关闭文本编辑窗口即可。改完之后文本内容如下： pick 3ca6ec3 '注释**********' s 1b40566 '注释*********' s 53f244a '注释**********' 3）然后保存退出，Git会压缩提交历史，如果有冲突，需要修改，修改的时候要注意，保留最新的历史，不然我们的修改就丢弃了。修改以后要记得敲下面的命令： pick 3ca6ec3 '注释**********' s 1b40566 '注释*********' s 53f244a '注释**********' ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:3","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"4）冲突解决 然后保存退出，Git会压缩提交历史，如果有冲突，需要修改，修改的时候要注意，保留最新的历史 git add . # 继续合并 git rebase --continue # 放弃合并 git rebase --abort 如果没有冲突，或者冲突已经解决，则会出现如下的编辑窗口： # This is a combination of 4 commits. #The first commit’s message is: 注释...... # The 2nd commit’s message is: 注释...... # The 3rd commit’s message is: 注释...... # Please enter the commit message for your changes. Lines starting # with ‘#’ will be ignored, and an empty message aborts the commit. ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:4","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"5）检查 git log查看 commit 历史信息，查询commit的信息 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:6:5","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"七、Git Hook Git Hook 也分为两个端: 客户端和服务端。 客户端的 Git Hook 就是工作在我们本地机器的，服务端的 Git Hook 则是工作在我们提交到远程的服务器仓库中。 客户端 Git Hook: pre-commit: 执行git commit命令时触发，常用于检查代码风格 prepare-commit-msg: 触发于 commit message 编辑器呼起前 ,default commit message创建后,常用于生成默认的标准化的提交说明 commit-msg: 开发者编写完并确认commit message后触发，常用于校验提交说明是否标准 post-commit: 整个git commit完成后触发，常用于邮件通知、提醒 applypatch-msg: 执行git am命令时触发，常用于检查命令提取出来的提交信息是否符合特定格式 pre-applypatch: git am提取出补丁并应用于当前分支后，准备提交前触发，常用于执行测试用例或检查缓冲区代码 post-applypatch: git am提交后触发，常用于通知、或补丁邮件回复（此钩子不能停止git am过程） pre-rebase: 执行git rebase命令时触发 post-rewrite: 执行会替换commit的命令时触发，比如git rebase或git commit –amend post-checkout: 执行git checkout命令成功后触发，可用于生成特定文档，处理大二进制文件等 post-merge: 成功完成一次 merge行为后触发 pre-push: 执行git push命令时触发，可用于执行测试用例 pre-auto-gc: 执行垃圾回收前触发 服务端 Git Hook: pre-receive: 当服务端收到一个 push 操作请求时触发，可用于检测 push 的内容 update: update 脚本和 pre-receive 脚本十分类似，不同之处在于它会为每一个准备更新的分支各运行一次。 假如推送者同时向多个分支推送内容，pre-receive 只运行一次，相比之下 update 则会为每一个被推送的分支各运行一次。 post-receive: post-receive 挂钩在整个过程完结以后运行，可以用来更新其他系统服务或者通知用户。它的用途包括给某个邮件列表发信，通知持续集成（continous integration）的服务器，或者更新问题追踪系统（ticket-tracking system） —— 甚至可以通过分析提交信息来决定某个问题（ticket）是否应该被开启，修改或者关闭。 使用git hook Git Hook 本身自带有脚本，会存放在仓库 .git/hooks 文件夹中，目录一般是这样的: - YourGitRepo |- .git |- hooks |- hooks--commit-msg.sample |- hooks--post-update.sample ... 注意如果是 sample 文件，要去掉 .sample 后缀，变成前面 Git Hook 分类 中提到对应的操作来作为文件名。 比如我要做的校验 commit 的提交信息，那么使用的 Git Hook 脚本名应该为 commit-msg. 在 hooks--commit-msg.sample 里的内容为: #!/bin/sh # # An example hook script to check the commit log message. # Called by \"git commit\" with one argument, the name of the file # that has the commit message. The hook should exit with non-zero # status after issuing an appropriate message if it wants to stop the # commit. The hook is allowed to edit the commit message file. # # To enable this hook, rename this file to \"commit-msg\". # Uncomment the below to add a Signed-off-by line to the message. # Doing this in a hook is a bad idea in general, but the prepare-commit-msg # hook is more suited to it. # # SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\\(.*\u003e\\).*$/Signed-off-by: \\1/p') # grep -qs \"^$SOB\" \"$1\" || echo \"$SOB\" \u003e\u003e \"$1\" # This example catches duplicate Signed-off-by lines. test \"\" = \"$(grep '^Signed-off-by: ' \"$1\" | sort | uniq -c | sed -e '/^[ ]*1[ ]/d')\" || { echo \u003e\u00262 Duplicate Signed-off-by lines. exit 1 } 上面说明里有一些基本说明, 这里获得的 $1 参数，其实是存放 commit msg 内容的文件路径，为 .git/COMMIT_EDITMSG. 利用命令: msg=$(cat $1) 就能取到 commit 的信息，稍作修改，就能达到我说的，校验团队 commit 信息的规范的目的了。 Git Hook 不生效 如果遇到不起作用的，可能脚本没有打开执行权限，导致没办法执行。我就是这样的情况。 cd 到 .git/hooks 目录下,执行 chmod 777 命令即可,如： chmod 777 commit-msg ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:7:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"八、Git GC 清理不必要的文件并优化本地存储库 参考链接：Git - 管理 | Administration - git gc - 开发者手册 - 云+社区 - 腾讯云 (tencent.com) Git的底层并没有采用 CVS、SVN 底层所采用的那套增量式文件系统，而是采用一套自行维护的存储文件系统。当文件变动发生提交时，该文件系统存储的不是文件的差异信息，而是文件快照，即整个文件内容，并保存指向快照的索引。这种做法，提高 Git 分支的使用效率；但也容易导致代码仓库中内容重复程度过高，从而仓库体积过大。当遇到这种情况时，或者需要将仓库推送到远程主机时，就需要Git中的gc（garbage collect）功能，也就是垃圾回收功能。 大体来说，当运行 “git gc” 命令时，Git会收集所有松散对象并将它们存入 packfile，合并这些 packfile 进一个大的 packfile，然后将不被任何 commit 引用并且已存在一段时间 (数月) 的对象删除。 此外，Git还会将所有引用 (references) 并入一个单独文件。 就细节而言，Git做了这几件事： pack_refs 过程 reflog expire 过程 repack 过程 prune 过程 rerere 过程 概要： git gc [--aggressive] [--auto] [--quiet] [--prune=\u003cdate\u003e | --no-prune] [--force] 描述： 在当前存储库中运行许多内务处理任务，例如压缩文件修订（以减少磁盘空间并提高性能）并移除可能由之前git add调用创建的不可达对象。 鼓励用户在每个存储库中定期运行此任务，以保持良好的磁盘空间利用率和良好的操作性能。 一些git命令可能会自动运行git gc; --auto详细信息请参阅下面的标志。如果您知道自己在做什么，并且所有您想要的都是永久禁用此行为而无需进一步考虑，请执行以下操作： $ git config --global gc.auto 0 选项： –aggressive 通常git gc运行速度很快，同时提供良好的磁盘空间利用率和性能 此选项将导致git gc更积极地优化存储库，但花费更多时间。这种优化的效果是持久的，所以这个选项只需要偶尔使用; 每隔几百个变更集左右。 –auto 使用此选项，git gc检查是否需要进行任何清洁工作; 如果没有，它会退出而不执行任何工作。一些git命令git gc --auto在执行可能会产生许多松散对象的操作之后运行。 如果存储库中的松散对象太多或包装太多，则需要进行内务处理。如果松散对象的数量超过了gc.auto配置变量的值，则所有松散对象都将使用组合到一个包中git repack -d -l。将值设置gc.auto为0将禁用自动填充松散物体。 如果包装数量超过了价值gc.autoPackLimit，那么现有包装（标有.keep文件的包装除外）将通过使用-A选项合并到一个包装中git repack。设置gc.autoPackLimit为0将禁用自动合并包装。 –prune= 修剪比日期更旧的松散对象（默认为2周前，可由配置变量覆盖gc.pruneExpire）。–prune =不管年龄大小，都修剪松散的物体，并且如果另一个进程同时写入存储库，则会增加腐败风险; 请参阅下面的“注意事项”。–prune默认打开。 –no-prune 不要修剪任何松动的物体。 –quiet 取消所有进度报告。 –force git gc即使可能有另一个git gc实例在此存储库上运行，也强制运行。 注意： git gc尽量不要删除在存储库中任何位置引用的对象。特别是，它不仅会保存当前一组分支和标记所引用的对象，还会保留由索引引用的对象，远程跟踪分支，git filter-branchrefs / original /中保存的引用或reflogs（可引用分支中的提交后来修改或倒带）。如果您希望某些对象被删除而不是，请检查所有这些位置，并决定在您的情况下删除这些引用是否有意义。 另一方面，当git gc与另一个进程同时运行时，可能会删除另一个进程正在使用但尚未创建引用的对象。这可能会导致其他进程失败或者可能会损坏存储库，如果其他进程稍后添加对已删除对象的引用。Git有两个功能可以显着缓解这个问题： --prune保留修改时间比日期更新的任何对象以及可从其访问的所有对象。 将对象添加到数据库的大多数操作都会更新对象的修改时间（如果该对象已存在，以便应用＃1）。 然而，这些功能并不能提供完整的解决方案，因此，同时运行命令的用户必须忍受一些腐败风险（实践中似乎很低），除非他们关闭自动垃圾收集git config gc.auto 0 ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:8:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["DevOps"],"content":"九、Git gpg签名 # 查看gpg密钥 [root@local ~]# gpg --list-key /root/.gnupg/pubring.kbx ------------------------ pub rsa4096 2021-08-23 [SC] C40EA42A60xxxxxxxxxxxxxxxxxx uid [ 绝对 ] cccc (local) \u003ct@local.com\u003e sub rsa4096 2021-08-23 [E] pub rsa4096 2021-08-23 [SC] 3CB22116355xxxxxxxxxxxxxxxxxx uid [ 绝对 ] tom (github) \u003ct@local.cc\u003e sub rsa4096 2021-08-23 [E] 配置使用gpg签名 # git 配置使用gpg签名 git config --global user.signingkey \u003cgpg-key-id\u003e # 提交是否强制 GPG，带上--global 是作用全局，局部的去除--global [root@sugar2 ~]# git config --global commit.gpgsign true # commit 提交设置GPG签名，如果没有设置强制，则需要加上-S [root@sugar2 ~]# git commit -S -m “commit message\" # 在github上签名的提交将显示包含“ Verified” 问题： [root@sugar ssl]# git commit -m \"init repo\" error: gpg 数据签名失败 fatal: 写提交对象失败 参考链接：https://zhuanlan.zhihu.com/p/97984430 解决办法：export GPG_TTY=$(tty) 在环境变量里增加一项GPG_TTY ","date":"2023-11-18","objectID":"/posts/2023-11-18-git/:9:0","tags":["git","vcs","dev"],"title":"Git","uri":"/posts/2023-11-18-git/"},{"categories":["安全信息"],"content":"漏洞信息 云服务商安全服务公告 云服务商 链接 cve官网 https://cve.mitre.org/ 阿里云 https://help.aliyun.com/noticelist/9213612.html?spm=a2c4g.789004748.n2.3.cddb4c07NBt9Rl 华为云 https://www.huaweicloud.com/notice.securecenter.html 腾讯云 https://cloud.tencent.com/announce?categorys=21\u0026page=1 阿里云漏洞数据库 https://avd.aliyun.com/ 国家信息漏洞库 http://www.cnnvd.org.cn/ 常用软件官方安全公告链接 名称 链接 redis https://github.com/redis/redis/security nginx http://nginx.org/en/security_advisories.html httpd https://httpd.apache.org/security ","date":"2023-11-12","objectID":"/posts/2023-11-12-security-info/:1:0","tags":["security","cve"],"title":"security-info","uri":"/posts/2023-11-12-security-info/"},{"categories":["安全信息"],"content":"安全服务推送 github: https://github.com/zema1/watchvuln version: \"3\" services: watchvuln: image: zemal/watchvuln container_name: watchvuln hostname: watchvuln restart: always environment: DINGDING_ACCESS_TOKEN: cd316d9dxxxxxxxxxxxxxxxxxxxxxxx DINGDING_SECRET: SECa87a39xxxxxxxxxxxxxxxxxxxxxxxxxxxx LARK_ACCESS_TOKEN: 1ddfb805-xxxxxxxxxxxxxxxxxxxxxxxxxxxx LARK_SECRET: GUUKIrxxxxxxxxxxxxxxxxxxxxxxxxxxxx INTERVAL: 30m volumes: - \"/etc/localtime:/etc/localtime:ro\" ","date":"2023-11-12","objectID":"/posts/2023-11-12-security-info/:2:0","tags":["security","cve"],"title":"security-info","uri":"/posts/2023-11-12-security-info/"},{"categories":["Database"],"content":"SQLite SQLite是一种开源，零配置，独立的，独立的，事务关系数据库引擎，旨在嵌入到应用程序中。 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:0:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"一、安装sqlite SQLite以其零配置而闻名，所以不需要复杂的设置或管理。 # rpm yum -y install sqlite3 # apt apt install sqlite3 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:1:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"二、sqlite命令 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:2:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"进入sqlite [sugar@MacBook-Pro ~]$ sqlite3 SQLite version 3.32.3 2020-06-18 14:16:19 Enter \".help\" for usage hints. Connected to a transient in-memory database. Use \".open FILENAME\" to reopen on a persistent database. sqlite\u003e .exit 如需获取可用的点命令的清单，可以在任何时候输入 “.help” sqlite\u003e .help .auth ON|OFF Show authorizer callbacks .backup ?DB? FILE Backup DB (default \"main\") to FILE .bail on|off Stop after hitting an error. Default OFF .binary on|off Turn binary output on or off. Default OFF .cd DIRECTORY Change the working directory to DIRECTORY .changes on|off Show number of rows changed by SQL .check GLOB Fail if output since .testcase does not match .clone NEWDB Clone data into NEWDB from the existing database .databases List names and files of attached databases .dbconfig ?op? ?val? List or change sqlite3_db_config() options .dbinfo ?DB? Show status information about the database .dump ?TABLE? Render database content as SQL .echo on|off Turn command echo on or off 上面的命令会显示各种重要的 SQLite 点命令的列表，如下所示： 命令 描述 .backup ? DB? FILE 备份 DB 数据库（默认是 “main”）到 FILE 文件。 .bail ON|OFF 发生错误后停止。默认为 OFF。 .databases 列出数据库的名称及其所依附的文件。 .dump ?TABLE? 以 SQL 文本格式转储数据库。如果指定了 TABLE 表，则只转储匹配 LIKE 模式的 TABLE 表。 .echo ON|OFF 开启或关闭 echo 命令。 .exit 退出 SQLite 提示符。 .explain ON|OFF 开启或关闭适合于 EXPLAIN 的输出模式。如果没有带参数，则为 EXPLAIN on，即开启 EXPLAIN。 .header(s) ON|OFF 开启或关闭头部显示。 .help 显示消息。 .import FILE TABLE 导入来自 FILE 文件的数据到 TABLE 表中。 .indices ?TABLE? 显示所有索引的名称。如果指定了 TABLE 表，则只显示匹配 LIKE 模式的 TABLE 表的索引。 .load FILE ?ENTRY? 加载一个扩展库。 .log FILE|off 开启或关闭日志。FILE 文件可以是 stderr（标准错误）/stdout（标准输出）。 .mode MODE 设置输出模式，MODE 可以是下列之一：csv 逗号分隔的值column 左对齐的列html HTML 的 代码insert TABLE 表的 SQL 插入（insert）语句line 每行一个值list 由 .separator 字符串分隔的值tabs 由 Tab 分隔的值tcl TCL 列表元素 .nullvalue STRING 在 NULL 值的地方输出 STRING 字符串。 .output FILENAME 发送输出到 FILENAME 文件。 .output stdout 发送输出到屏幕。 .print STRING… 逐字地输出 STRING 字符串。 .prompt MAIN CONTINUE 替换标准提示符。 .quit 退出 SQLite 提示符。 .read FILENAME 执行 FILENAME 文件中的 SQL。 .schema ?TABLE? 显示 CREATE 语句。如果指定了 TABLE 表，则只显示匹配 LIKE 模式的 TABLE 表。 .separator STRING 改变输出模式和 .import 所使用的分隔符。 .show 显示各种设置的当前值。 .stats ON|OFF 开启或关闭统计。 .tables ?PATTERN? 列出匹配 LIKE 模式的表的名称。 .timeout MS 尝试打开锁定的表 MS 毫秒。 .width NUM NUM 为 “column” 模式设置列宽度。 .timer ON|OFF 开启或关闭 CPU 定时器。 用.show命令来查看 SQLite 命令提示符的默认设置 sqlite\u003e .show echo: off eqp: off explain: auto headers: off mode: list nullvalue: \"\" output: stdout colseparator: \"|\" rowseparator: \"\\n\" stats: off width: filename: :memory: sqlite\u003e ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:2:1","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"格式化输出 .header on .mode column .timer on .changes on 这样设置只是在当前终端中设置了格式化输出，当再次打开时则需要再次设置，可以把sqlite的配置写入到~/.sqliter [sugar@localhost domain]$ cat ~/.sqliterc .header on .mode column .timer on [sugar@localhost domain]$ sqlite3 domain.db -- Loading resources from /Users/sugar/.sqliterc SQLite version 3.37.0 2021-12-09 01:34:53 Enter \".help\" for usage hints. sqlite\u003e .tables ssls sqlite\u003e select * from ssls; id created_at updated_at deleted_at status web -- -------------------------------- -------------------------------- ---------- ------ ----------------- 1 2022-10-14 23:31:24.473488+08:00 2022-10-14 23:31:24.473488+08:00 1 https://gitea.com Run Time: real 0.001 user 0.000178 sys 0.000250 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:2:2","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"三、sql操作 创建数据库 $ sqlite3 cccc.db SQLite version 3.32.3 2020-06-18 14:16:19 Enter \".help\" for usage hints. sqlite\u003e 上面的命令将在当前目录下创建一个文件 cccc.db。该文件将被 SQLite 引擎用作数据库。如果您已经注意到 sqlite3 命令在成功创建数据库文件之后，将提供一个 sqlite\u003e 提示符。 一旦数据库被创建，您就可以使用 SQLite 的 .databases 命令来检查它是否在数据库列表中，如下所示： sqlite\u003e .database main: /Users/sugar/Desktop/workspace/cccc.db sqlite\u003e 数据库备份 sqlite3 cccc.db .dump \u003e cccc.sql 恢复数据库 sqlite3 cccc.db \u003c cccc.sql 查看表详细信息 .schema 非交互式执行sql [sugar@Sugar sqlite]$ sqlite3 cccc.db \"select * from msg;\" -- Loading resources from /Users/sugar/.sqliterc age id --- ---- 19 1001 ","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:3:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["Database"],"content":"四、sql语法 大小写 SQLite不区分大小写。但是，有一些区分大小写的命令。例如：GLOB和glob在SQLite语句中有不同的含义。 注释： 注释用于在SQLite代码中增加代码的可读性。 注释不能嵌套。 注释以两个连续的“ - ”字符。 也可使用“/*”字符开始，并延伸至下一个“*/”字符对所包括的内容视为注释。 1、表操作 列的数据类型 NULL —该值为 NULL 值 INTEGER —有符号整数 REAL —浮点值 TEXT-文本字符串 BLOB —数据块 -- 创建表 sqlite\u003e CREATE TABLE Testing(Id INTEGER); Run Time: real 0.002 user 0.000269 sys 0.001006 changes: 0 total_changes: 0 sqlite\u003e -- 查看表结构 sqlite\u003e .schema CREATE TABLE Testing(Id INTEGER); sqlite\u003e .schema Testing CREATE TABLE Testing(Id INTEGER); sqlite\u003e -- 如果存在则不创建 CREATE TABLE IF NOT EXISTS Testing(Id INTEGER); -- 复制表 CREATE TABLE Cars2 AS SELECT * FROM Cars; -- 查看所有表 sqlite\u003e .tables Testing -- 通用语法 sqlite\u003e select * from sqlite_master; type name tbl_name rootpage sql ----- ------- -------- -------- -------------------------------- table Testing Testing 2 CREATE TABLE Testing(Id INTEGER) Run Time: real 0.001 user 0.000111 sys 0.000102 changes: 0 total_changes: 0 sqlite\u003e -- 删除表 sqlite\u003e DROP TABLE Testing; sqlite\u003e DROP TABLE IF EXISTS Testing; -- 重命名数表 sqlite\u003e CREATE TABLE Names(Id INTEGER, Name TEXT); sqlite\u003e ALTER TABLE Names RENAME TO NamesOfFriends; sqlite\u003e .schema NamesOfFriends 2、数据操作 sqlite\u003e CREATE TABLE Cars(Id INTEGER PRIMARY KEY, Name TEXT,Price INTEGER DEFAULT 'Not available'); -- 插入数据 sqlite\u003e INSERT INTO Cars(Id, Name, Price) VALUES(1, 'Audi', 52642); -- 删除数据 sqlite\u003e DELETE FROM Cars2 WHERE Id=1; -- 删除表所有数据 sqlite\u003e DELETE FROM Cars2; -- 更新数据 sqlite\u003e UPDATE Cars SET Name='Skoda Octavia' WHERE Id=3; 3、约束 # 非空 NOT NULL # 唯一 UNIQUE # 主键 PRIMARY KEY # 外键 FOREIGN KEY # 默认值 sqlite\u003e CREATE TABLE Hotels(Id INTEGER PRIMARY KEY, Name TEXT,City TEXT DEFAULT 'not available'); 所有的SQLite语句都是以关键字(如：SELECT，INSERT，UPDATE，DELETE，ALTER，DROP等)开始的。所有语句都以分号(;)结尾。 ANALYZE语句的语法： ANALYZE; -- or ANALYZE database_name; -- or ANALYZE database_name.table_name; AND/OR子句的语法： SELECT column1, column2....columnN FROM table_name WHERE CONDITION-1 {AND|OR} CONDITION-2; ALTER TABLE语句的语法 ALTER TABLE table_name ADD COLUMN column_def...; ALTER TABLE语句(Rename)语句的语法 ALTER TABLE table_name RENAME TO new_table_name; ATTACH DATABASE语句的语法： ATTACH DATABASE 'DatabaseName' As 'Alias-Name'; BEGIN TRANSACTION语句的语法： BEGIN; -- or BEGIN EXCLUSIVE TRANSACTION; BETWEEN语句的语法： SELECT column1, column2....columnN FROM table_name WHERE column_name BETWEEN val-1 AND val-2; SQLite COMMIT Statement: COMMIT; CREATE INDEX语句的语法： CREATE INDEX index_name ON table_name ( column_name COLLATE NOCASE ); CREATE UNIQUE INDEX语句的语法： CREATE UNIQUE INDEX index_name ON table_name ( column1, column2,...columnN); CREATE TABLE语句的语法： CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY( one or more columns )); CREATE TRIGGER语句的语法： CREATE TRIGGER database_name.trigger_name BEFORE INSERT ON table_name FOR EACH ROW BEGIN stmt1; stmt2; .... END; CREATE VIEW语句的语法： CREATE VIEW database_name.view_name AS SELECT statement....; CREATE VIRTUAL TABLE语句的语法： CREATE VIRTUAL TABLE database_name.table_name USING weblog( access.log ); -- or CREATE VIRTUAL TABLE database_name.table_name USING fts3( ); COMMIT TRANSACTION语句的语法： COMMIT; COUNT语句的语法： SELECT COUNT(column_name) FROM table_name WHERE CONDITION; DELETE语句的语法： DELETE FROM table_name WHERE {CONDITION}; DETACH DATABASE语句的语法： DETACH DATABASE 'Alias-Name'; DISTINCT语句的语法： SELECT DISTINCT column1, column2....columnN FROM table_name; DROP INDEX语句的语法： DROP INDEX database_name.index_name; DROP TABLE语句的语法： DROP TABLE database_name.table_name; DROP VIEW语句的语法： DROP INDEX database_name.view_name; SQLite DROP TRIGGER 语句的语法： DROP INDEX database_name.trigger_name; SQLite EXISTS语句的语法： SELECT column1, column2....columnN FROM table_name WHERE column_name EXISTS (SELECT * FROM table_name ); EXPLAIN语句的语法： EXPLAIN INSERT statement...; -- or EXPLAIN QUERY PLAN SELECT statement...; GLOB语句的语法： SELECT column1, column2....columnN FROM table_name WHERE column_name GLOB { PATTERN }; GROUP BY语句的语法： SELECT SUM(column_name) FROM table_name WHERE CONDITION GROUP BY column_name; HAVING语句的语法： SELEC","date":"2023-11-12","objectID":"/posts/2023-11-12-sqlite3/:4:0","tags":["sqlite","sqlite3","db"],"title":"sqlite3","uri":"/posts/2023-11-12-sqlite3/"},{"categories":["DevOps"],"content":"钉钉机器人 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:0:0","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"一、shell脚本 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:1:0","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"1、基于关键字或者 ip 版 发送txt格式消息 info='hello' logFile='/var/log/dingbot.log' #发送消息 sendMsg() { token='1e18ffe069052b56f5a0f8fe9b6c058373e7df7ef4xxxxxxxxxxxxxxx' result=$(curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{'msgtype': 'text','text': {'content': 'msg:\\n$*'}}\") [ $(echo $result | grep \"errmsg.*ok\") ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result msg: $*\" \u003e\u003e$logFile } sendMsg $info 发送 markdown 格式消息 logFile='/var/log/DingBot.log' token='1e18ffe069052b56f5a0f8fe9b6c058373xxxxxxxxxxxxxx' #发送消息 sendMsg() { local info=$* result=$(curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{'msgtype': 'text', 'text': { 'content': '$info' } }\") [ $(echo $result | grep \"errmsg.*ok\") ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result MessagesType: text [ text: $* ]\" \u003e\u003e$logFile } SendMsgByMD() { local info=$1 # $info markdown的标题 local infoMsg=$2 # $infoMsg 内容 # token='1e18ffe069052b56f5a0f8fe9b6c058373e7df7xxxxxxxxxxxxxx' result=$(curl -s \"https://oapi.dingtalk.com/robot/send?access_token=$token\" \\ -H 'Content-Type: application/json' \\ -d \"{ 'msgtype': 'markdown', 'markdown': { 'title':'$info', 'text': '$infoMsg' }, 'at': { 'atMobiles': [ '156xxxx8827', '189xxxx8325' ], 'isAtAll': true } }\") [ $(echo $result | grep \"errmsg.*ok\") ] \u0026\u0026 echo 'send succees!' echo \"$(date +'%Y-%m-%d %H:%M.%S') state: $result MessagesType: markdown [ title: $info text: $infoMsg ]\" \u003e\u003e$logFile } #main() (sendMsg 'zabbix') \u0026 (SendMsgByMD 'zabbix' '# send msg') \u0026 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:1:1","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"2、签名计算版 计算签名是使用的date是linux版的，而mac上的date是unix版的，在mac上需要替换为linux版的date才能正常计算签名。 ## 钉钉机器人配置 dingbot_secret='SECa87axxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' dingbot_url='https://oapi.dingtalk.com/robot/send?access_token=cd3xxxxxxxxxxxxx' ## secret_type keywords || sign ding_secret_type='sign' ## 需要艾特的人的手机号码，以空格隔开 atMobiles=(13346123456 13346123457) ## encode url function url_encode() { t=\"${1}\" if [[ -n \"${1}\" \u0026\u0026 -n \"${2}\" ]];then if ! echo 'xX' | grep -q \"${t}\";then t='x' fi echo -n \"${2}\" | od -t d1 | awk -v a=\"${t}\" '{for (i = 2; i \u003c= NF; i++) {printf(($i\u003e=48 \u0026\u0026 $i\u003c=57) || ($i\u003e=65 \u0026\u0026$i\u003c=90) || ($i\u003e=97 \u0026\u0026 $i\u003c=122) ||$i==45 || $i==46 || $i==95 || $i==126 ?\"%c\" : \"%%%02\"a, $i)}}' else echo -e '$1 and $2 can not empty\\n$1 ==\u003e 'x' or 'X', x ==\u003e lower, X ==\u003e toupper.\\n$2 ==\u003e Strings need to url encode' fi } ## Dingbot function dingbot(){ send_strs=\"${1}\" new_url=\"${dingbot_url}\" at_who='' for i in ${atMobiles[*]} do if [ -n \"${at_who}\" ];then at_who=\"${at_who},\\\"${i}\\\"\" else at_who=\"\\\"${i}\\\"\" fi done if [ \"${ding_secret_type}\" == 'keywords' ];then curl -s -X POST -H 'Content-Type: application/json' \"${new_url}\" \\ -d \"{\\\"at\\\":{\\\"atMobiles\\\":[${at_who}]},\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"${send_strs}\\\"}}\" elif [ \"${ding_secret_type}\" == 'sign' ];then timestamp=$(date \"+%s%3N\") dingbot_sign=$(echo -ne \"${timestamp}\\n${dingbot_secret}\" | openssl dgst -sha256 -hmac \"${dingbot_secret}\" -binary | base64) dingbot_sign=$(url_encode 'X' \"${dingbot_sign}\") post_url=\"${dingbot_url}\u0026timestamp=${timestamp}\u0026sign=${dingbot_sign}\" curl -s -X POST -H 'Content-Type: application/json' \"${post_url}\" \\ -d \"{\\\"at\\\":{\\\"atMobiles\\\":[${at_who}]},\\\"msgtype\\\":\\\"text\\\",\\\"text\\\":{\\\"content\\\":\\\"${send_strs}\\\"}}\" else echo \"secret_type 未知，请检查配置\" fi } dingbot \"hello\" ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:1:2","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"二、python版 ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:2:0","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"1、基于关键字或者 ip #!/usr/bin/python3 # encoding: utf-8 import requests import json def dingmsg(): #钉钉机器人的url ding_url = 'https://oapi.dingtalk.com/robot/send?access_token=' #钉钉机器人的token token = 'ba9b7c169caebb1048a66845fa8344348b3e8fdaefxxxxxxxxxxx' #请求的url，webhook的地址 webhook = ding_url+token #构建请求的头部 header = { \"Content-Type\": \"application/json\", \"Charset\": \"UTF-8\" } #构建请求数据 text = \"this is first python to test dingding\" msg = { \"msgtype\": \"text\", \"text\": { \"content\": text, } } #对请求的数据进行封装 msg_json = json.dumps(msg) #发起请求 info = requests.post(url=webhook,data=msg_json,headers=header) #打印返回的结果 print(info.text) if __name__ == \"__main__\": dingmsg() ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:2:1","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["DevOps"],"content":"2、基于加签计算 #!/usr/bin/python3 # encoding: utf-8 import requests import json import time import hmac import hashlib import base64 import urllib.parse class dingRobot: def __init__(self): self.dingUrl = 'https://oapi.dingtalk.com/robot/send?access_token=' self.__secret = 'SECc95942d1139feaefcdef6abf33e6497eb3d0120b4ca3dxxxxxxxxxx' self.__token = 'ba9b7c169caebb1048a66845fa8344348b3e8fdaef264e6exxxxxxxxxxxdc' self.__sign = '' self.__timestamp = '' def createTimestampSign(self): self.__timestamp = str(round(time.time() * 1000)) secret_enc = self.__secret.encode('utf-8') string_to_sign = '{}\\n{}'.format(self.__timestamp, self.__secret) string_to_sign_enc = string_to_sign.encode('utf-8') hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest() self.__sign = urllib.parse.quote_plus(base64.b64encode(hmac_code)) def sendMsg(self,text): self.createTimestampSign() # 请求的url，webhook的地址 webhook = self.dingUrl + self.__token + '\u0026timestamp=' + self.__timestamp + '\u0026sign=' + self.__sign # 构建请求的头部 header = { \"Content-Type\": \"application/json\", \"Charset\": \"UTF-8\" } # 构建请求数据 # text = \"this is first python to test dingding\" msg = { \"msgtype\": \"text\", \"text\": { \"content\": text, } } # 对请求的数据进行封装 msg_json = json.dumps(msg) # 发起请求 info = requests.post(url=webhook, data=msg_json, headers=header) return info if __name__ == \"__main__\": robot = dingRobot() result = robot.sendMsg('只是用于测试') if json.loads(result.text)['errcode'] == 0: print(\"发送消息成功\") else: print(\"发送消息失败\") ","date":"2023-11-11","objectID":"/posts/2023-11-11-dingbot/:2:2","tags":["dingbot"],"title":"dingbot","uri":"/posts/2023-11-11-dingbot/"},{"categories":["linux 基础"],"content":"服务器中有关常用端口的信息在/etc/services文件中记录 [root@localhost ~]# vim /etc/services 协议 端口 说明 FTP 21 FTP服务上传和下载文件。 SSH 22 远程连接Linux弹性云服务器或者SFTP。 Telnet 23 使用Telnet协议访问网站。 HTTP 80 使用HTTP协议访问网站。 POP3 110 使用POP3协议接受邮件。 IMAP 143 使用IMAP协议接受邮件。 LDAP 389 LDAP端口 HTTPS 443 使用HTTPS协议访问网站。 LDAPS 636 LDAP over SSL SQL Server 1433 SQL Server的TCP端口，用于供SQL Server对外提供服务。 SQL Server 1434 SQL Server的TCP端口，用于返回SQLServer使用了哪个TCP/IP端口。 Oracle 1521 Oracle通信端口，弹性云服务器上部署了Oracle SQL需要放行的端口。 MySQL 3306 MySQL数据库对外提供服务的端口。 Windows Server Remote Desktop Services 3389 Windows远程桌面服务端口，通过这个端口可以连接Windows弹性云服务器。 Postgresql 5432 Postgresql数据库对外提供服务端口 Redis 6379 Redis对外提供服务端口 RabbitMQ 5672/15672 5672是rabbitmq对外提供服务端口，15672是rabbitmq management对外提供服务端口 代理 8080 8080端口常用于WWW代理服务，实现网页浏览，实现网页浏览。如果您使用8080端口，访问网站或使用代理服务器时，需要在IP地址后面加上：8080。安装Apache Tomcat服务后，默认服务端口为8080。 NetBIOS 137、138、139 NetBIOS协议常被用于Windows文件、打印机共享和Samba。·137、138:UDP端口，通过网上邻居传输文件时使用的端口。·139:通过这个端口进入的连接试图获得NetBIOS/SMB服务。 无法访问公有云某些端口 1）问题现象： 访问公有云特定端口，在部分地区部分运营商无法访问，而其它端口访问正常。 2）问题分析： 部分运营商判断如下表的端口为高危端口，默认被屏蔽。 高危端口 协议 端口 TCP 42 135 138 139 444 445 593 1025 1068 1434 3127 3128 3129 3130 UDP 135～139 1026 1027 1028 解决方案： 建议您修改敏感端口为其它非高危端口来承载业务。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-port/:0:0","tags":["port"],"title":"port","uri":"/posts/2023-11-11-port/"},{"categories":["DevOps"],"content":"flatpak ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:0:0","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"简介 Flatpak 是一种新的通用包装格式。启用 Flatpak 将使您能够轻松安装许多 Linux 应用程序。这是在 Ubuntu 和其他 Linux 发行版中使用 Flatpak 的方法。 在 Linux 中安装应用程序就像打开软件中心、搜索和安装一样简单。App Store 中没有的应用程序可以通过 DEB 或 RPM 包安装。其中一些可通过 PPA（用于基于 Debian 的发行版）获得，如果没有，可以从源代码构建。 虽然有一些限制。App Store 通常没有最新版本的应用程序，处理依赖项可能很烦人，而且 PPA 可能并不总是安全的！而且，从源头构建需要一些终端动手操作。 对于多个 Linux 发行版和包管理系统，需要一个通用打包系统，它可以运行应用程序，而不管您使用的是什么 Linux 发行版。Canonical 想到了它并创建了Snaps。还有一个名为AppImage的独立通用软件包 ，您可以在其中下载应用程序并运行它，而无需实际安装应用程序。 除了 Snaps 和AppImage之外，还有另一个名为Flatpak的通用包系统。我们将了解如何在大多数 Linux 发行版上安装和使用 Flatpak 及其优势。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:0:1","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"什么是 Flatpak？ Flatpak基本上是 Linux 上的应用程序框架。由于不同的发行版更喜欢自己的包管理，Flatpak 旨在提供具有其他优势的跨平台解决方案。它使开发人员的工作更加轻松。几乎所有 Linux 发行版（支持 Flatpak）都可以使用单个应用程序构建，而无需对捆绑包进行任何修改。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:1:0","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"Flatpak 的主要优势 除了为不同的 Linux 发行版提供单个捆绑包之外，Flatpak 还提供与 Linux 桌面的集成，从而更容易浏览、安装和使用 Flatpak 应用程序，例如 Gnome 软件中心可用于安装 Flatpak。 Flatpak 是向前兼容的，即相同的 Flatpak 应用程序可以在发行版的下一个版本上运行而无需更改。 维护可以由应用程序使用的运行时依赖项。缺少的可以作为应用程序的一部分添加。 虽然 Flatpak 提供了应用分发的中心化服务，但它完全支持应用的去中心化分发。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:1:1","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"使用 # 查看当前的remote [root@sugar ~]# flatpak remotes # 最方便的方式添加远程仓库是使用 .flatpakrepo 文件，它包含远程仓库的信息和GPG秘钥： [root@sugar ~]# flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo # 移除远程仓库 [root@sugar ~]# flatpak remote-delete flathub # 查询软件 flatpak search gimp # 安装软件 flatpak install flathub org.gimp.GIMP 使用国内镜像 $ flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo $ flatpak remote-modify flathub --url=https://mirror.sjtu.edu.cn/flathub # 或者 $ flatpak remote-add --if-not-exists sjtu https://mirror.sjtu.edu.cn/flathub/flathub.flatpakrepo # 如果您中断了某次安装，重新下载可能会出现找不到文件的问题。您可以使用 flatpak repair 解决相关的问题。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-flatpak/:1:2","tags":["flatpak"],"title":"flatpak","uri":"/posts/2023-11-11-flatpak/"},{"categories":["DevOps"],"content":"Daemon 守护进程服务 systemd supervisor launchd ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:0:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"一、supervisor ​ 是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程 supervisor官网：supervisord.org ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"安装supervisor supervisor是用python开发的，支持yum和pip安装 [root@localhost ~]# yum install supervisor [root@localhost ~]# pip3 install supervisor ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:1","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"配置文件 若没有配置文件，可以生成主配置文件模板 [root@localhost ~]# echo_supervisord_conf \u003e /etc/supervisord.conf # 参考链接 http://supervisord.org/configuration.html 配置模板 # 参数可以根据需求进行调整 [program:pock] directory=/home/sugars/pock/backend command=/home/sugars/pock/pock_venv/bin/python3 /home/sugars/pock/backend/sugars.py autostart=true autorestart=true startsecs=7 user = sugars stderr_logfile=/var/log/supervisor/pock-err.log stdout_logfile=/var/log/supervisor/pock.log redirect_stderr = true stdout_logfile_maxbytes = 50MB stdout_logfile_backups = 3 stopasgroup=true killasgroup=true 配置文件读取目录于顺序 # 配置文件明名为supervisor.comf,如果不使用`-c` 指定文件名，则自动匹配的文件路径为 1) ../etc/supervisord.conf 2) ../supervisord.conf 3) $CWD/supervisord.conf 4) $CWD/etc/supervisord.conf 5) /etc/supervisord.conf 6) /etc/supervisor/supervisord.conf systemctl start supervisord ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:2","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"supervisor命令说明 supervisorctl status 查看进程运行状态 supervisorctl start g_name 启动进程 supervisorctl stop g_name 关闭进程 supervisorctl restart g_name 重启进程 supervisorctl update 重新载入配置文件(配置文件修改后使用该命令加载新的配置) supervisorctl shutdown 关闭 supervisord supervisorctl clear g_name 清空进程日志 supervisorctl 进入到交互模式下。使用help查看所有命令。 supervisorctl start/stop/restart + all 表示启动，关闭，重启所有进程 supervisorctl reload //重新启动配置中的所有程序 新添加一个program后的操作 root@serialt:~# supervisorctl update sugar 停止sugar服务 root@serialt:~# supervisorctl stop sugar 启动sugar服务 root@serialt:~# supervisorctl start sugar 重启sugar服务 root@serialt:~# supervisorctl restart sugar ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:3","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"日志管理 在rhel中，supervisord的日志轮转管理是通过调用logrotate来实现的，其配置文件内容是 [root@serialt ~]# cat /etc/logrotate.d/supervisor /var/log/supervisor/*.log { missingok weekly notifempty nocompress } 会自动轮转/var/log/supervisor/*.log的文件，若把用supervisor管理的日志也输入到/var/log/supervisor/里会导致日志文件被轮转成带时间戳的格式 sugar.log sugar.log-20211019 sugar.log-20211026 sugar.log.1 sugar.log.2 sugar.log.3 两种解决办法： 1）修改supervisord的日志记录文件，同时修改supervisord的logrotate配置文件 2）supervisord管理的进程的日志不输出到/var/log/supervisor里 日志压缩 supervisord本身日志只能轮转，不能用于压缩，要实现日志压缩论证，需要借用logrotate [root@tc ~]# cat /etc/logrotate.d/sugar /var/log/sugar/*.log { missingok daily notifempty create 0664 nobody root #dateext #dateformat .%Y%m%d rotate 20 compress delaycompress copytruncate size 10K } ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:1:4","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"二、systemd 常用命令 systemctl restart foo systemctl stop foo systemctl start foo systemctl status foo systemctl cat foo systemctl daemon-reload 配置模板 [Unit] Description=Gins After=network-online.target Documentation=https://serialt.github.io/ Documentation=https://serialt.github.io on-failure always [Service] Type=simple WorkingDirectory=/usr/local/gin KillSignal=SIGTERM ExecStart=/usr/local/gins/bin/gins start ExecStop=/bin/kill -SIGTERM $MAINPID Restart=on-failure RestartSec=3 TimeoutSec=50 User=gins Group=gins [Install] WantedBy=multi-user.target systemd 236之后的版本可以直接在systemd的unit文件里面配置StandardOutput和StandardError两个参数来将相关运行日志输出到指定的文件中。 [Unit] Description=Gins After=network.target Documentation=https://serialt.github.io/ Documentation=https://serialt.github.io on-failure always [Service] Type=simple WorkingDirectory=/usr/local/gin KillSignal=SIGTERM ExecStart=/usr/local/gins/bin/gins start ExecStop=/bin/kill -SIGTERM $MAINPID # append类型可以在原有文件末尾继续追加内容，而file类型则是重新打开一个新文件 # 两者的区别类似于 echo \u003e\u003e 和 echo \u003e StandardOutput=append:/home/coredns/logs/coredns.log StandardError=append:/home/coredns/logs/coredns_error.log Restart=on-failure RestartSec=3 TimeoutSec=50 User=gins Group=gins [Install] WantedBy=multi-user.target ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:2:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"三、launchd服务 https://www.fythonfang.com/blog/2021/4/19/mac-launchd-daemons-and-agents-tutorial ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:0","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"基本概念 launchd 是 MacOS 上用于管理系统级或者用户级后台服务进程的管理工具。也是官方推荐的系统后台进程管理工具，就好像在 Linux 系统里，我们使用 systemd 去管理后台服务进程一样。 launchd 是一个程序，以系统常驻进程的形态运转，是 MacOS 系统启动后的第一个进程，在 Terminal 终端，键入命令 ps aux 可以看到，launchd 的进程ID（PID）是 1。也即这是系统的第一个进程。 与 launchd 交互的工具，叫 launchctl。可以认为是它的管理客户端程序。通过该命令，我们可以发送指令给 launchd 完成对系统服务或后台进程的管理。 launchd 的管理对象都是后台进程，这些后台进程使用一种特定格式的配置文件叫 launchd.plist 来描述被管理的对象。这种文件是 XML 格式的，根据不同的运行权限，放在不同的目录里面，请看下面的表格。 目录 说明 ~/Library/LaunchAgents 用户自己提供的用户级 Agent。 /Library/LaunchAgents 管理员提供的用户级 Agent。 /Library/LaunchDaemons 管理员提供的系统级 Daemon。 /System/Library/LaunchAgents 苹果官方提供的用户级 Agent。 /System/Library/LaunchDaemons 苹果官方提供的系统级 Daemon。 存放 launchd 配置文件的常用目录 通过 launchd 管理的进程，人为被分为了几个种类： 服务（Services）—— 在后台运行，用以支持图形界面应用（GUI App）运行的服务进程，比如响应系统全局快捷键，或者进行网络通信等； 守护进程（Daemons）—— 理论上，不属于服务的后台进程，都归为守护进程一类，不过这里特指运行在后台，且不能与用户交互图形界面产生联系的进程； 代理（Agents）—— 以用户的名义，在后台运行的进程，可以和用户图形界面产生联系，比如呼起一个软件的界面，不过官方不推荐这么用。 一般文件名都以com.domain.programName.plist格式命名，不管是 Daemons 还是 Agents 格式都是一样的，只是存放位置不同。看下面一个 hello world 的例子 ~/Library/LaunchAgents/com.example.hello.plist \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e \u003cplist version=\"1.0\"\u003e \u003cdict\u003e \u003ckey\u003eLabel\u003c/key\u003e \u003cstring\u003ecom.example.hello\u003c/string\u003e \u003ckey\u003eProgramArguments\u003c/key\u003e \u003carray\u003e \u003cstring\u003e/bin/echo\u003c/string\u003e \u003cstring\u003ehello world\u003c/string\u003e \u003c/array\u003e \u003c/dict\u003e \u003c/plist\u003e 上面定义了一个最简单的任务只使用了Label和ProgramAgruments两个键 Label这是个必须的键，指定这个任务名 ProgramArguments是带参数的可执行文件上面等同于运行/bin/echo hello world命令，如果执行的程序不带参数可以使用Program键，但一个任务中必须包含这两个中的其中一个键 还有一些常用的键名，所有的键可参考man 5 launchd.plist或者这里 Keys Description EnvironmentVariables 设置运行环境变量 StandardOutPath 标准输出到文件 StandardErrorPath 标准错误到文件 RunAtLoad 是否再加载的时候就运行 StartInterval 设置程序每隔多少秒运行一次 KeepAlive 是否设置程序是一直存活着 如果退出就重启 UserName 设置用户名只在 Daemons 可用 WorkingDirectory 设置工作目录 # 检查配置 $ plutil ~/Library/LaunchAgents/com.example.hello.plist /Users/fython/Library/LaunchAgents/com.example.hello.plist: OK # 加载配置文件 $ launchctl load ~/Library/LaunchAgents/com.example.hello.plist # 启动服务 $ launchctl start com.example.hello $ cat /tmp/hello.log hello world $ launchctl list | grep hello - 0 com.example.hello $ launchctl remove com.example.hello # remove jobs 一个任务首先需要被加载(load)，然后启动(start)正常运行完退出，所以我们查看/tmp目录下会有日志输出 ​ 1）任务一般都要手动启动(start)，如果设置了RunAtLoad或者KeepAlive则在launchctl load时就启动 ​ 2）使用launchctl list列出当前加载的任务，第一列代表进程id，因为上面的程序运行一次就退出了所以显示-，第二列是程序上次运行退出的code，0代表正常退出，如果是正数代表退出的时候是有错误的，负数代表是接收到信号被终止的 ​ 3）launchctl stop \u003cservice_name\u003e可以终止一个在运行中的任务，launchctl unload \u003cpath\u003e指定路径卸载一个任务，launchctl remove \u003cservice_name\u003e通过服务名卸载任务 ​ 4）launchctl load \u003cpath\u003e只会加载没有被disable的任务，可以加-w参数 launchctl load -w \u003cpath\u003e覆盖如果设置了disable的，下次开机启动一定会起来。launchctl unload \u003cpath\u003e只会停止和卸载这个任务，但下次启动还会加载，可以使用-w参数launchctl unload -w \u003cpath\u003e停止任务，下次启动也不会起来，也就是标记了disable ​ 5）调试一个任务可以配合使用plutil命令检查语法，设置StandardOutPath、StandardErrorPath、Debug键，也可以看看苹果自带的Console.app应用中的system.log ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:1","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"基本操作 # 罗列系统当前运行的进程清单 launchctl list # 查看特定服务的配置信息 launchctl list com.adobe.AdobeCreativeCloud # 加载特定的服务配置 launchctl load \u003cfile_path\u003e # 卸载特定的服务配置 launchctl unload -w /Library/LaunchAgents/com.adobe.AdobeCreativeCloud.plist # 特此说明，-w 参数的作用是，如果自动执行了 load 命令尝试去恢复服务注册，则让其无效 plist 文件配置 www.launchd.info ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:2","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DevOps"],"content":"配置参数 1）配置job名 \u003ckey\u003eLabel\u003c/key\u003e \u003cstring\u003ecom.local.cmd\u003c/string\u003e 2）cmd启动配置 \u003ckey\u003eProgramArguments\u003c/key\u003e \u003carray\u003e \u003cstring\u003e/usr/bin/rsync\u003c/string\u003e \u003cstring\u003e--archive\u003c/string\u003e \u003cstring\u003e--compress-level=9\u003c/string\u003e \u003cstring\u003e/Volumes/Macintosh HD\u003c/string\u003e \u003cstring\u003e/Volumes/Backup\u003c/string\u003e \u003c/array\u003e 执行后命令 /usr/bin/rsync --archive --compress-level=9 \"/Volumes/Macintosh HD\" \"/Volumes/Backup\" 3）环境变量设置 \u003ckey\u003eEnvironmentVariables\u003c/key\u003e \u003cdict\u003e \u003ckey\u003ePATH\u003c/key\u003e \u003cstring\u003e/bin:/usr/bin:/usr/local/bin\u003c/string\u003e \u003c/dict\u003e 3）设置工作目录 \u003ckey\u003eWorkingDirectory\u003c/key\u003e \u003cstring\u003e/tmp\u003c/string\u003e 4）资源限制 \u003ckey\u003eHardResourceLimits\u003c/key\u003e \u003cdict\u003e \u003ckey\u003eFileSize\u003c/key\u003e \u003cinteger\u003e1048576\u003c/integer\u003e \u003c/dict\u003e \u003ckey\u003eSoftResourceLimits\u003c/key\u003e \u003cdict\u003e \u003ckey\u003eFileSize\u003c/key\u003e \u003cinteger\u003e524288\u003c/integer\u003e \u003c/dict\u003e 5）其他 RunAtLoad \u003ckey\u003eRunAtLoad\u003c/key\u003e \u003ctrue/\u003e 每隔多少秒执行 单位 秒 \u003ckey\u003eStartInterval\u003c/key\u003e \u003cinteger\u003e3600\u003c/integer\u003e 定时执行 \u003ckey\u003eStartCalendarInterval\u003c/key\u003e \u003cdict\u003e \u003ckey\u003eHour\u003c/key\u003e \u003cinteger\u003e3\u003c/integer\u003e \u003ckey\u003eMinute\u003c/key\u003e \u003cinteger\u003e0\u003c/integer\u003e \u003c/dict\u003e 可用参数 Month Integer Month of year (1..12, 1 being January) Day Integer Day of month (1..31) Weekday Integer Day of week (0..7, 0 and 7 being Sunday) Hour Integer Hour of day (0..23) Minute Integer Minute of hour (0..59) 示例1： /Library/LaunchDaemons/com.fython.clash.plist \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e \u003cplist version=\"1.0\"\u003e \u003cdict\u003e \u003ckey\u003eLabel\u003c/key\u003e \u003cstring\u003ecom.fython.clash\u003c/string\u003e \u003ckey\u003eRunAtLoad\u003c/key\u003e \u003ctrue/\u003e \u003ckey\u003eUserName\u003c/key\u003e \u003cstring\u003eroot\u003c/string\u003e \u003ckey\u003eStandardErrorPath\u003c/key\u003e \u003cstring\u003e/Users/fython/bin/clash/stderr.log\u003c/string\u003e \u003ckey\u003eStandardOutPath\u003c/key\u003e \u003cstring\u003e/Users/fython/bin/clash/stdout.log\u003c/string\u003e \u003ckey\u003eWorkingDirectory\u003c/key\u003e \u003cstring\u003e/Users/fython/bin/clash\u003c/string\u003e \u003ckey\u003eProgramArguments\u003c/key\u003e \u003carray\u003e \u003cstring\u003e/Users/fython/bin/clash/clash\u003c/string\u003e \u003cstring\u003e-f\u003c/string\u003e \u003cstring\u003econfig.yaml\u003c/string\u003e \u003cstring\u003e-d\u003c/string\u003e \u003cstring\u003e/Users/fython/bin/clash\u003c/string\u003e \u003c/array\u003e \u003ckey\u003eKeepAlive\u003c/key\u003e \u003ctrue/\u003e \u003c/dict\u003e \u003c/plist\u003e ","date":"2023-11-11","objectID":"/posts/2023-11-11-daemon/:3:3","tags":["daemon","systemd","supervisor","launchd"],"title":"daemon","uri":"/posts/2023-11-11-daemon/"},{"categories":["DNS"],"content":"CoreDNS 在内网服务中，需要部署内部的 dns，用于各种服务的 dns 解析。常见的 dns server 有 bind，dnsmasq，coredns 等。coredns 出名于用于 kubernetes 中 service 到 ip 的解析，由于是使用 go 开发的，构建的二进制很发布部署使用，同时 coredns 也兼容 bind 的域名解析配置文件。 官网：https://coredns.io/ 参考链接：https://blog.gmem.cc/coredns-study-note ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:0:0","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"一、基本使用 常用插件 bind 指定服务器监听的网络接口（IP地址）： bind ADDRESS … . { bind 127.0.0.1 ::1 } . { bind 127.0.0.1 bind ::1 } autopath 允许服务器端进行的搜索后缀（search domain）补全。如果插件发现客户端查询的名称，匹配search path的第一个元素，则自动遍历search path中的domain链，并返回第一个非NXDOMAIN结果。如果出现失败，则返回原始查询的应答。 由于autopath的应答中的名称，和原始问题不匹配，因此他会在CoreDNS中添加一个CNAME，从原始名称指向应答中的名称。 # ZONE autopath权威负责的Zone # RESOLV-CONF 包含search domain的配置文件。或者指向其它插件，例如@kubernetes，这时从其它插件读取search domain # 配置文件中必须有 search domain1 domain2 ... 这样的行 autopath [ZONE...] RESOLV-CONF cache 实现前端缓存，用于查询后端（Upstream、Database…）成本较高的场景。启用此插件后，除了Zone transfers / Metadata以外的记录会被缓存默认3600s。 # TTL 缓存有效期，单位秒，默认3600 # ZONES 哪些Zone支持缓存 cache [TTL] [ZONES...] { # 成功的DNS应答的缓存配置 success CAPACITY [TTL] [MINTTL] # Denial of existence应答的缓存配置 denial CAPACITY [TTL] [MINTTL] prefetch AMOUNT [[DURATION] [PERCENTAGE%]] } loop 能够检测简单的forwarding循环并终止服务器。 debug 能够从Panic中恢复，用于调试用途 errors 启用错误日志记录，格式： errors { # 在DURATION期间抓取匹配REGEXP的错误日志，聚合为单条日志 consolidate DURATION REGEXP } . { errors { consolidate 5m \".* i/o timeout$\" consolidate 30s \"^Failed to .+\" } } forward 将DNS请求转发给上游DNS服务器，支持DNS / TCP / DNS over TLS。该插件代替原先的proxy插件。 # FROM 匹配此后缀的DNS查询会被转发 # TO 上游服务器的端点，支持指定协议，例如tls://9.9.9.9 forward FROM TO... { # 空格分隔的，不进行转发的域名列表 except IGNORED_NAMES... # 强制基于TCP协议 force_tcp # 优先使用UDP prefer_udp # 多久后丢弃连接， expire DURATION # 判定为不健康需要的连续失败辞书 max_fails INTEGER # DNS over TLS配置 tls CERT KEY CA tls_servername NAME # 选取上游服务器的算法，默认random policy random|round_robin|sequential # 健康检查周期 health_check DURATION } 直接转发，用于兜底的示例： forward . 223.5.5.5 1.1.1.1 使用TLS的示例： forward . tls://9.9.9.9 { tls_servername dns.quad9.net health_check 5s } 强制TCP转发： svc.k8s.gmem.cc { forward . 127.0.0.1:5353 { force_tcp } } 从文件中读取上游DNS： forward . /etc/resolv.conf 如果CoreDNS运行在K8S中，则CoreDNS的Pod的/etc/resolv.conf内容的基础，取决于kubelet的–resolv-conf配置，默认值指向宿主机的/etc/resolv.conf文件。 上游健康检查 首次转发，随机选取一个上游服务器，后续一直使用，直到它不健康了。 当出现一个错误 —— 任何DNS响应都不看作错误（REFUSED, NOTIMPL, SERVFAIL … ）—— 则CoreDNS启动健康检查循环（默认0.5s一次），直到上游服务器恢复健康。 如果max_fails设置为0则不进行健康检查，总是认为上游服务器是健康的。 CoreDNS不向不健康的上游服务器转发请求，如果所有上游服务器都不健康，则随机选取一个转发。 health 启用进程级别的监控检查。示例： health :8080，你可以访问:8080/health获取健康状态。 ready 提供readiness探针。示例： ready localhost:8091 hosts 以/etc/hosts风格提供Zone数据，格式： # FILE 从文件中读取Zone数据，默认从/etc/hosts读取 # ZONES 此插件的权威Zone hosts [FILE [ZONES...]] { # 内联的HOSTS条目 [INLINE] # 修改生成的DNS记录的DNS TTL ttl SECONDS # 禁止自动生成in-addr.arpa或ip6.arpa条目 no_reverse # 重新载入文件的间隔，例如 300ms 1.5h 2h45m reload DURATION # 对于匹配的ZONES，如果此插件没有记录，则由下一个插件处理 fallthrough [ZONES...] } hosts { 172.21.0.1 kdc-1 fallthrough } import 该插件有两个用途： 导入其它配置文件到主配置文件 导入配置片段 格式： import PATTERN log 记录查询日志，格式： # NAMES 匹配的DNS查询被记录 # FORMAT 日志格式， log [NAMES...] [FORMAT] log [NAMES...] [FORMAT] { class CLASSES... } CLASSES 指定哪些RCode会被记录 取值 说明 success 记录成功的请求 denial 记录NXDOMAIN的请求、NOERROR但是没有数据的（nodata，域名存在，但是请求的记录类型没有） error 记录SERVFAIL、NOTIMP、REFUSED等等，任何提示远程服务器不愿意解析请求的应答都包含在内 all 默认，记录所有请求 rewrite 执行内部的消息重写。格式 # FIELD 请求/应答的什么字段需要被重写 # type 请求的TYPE字段 # class 消息的类型 # name 请求中的DNS名称 # answer name 应答中的DNS名称 # ttl TTL值 rewrite [continue|stop] FIELD [FROM TO|FROM TTL] 要重写DNS请求中的名称，使用格式： rewrite [continue|stop] name [exact|prefix|suffix|substring|regex] STRING STRING 示例： rewrite name substring k8s.gmem.cc k8s.gmem.site rewrite name regex (.*)\\.gmem\\.cc {1}.gmem.site rewrite name suffix .gmem.cc. .gmem.site. 要重写DNS响应中的名称，参考： rewrite stop { name regex (.*)\\.gmem\\.site {1}.gmem.site answer name (.*)\\.gmem\\.site {1}.gmem.site } template 提供一个模板，基于请求来动态的生成响应。格式 # CLASS 查询分类，IN或ANY # TYPE 查询类型，A、PTR... ANY匹配所有类型 # ZONE 此模板的Zone template CLASS TYPE [ZONE...] { # 匹配请求DNS名称的正则式 match REGEX... # DNS应答 answer RR additional RR authority RR rcode CODE # 用于解析CNAMEs的上有集群 upstream fallthrough [ZONE...] } 泛域名 使用template插件可以实现泛域名解析，下面是一个例子： template IN A mesh.gmem.cc { match .*\\.mesh\\.gmem\\.cc answer \"{{ .Name }} 60 IN A 10.0.11.11\" fallthrough } 当前版本有一个奇怪的行为： 上述配置导致hosts插件指定的10.0.11.1 mesh.gmem.cc条目失效，必须指定fallthrough才能避免此问题。 启动服务 docker run -d --restart=always --name coredns-srv -p 53:53/udp -v `pwd`/conf:/Conf coredns/c","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:1:0","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"可行的配置 参考链接：https://segmentfault.com/a/1190000022179401 Corefile .:53 { health { lameduck 5s } auto { directory ./zones reload 1m } hosts { 127.0.0.1 local.io ttl 120 reload 1m fallthrough } #chaos CoreDNS-001 info@coredns.io # prometheus 0.0.0.0:0153 log #cache 120 loop errors forward . 114.114.114.114:53 8.8.8.8:53 [2400:3200::1]:53 loadbalance } db.local.com $TTL 3600 ; 记录超时时间 $ORIGIN local.com. ; 指定 origin，下面的@符号可以作为他的别名，注意后面的. ; SOA 格式 [domain_name] IN SOA [域主服务器或主DNS服务器名] [管理员email] (时间信息) @ IN SOA ns1.local.com. admin.local.com. ( 2019071601 ; Serial 4H ; Refresh 1H ; Retry 7D ; Expire 4H ) ; Negative Cache TTL ; 配置 DNS 记录，指向 ns1.local.com @ IN NS ns1 ; 配置 ns1.local.com 的 A 记录, 指向coredns所在的机器 ns1 IN A 192.168.78.51 ; 配置 local.com 的 A 记录，指向网站或其他用途的机器 @ IN A 192.168.78.51 git IN A 192.168.78.51 drone IN A 192.168.78.51 drone-runner IN A 192.168.78.51 www IN A 192.168.78.51 ccc IN A 192.168.78.51 ; 配置泛域名，没有准确的三级子域名的域名全部指向此IPV4地址 * IN A 192.168.78.50 启动服务 docker run -tid -p 53:53/udp -v /yaml/coredns/Corefile:/Corefile -v /yaml/coredns/zones:/zones --name=coredns coredns/coredns ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:1:1","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"二、增加和编译插件 编译安装coredns： coredns官方对于插件的分类基本可以分为三种：Plugins、External Plugins和其他。其中Plugins一般都会被默认编译到coredns的预编译版本中，而External Plugins则不会。官方的文档对外部插件的定义有着明确的解释，主要要求大概是有用、高效、符合标准、文档齐全、通过测试等。 官方给出了一个详细的文档说明，编译插件基本可以分为修改源码和修改编译的配置文件这两种方式，这里我们采用简单高效的修改配置文件的方式进行测试。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:2:0","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"1、编译 下载源码：https://github.com/coredns/coredns.git 在我们前面下载的官方源码中，有一个plugin的目录，里面是各种插件的安装包，同时还有一个plugin.cfg的文件，里面列出了会编译到coredns中的插件， [root@sugar2 coredns]# tail plugin.cfg secondary:secondary etcd:etcd loop:loop forward:forward grpc:grpc erratic:erratic whoami:whoami on:github.com/coredns/caddy/onevent sign:sign git:github.com/miekg/coredns-git 添加一个git插件 git:github.com/miekg/coredns-git 对于在plugin目录下已经存在的插件，则可以直接写成plugin中的目录名，不在的则写插件的仓库，可以使用go get下载： sign:sign 下载插件： go get github.com/miekg/coredns-git 然后我们开始编译 [root@sugar2 coredns]# make ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:2:1","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["DNS"],"content":"2、验证插件 可以使用-plugins输出包含的插件 [root@sugar2 coredns]# ./coredns -plugins Server types: dns Caddyfile loaders: flag default Other plugins: dns.acl dns.any dns.auto dns.autopath dns.azure dns.bind dns.bufsize dns.cache dns.cancel dns.chaos dns.clouddns dns.debug dns.dns64 dns.dnssec dns.dnstap dns.erratic dns.errors dns.etcd dns.file dns.forward dns.geoip dns.git dns.grpc dns.header dns.health dns.hosts dns.k8s_external dns.kubernetes dns.loadbalance dns.local dns.log dns.loop dns.metadata dns.minimal dns.nsid dns.pprof dns.prometheus dns.ready dns.reload dns.rewrite dns.root dns.route53 dns.secondary dns.sign dns.template dns.tls dns.trace dns.transfer dns.whoami on 1）使用git插件 建立存储zones文件的的git仓库：git@local.io:sugar/coredns_zone.git 配置文件模板 .:53 { health { lameduck 5s } auto { directory /usr/local/coredns/zones reload 1m } hosts { ttl 120 reload 1m fallthrough } #chaos CoreDNS-001 info@coredns.io prometheus 0.0.0.0:9153 log cache 300 loop errors forward . 114.114.114.114:53 8.8.8.8:53 [2400:3200::1]:53 loadbalance git git@local.io:sugar/coredns_zone.git /usr/local/coredns/zones { branch master interval 3000 # pull的时间间隔 args --depth=1 pull_args --force } } supervisord [root@ftp coredns]# cat /etc/supervisord.d/coredns.ini [program:coredns] directory=/usr/local/coredns command=/usr/local/coredns/coredns -conf /usr/local/coredns/Corefile autostart=true autorestart=true startsecs=7 user = root stderr_logfile=/var/log/coredns/coredns-err.log stdout_logfile=/var/log/coredns/coredns.log redirect_stderr = true stdout_logfile_maxbytes = 100MB stdout_logfile_backups = 4 stopasgroup=true killasgroup=true ","date":"2023-11-11","objectID":"/posts/2023-11-11-coredns/:2:2","tags":["dns","coredns"],"title":"coredns","uri":"/posts/2023-11-11-coredns/"},{"categories":["虚拟化"],"content":"​ Multipass 是一个轻量虚拟机管理器，是由 Ubuntu 运营公司 Canonical 所推出的开源项目。运行环境支持 Linux、Windows、macOS。在不同的操作系统上，使用的是不同的虚拟化技术。在 Linux 上使用的是 KVM、Window 上使用 Hyper-V、macOS 中使用 HyperKit 以最小开销运行VM，支持在笔记本模拟小型云。Multipass唯一的遗憾是支持Linux版本只有Ubuntu。 同时，Multipass 提供了一个命令行界面来启动和管理 Linux 实例。下载一个全新的镜像需要几秒钟的时间，并且在几分钟内就可以启动并运行 VM。 github地址：https://github.com/canonical/multipass 官网：https://multipass.run/ ","date":"2023-11-11","objectID":"/posts/2023-11-11-multipass/:0:0","tags":["multipass","vm"],"title":"multipass","uri":"/posts/2023-11-11-multipass/"},{"categories":["虚拟化"],"content":"安装 Mac： # 1）brew 安装 brew install --cask multipass # 2)github或者官网下二进制安装 Linux： ubuntu官方只release了snap安装版本 sudo snap install multipass Windows： github下载安装包 ","date":"2023-11-11","objectID":"/posts/2023-11-11-multipass/:0:1","tags":["multipass","vm"],"title":"multipass","uri":"/posts/2023-11-11-multipass/"},{"categories":["虚拟化"],"content":"使用 1）查找可以下载的ubuntu镜像（multipass官方镜像只有ubuntu） [root@sugar ~]$ multipass find Image Aliases Version Description 18.04 bionic 20221014 Ubuntu 18.04 LTS 20.04 focal 20221018 Ubuntu 20.04 LTS 22.04 jammy,lts 20221101.1 Ubuntu 22.04 LTS anbox-cloud-appliance latest Anbox Cloud Appliance charm-dev latest A development and testing environment for charmers docker latest A Docker environment with Portainer and related tools jellyfin latest Jellyfin is a Free Software Media System that puts you in control of managing and streaming your media. minikube latest minikube is local Kubernetes 2）创建虚拟机 参数： -n, --name: 名称 -c, --cpus: cpu核心数, 默认: 1 -m, --mem: 内存大小, 默认: 1G -d, --disk: 硬盘大小, 默认: 5G 创建虚拟机时需要联网下载镜像 # 使用最新版LTS镜像 [root@sugar ~]$ multipass launch -n vm01 -c 1 -m 1G -d 10G # 设置使用的镜像 [root@sugar ~]$ multipass launch focal -n vm01 -c 1 -m 1G -d 10G # 设置网络 # name 网卡名 # mode dhcp方式，auto或者manual，默认auto # mac 设置mac地址 [root@sugar ~]$ multipass launch --network en0 --network name=bridge0,mode=manual 修改配置 [root@sugar ~]$ multipass set local.\u003cinstance-name\u003e.(cpus|disk|memory) xxx 3）与虚拟机交互 # 默认是以ubuntu用户进入 [root@sugar ~]$ multipass shell vm01 # 在虚拟机外执行命令 [root@sugar ~]$ multipass exec vm01 -- pwd 4）启动与关闭 [root@sugar ~]$ multipass start vm01 [root@sugar ~]$ multipass start vm01 vm02 [root@sugar ~]$ multipass start --all [root@sugar ~]$ multipass suspend vm01 [root@sugar ~]$ multipass suspend --all [root@sugar ~]$ multipass stop vm01 [root@sugar ~]$ multipass stop --all [root@sugar ~]$ multipass delete vm01 [root@sugar ~]$ multipass delete --all # 从一个删除的实例中恢复 [root@sugar ~]$ multipass recover keen-yak # 移除一个实例 [root@sugar ~]$ multipass delete keen-yak [root@sugar ~]$ multipass purge [root@sugar ~]$ multipass list No instances found. # 或者 [root@sugar ~]$$ multipass delete --purge keen-yak 5）数据共享 mount $ multipass mount $HOME keen-yak $ multipass info keen-yak … Mounts: /home/michal =\u003e /home/michal # 挂载指定路径 $ multipass mount $HOME keen-yak:/some/path # 查看信息 $ multipass info keen-yak # 卸载 $ multipass umount keen-yak 传输文件 $ multipass transfer keen-yak:/etc/crontab keen-yak:/etc/fstab /home/michal $ ls -l /home/michal/crontab /home/michal/fstab -rw-r--r-- 1 michal michal 722 Oct 18 12:13 /home/michal/crontab -rw-r--r-- 1 michal michal 82 Oct 18 12:13 /home/michal/fstab $ multipass transfer /home/michal/crontab /home/michal/fstab keen-yak: $ multipass exec keen-yak -- ls -l crontab fstab -rw-rw-r-- 1 ubuntu ubuntu 722 Oct 18 12:14 crontab -rw-rw-r-- 1 ubuntu ubuntu 82 Oct 18 12:14 fstab 6）容器自动化 为了保持开发环境和线上环境一致性 同时节省部署时间 multipass 给我们提供了 –cloud-init 选项进行容器启动初始化配置: multipass launch --name ubuntu --cloud-init config.yaml 上面 config.yaml 则是容器的初始化配置文件，例如，我们想在初始化容器的时候，自动下载安装 Node.js，内容如下： #cloud-config runcmd: - curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - - sudo apt-get install -y nodejs runcmd 可以指定容器 首次启动 时运行的命令 凡是用户自定义的cloud-init的配置文件,必须以#cloud-config开头，这是cloud-init识别它的方式。 yaml 配置文件参考链接：https://cloudinit.readthedocs.io/en/latest/topics/examples.html?highlight=lock-passwd#including-users-and-groups ","date":"2023-11-11","objectID":"/posts/2023-11-11-multipass/:0:2","tags":["multipass","vm"],"title":"multipass","uri":"/posts/2023-11-11-multipass/"},{"categories":["mac"],"content":"Mac 优化 ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:0:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["mac"],"content":"1、mac终端增加颜色，参考centos7 eval \"$(/opt/homebrew/bin/brew shellenv)\" # Setting PATH for Python 3.9 # The original version is saved in .bash_profile.pysave PATH=\"/Library/Frameworks/Python.framework/Versions/3.9/bin:${PATH}\" export PG_HOME=/opt/homebrew/Cellar/postgresql@10/10.17 export PATH export GOPROXY=https://goproxy.cn,direct export GOPATH=/Users/sugar/go export GO111MODULE=\"on\" export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN:$PG_HOME/bin # 参考RHEL console export PS1=\"[\\u@\\h \\W]\\\\$ \" export CLICOLOR=1 export LSCOLORS=ExGxFxdaCxDaDahbadeche export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:1:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["mac"],"content":"2、安装homebrew 参考：http://mirrors.ustc.edu.cn/help/brew.git.html 配置环境变量 [sugar@localhost ~]$ cat ~/.bash_profile # brew 安装其他目录下才需要设置 #eval \"$(/opt/homebrew/bin/brew shellenv)\" export HOMEBREW_BREW_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/brew.git\" export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/homebrew-core.git\" export HOMEBREW_BOTTLE_DOMAIN=\"https://mirrors.ustc.edu.cn/homebrew-bottles\" 安装 /bin/bash -c \"$(curl -fsSL https://cdn.jsdelivr.net/gh/Homebrew/install@HEAD/install.sh)\" 3、去除自动生成.DS_Store文件 .DS_Store是Mac OS保存文件夹的自定义属性的隐藏文件，如文件的图标位置或背景色，相当于Windows的desktop.ini 1）禁止.DS_Store文件的生成： defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUE 2）恢复.DS_Store文件的生成 defaults delete com.apple.desktopservices DSDontWriteNetworkStores 3）删除磁盘上的 .DS_Store,删除当前目录及其子目录下的所有.DS_Store 文件: sudo find . -name '*.DS_Store' -type f -delete 最后重启电脑即可生效！ ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:2:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["mac"],"content":"4、环境变量 eval \"$(/opt/homebrew/bin/brew shellenv)\" export HOMEBREW_BREW_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/brew.git\" export HOMEBREW_BOTTLE_DOMAIN=\"https://mirrors.ustc.edu.cn/homebrew-bottles\" export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.ustc.edu.cn/homebrew-core.git\" export PG_HOME=/opt/homebrew/Cellar/postgresql@10/10.17 export GOPROXY=https://goproxy.cn,direct export GOPATH=/Users/sugar/go export GO111MODULE=\"on\" export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN:$PG_HOME/bin export GOPRIVATE=\"local.com,gitee.com/cccccc\" export GOINSECURE=\"local.com\" #export CGO_ENABLED=\"0\" #export PS1='[\\u@\\h \\W]\\$ ' export PS1=\"[\\u@\\h \\W]\\\\$ \" export CLICOLOR=1 export LSCOLORS=ExGxFxdaCxDaDahbadeche export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 function k8s-local(){ unset KUBECONFIG export KUBECONFIG=~/.kube/kubeconfig-local.json kubectl cluster-info kubectl get namespace } function k8s-1(){ unset KUBECONFIG export KUBECONFIG=~/.kube/kubeconfig-1.json kubectl cluster-info kubectl get namespace } alias ll='ls -l' alias lh='ls -lh' #UserIP=$(who -u am i | cut -d\"(\" -f 2 | sed -e \"s/[()]//g\") export HISTTIMEFORMAT=\"[%F %T] [`whoami`] \" export HISTSIZE=99999 export HISTFILESIZE=550 # socket5 proxy(){ export http_proxy=\"http://127.0.0.1:5559\" export https_proxy=\"http://127.0.0.1:5559\" # 设置代理 networksetup -setwebproxy Wi-Fi 127.0.0.1 5559 networksetup -setsecurewebproxy Wi-Fi 127.0.0.1 5559 networksetup -setsocksfirewallproxy Wi-Fi 127.0.0.1 5558 # 打开系统代理 networksetup -setwebproxystate Wi-Fi on networksetup -setsecurewebproxystate Wi-Fi on networksetup -setsocksfirewallproxystate Wi-Fi on ~/Desktop/v2cc/proxy } # 取消设置的代理 noproxy(){ unset http_proxy unset https_proxy networksetup -setwebproxystate Wi-Fi off networksetup -setsecurewebproxystate Wi-Fi off networksetup -setsocksfirewallproxystate Wi-Fi off } export PATH=\"/opt/homebrew/opt/icu4c/bin:$PATH\" export PATH=\"/opt/homebrew/opt/icu4c/sbin:$PATH\" #For compilers to find icu4c you may need to set: export LDFLAGS=\"-L/opt/homebrew/opt/icu4c/lib\" export CPPFLAGS=\"-I/opt/homebrew/opt/icu4c/include\" #For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\"/opt/homebrew/opt/icu4c/lib/pkgconfig\" export PATH=\"/opt/homebrew/opt/node@14/bin:$PATH\" export LDFLAGS=\"-L/opt/homebrew/opt/node@14/lib\" export CPPFLAGS=\"-I/opt/homebrew/opt/node@14/include\" 5、使用bash-completion补全 bash-completion部分已经不兼容，需要使用v2版 brew install bash-completion@2 vim ~/.bash_profile # use bash-completion export BASH_COMPLETION_COMPAT_DIR=\"/opt/homebrew/etc/bash_completion.d\" [[ -r \"/opt/homebrew/etc/profile.d/bash_completion.sh\" ]] \u0026\u0026 . \"/opt/homebrew/etc/profile.d/bash_completion.sh\" 6、kubectl命令补齐 vim ~/.bash_profile kubectl completion bash \u003e /opt/homebrew/etc/bash_completion.d/kubectl # 设置别名 echo 'alias k=kubectl' \u003e\u003e~/.bash_profile echo 'complete -o default -F __start_kubectl k' \u003e\u003e~/.bash_profile 7、应用下载网站 http://mac-torrent-download.net/ https://www.torrentmac.net/ https://mac-torrents.io/ 8 、软件出现 【xxxxx将对您的电脑造成伤害，您应该将它移动到废纸篓】 # 切换到软件或者cmd所在的目录 codesign -f -s - --deep xxxx_app_name # 例如 codesign -f -s - --deep terraform 9、安装“Chromium”已损坏，无法打开。 您应该将它移到废纸篓。 # 因为签名不造成的，执行以下命令 sudo xattr -cr /Applications/Chromium.app 10、配置github代理 # http || https # Host github.com # User git # ProxyCommand nc -v -x 127.0.0.1:5559 %h %p Host github.com User git ProxyCommand nc -v -x 127.0.0.1:5558 %h %p ","date":"2023-11-11","objectID":"/posts/2023-11-11-mac/:3:0","tags":["mac"],"title":"mac","uri":"/posts/2023-11-11-mac/"},{"categories":["linux 基础"],"content":"ubuntu 基础 ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:0:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"一、apt源 修改apt源为国内源，主配置文件：/etc/apt/sources.list，配置文件目录：/etc/apt/sources.d，以1804为例。 # 修改 /etc/apt/sources.list deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 修改命令 sudo sed -i \"s@http://.*archive.ubuntu.com@http://repo.huaweicloud.com@g\" /etc/apt/sources.list sudo sed -i \"s@http://.*security.ubuntu.com@http://repo.huaweicloud.com@g\" /etc/apt/sources.list ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:1:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"apt 使用问题 1）apt-get安装中的E: Sub-process /usr/bin/dpkg returned an error code (1)问题 参考网址：https://www.cnblogs.com/orzs/p/10844869.html cd /var/lib/dpkg/ sudo mv info/ info_bak # 现将info文件夹更名 sudo mkdir info # 再新建一个新的info文件夹 sudo apt-get update # 更新 sudo apt-get -f install # 修复 sudo mv info/* info_bak/ # 执行完上一步操作后会在新的info文件夹下生成一些文件，现将这些文件全部移到info_bak文件夹下 sudo rm -rf info # 把自己新建的info文件夹删掉 sudo mv info_bak info # 把以前的info文件夹重新改回名 2）Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend) 解决办法： 第一种情况： 进程中存在与apt相关的正在运行的进程： 首先检查是否在运行apt,apt-get相关的进程 ps aux | grep -i apt 如果存在与apt相关的正在运行的进程，kill掉进程； sudo kill -9 \u003cprocess id\u003e 或者直接简单粗暴的： sudo killall apt apt-get 如果进行完上面的步骤还是无法顺利执行apt-get 操作，则属于第二种情况： 第二种情况： 进程列表中已经没有与apt,apt-get相关的进程在运行，但依然报错，在这种情况下，产生错误的根本原因是lock file。 loack file用于防止两个或多个进程使用相同的数据。 当运行apt或apt-commands时，它会在几个地方创建lock files。 当前一个apt命令未正确终止时，lock file未被删除，因此它们会阻止任何新的apt / apt-get命令实例，比如正在执行apt-get upgrade，在执行过程中直接ctrl+c取消了该操作，很有可能就会造成这种情况。 要解决此问题，首先要删除lock file。 使用lsof命令获取持有lock file的进程的进程ID,依次运行如下命令： lsof /var/lib/dpkg/lock lsof /var/lib/apt/lists/lock lsof /var/cache/apt/archives/lock 需要注意的是，以上命令执行结果如果无返回，说明没有正在运行的进程；如果返回了相应的进程，需要kill掉。 删除所有的lock file sudo rm /var/lib/apt/lists/lock sudo rm /var/cache/apt/archives/lock sudo rm /var/lib/dpkg/lock 最后重新配置一下dpkg： sudo dpkg --configure -a 如果上述命令不出任何错误，就万事大吉了。（我是到这里问题就解决了） 但是有时候，生活总是嫌你不够惨，执行配置命令时可能会出现以下错误： dpkg: error: dpkg frontend is locked by another process 这需要我们额外进行一些操作： 找出正在锁定lock file的进程： lsof /var/lib/dpkg/lock-frontend kill掉输出的进程（如果输出为空则忽略） sudo kill -9 PID 删除lock file并重新配置dpkg: sudo rm /var/lib/dpkg/lock-frontend sudo dpkg --configure -a ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:1:1","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"升级系统 ubuntu 1804 升级到2004 1）切换apt源 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 2）更新和重启系统 apt update apt upgrade reboot 3）更新系统 do-release-upgrade Reading cache Checking package manager Continue running under SSH? This session appears to be running under ssh. It is not recommended to perform a upgrade over ssh currently because in case of failure it is harder to recover. If you continue, an additional ssh daemon will be started at port '1022'. Do you want to continue? Continue [yN] y Starting additional sshd To make recovery in case of failure easier, an additional sshd will be started on port '1022'. If anything goes wrong with the running ssh you can still connect to the additional one. If you run a firewall, you may need to temporarily open this port. As this is potentially dangerous it's not done automatically. You can open the port with e.g.: 'iptables -I INPUT -p tcp --dport 1022 -j ACCEPT' ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:1:2","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"二、安装 docker ubuntu与红帽系列系统不同，在配置apt源时需要先配置要添加的密钥的证书 root@harbor:~# curl -fsSL https://mirrors.huaweicloud.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - root@harbor:~# sudo apt-get install software-properties-common root@harbor:~# add-apt-repository \"deb [arch=amd64] https://mirrors.huaweicloud.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" root@harbor:~# apt-get update root@harbor:~# apt-get install docker-ce ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:2:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"三、vim 设置 ubuntu上默认的许多文件的编辑器是nano，其使用非常不友好，可以修改为vim root@ubuntu:~# sudo select-editor Select an editor. To change later, run 'select-editor'. 1. /bin/nano \u003c---- easiest 2. /usr/bin/vim.basic 3. /usr/bin/vim.tiny 4. /bin/ed Choose 1-4 [1]: 2 # 先择vim.basic，设置好后就可以在编辑一些文件或服务时使用vim ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:3:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"四、exsi 配置 exsi 安装ubuntu2004 报错 multipathd[651]: sda: add missing path multipathd[651]: sda: failed to get udev uid: Invalid argument multipathd[651]: sda: failed to get sysfs uid: Invalid argument multipathd[651]: sda: failed to get sgio uid: No such file or directory multipathd[651]: sda: add missing path multipathd[651]: sda: failed to get udev uid: Invalid argument multipathd[651]: sda: failed to get sysfs uid: Invalid argument multipathd[651]: sda: failed to get sgio uid: No such file or directory 解决办法： https://askubuntu.com/questions/1242731/ubuntu-20-04-multipath-configuration 方法一： exsi虚拟机配置文件中增加 disk.EnableUUID = \"TRUE\" 方法二： # vim defaults { user_friendly_names yes } blacklist { device { vendor \"VMware\" product \"Virtual disk\" } } # 重启 /etc/init.d/multipath-tools restart # 或者 systemctl restart multipathd defaults { user_friendly_names yes } blacklist { devnode \"^(ram|raw|loop|fd|md|dm-|sr|scd|st|sda)[0-9]*\" } ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:4:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"五、network配置 静态IP 1、配置静态ip root@ubuntu:/etc/netplan# pwd /etc/netplan root@ubuntu:/etc/netplan# vim 50-cloud-init.yaml network: version: 2 renderer: networkd ethernets: ens160: dpch4: no addresses: - 192.168.100.17/24 gateway4: 192.168.100.1 nameservers: addresses: - 223.5.5.5 或者 network: ethernets: ens3: dhcp4: no addresses: [192.168.100.141/24] gateway4: 192.168.100.1 nameservers: addresses: [114.114.114.114,8.8.8.8] version: 2 2204开始 network: version: 2 ethernets: ens3: dhcp4: false addresses: [192.168.100.141/24] routes: - to: default via: 192.168.100.1 nameservers: addresses: [114.114.114.114,8.8.8.8] 2、加载配置 root@ubuntu:~# netplan apply #测试网络 root@ubuntu:~# ping baidu.com 3、连接wifi network: version: 2 wifis: wlan0: dhcp4: true access-points: \"sugar\": # ssid name password: \"password\" ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:5:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"六、rc.local 设置 [root@tc ~]# cat /etc/systemd/system/rc-local.service [Unit] Description=/etc/rc.local Compatibility Documentation=man:systemd-rc-local-generator(8) ConditionFileIsExecutable=/etc/rc.local After=network.target [Service] Type=forking ExecStart=/etc/rc.local TimeoutStartSec=0 TimeoutStopSec=30 RemainAfterExit=yes GuessMainPID=no [Install] WantedBy=multi-user.target [root@tc rc.d]# cat rc.local #!/bin/bash date \u003e\u003e /tmp/data.txt exit 0 ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:6:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"七、ssh 服务配置 ubuntu默认不安装openssh-server 1、安装openssl-server root@ubuntu:~# apt-get install openssh-sevrer root@ubuntu:~# systemctl start ssh root@ubuntu:~# systemctl enable ssh # 查询可安装的包所有版本 apt list -a ssh Listing... Done ssh/jammy-updates,jammy-security 1:8.9p1-3ubuntu0.6 all ssh/jammy 1:8.9p1-3 all apt install ssh=1:8.9p1-3 all 2、允许root用户远程登陆 ubuntu默认不允许root用户远程登陆 root@ubuntu:~# vim /etc/ssh/sshd_config 32 #PermitRootLogin prohibit-password 修改为 33 PermitRootLogin yes 打开密钥认证 56 #PasswordAuthentication yes 修改为 57 PasswordAuthentication yes 为root用户设置密码 root@ubuntu:~# passwd root 重启ssh服务 root@ubuntu:~# systemctl restart ssh ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:7:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"八、unsnapd ubuntu 系统卸载snap 停止开机自启 sudo systemctl disable snapd.service sudo systemctl disable snapd.socket sudo systemctl disable snapd.seeded.service 卸载snap安装的软件 # 查询当前系统上snap安装了哪些app snap list # 卸载 sudo snap remove xxxxx_app 禁止重新安装snap sudo vim /etc/apt/preferences.d/nosnap.pref Package: snapd Pin: release a=* Pin-Priority: -10 ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:8:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["linux 基础"],"content":"九、用户管理 1、用户 Ubuntu系统中存在的是nobody和nogroup 在使用useradd命令创建用户的时候，ubuntu不会为主动为用户创建家目录，其默认的shell也不是bash 创建一个具有家目录的用户，其shell为bash root@ubuntu:~# useradd -m test3 -s /bin/bash # 若没有指定shell，可以进行修改 root@ubuntu:~# chsh -s /bin/bash test1 2、创建用户，非交互式更改密码 root@ubuntu:~# useradd tom root@ubuntu:~# echo tom:jerry | chpasswd 格式：echo username:password | chpasswd 3、sudo权限免密 root@ubuntu:~# vim /etc/sudoers ops_serialt ALL=(ALL) NOPASSWD: ALL 4、ubuntu 2004重置密码 参考链接：https://blog.51cto.com/u_15169172/2793265 1）重启服务器后按e进入grub菜单 2）在linux的一行的最后修改为rw init=/bin/bash 3）按ctrl + x启动系统 按下Ctrl+c可以撤销登录 4）查看根目录是否有写的权限：mount | grep -w / 5）重置密码 确认根目录正处于rw状态后，那就可以直接重置或破解Ubuntu 20.04任何用户的密码了。 重置root密码： passwd root 6）重启 完成重置密码或者破解密码的工作后，重启Ubuntu 20.04，执行以下命令重启服务器： exec /sbin/init ","date":"2023-11-11","objectID":"/posts/2023-11-11-ubuntu/:9:0","tags":["ubuntu","linux"],"title":"ubuntu basic","uri":"/posts/2023-11-11-ubuntu/"},{"categories":["DevOps"],"content":"WSL2 windows上到linux(windows sub system for linux ) ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:0","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"一、安装 wsl 2 如果系统中带有 wsl，则需要升级到 wsl 2。 以管理员身份打开 PowerShell（“开始”菜单 \u003e“PowerShell”\u003e 单击右键 \u003e“以管理员身份运行”），然后输入以下命令： dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 启动虚拟化功能，然后重启windows dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 下载 linux 内核更新包 https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi 修改 wsl 2 为默认的版本 wsl --set-default-version 2 下载 linux 发行版 Ubuntu 20.04 Ubuntu 20.04 ARM Ubuntu 18.04 Ubuntu 18.04 ARM Ubuntu 16.04 Debian GNU/Linux Kali Linux SUSE Linux Enterprise Server 12 SUSE Linux Enterprise Server 15 SP2 openSUSE Leap 15.2 Fedora Remix for WSL 将获得 \u003cdistro\u003e.appx 包 导入系统 app-name 是 Linux 发行版 .appx 文件的名称。 Add-AppxPackage .\\app_name.appx ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:1","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"二、wsl 基本命令 wsl 常用命令 # 安装特定的linux发行版 wsl -d \u003cDistribution Name\u003e # 列出可用的 Linux 发行版 wsl -l -o # 列出已安装的 Linux 发行版 wsl --list --verbose # 将 WSL 版本设置为 1 或 2 wsl --set-version 2 # 设置默认 WSL 版本 wsl --set-default-version \u003cVersion\u003e wsl --set-default-version 2 # 设置默认 Linux 发行版 wsl --set-default \u003cDistribution Name\u003e # 将目录更改为主页 wsl ~ # 通过 PowerShell 或 CMD 运行特定的 Linux 发行版 wsl --distribution \u003cDistribution Name\u003e --user \u003cUser Name\u003e # 启动一个发行版 wsl -d Ubuntu-20.04 -u root 更新 WSL wsl --update 回滚wsl版本 wsl --update rollback 检查 WSL 状态 wsl --status 以特定用户的身份运行 wsl -u \u003cUsername\u003e 更改发行版的默认用户 \u003cDistributionName\u003e config --default-user \u003cUsername\u003e # ubuntu config --default-user johndoe 会将 Ubuntu 发行版的默认用户更改为“johndoe”用户。 关闭 wsl --shutdown 内存限制 .wslconfig 文件 关闭一个发行版 wsl --terminate \u003cDistribution Name\u003e 将发行版导出到 TAR 文件 wsl --export \u003cDistribution Name\u003e \u003cFileName\u003e 导入新发行版 wsl --import \u003cDistribution Name\u003e \u003cInstallLocation\u003e \u003cFileName\u003e 注销或卸载 Linux 发行版，注销后就被删除，注意！！！ wsl --unregister \u003cDistributionName\u003e 装载磁盘或设备 wsl --mount \u003cDiskPath\u003e 安装特定的linux发行版 wsl -d \u003cDistribution Name\u003e wsl 配置文件 https://docs.microsoft.com/zh-cn/windows/wsl/wsl-config ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:2","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"三、发行版维护 1、迁移工作目录 wsl 默认安装c盘里，c盘因为硬盘分区的问题，可能分配空间比较小，因此可能存在需要迁移的操作。 1）关闭运行的系统 PS C:\\Users\\serialt\u003e PS C:\\Users\\serialt\u003e wsl -l -v NAME STATE VERSION * Ubuntu-20.04 Running 2 docker-desktop Stopped 2 docker-desktop-data Stopped 2 PS C:\\Users\\serialt\u003e wsl --shutdown PS C:\\Users\\serialt\u003e wsl -l -v NAME STATE VERSION * Ubuntu-20.04 Stopped 2 docker-desktop Stopped 2 docker-desktop-data Stopped 2 PS C:\\Users\\serialt\u003e 2）导出与导入发行版 wsl --export docker-desktop-data \"E:\\wsl\\docker-data\\docker-desktop-data.tar\" wsl --unregister docker-desktop-data wsl --import docker-desktop-data D:\\docker\\desktop \"E:\\wsl\\docker-data\\docker-desktop-data.tar\" --version 2 wsl --export docker-desktop \"E:\\wsl\\docker-data\\docker-desktop.tar\" wsl --unregister docker-desktop wsl --import docker-desktop D:\\docker\\desktop \"E:\\wsl\\docker-data\\docker-desktop.tar\" --version 2 ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:3","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"四、自定义发行版 参考链接：https://docs.microsoft.com/zh-cn/windows/wsl/use-custom-distro 通过使用 tar 文件导入任何 Linux 发行版，可在适用于 Linux 的 Windows 子系统 (WSL) 中使用该发行版（即使它不在 Microsoft Store 中提供）。 本文演示了如何通过使用 Docker 容器获取 Linux 发行版 CentOS 的 tar 文件来将它导入，以便与 WSL 一起使用。 此过程可应用于导入任何 Linux 发行版。 1、获取发行版的tar文件 首先，需要获取一个 tar 文件，其中包含发行版的所有 Linux 二进制文件。 可通过多种方式获取 tar 文件，其中两种方式包括： 下载提供的 tar 文件。 可在 Alpine Linux 下载站点的“微型根文件系统”部分找到 Alpine 的示例。 查找 Linux 发行版容器，将实例导出为 tar 文件。 以下示例将使用 CentOS 容器演示此过程。 获取CentOS的tar文件 从容器中导出tar文件 [root@tc tabby]# docker pull rockylinux Using default tag: latest latest: Pulling from library/rockylinux 72a2451028f1: Pull complete Digest: sha256:5fed5497b568bcf7a90a00965987fc099edbcf44b1179a5ef6d4b47758281ca5 Status: Downloaded newer image for rockylinux:latest docker.io/library/rockylinux:latest [root@tc tabby]# docker run -tid --name=rocky rockylinux 38b201fca776cc1aadf029cbf5a1d6a1fb57ff62f5d71d4ed0416d870b407550 [root@tc tabby]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 38b201fca776 rockylinux \"/bin/bash\" 4 seconds ago Up 2 seconds rocky [root@tc tabby]# [root@tc tabby]# dockerContainerID=$(docker container ls -a | grep -i rocky | awk '{print $1}') [root@tc tabby]# docker export $dockerContainerID \u003e /mnt/e/rocky.tar [root@tc tabby]# du -sh /mnt/e/rocky.tar 202M /mnt/e/rocky.tar 2、导入到wsl中 准备好 tar 文件后，可使用以下命令导入它：wsl --import \u003cDistro\u003e \u003cInstallLocation\u003e \u003cFileName\u003e。 # 创建好存储发行版的目录 cd E:\\wsl2 mkdir E:\\wsl2\\Rocky # 导入tar文件 PS E:\\wsl2\u003e wsl --import Rocky E:\\wsl2\\Rocky ..\\rocky.tar PS E:\\wsl2\u003e wsl -l -v NAME STATE VERSION * docker-desktop-data Stopped 2 Rocky Stopped 2 docker-desktop Stopped 2 Ubuntu-20.04 Running 2 PS E:\\wsl2\u003e 3、启动 wsl -d Rocky -u root 自定义的发行版可能存在因使用system管理服务而无法使用service去管理服务 ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:4","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["DevOps"],"content":"五、wsl 配置文件 1、wsl.conf ​```toml [root@tc tcs]# cat /etc/wsl.conf # Automatically mount Windows drive when the distribution is launched [automount] # Set to true will automount fixed drives (C:/ or D:/) with DrvFs under the root directory set above. Set to false means drives won't be mounted automatically, but need to be mounted manually or with fstab. enabled = true # Sets the directory where fixed drives will be automatically mounted. This example changes the mount location, so your C-drive would be /c, rather than the default /mnt/c. #root = /mnt/d/serialt/ # DrvFs-specific options can be specified. options = \"metadata,uid=1003,gid=1003,umask=077,fmask=11,case=off\" # Sets the `/etc/fstab` file to be processed when a WSL distribution is launched. mountFsTab = true # Network host settings that enable the DNS server used by WSL 2. This example changes the hostname, sets generateHosts to false, preventing WSL from the default behavior of auto-generating /etc/hosts, and sets generateResolvConf to false, preventing WSL from auto-generating /etc/resolv.conf, so that you can create your own (ie. nameserver 1.1.1.1). [network] hostname = tc generateHosts = true generateResolvConf = true # Set whether WSL supports interop process like launching Windows apps and adding path variables. Setting these to false will block the launch of Windows processes and block adding $PATH environment variables. [interop] enabled = false appendWindowsPath = true # Set the user when launching a distribution with WSL. [user] default = root # Set a command to run when a new WSL instance launches. This example starts the Docker container service. [boot] command = service docker start [root@tc tcs]# ​``` ","date":"2023-11-11","objectID":"/posts/2023-11-11-wsl/:1:5","tags":["wsl","wsl-2","wsl-windows"],"title":"wsl","uri":"/posts/2023-11-11-wsl/"},{"categories":["Go 库文档"],"content":"gopsutil 库 参考链接：https://segmentfault.com/a/1190000022281174 ","date":"2023-11-11","objectID":"/posts/2023-11-11-gopsutil/:1:0","tags":["Go","gopsutil"],"title":"Go gopsutil","uri":"/posts/2023-11-11-gopsutil/"},{"categories":["Go 库文档"],"content":"简介 gopsutil是 Python 工具库psutil 的 Golang 移植版，可以帮助我们方便地获取各种系统和硬件信息。gopsutil为我们屏蔽了各个系统之间的差异，具有非常强悍的可移植性。有了gopsutil，我们不再需要针对不同的系统使用syscall调用对应的系统方法。更棒的是gopsutil的实现中没有任何cgo的代码，使得交叉编译成为可能。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-gopsutil/:1:1","tags":["Go","gopsutil"],"title":"Go gopsutil","uri":"/posts/2023-11-11-gopsutil/"},{"categories":["Go 库文档"],"content":"快速使用 安装 go get github.com/shirou/gopsutil 使用 package main import ( \"fmt\" \"github.com/shirou/gopsutil/mem\" ) func main() { v, _ := mem.VirtualMemory() fmt.Printf(\"Total: %v, Available: %v, UsedPercent:%f%%\\n\", v.Total, v.Available, v.UsedPercent) fmt.Println(v) } gopsutil将不同的功能划分到不同的子包中： cpu：CPU 相关； disk：磁盘相关； docker：docker 相关； host：主机相关； mem：内存相关； net：网络相关； process：进程相关； winservices：Windows 服务相关。 想要使用对应的功能，要导入对应的子包。例如，上面代码中，我们要获取内存信息，导入的是mem子包。mem.VirtualMemory()方法返回内存信息结构mem.VirtualMemoryStat，该结构有丰富的字段，我们最常使用的无外乎Total（总内存）、Available（可用内存）、Used（已使用内存）和UsedPercent（内存使用百分比）。mem.VirtualMemoryStat还实现了fmt.Stringer接口，以 JSON 格式返回内存信息。语句fmt.Println(v)会自动调用v.String()，将返回信息输出。程序输出： Total: 8526921728, Available: 3768975360, UsedPercent:55.000000% {\"total\":8526921728,\"available\":3768975360,\"used\":4757946368,\"usedPercent\":55,\"free\":0,\"active\":0,\"inactive\":0,\"wired\":0,\"laundry\":0,\"buffers\":0,\"cached\":0,\"writeback\":0,\"dirty\":0,\"writebacktmp\":0,\"shared\":0,\"slab\":0,\"sreclaimable\":0,\"sunreclaim\":0,\"pagetables\":0,\"swapcached\":0,\"commitlimit\":0,\"committedas\":0,\"hightotal\":0,\"highfree\":0,\"lowtotal\":0,\"lowfree\":0,\"swaptotal\":0,\"swapfree\":0,\"mapped\":0,\"vmalloctotal\":0,\"vmallocused\":0,\"vmallocchunk\":0,\"hugepagestotal\":0,\"hugepagesfree\":0,\"hugepagesize\":0} 单位为字节，我的电脑内存 8GB，当前使用百分比为 55%，可用内存 3768975360B（即 3.51GB）。 CPU 我们知道 CPU 的核数有两种，一种是物理核数，一种是逻辑核数。物理核数就是主板上实际有多少个 CPU，一个物理 CPU 上可以有多个核心，这些核心被称为逻辑核。gopsutil中 CPU 相关功能在cpu子包中，cpu子包提供了获取物理和逻辑核数、CPU 使用率的接口： Counts(logical bool)：传入false，返回物理核数，传入true，返回逻辑核数； Percent(interval time.Duration, percpu bool)：表示获取interval时间间隔内的 CPU 使用率，percpu为false时，获取总的 CPU 使用率，percpu为true时，分别获取每个 CPU 的使用率，返回一个[]float64类型的值。 例如： func main() { physicalCnt, _ := cpu.Counts(false) logicalCnt, _ := cpu.Counts(true) fmt.Printf(\"physical count:%d logical count:%d\\n\", physicalCnt, logicalCnt) totalPercent, _ := cpu.Percent(3*time.Second, false) perPercents, _ := cpu.Percent(3*time.Second, true) fmt.Printf(\"total percent:%v per percents:%v\", totalPercent, perPercents) } 上面代码获取物理核数和逻辑核数，并获取 3s 内的总 CPU 使用率和每个 CPU 各自的使用率，程序输出（注意每次运行输出可能都不相同）： physical count:4 logical count:8 total percent:[30.729166666666668] per percents:[32.64248704663213 26.94300518134715 44.559585492227974 23.958333333333336 36.787564766839374 20.3125 38.54166666666667 28.125] 详细信息调用cpu.Info()可获取 CPU 的详细信息，返回[]cpu.InfoStat： func main() { infos, _ := cpu.Info() for _, info := range infos { data, _ := json.MarshalIndent(info, \"\", \" \") fmt.Print(string(data)) } } 为了方便查看，我使用 JSON 输出结果： { \"cpu\": 0, \"vendorId\": \"GenuineIntel\", \"family\": \"198\", \"model\": \"\", \"stepping\": 0, \"physicalId\": \"BFEBFBFF000906E9\", \"coreId\": \"\", \"cores\": 8, \"modelName\": \"Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz\", \"mhz\": 3601, \"cacheSize\": 0, \"flags\": [], \"microcode\": \"\" } 由结果可以看出，CPU 是 Intel 的 i7-7700 系列，频率 3.60GHz。上面是我在 Windows 上运行的返回结果，内部使用了github.com/StackExchange/wmi库。在 Linux 下每个逻辑 CPU 都会返回一个InfoStat结构。 时间占用 调用cpu.Times(percpu bool)可以获取从开机算起，总 CPU 和 每个单独的 CPU 时间占用情况。传入percpu=false返回总的，传入percpu=true返回单个的。每个 CPU 时间占用情况是一个TimeStat结构： // src/github.com/shirou/gopsutil/cpu/cpu.go type TimesStat struct { CPU string `json:\"cpu\"` User float64 `json:\"user\"` System float64 `json:\"system\"` Idle float64 `json:\"idle\"` Nice float64 `json:\"nice\"` Iowait float64 `json:\"iowait\"` Irq float64 `json:\"irq\"` Softirq float64 `json:\"softirq\"` Steal float64 `json:\"steal\"` Guest float64 `json:\"guest\"` GuestNice float64 `json:\"guestNice\"` } CPU：CPU 标识，如果是总的，该字段为cpu-total，否则为cpu0、cpu1…； User：用户时间占用（用户态）； System：系统时间占用（内核态）； Idle：空闲时间； … 例如： func main() { infos, _ := cpu.Times(true) for _, info := range infos { data, _ := json.MarshalIndent(info, \"\", \" \") fmt.Print(string(data)) } } 为了方便查看，我用 JSON 输出结果，下面是其中一个输出： { \"cpu\": \"cpu0\", \"user\": 674.46875, \"system\": 1184.984375, \"idle\": 7497.1875, \"nice\": 0, \"iowait\": 0, \"irq\": 75.578125, \"softirq\": 0, \"steal\": 0, \"guest\": 0, \"guestNice\": 0 } 磁盘 子包disk用于获取磁盘信息。disk可获取 IO 统计、分区和使用率信息。下面依次介绍。 IO 统计 调用disk.IOCounters()函数，返回的 IO 统计信息用map[string]IOCountersStat类型表示。每个分区一个结构，键为分区名，值为统计信息。这里摘取统计","date":"2023-11-11","objectID":"/posts/2023-11-11-gopsutil/:1:2","tags":["Go","gopsutil"],"title":"Go gopsutil","uri":"/posts/2023-11-11-gopsutil/"},{"categories":["Go 库文档"],"content":"Go 读取yaml格式配置文件 package config import ( \"fmt\" \"io/ioutil\" \"gopkg.in/yaml.v3\" ) type Service struct { Host string `json:\"host\" yaml:\"host\"` Port string `json:\"port\" yaml:\"port\"` } type MyConfig struct { Service Service `json:\"service\" yaml:\"service\"` } var Config *MyConfig func LoadConfig(filepath string) { if filepath == \"\" { return } // 读yaml文件 config, err := ioutil.ReadFile(filepath) if err != nil { fmt.Printf(\"read config failed, please check the path: %v , err: %v\", filepath, err) } err = yaml.Unmarshal(config, \u0026Config) if err != nil { fmt.Printf(\"Unmarshal to struct, err: %v\", err) } fmt.Printf(\"LoadConfig: %v\", Config) } // 写yaml文件 data, err := yaml.Marshal(SkopeoData) if err != nil { slog.Error(\"yaml marshal failed\", \"err\", err) return } err = os.WriteFile(config.AutoSyncfile, data, 0644) if err != nil { slog.Error(\"Write auto sync data to file failed\", \"err\", err) } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-yaml/:1:0","tags":["Go","yaml"],"title":"Go yaml","uri":"/posts/2023-11-11-go-yaml/"},{"categories":["Go 库文档"],"content":"Go语言内置包之strconv Go语言中strconv包实现了基本数据类型和其字符串表示的相互转换。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:0","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"strconv包 strconv包实现了基本数据类型与其字符串表示的转换，主要有以下常用函数： Atoi()、Itia()、parse系列、format系列、append系列。 更多函数请查看官方文档。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:1","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"string与int类型转换 这一组函数是我们平时编程中用的最多的。 Atoi() Atoi()函数用于将字符串类型的整数转换为int类型，函数签名如下。 func Atoi(s string) (i int, err error) 如果传入的字符串参数无法转换为int类型，就会返回错误。 s1 := \"100\" i1, err := strconv.Atoi(s1) if err != nil { fmt.Println(\"can't convert to int\") } else { fmt.Printf(\"type:%T value:%#v\\n\", i1, i1) //type:int value:100 } Itoa() Itoa()函数用于将int类型数据转换为对应的字符串表示，具体的函数签名如下。 func Itoa(i int) string 示例代码如下： i2 := 200 s2 := strconv.Itoa(i2) fmt.Printf(\"type:%T value:%#v\\n\", s2, s2) //type:string value:\"200\" a的典故 【扩展阅读】这是C语言遗留下的典故。C语言中没有string类型而是用字符数组(array)表示字符串，所以Itoa对很多C系的程序员很好理解。 Parse系列函数 Parse类函数用于转换字符串为给定类型的值：ParseBool()、ParseFloat()、ParseInt()、ParseUint()。 ParseBool() func ParseBool(str string) (value bool, err error) 返回字符串表示的bool值。它接受1、0、t、f、T、F、true、false、True、False、TRUE、FALSE；否则返回错误。 ParseInt() func ParseInt(s string, base int, bitSize int) (i int64, err error) 返回字符串表示的整数值，接受正负号。 base指定进制（2到36），如果base为0，则会从字符串前置判断，”0x”是16进制，”0”是8进制，否则是10进制； bitSize指定结果必须能无溢出赋值的整数类型，0、8、16、32、64 分别代表 int、int8、int16、int32、int64； 返回的err是*NumErr类型的，如果语法有误，err.Error = ErrSyntax；如果结果超出类型范围err.Error = ErrRange。 ParseUnit() func ParseUint(s string, base int, bitSize int) (n uint64, err error) ParseUint类似ParseInt但不接受正负号，用于无符号整型。 ParseFloat() func ParseFloat(s string, bitSize int) (f float64, err error) 解析一个表示浮点数的字符串并返回其值。 如果s合乎语法规则，函数会返回最为接近s表示值的一个浮点数（使用IEEE754规范舍入）。 bitSize指定了期望的接收类型，32是float32（返回值可以不改变精确值的赋值给float32），64是float64； 返回值err是*NumErr类型的，语法有误的，err.Error=ErrSyntax；结果超出表示范围的，返回值f为±Inf，err.Error= ErrRange。 代码示例 b, err := strconv.ParseBool(\"true\") f, err := strconv.ParseFloat(\"3.1415\", 64) i, err := strconv.ParseInt(\"-2\", 10, 64) u, err := strconv.ParseUint(\"2\", 10, 64) 这些函数都有两个返回值，第一个返回值是转换后的值，第二个返回值为转化失败的错误信息。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:2","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"Format系列函数 Format系列函数实现了将给定类型数据格式化为string类型数据的功能。 FormatBool() func FormatBool(b bool) string 根据b的值返回”true”或”false”。 FormatInt() func FormatInt(i int64, base int) string 返回i的base进制的字符串表示。base 必须在2到36之间，结果中会使用小写字母’a’到’z’表示大于10的数字。 FormatUint() func FormatUint(i uint64, base int) string 是FormatInt的无符号整数版本。 FormatFloat() func FormatFloat(f float64, fmt byte, prec, bitSize int) string 函数将浮点数表示为字符串并返回。 bitSize表示f的来源类型（32：float32、64：float64），会据此进行舍入。 fmt表示格式：’f’（-ddd.dddd）、’b’（-ddddp±ddd，指数为二进制）、’e’（-d.dddde±dd，十进制指数）、’E’（-d.ddddE±dd，十进制指数）、’g’（指数很大时用’e’格式，否则’f’格式）、’G’（指数很大时用’E’格式，否则’f’格式）。 prec控制精度（排除指数部分）：对’f’、’e’、’E’，它表示小数点后的数字个数；对’g’、’G’，它控制总的数字个数。如果prec 为-1，则代表使用最少数量的、但又必需的数字来表示f。 代码示例 s1 := strconv.FormatBool(true) s2 := strconv.FormatFloat(3.1415, 'E', -1, 64) s3 := strconv.FormatInt(-2, 16) s4 := strconv.FormatUint(2, 16) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:3","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"其他 isPrint() func IsPrint(r rune) bool 返回一个字符是否是可打印的，和unicode.IsPrint一样，r必须是：字母（广义）、数字、标点、符号、ASCII空格。 CanBackquote() func CanBackquote(s string) bool 返回字符串s是否可以不被修改的表示为一个单行的、没有空格和tab之外控制字符的反引号字符串。 其他 除上文列出的函数外，strconv包中还有Append系列、Quote系列等函数。具体用法可查看官方文档。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-strconv/:0:4","tags":["Go","strconv"],"title":"Go strconv","uri":"/posts/2023-11-11-go-strconv/"},{"categories":["Go 库文档"],"content":"Go tail库 实时读取文件内容 go get github.com/hpcloud/tail 示例： package main import ( \"fmt\" \"time\" \"github.com/hpcloud/tail\" ) func main() { fileName := \"./my.log\" config := tail.Config{ ReOpen: true, // 重新打开 Follow: true, // 是否跟随 Location: \u0026tail.SeekInfo{Offset: 0, Whence: 2}, // 从文件的哪个地方开始读 MustExist: false, // 文件不存在不报错 Poll: true, } tails, err := tail.TailFile(fileName, config) if err != nil { fmt.Println(\"tail file failed, err:\", err) return } var ( line *tail.Line ok bool ) for { line, ok = \u003c-tails.Lines if !ok { fmt.Printf(\"tail file close reopen, filename:%s\\n\", tails.Filename) time.Sleep(time.Second) continue } fmt.Println(\"line:\", line.Text) } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-tail/:1:0","tags":["Go","tail"],"title":"Go tail","uri":"/posts/2023-11-11-go-tail/"},{"categories":["Go 库文档"],"content":"Go语言标准库net包介绍 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-net/:1:0","tags":["Go","net"],"title":"Go net","uri":"/posts/2023-11-11-go-net/"},{"categories":["Go 库文档"],"content":"一、域名解析 DNS 记录是与 DNS 服务器关联的映射文件，无论每个域名与哪个 IP 地址关联，它们都能处理发送到每个域名的请求。net 包包含各种方法来查找 DNS 记录的细节。让我们运行一些示例，收集有关 DNS 服务器的信息以及目标域名的相应记录： 本文是 Go语言中文网组织的 GCTT 翻译，发布在 Go语言中文网公众号，转载请联系我们授权。 1、Go 程序查找域名的 A 记录 net.LookupIP() 函数接受一个字符串（domain-name）并返回一个包含主机的 IPv4 和 IPv6 地址的 net.IP 对象切片。 package main import ( \"fmt\" \"net\" ) func main() { iprecords, _ := net.LookupIP(\"facebook.com\") for _, ip := range iprecords { fmt.Println(ip) } } 上述程序的输出列出了以 IPv4 和 IPv6 格式返回的 facebook.com 的 A 记录。 C:\\golang\\dns\u003e Go run example1.go 2a03:2880:f12f:83:face:b00c:0:25de 31.13.79.35 2、Go 程序查找域名的 CNAME 记录 CNAME 是规范名称的缩写。CNAME 本质上是绑定路径的域名和子域名的文本别名。net.LookupCNAME() 函数接受主机域名（m.facebook.com）作为字符串，并返回给定主机的单个规范域名 package main import ( \"fmt\" \"net\" ) func main() { cname, _ := net.LookupCNAME(\"m.facebook.com\") fmt.Println(cname) } m.facebook.com 域名返回的 CNAME 记录如下所示： C:\\golang\\dns\u003e Go run example2.go star-mini.c10r.facebook.com。 3、Go 程序查找域名的 PTR 指针记录 这些记录提供从地址到名称的反向绑定。PTR 记录应与正向记录完全匹配。net.LookupAddr() 函数对地址执行反向查找，并返回映射到给定地址的名称列表。 package main import ( \"fmt\" \"net\" ) func main() { ptr, _ := net.LookupAddr(\"6.8.8.8\") for _, ptrvalue := range ptr { fmt.Println(ptrvalue) } } 对于给定的地址，上述程序返回单个反向记录，如下所示： C:\\golang\\dns\u003ego run example3.go tms_server.yuma.army.mil. 4、Go 程序查找域名的名称服务器（NS）记录 NS 记录描述了区域的授权名称服务器。NS 还将子域名委托给区域文件上的其他组织。net.LookupNS() 函数将域名（facebook.com）作为字符串，并返回 DNS-NS 记录作为 NS 结构的切片。 package main import ( \"fmt\" \"net\" ) func main() { nameserver, _ := net.LookupNS(\"facebook.com\") for _, ns := range nameserver { fmt.Println(ns) } } 支持该域名的 NS 记录如下所示： C:\\golang\\dns\u003ego run example4.go \u0026{a.ns.facebook.com.} \u0026{b.ns.facebook.com.} 5、Go 程序查找域的 MX 记录 这些记录用来记录可以交换电子邮件的服务器。net.LookupMX() 函数将域名作为字符串，并返回按首选项排序的 MX 结构切片。MX 结构由类型为字符串的 HOST 和 类型为 uint16 的 Pref 组成。 package main import ( \"fmt\" \"net\" ) func main() { mxrecords, _ := net.LookupMX(\"facebook.com\") for _, mx := range mxrecords { fmt.Println(mx.Host, mx.Pref) } } 域名（facebook.com）的输出列表 MX 记录。 C:\\golang\\dns\u003ego run example5.go msgin.vvv.facebook.com. 10 6、Go 程序查找域名的 SRV 服务记录 LookupSRV 函数尝试解析给定服务，协议和域名的 SRV 查询。第二个参数是 “tcp” 或 “udp”。返回的记录按优先级排序，并按照权重随机化。 package main import ( \"fmt\" \"net\" ) func main() { cname, srvs, err := net.LookupSRV(\"xmpp-server\", \"tcp\", \"golang.org\") if err != nil { panic(err) } fmt.Printf(\"\\ncname: %s \\n\\n\", cname) for _, srv := range srvs { fmt.Printf(\"%v:%v:%d:%d\\n\", srv.Target, srv.Port, srv.Priority, srv.Weight) } } 下面的输出演示了 CNAME 返回，后跟由冒号分隔的 SRV 记录的目标，端口，优先级和权重。 C:\\golang\\dns\u003ego run example6.go cname: _xmpp-server._tcp.golang.org. 7、Go 程序查找域名的 TXT 记录 TXT 记录存储有关 SPF 的信息，该信息可以识别授权服务器以代表您的组织发送电子邮件。net.LookupTXT() 函数将域名（facebook.com）作为字符串，并返回 DNS TXT 记录的字符串切片。 package main import ( \"fmt\" \"net\" ) func main() { txtrecords, _ := net.LookupTXT(\"facebook.com\") for _, txt := range txtrecords { fmt.Println(txt) } } gmail.com 的单个 TXT 记录如下所示。 C:\\golang\\dns\u003ego run example7.go v=spf1 redirect=_spf.facebook.com via: http://www.golangprograms.com/find-dns-records-programmatically.html 作者：golangprograms[1]译者：lovechuck[2]校对：polaris1119[3] ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-net/:1:1","tags":["Go","net"],"title":"Go net","uri":"/posts/2023-11-11-go-net/"},{"categories":["Go 库文档"],"content":"参考资料 [1]golangprograms: http://www.golangprograms.com [2]lovechuck: https://github.com/lovechuck [3]polaris1119: https://github.com/polaris1119 [4]GCTT: https://github.com/studygolang/GCTT [5]Go 中文网: https://studygolang.com/ ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-net/:1:2","tags":["Go","net"],"title":"Go net","uri":"/posts/2023-11-11-go-net/"},{"categories":["Go 库文档"],"content":"mapstructure 转换库 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:0","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"简介 mapstructure用于将通用的map[string]interface{}解码到对应的 Go 结构体中，或者执行相反的操作。很多时候，解析来自多种源头的数据流时，我们一般事先并不知道他们对应的具体类型。只有读取到一些字段之后才能做出判断。这时，我们可以先使用标准的encoding/json库将数据解码为map[string]interface{}类型，然后根据标识字段利用mapstructure库转为相应的 Go 结构体以便使用。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:1","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"快速使用 本文代码采用 Go Modules。 首先创建目录并初始化： $ mkdir mapstructure \u0026\u0026 cd mapstructure $ go mod init github.com/darjun/go-daily-lib/mapstructure 下载mapstructure库： $ go get github.com/mitchellh/mapstructure 使用： package main import ( \"encoding/json\" \"fmt\" \"log\" \"github.com/mitchellh/mapstructure\" ) type Person struct { Name string Age int Job string } type Cat struct { Name string Age int Breed string } func main() { datas := []string{` { \"type\": \"person\", \"name\":\"dj\", \"age\":18, \"job\": \"programmer\" } `, ` { \"type\": \"cat\", \"name\": \"kitty\", \"age\": 1, \"breed\": \"Ragdoll\" } `, } for _, data := range datas { var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } switch m[\"type\"].(string) { case \"person\": var p Person mapstructure.Decode(m, \u0026p) fmt.Println(\"person\", p) case \"cat\": var cat Cat mapstructure.Decode(m, \u0026cat) fmt.Println(\"cat\", cat) } } } 运行结果： $ go run main.go person {dj 18 programmer} cat {kitty 1 Ragdoll} 我们定义了两个结构体Person和Cat，他们的字段有些许不同。现在，我们约定通信的 JSON 串中有一个type字段。当type的值为person时，该 JSON 串表示的是Person类型的数据。当type的值为cat时，该 JSON 串表示的是Cat类型的数据。 上面代码中，我们先用json.Unmarshal将字节流解码为map[string]interface{}类型。然后读取里面的type字段。根据type字段的值，再使用mapstructure.Decode将该 JSON 串分别解码为Person和Cat类型的值，并输出。 实际上，Google Protobuf 通常也使用这种方式。在协议中添加消息 ID 或全限定消息名。接收方收到数据后，先读取协议 ID 或全限定消息名。然后调用 Protobuf 的解码方法将其解码为对应的Message结构。从这个角度来看，mapstructure也可以用于网络消息解码，如果你不考虑性能的话😄。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:2","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"字段标签 默认情况下，mapstructure使用结构体中字段的名称做这个映射，例如我们的结构体有一个Name字段，mapstructure解码时会在map[string]interface{}中查找键名name。注意，这里的name是大小写不敏感的！ type Person struct { Name string } 当然，我们也可以指定映射的字段名。为了做到这一点，我们需要为字段设置mapstructure标签。例如下面使用username代替上例中的name： type Person struct { Name string `mapstructure:\"username\"` } 看示例： type Person struct { Name string `mapstructure:\"username\"` Age int Job string } type Cat struct { Name string Age int Breed string } func main() { datas := []string{` { \"type\": \"person\", \"username\":\"dj\", \"age\":18, \"job\": \"programmer\" } `, ` { \"type\": \"cat\", \"name\": \"kitty\", \"Age\": 1, \"breed\": \"Ragdoll\" } `, ` { \"type\": \"cat\", \"Name\": \"rooooose\", \"age\": 2, \"breed\": \"shorthair\" } `, } for _, data := range datas { var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } switch m[\"type\"].(string) { case \"person\": var p Person mapstructure.Decode(m, \u0026p) fmt.Println(\"person\", p) case \"cat\": var cat Cat mapstructure.Decode(m, \u0026cat) fmt.Println(\"cat\", cat) } } } 上面代码中，我们使用标签mapstructure:\"username\"将Person的Name字段映射为username，在 JSON 串中我们需要设置username才能正确解析。另外，注意到，我们将第二个 JSON 串中的Age和第三个 JSON 串中的Name首字母大写了，但是并没有影响解码结果。mapstructure处理字段映射是大小写不敏感的。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:3","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"内嵌结构 结构体可以任意嵌套，嵌套的结构被认为是拥有该结构体名字的另一个字段。例如，下面两种Friend的定义方式对于mapstructure是一样的： type Person struct { Name string } // 方式一 type Friend struct { Person } // 方式二 type Friend struct { Person Person } 为了正确解码，Person结构的数据要在person键下： map[string]interface{} { \"person\": map[string]interface{}{\"name\": \"dj\"}, } 我们也可以设置mapstructure:\",squash\"将该结构体的字段提到父结构中： type Friend struct { Person `mapstructure:\",squash\"` } 这样只需要这样的 JSON 串，无效嵌套person键： map[string]interface{}{ \"name\": \"dj\", } 看示例： type Person struct { Name string } type Friend1 struct { Person } type Friend2 struct { Person `mapstructure:\",squash\"` } func main() { datas := []string{` { \"type\": \"friend1\", \"person\": { \"name\":\"dj\" } } `, ` { \"type\": \"friend2\", \"name\": \"dj2\" } `, } for _, data := range datas { var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } switch m[\"type\"].(string) { case \"friend1\": var f1 Friend1 mapstructure.Decode(m, \u0026f1) fmt.Println(\"friend1\", f1) case \"friend2\": var f2 Friend2 mapstructure.Decode(m, \u0026f2) fmt.Println(\"friend2\", f2) } } } 注意对比Friend1和Friend2使用的 JSON 串的不同。 另外需要注意一点，如果父结构体中有同名的字段，那么mapstructure会将JSON 中对应的值同时设置到这两个字段中，即这两个字段有相同的值。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:4","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"未映射的值 如果源数据中有未映射的值（即结构体中无对应的字段），mapstructure默认会忽略它。 我们可以在结构体中定义一个字段，为其设置mapstructure:\",remain\"标签。这样未映射的值就会添加到这个字段中。注意，这个字段的类型只能为map[string]interface{}或map[interface{}]interface{}。 看示例： type Person struct { Name string Age int Job string Other map[string]interface{} `mapstructure:\",remain\"` } func main() { data := ` { \"name\": \"dj\", \"age\":18, \"job\":\"programmer\", \"height\":\"1.8m\", \"handsome\": true } ` var m map[string]interface{} err := json.Unmarshal([]byte(data), \u0026m) if err != nil { log.Fatal(err) } var p Person mapstructure.Decode(m, \u0026p) fmt.Println(\"other\", p.Other) } 上面代码中，我们为结构体定义了一个Other字段，用于保存未映射的键值。输出结果： other map[handsome:true height:1.8m] ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:5","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"逆向转换 前面我们都是将map[string]interface{}解码到 Go 结构体中。mapstructure当然也可以将 Go 结构体反向解码为map[string]interface{}。在反向解码时，我们可以为某些字段设置mapstructure:\",omitempty\"。这样当这些字段为默认值时，就不会出现在结构的map[string]interface{}中： type Person struct { Name string Age int Job string `mapstructure:\",omitempty\"` } func main() { p := \u0026Person{ Name: \"dj\", Age: 18, } var m map[string]interface{} mapstructure.Decode(p, \u0026m) data, _ := json.Marshal(m) fmt.Println(string(data)) } 上面代码中，我们为Job字段设置了mapstructure:\",omitempty\"，且对象p的Job字段未设置。运行结果： $ go run main.go {\"Age\":18,\"Name\":\"dj\"} ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:6","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"Metadata 解码时会产生一些有用的信息，mapstructure可以使用Metadata收集这些信息。Metadata结构如下： // mapstructure.go type Metadata struct { Keys []string Unused []string } Metadata只有两个导出字段： Keys：解码成功的键名； Unused：在源数据中存在，但是目标结构中不存在的键名。 为了收集这些数据，我们需要使用DecodeMetadata来代替Decode方法： type Person struct { Name string Age int } func main() { m := map[string]interface{}{ \"name\": \"dj\", \"age\": 18, \"job\": \"programmer\", } var p Person var metadata mapstructure.Metadata mapstructure.DecodeMetadata(m, \u0026p, \u0026metadata) fmt.Printf(\"keys:%#v unused:%#v\\n\", metadata.Keys, metadata.Unused) } 先定义一个Metadata结构，传入DecodeMetadata收集解码的信息。运行结果： $ go run main.go keys:[]string{\"Name\", \"Age\"} unused:[]string{\"job\"} ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:7","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"错误处理 mapstructure执行转换的过程中不可避免地会产生错误，例如 JSON 中某个键的类型与对应 Go 结构体中的字段类型不一致。Decode/DecodeMetadata会返回这些错误： type Person struct { Name string Age int Emails []string } func main() { m := map[string]interface{}{ \"name\": 123, \"age\": \"bad value\", \"emails\": []int{1, 2, 3}, } var p Person err := mapstructure.Decode(m, \u0026p) if err != nil { fmt.Println(err.Error()) } } 上面代码中，结构体中Person中字段Name为string类型，但输入中name为int类型；字段Age为int类型，但输入中age为string类型；字段Emails为[]string类型，但输入中emails为[]int类型。故Decode返回错误。运行结果： $ go run main.go 5 error(s) decoding: * 'Age' expected type 'int', got unconvertible type 'string' * 'Emails[0]' expected type 'string', got unconvertible type 'int' * 'Emails[1]' expected type 'string', got unconvertible type 'int' * 'Emails[2]' expected type 'string', got unconvertible type 'int' * 'Name' expected type 'string', got unconvertible type 'int' 从错误信息中很容易看出哪里出错了。 弱类型输入 有时候，我们并不想对结构体字段类型和map[string]interface{}的对应键值做强类型一致的校验。这时可以使用WeakDecode/WeakDecodeMetadata方法，它们会尝试做类型转换： type Person struct { Name string Age int Emails []string } func main() { m := map[string]interface{}{ \"name\": 123, \"age\": \"18\", \"emails\": []int{1, 2, 3}, } var p Person err := mapstructure.WeakDecode(m, \u0026p) if err == nil { fmt.Println(\"person:\", p) } else { fmt.Println(err.Error()) } } 虽然键name对应的值123是int类型，但是在WeakDecode中会将其转换为string类型以匹配Person.Name字段的类型。同样的，age的值\"18\"是string类型，在WeakDecode中会将其转换为int类型以匹配Person.Age字段的类型。 需要注意一点，如果类型转换失败了，WeakDecode同样会返回错误。例如将上例中的age设置为\"bad value\"，它就不能转为int类型，故而返回错误。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:8","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"解码器 除了上面介绍的方法外，mapstructure还提供了更灵活的解码器（Decoder）。可以通过配置DecoderConfig实现上面介绍的任何功能： // mapstructure.go type DecoderConfig struct { ErrorUnused bool ZeroFields bool WeaklyTypedInput bool Metadata *Metadata Result interface{} TagName string } 各个字段含义如下： ErrorUnused：为true时，如果输入中的键值没有与之对应的字段就返回错误； ZeroFields：为true时，在Decode前清空目标map。为false时，则执行的是map的合并。用在struct到map的转换中； WeaklyTypedInput：实现WeakDecode/WeakDecodeMetadata的功能； Metadata：不为nil时，收集Metadata数据； Result：为结果对象，在map到struct的转换中，Result为struct类型。在struct到map的转换中，Result为map类型； TagName：默认使用mapstructure作为结构体的标签名，可以通过该字段设置。 看示例： type Person struct { Name string Age int } func main() { m := map[string]interface{}{ \"name\": 123, \"age\": \"18\", \"job\": \"programmer\", } var p Person var metadata mapstructure.Metadata decoder, err := mapstructure.NewDecoder(\u0026mapstructure.DecoderConfig{ WeaklyTypedInput: true, Result: \u0026p, Metadata: \u0026metadata, }) if err != nil { log.Fatal(err) } err = decoder.Decode(m) if err == nil { fmt.Println(\"person:\", p) fmt.Printf(\"keys:%#v, unused:%#v\\n\", metadata.Keys, metadata.Unused) } else { fmt.Println(err.Error()) } } 这里用Decoder的方式实现了前面弱类型输入小节中的示例代码。实际上WeakDecode内部就是通过这种方式实现的，下面是WeakDecode的源码： // mapstructure.go func WeakDecode(input, output interface{}) error { config := \u0026DecoderConfig{ Metadata: nil, Result: output, WeaklyTypedInput: true, } decoder, err := NewDecoder(config) if err != nil { return err } return decoder.Decode(input) } 再实际上，Decode/DecodeMetadata/WeakDecodeMetadata内部都是先设置DecoderConfig的对应字段，然后创建Decoder对象，最后调用其Decode方法实现的。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-mapstructure/:1:9","tags":["Go","mapstructure"],"title":"Go mapstructure","uri":"/posts/2023-11-11-go-mapstructure/"},{"categories":["Go 库文档"],"content":"Go leveldb库 github地址：https://github.com/syndtr/goleveldb 安装： go get github.com/syndtr/goleveldb/leveldb ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:0","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"简介： levelDB在区块链中比较常用，其是Google开源的持久化单机Key-Value文件数据库，其支持按照文件大小切分文件的功能。levelDB具有很高的随机写，顺序读/写性能，但是随机读的性能很一般，也就是说，levelDB很适合应用在查询较少，而写很多的场景。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:1","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"LevelDB特点 1）key和value都是任意长度的字节数组； 2）entry（即一条k-v记录）默认是按照key的字典顺序存储的，开发者也可以重写这个方法； 3）提供了基本的增删改查接口； 4）支持批量操作以原子操作进行； 5）开源创建数据全景的snapshot（快照），并允许在快照中查询； 6）开源通过向前（后）迭代器遍历数据（迭代器隐含的创建了一个snapshot）； 7）自动使用Snappy压缩数据； 8）可移植性。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:2","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"levelDB限制 1）NoSQL，不支持sql语句，也不支持索引； 2）一次只允许一个进程访问一个特定的数据库； 3）没有内置的C/S架构，开发者需要使用levelDB库自己封装一个server； ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:3","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"使用： 1）打开、创建数据库 db, err := leveldb.OpenFile(\"./block.db\", nil) 2）写入key数据 err = db.Put([]byte(\"hello\"), []byte(\"world\"), nil) 3）读取key数据 data, _ := db.Get([]byte(\"hello\"), nil) 4）遍历数据库 iter := db.NewIterator(nil, nil) for iter.Next() { logger.Debug(iter.Key() + iter.Value()) } 5）读取某个前缀的所有KEY数据 读出来的数据会被放进一个Iterator中。加入数据库现在有key-$num为头的数条数据 iter := db.NewIterator(dbUtil.BytesPrefix([]byte(\"key-\")), nil) 遍历读取这些数据 for iter.Next() { logger.Debug(string(iter.Key()) + string(iter.Value())) } 读取最后一条数据 if iter.Last() { logger.Debug(iter.Key() + iter.Value()) } 6）删除某个KEY err = db.Delete([]byte(\"key-3\"), nil) 7）批量写 batch := new(leveldb.Batch) batch.Put([]byte(\"foo\"), []byte(\"value\")) batch.Put([]byte(\"bar\"), []byte(\"another value\")) batch.Delete([]byte(\"baz\")) err = db.Write(batch, nil) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-leveldb/:1:4","tags":["Go","leveldb"],"title":"Go leveldb","uri":"/posts/2023-11-11-go-leveldb/"},{"categories":["Go 库文档"],"content":"Go ini库 参考：https://juejin.cn/post/6844904048764649479 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:0","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"简介 ini 是 Windows 上常用的配置文件格式。MySQL 的 Windows 版就是使用 ini 格式存储配置的。 go-ini是 Go 语言中用于操作 ini 文件的第三方库。 本文介绍go-ini库的使用。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:1","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"快速使用 go-ini 是第三方库，使用前需要安装： $ go get gopkg.in/ini.v1 也可以使用 GitHub 上的仓库： $ go get github.com/go-ini/ini 首先，创建一个my.ini配置文件： app_name = awesome web # possible values: DEBUG, INFO, WARNING, ERROR, FATAL log_level = DEBUG [mysql] ip = 127.0.0.1 port = 3306 user = dj password = 123456 database = awesome [redis] ip = 127.0.0.1 port = 6381 使用 go-ini 库读取： package main import ( \"fmt\" \"log\" \"gopkg.in/ini.v1\" ) func main() { cfg, err := ini.Load(\"my.ini\") if err != nil { log.Fatal(\"Fail to read file: \", err) } fmt.Println(\"App Name:\", cfg.Section(\"\").Key(\"app_name\").String()) fmt.Println(\"Log Level:\", cfg.Section(\"\").Key(\"log_level\").String()) fmt.Println(\"MySQL IP:\", cfg.Section(\"mysql\").Key(\"ip\").String()) mysqlPort, err := cfg.Section(\"mysql\").Key(\"port\").Int() if err != nil { log.Fatal(err) } fmt.Println(\"MySQL Port:\", mysqlPort) fmt.Println(\"MySQL User:\", cfg.Section(\"mysql\").Key(\"user\").String()) fmt.Println(\"MySQL Password:\", cfg.Section(\"mysql\").Key(\"password\").String()) fmt.Println(\"MySQL Database:\", cfg.Section(\"mysql\").Key(\"database\").String()) fmt.Println(\"Redis IP:\", cfg.Section(\"redis\").Key(\"ip\").String()) redisPort, err := cfg.Section(\"redis\").Key(\"port\").Int() if err != nil { log.Fatal(err) } fmt.Println(\"Redis Port:\", redisPort) } 在 ini 文件中，每个键值对占用一行，中间使用=隔开。以#开头的内容为注释。ini 文件是以分区（section）组织的。 分区以[name]开始，在下一个分区前结束。所有分区前的内容属于默认分区，如my.ini文件中的app_name和log_level。 使用go-ini读取配置文件的步骤如下： 首先调用ini.Load加载文件，得到配置对象cfg； 然后以分区名调用配置对象的Section方法得到对应的分区对象section，默认分区的名字为\"\"，也可以使用ini.DefaultSection； 以键名调用分区对象的Key方法得到对应的配置项key对象； 由于文件中读取出来的都是字符串，key对象需根据类型调用对应的方法返回具体类型的值使用，如上面的String、MustInt方法。 运行以下程序，得到输出： App Name: awesome web Log Level: DEBUG MySQL IP: 127.0.0.1 MySQL Port: 3306 MySQL User: dj MySQL Password: 123456 MySQL Database: awesome Redis IP: 127.0.0.1 Redis Port: 6381 配置文件中存储的都是字符串，所以类型为字符串的配置项不会出现类型转换失败的，故String()方法只返回一个值。 但如果类型为Int/Uint/Float64这些时，转换可能失败。所以Int()/Uint()/Float64()返回一个值和一个错误。 要留意这种不一致！如果我们将配置中 redis 端口改成非法的数字 x6381，那么运行程序将报错： 2020/01/14 22:43:13 strconv.ParseInt: parsing \"x6381\": invalid syntax 复制代码 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:2","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"Must*便捷方法 如果每次取值都需要进行错误判断，那么代码写起来会非常繁琐。为此，go-ini也提供对应的MustType（Type 为Init/Uint/Float64等）方法，这个方法只返回一个值。 同时它接受可变参数，如果类型无法转换，取参数中第一个值返回，并且该参数设置为这个配置的值，下次调用返回这个值： package main import ( \"fmt\" \"log\" \"gopkg.in/ini.v1\" ) func main() { cfg, err := ini.Load(\"my.ini\") if err != nil { log.Fatal(\"Fail to read file: \", err) } redisPort, err := cfg.Section(\"redis\").Key(\"port\").Int() if err != nil { fmt.Println(\"before must, get redis port error:\", err) } else { fmt.Println(\"before must, get redis port:\", redisPort) } fmt.Println(\"redis Port:\", cfg.Section(\"redis\").Key(\"port\").MustInt(6381)) redisPort, err = cfg.Section(\"redis\").Key(\"port\").Int() if err != nil { fmt.Println(\"after must, get redis port error:\", err) } else { fmt.Println(\"after must, get redis port:\", redisPort) } } 配置文件还是 redis 端口为非数字 x6381 时的状态，运行程序： before must, get redis port error: strconv.ParseInt: parsing \"x6381\": invalid syntax redis Port: 6381 after must, get redis port: 6381 复制代码 我们看到第一次调用Int返回错误，以 6381 为参数调用MustInt之后，再次调用Int，成功返回 6381。MustInt源码也比较简单： // gopkg.in/ini.v1/key.go func (k *Key) MustInt(defaultVal ...int) int { val, err := k.Int() if len(defaultVal) \u003e 0 \u0026\u0026 err != nil { k.value = strconv.FormatInt(int64(defaultVal[0]), 10) return defaultVal[0] } return val } 复制代码 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:3","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"分区操作 获取信息 在加载配置之后，可以通过Sections方法获取所有分区，SectionStrings()方法获取所有分区名。 sections := cfg.Sections() names := cfg.SectionStrings() fmt.Println(\"sections: \", sections) fmt.Println(\"names: \", names) 复制代码 运行输出 3 个分区： [DEFAULT mysql redis] 复制代码 调用Section(name)获取名为name的分区，如果该分区不存在，则自动创建一个分区返回： newSection := cfg.Section(\"new\") fmt.Println(\"new section: \", newSection) fmt.Println(\"names: \", cfg.SectionStrings()) 创建之后调用SectionStrings方法，新分区也会返回： names: [DEFAULT mysql redis new] 也可以手动创建一个新分区，如果分区已存在，则返回错误： err := cfg.NewSection(\"new\") 父子分区 在配置文件中，可以使用占位符%(name)s表示用之前已定义的键name的值来替换，这里的s表示值为字符串类型： NAME = ini VERSION = v1 IMPORT_PATH = gopkg.in/%(NAME)s.%(VERSION)s [package] CLONE_URL = https://%(IMPORT_PATH)s [package.sub] 上面在默认分区中设置IMPORT_PATH的值时，使用了前面定义的NAME和VERSION。 在package分区中设置CLONE_URL的值时，使用了默认分区中定义的IMPORT_PATH。 我们还可以在分区名中使用.表示两个或多个分区之间的父子关系，例如package.sub的父分区为package，package的父分区为默认分区。 如果某个键在子分区中不存在，则会在它的父分区中再次查找，直到没有父分区为止： cfg, err := ini.Load(\"parent_child.ini\") if err != nil { fmt.Println(\"Fail to read file: \", err) return } fmt.Println(\"Clone url from package.sub:\", cfg.Section(\"package.sub\").Key(\"CLONE_URL\").String()) 运行程序输出： Clone url from package.sub: https://gopkg.in/ini.v1 子分区中package.sub中没有键CLONE_URL，返回了父分区package中的值。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:4","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"保存配置 有时候，我们需要将生成的配置写到文件中。例如在写工具的时候。保存有两种类型的接口，一种直接保存到文件，另一种写入到io.Writer中： err = cfg.SaveTo(\"my.ini\") err = cfg.SaveToIndent(\"my.ini\", \"\\t\") cfg.WriteTo(writer) cfg.WriteToIndent(writer, \"\\t\") 下面我们通过程序生成前面使用的配置文件my.ini并保存： package main import ( \"fmt\" \"os\" \"gopkg.in/ini.v1\" ) func main() { cfg := ini.Empty() defaultSection := cfg.Section(\"\") defaultSection.NewKey(\"app_name\", \"awesome web\") defaultSection.NewKey(\"log_level\", \"DEBUG\") mysqlSection, err := cfg.NewSection(\"mysql\") if err != nil { fmt.Println(\"new mysql section failed:\", err) return } mysqlSection.NewKey(\"ip\", \"127.0.0.1\") mysqlSection.NewKey(\"port\", \"3306\") mysqlSection.NewKey(\"user\", \"root\") mysqlSection.NewKey(\"password\", \"123456\") mysqlSection.NewKey(\"database\", \"awesome\") redisSection, err := cfg.NewSection(\"redis\") if err != nil { fmt.Println(\"new redis section failed:\", err) return } redisSection.NewKey(\"ip\", \"127.0.0.1\") redisSection.NewKey(\"port\", \"6381\") err = cfg.SaveTo(\"my.ini\") if err != nil { fmt.Println(\"SaveTo failed: \", err) } err = cfg.SaveToIndent(\"my-pretty.ini\", \"\\t\") if err != nil { fmt.Println(\"SaveToIndent failed: \", err) } cfg.WriteTo(os.Stdout) fmt.Println() cfg.WriteToIndent(os.Stdout, \"\\t\") } 运行程序，生成两个文件my.ini和my-pretty.ini，同时控制台输出文件内容。 my.ini： app_name = awesome web log_level = DEBUG [mysql] ip = 127.0.0.1 port = 3306 user = root password = 123456 database = awesome [redis] ip = 127.0.0.1 port = 6381 my-pretty.ini： app_name = awesome web log_level = DEBUG [mysql] ip = 127.0.0.1 port = 3306 user = root password = 123456 database = awesome [redis] ip = 127.0.0.1 port = 6381 *Indent方法会对子分区下的键增加缩进，看起来美观一点。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:5","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"分区与结构体字段映射 定义结构变量，加载完配置文件后，调用MapTo将配置项赋值到结构变量的对应字段中。 package main import ( \"fmt\" \"gopkg.in/ini.v1\" ) type Config struct { AppName string `ini:\"app_name\"` LogLevel string `ini:\"log_level\"` MySQL MySQLConfig `ini:\"mysql\"` Redis RedisConfig `ini:\"redis\"` } type MySQLConfig struct { IP string `ini:\"ip\"` Port int `ini:\"port\"` User string `ini:\"user\"` Password string `ini:\"password\"` Database string `ini:\"database\"` } type RedisConfig struct { IP string `ini:\"ip\"` Port int `ini:\"port\"` } func main() { cfg, err := ini.Load(\"my.ini\") if err != nil { fmt.Println(\"load my.ini failed: \", err) } c := Config{} cfg.MapTo(\u0026c) fmt.Println(c) } MapTo内部使用了反射，所以结构体字段必须都是导出的。如果键名与字段名不相同，那么需要在结构标签中指定对应的键名。 这一点与 Go 标准库encoding/json和encoding/xml不同。标准库json/xml解析时可以将键名app_name对应到字段名AppName。 或许这是go-ini库可以优化的点？ 先加载，再映射有点繁琐，直接使用ini.MapTo将两步合并： err = ini.MapTo(\u0026c, \"my.ini\") 复制代码 也可以只映射一个分区： mysqlCfg := MySQLConfig{} err = cfg.Section(\"mysql\").MapTo(\u0026mysqlCfg) 还可以通过结构体生成配置： cfg := ini.Empty() c := Config { AppName: \"awesome web\", LogLevel: \"DEBUG\", MySQL: MySQLConfig { IP: \"127.0.0.1\", Port: 3306, User: \"root\", Password:\"123456\", Database:\"awesome\", }, Redis: RedisConfig { IP: \"127.0.0.1\", Port: 6381, }, } err := ini.ReflectFrom(cfg, \u0026c) if err != nil { fmt.Println(\"ReflectFrom failed: \", err) return } err = cfg.SaveTo(\"my-copy.ini\") if err != nil { fmt.Println(\"SaveTo failed: \", err) return } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:6","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"总结 本文介绍了go-ini库的基本用法和一些有趣的特性。示例代码已上传GitHub。 其实go-ini还有很多高级特性。官方文档非常详细，推荐去看，而且有中文哟~ 作者无闻，相信做 Go 开发的都不陌生。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:7","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"参考 go-ini GitHub 仓库 go-ini 官方文档 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-ini/:1:8","tags":["Go","ini"],"title":"Go ini","uri":"/posts/2023-11-11-go-ini/"},{"categories":["Go 库文档"],"content":"homedir家目录 GitHub地址：https://github.com/mitchellh/go-homedir 使用os/user获取用户家目录： package main import ( \"fmt\" \"log\" \"os/user\" ) func main() { u, err := user.Current() if err != nil { log.Fatal(err) } fmt.Println(\"Home dir:\", u.HomeDir) } 那么为什么还要go-homedir库？ 在 Darwin 系统上，标准库os/user的使用需要 cgo。所以，任何使用os/user的代码都不能交叉编译。 但是，大多数人使用os/user的目的仅仅只是想获取主目录。因此，go-homedir库出现了。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:0","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"快速使用 go-homedir是第三方包，使用前需要先安装： $ go get github.com/mitchellh/go-homedir 使用非常简单： package main import ( \"fmt\" \"log\" \"github.com/mitchellh/go-homedir\" ) func main() { dir, err := homedir.Dir() if err != nil { log.Fatal(err) } fmt.Println(\"Home dir:\", dir) dir = \"~/golang/src\" expandedDir, err := homedir.Expand(dir) if err != nil { log.Fatal(err) } fmt.Printf(\"Expand of %s is: %s\\n\", dir, expandedDir) } go-homedir有两个功能： Dir：获取用户主目录； Expand：将路径中的第一个~扩展成用户主目录。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:1","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"高级用法 由于Dir的调用可能涉及一些系统调用和外部执行命令，多次调用费性能。所以go-homedir提供了缓存的功能。默认情况下，缓存是开启的。 我们也可以将DisableCache设置为false来关闭它。 package main import ( \"fmt\" \"log\" \"github.com/mitchellh/go-homedir\" ) func main() { homedir.DisableCache = false dir, err := homedir.Dir() if err != nil { log.Fatal(err) } fmt.Println(\"Home dir:\", dir) } 使用缓存时，如果程序运行中修改了主目录，再次调用Dir还是返回之前的目录。如果需要获取最新的主目录，可以先调用Reset清除缓存。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:2","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"实现 go-homedir源码只有一个文件homedir.go，今天我们大概看一下Dir的实现，去掉缓存相关代码： func Dir() (string, error) { var result string var err error if runtime.GOOS == \"windows\" { result, err = dirWindows() } else { // Unix-like system, so just assume Unix result, err = dirUnix() } if err != nil { return \"\", err } return result, nil } 判断当前的系统是windows还是类 Unix，分别调用不同的方法。先看 windows 的，比较简单： func dirWindows() (string, error) { // First prefer the HOME environmental variable if home := os.Getenv(\"HOME\"); home != \"\" { return home, nil } // Prefer standard environment variable USERPROFILE if home := os.Getenv(\"USERPROFILE\"); home != \"\" { return home, nil } drive := os.Getenv(\"HOMEDRIVE\") path := os.Getenv(\"HOMEPATH\") home := drive + path if drive == \"\" || path == \"\" { return \"\", errors.New(\"HOMEDRIVE, HOMEPATH, or USERPROFILE are blank\") } return home, nil } 流程如下： 读取环境变量HOME，如果不为空，返回这个值； 读取环境变量USERPROFILE，如果不为空，返回这个值； 读取环境变量HOMEDRIVE和HOMEPATH，如果两者都不为空，拼接这两个值返回。 类 Unix 系统的实现稍微复杂一点： func dirUnix() (string, error) { homeEnv := \"HOME\" if runtime.GOOS == \"plan9\" { // On plan9, env vars are lowercase. homeEnv = \"home\" } // First prefer the HOME environmental variable if home := os.Getenv(homeEnv); home != \"\" { return home, nil } var stdout bytes.Buffer // If that fails, try OS specific commands if runtime.GOOS == \"darwin\" { cmd := exec.Command(\"sh\", \"-c\", `dscl -q . -read /Users/\"$(whoami)\" NFSHomeDirectory | sed 's/^[^ ]*: //'`) cmd.Stdout = \u0026stdout if err := cmd.Run(); err == nil { result := strings.TrimSpace(stdout.String()) if result != \"\" { return result, nil } } } else { cmd := exec.Command(\"getent\", \"passwd\", strconv.Itoa(os.Getuid())) cmd.Stdout = \u0026stdout if err := cmd.Run(); err != nil { // If the error is ErrNotFound, we ignore it. Otherwise, return it. if err != exec.ErrNotFound { return \"\", err } } else { if passwd := strings.TrimSpace(stdout.String()); passwd != \"\" { // username:password:uid:gid:gecos:home:shell passwdParts := strings.SplitN(passwd, \":\", 7) if len(passwdParts) \u003e 5 { return passwdParts[5], nil } } } } // If all else fails, try the shell stdout.Reset() cmd := exec.Command(\"sh\", \"-c\", \"cd \u0026\u0026 pwd\") cmd.Stdout = \u0026stdout if err := cmd.Run(); err != nil { return \"\", err } result := strings.TrimSpace(stdout.String()) if result == \"\" { return \"\", errors.New(\"blank output when reading home directory\") } return result, nil } 流程如下： 先读取环境变量HOME（注意 plan9 系统上为home），如果不为空，返回这个值； 使用getnet命令查看系统的数据库中的相关记录，我们知道passwd文件中存储了用户信息，包括用户的主目录。使用getent命令查看passwd中当前用户的那条记录，然后从中找到主目录部分返回； 如果上一个步骤失败了，我们知道cd后不加参数是直接切换到用户主目录的，而pwd可以显示当前目录。那么就可以结合这两个命令返回主目录。 这里分析源码并不是表示使用任何库都要熟悉它的源码，毕竟使用库就是为了方便开发。 但是源码是我们学习和提高的一个非常重要的途径。我们在使用库遇到问题的时候也要有能力从文档或甚至源码中查找原因。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-homedir/:1:3","tags":["Go","homedir"],"title":"Go homedir","uri":"/posts/2023-11-11-go-homedir/"},{"categories":["Go 库文档"],"content":"Go Fsnotify库 官方仓库：github.com/fsnotify/fsnotify 用于监控文件或目录的改变 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fsnotify/:1:0","tags":["Go","fsnotify"],"title":"Go fsnotify","uri":"/posts/2023-11-11-go-fsnotify/"},{"categories":["Go 库文档"],"content":"1、官网示例 package main import ( \"log\" \"github.com/fsnotify/fsnotify\" ) func main() { watcher, err := fsnotify.NewWatcher() if err != nil { log.Fatal(err) } defer watcher.Close() done := make(chan bool) go func() { for { select { case event := \u003c-watcher.Events: log.Println(\"event:\", event) if event.Op\u0026fsnotify.Write == fsnotify.Write { log.Println(\"modified file:\", event.Name) } case err := \u003c-watcher.Errors: log.Println(\"error:\", err) } } }() err = watcher.Add(\"/tmp/foo\") if err != nil { log.Fatal(err) } \u003c-done } fsnotify的使用比较简单: 先条用NewWatcher创建一个监听器 然后条用监听器的Add监听文件或目录 如果目录或文件有事件发生，监听器的通道Events可以取出事件。如果出现错误，监听器中的通道Errors可以取出错误信息。 其实，重命名时会产生两个事件，一个是原文件的RENAME事件，一个是新文件的CREATE事件。 注意，fsnotify使用了操作系统接口，监听器中保存了系统资源的句柄，所以使用后需要关闭。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fsnotify/:1:1","tags":["Go","fsnotify"],"title":"Go fsnotify","uri":"/posts/2023-11-11-go-fsnotify/"},{"categories":["Go 库文档"],"content":"2、事件 上面示例中的事件是fsnotify.Event类型： // fsnotify/fsnotify.go type Event struct { Name string Op Op } 事件只有两个字段，Name表示发生变化的文件或目录名，Op表示具体的变化。Op有 5 中取值： // fsnotify/fsnotify.go type Op uint32 const ( Create Op = 1 \u003c\u003c iota Write Remove Rename Chmod ) 3、监控目录 参考链接：https://blog.csdn.net/finghting321/article/details/102852746 package main; import ( \"github.com/fsnotify/fsnotify\" \"fmt\" \"path/filepath\" \"os\" ) type NotifyFile struct { watch *fsnotify.Watcher } func NewNotifyFile() *NotifyFile { w := new(NotifyFile) w.watch, _ = fsnotify.NewWatcher() return w } //监控目录 func (this *NotifyFile) WatchDir(dir string) { //通过Walk来遍历目录下的所有子目录 filepath.Walk(dir, func(path string, info os.FileInfo, err error) error { //判断是否为目录，监控目录,目录下文件也在监控范围内，不需要加 if info.IsDir() { path, err := filepath.Abs(path) if err != nil { return err } err = this.watch.Add(path) if err != nil { return err } fmt.Println(\"监控 : \", path) } return nil }) go this.WatchEvent() //协程 } func (this *NotifyFile) WatchEvent() { for { select { case ev := \u003c-this.watch.Events: { if ev.Op\u0026fsnotify.Create == fsnotify.Create { fmt.Println(\"创建文件 : \", ev.Name) //获取新创建文件的信息，如果是目录，则加入监控中 file, err := os.Stat(ev.Name) if err == nil \u0026\u0026 file.IsDir() { this.watch.Add(ev.Name) fmt.Println(\"添加监控 : \", ev.Name) } } if ev.Op\u0026fsnotify.Write == fsnotify.Write { //fmt.Println(\"写入文件 : \", ev.Name) } if ev.Op\u0026fsnotify.Remove == fsnotify.Remove { fmt.Println(\"删除文件 : \", ev.Name) //如果删除文件是目录，则移除监控 fi, err := os.Stat(ev.Name) if err == nil \u0026\u0026 fi.IsDir() { this.watch.Remove(ev.Name) fmt.Println(\"删除监控 : \", ev.Name) } } if ev.Op\u0026fsnotify.Rename == fsnotify.Rename { //如果重命名文件是目录，则移除监控 ,注意这里无法使用os.Stat来判断是否是目录了 //因为重命名后，go已经无法找到原文件来获取信息了,所以简单粗爆直接remove fmt.Println(\"重命名文件 : \", ev.Name) this.watch.Remove(ev.Name) } if ev.Op\u0026fsnotify.Chmod == fsnotify.Chmod { fmt.Println(\"修改权限 : \", ev.Name) } } case err := \u003c-this.watch.Errors: { fmt.Println(\"error : \", err) return } } } func main() { watch := FSNotify.NewNotifyFile() watch.WatchDir(\"G:\\\\Ferry\") select {} return } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fsnotify/:1:2","tags":["Go","fsnotify"],"title":"Go fsnotify","uri":"/posts/2023-11-11-go-fsnotify/"},{"categories":["Go 库文档"],"content":"Go fmt模块 参考链接：https://www.liwenzhou.com/posts/Go/go_fmt/ fmt fmt包实现了类似C语言printf和scanf的格式化I/O。主要分为向外输出内容和获取输入内容两大部分。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:0","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"向外输出 标准库fmt提供了以下几种输出相关函数。 Print Print系列函数会将内容输出到系统的标准输出，区别在于Print函数直接输出内容，Printf函数支持格式化输出字符串，Println函数会在输出内容的结尾添加一个换行符。 func Print(a ...interface{}) (n int, err error) func Printf(format string, a ...interface{}) (n int, err error) func Println(a ...interface{}) (n int, err error) 例如： func main() { fmt.Print(\"在终端打印该信息。\") name := \"沙河小王子\" fmt.Printf(\"我是：%s\\n\", name) fmt.Println(\"在终端打印单独一行显示\") } 输出结果： 在终端打印该信息。我是：沙河小王子 在终端打印单独一行显示 Fprint Fprint系列函数会将内容输出到一个io.Writer接口类型的变量w中，我们通常用这个函数往文件中写入内容。 func Fprint(w io.Writer, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error) 例如： // 向标准输出写入内容 fmt.Fprintln(os.Stdout, \"向标准输出写入内容\") fileObj, err := os.OpenFile(\"./xx.txt\", os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644) if err != nil { fmt.Println(\"打开文件出错，err:\", err) return } name := \"沙河小王子\" // 向打开的文件句柄中写入内容 fmt.Fprintf(fileObj, \"往文件中写如信息：%s\", name) Sprint Sprint系列函数会把传入的数据生成并返回一个字符串。 func Sprint(a ...interface{}) string func Sprintf(format string, a ...interface{}) string func Sprintln(a ...interface{}) string 示例： s1 := fmt.Sprint(\"沙河小王子\") name := \"沙河小王子\" age := 18 s2 := fmt.Sprintf(\"name:%s,age:%d\", name, age) s3 := fmt.Sprintln(\"沙河小王子\") fmt.Println(s1, s2, s3) Errorf Errorf函数根据format参数生成格式化字符串并返回一个包含该字符串的错误。 func Errorf(format string, a ...interface{}) error 通常使用这种方式来自定义错误类型，例如： err := fmt.Errorf(\"这是一个错误\") Go1.13版本为fmt.Errorf函数新加了一个%w占位符用来生成一个可以包裹Error的Wrapping Error。 e := errors.New(\"原始错误e\") w := fmt.Errorf(\"Wrap了一个错误%w\", e) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:1","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"格式化占位符 *printf系列函数都支持format格式化参数，在这里我们按照占位符将被替换的变量类型划分，方便查询和记忆。 通用占位符 占位符 说明 %v 值的默认格式表示 %+v 类似%v，但输出结构体时会添加字段名 %#v 值的Go语法表示 %T 打印值的类型 %% 百分号 示例代码如下： fmt.Printf(\"%v\\n\", 100) fmt.Printf(\"%v\\n\", false) o := struct{ name string }{\"小王子\"} fmt.Printf(\"%v\\n\", o) fmt.Printf(\"%#v\\n\", o) fmt.Printf(\"%T\\n\", o) fmt.Printf(\"100%%\\n\") 输出结果如下： 100 false {小王子} struct { name string }{name:\"小王子\"} struct { name string } 100% 布尔型 占位符 说明 %t true或false 整型 占位符 说明 %b 表示为二进制 %c 该值对应的unicode码值 %d 表示为十进制 %o 表示为八进制 %x 表示为十六进制，使用a-f %X 表示为十六进制，使用A-F %U 表示为Unicode格式：U+1234，等价于”U+%04X” %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 示例代码如下： n := 65 fmt.Printf(\"%b\\n\", n) fmt.Printf(\"%c\\n\", n) fmt.Printf(\"%d\\n\", n) fmt.Printf(\"%o\\n\", n) fmt.Printf(\"%x\\n\", n) fmt.Printf(\"%X\\n\", n) 输出结果如下： 1000001 A 65 101 41 41 浮点数与复数 占位符 说明 %b 无小数部分、二进制指数的科学计数法，如-123456p-78 %e 科学计数法，如-1234.456e+78 %E 科学计数法，如-1234.456E+78 %f 有小数部分但无指数部分，如123.456 %F 等价于%f %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） %G 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） 示例代码如下： f := 12.34 fmt.Printf(\"%b\\n\", f) fmt.Printf(\"%e\\n\", f) fmt.Printf(\"%E\\n\", f) fmt.Printf(\"%f\\n\", f) fmt.Printf(\"%g\\n\", f) fmt.Printf(\"%G\\n\", f) 输出结果如下： 6946802425218990p-49 1.234000e+01 1.234000E+01 12.340000 12.34 12.34 字符串和[]byte 占位符 说明 %s 直接输出字符串或者[]byte %q 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 %x 每个字节用两字符十六进制数表示（使用a-f %X 每个字节用两字符十六进制数表示（使用A-F） 示例代码如下： s := \"小王子\" fmt.Printf(\"%s\\n\", s) fmt.Printf(\"%q\\n\", s) fmt.Printf(\"%x\\n\", s) fmt.Printf(\"%X\\n\", s) 输出结果如下： 小王子 \"小王子\" e5b08fe78e8be5ad90 E5B08FE78E8BE5AD90 指针 占位符 说明 %p 表示为十六进制，并加上前导的0x 示例代码如下： a := 10 fmt.Printf(\"%p\\n\", \u0026a) fmt.Printf(\"%#p\\n\", \u0026a) 输出结果如下： 0xc000094000 c000094000 宽度标识符 宽度通过一个紧跟在百分号后面的十进制数指定，如果未指定宽度，则表示值时除必需之外不作填充。精度通过（可选的）宽度后跟点号后跟的十进制数指定。如果未指定精度，会使用默认精度；如果点号后没有跟数字，表示精度为0。举例如下： 占位符 说明 %f 默认宽度，默认精度 %9f 宽度9，默认精度 %.2f 默认宽度，精度2 %9.2f 宽度9，精度2 %9.f 宽度9，精度0 示例代码如下： n := 12.34 fmt.Printf(\"%f\\n\", n) fmt.Printf(\"%9f\\n\", n) fmt.Printf(\"%.2f\\n\", n) fmt.Printf(\"%9.2f\\n\", n) fmt.Printf(\"%9.f\\n\", n) 输出结果如下： 12.340000 12.340000 12.34 12.34 12 其他falg 占位符 说明 ’+’ 总是输出数值的正负号；对%q（%+q）会生成全部是ASCII字符的输出（通过转义）； ’ ‘ 对数值，正数前加空格而负数前加负号；对字符串采用%x或%X时（% x或% X）会给各打印的字节之间加空格 ’-’ 在输出右边填充空白而不是默认的左边（即从默认的右对齐切换为左对齐）； ’#’ 八进制数前加0（%#o），十六进制数前加0x（%#x）或0X（%#X），指针去掉前面的0x（%#p）对%q（%#q），对%U（%#U）会输出空格和单引号括起来的go字面值； ‘0’ 使用0而不是空格填充，对于数值类型会把填充的0放在正负号后面； 举个例子： s := \"小王子\" fmt.Printf(\"%s\\n\", s) fmt.Printf(\"%5s\\n\", s) fmt.Printf(\"%-5s\\n\", s) fmt.Printf(\"%5.7s\\n\", s) fmt.Printf(\"%-5.7s\\n\", s) fmt.Printf(\"%5.2s\\n\", s) fmt.Printf(\"%05s\\n\", s) 输出结果如下： 小王子 小王子 小王子 小王子 小王子 小王 00小王子 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:2","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"获取输入 Go语言fmt包下有fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，可以在程序运行过程中从标准输入获取用户的输入。 fmt.Scan 函数定签名如下： func Scan(a ...interface{}) (n int, err error) Scan从标准输入扫描文本，读取由空白符分隔的值保存到传递给本函数的参数中，换行符视为空白符。 本函数返回成功扫描的数据个数和遇到的任何错误。如果读取的数据个数比提供的参数少，会返回一个错误报告原因。 具体代码示例如下： func main() { var ( name string age int married bool ) fmt.Scan(\u0026name, \u0026age, \u0026married) fmt.Printf(\"扫描结果 name:%s age:%d married:%t \\n\", name, age, married) } 将上面的代码编译后在终端执行，在终端依次输入小王子、28和false使用空格分隔。 $ ./scan_demo 小王子 28 false 扫描结果 name:小王子 age:28 married:false fmt.Scan从标准输入中扫描用户输入的数据，将以空白符分隔的数据分别存入指定的参数。 fmt.Scanf 函数签名如下： func Scanf(format string, a ...interface{}) (n int, err error) Scanf从标准输入扫描文本，根据format参数指定的格式去读取由空白符分隔的值保存到传递给本函数的参数中。 本函数返回成功扫描的数据个数和遇到的任何错误。 代码示例如下： func main() { var ( name string age int married bool ) fmt.Scanf(\"1:%s 2:%d 3:%t\", \u0026name, \u0026age, \u0026married) fmt.Printf(\"扫描结果 name:%s age:%d married:%t \\n\", name, age, married) } 将上面的代码编译后在终端执行，在终端按照指定的格式依次输入小王子、28和false。 $ ./scan_demo 1:小王子 2:28 3:false 扫描结果 name:小王子 age:28 married:false fmt.Scanf不同于fmt.Scan简单的以空格作为输入数据的分隔符，fmt.Scanf为输入数据指定了具体的输入内容格式，只有按照格式输入数据才会被扫描并存入对应变量。 例如，我们还是按照上个示例中以空格分隔的方式输入，fmt.Scanf就不能正确扫描到输入的数据。 $ ./scan_demo 小王子 28 false 扫描结果 name: age:0 married:false fmt.Scanln 函数签名如下： func Scanln(a ...interface{}) (n int, err error) Scanln类似Scan，它在遇到换行时才停止扫描。最后一个数据后面必须有换行或者到达结束位置。 本函数返回成功扫描的数据个数和遇到的任何错误。 具体代码示例如下： func main() { var ( name string age int married bool ) fmt.Scanln(\u0026name, \u0026age, \u0026married) fmt.Printf(\"扫描结果 name:%s age:%d married:%t \\n\", name, age, married) } 将上面的代码编译后在终端执行，在终端依次输入小王子、28和false使用空格分隔。 $ ./scan_demo 小王子 28 false 扫描结果 name:小王子 age:28 married:false fmt.Scanln遇到回车就结束扫描了，这个比较常用。 bufio.NewReader 有时候我们想完整获取输入的内容，而输入的内容可能包含空格，这种情况下可以使用bufio包来实现。示例代码如下： func bufioDemo() { reader := bufio.NewReader(os.Stdin) // 从标准输入生成读对象 fmt.Print(\"请输入内容：\") text, _ := reader.ReadString('\\n') // 读到换行 text = strings.TrimSpace(text) fmt.Printf(\"%#v\\n\", text) } Fscan系列 这几个函数功能分别类似于fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，只不过它们不是从标准输入中读取数据而是从io.Reader中读取数据。 func Fscan(r io.Reader, a ...interface{}) (n int, err error) func Fscanln(r io.Reader, a ...interface{}) (n int, err error) func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) Sscan系列 这几个函数功能分别类似于fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，只不过它们不是从标准输入中读取数据而是从指定字符串中读取数据。 func Sscan(str string, a ...interface{}) (n int, err error) func Sscanln(str string, a ...interface{}) (n int, err error) func Sscanf(str string, format string, a ...interface{}) (n int, err error) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-fmt/:1:3","tags":["Go","fmt"],"title":"Go fmt","uri":"/posts/2023-11-11-go-fmt/"},{"categories":["Go 库文档"],"content":"Go文件操作 参考链接：https://www.liwenzhou.com/posts/Go/go_file/ ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:0","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"文件 计算机中的文件是存储在外部介质（通常是磁盘）上的数据集合，文件分为文本文件和二进制文件 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:1","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"文件打开和关闭 os.Open()函数能够打开一个文件，返回一个*File和一个err。对得到的文件实例调用close()方法能够关闭文件。 package main import ( \"fmt\" \"os\" ) func main() { // 只读方式打开当前目录下的main.go文件 file, err := os.Open(\"./main.go\") if err != nil { fmt.Println(\"open file failed!, err:\", err) return } // 关闭文件 file.Close() } 为了防止文件忘记关闭，我们通常使用defer注册文件关闭语句。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:2","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"读取文件 file.Read() 基本使用 Read方法的定义如下： func (f *File) Read(b []byte) (n int, err error) 它接收一个字节切片，返回读取的字节数和可能的具体错误，读到文件末尾时会返回0和io.EOF。 举个例子： func main() { // 只读方式打开当前目录下的main.go文件 file, err := os.Open(\"./main.go\") if err != nil { fmt.Println(\"open file failed!, err:\", err) return } defer file.Close() // 使用Read方法读取数据 var tmp = make([]byte, 128) n, err := file.Read(tmp) if err == io.EOF { fmt.Println(\"文件读完了\") return } if err != nil { fmt.Println(\"read file failed, err:\", err) return } fmt.Printf(\"读取了%d字节数据\\n\", n) fmt.Println(string(tmp[:n])) } 循环读取 使用for循环读取文件中所有的数据 func main() { // 只读方式打开当前目录下的main.go文件 file, err := os.Open(\"./main.go\") if err != nil { fmt.Println(\"open file failed!, err:\", err) return } defer file.Close() // 循环读取文件 var content []byte var tmp = make([]byte, 128) for { n, err := file.Read(tmp) if err == io.EOF { fmt.Println(\"文件读完了\") break } if err != nil { fmt.Println(\"read file failed, err:\", err) return } content = append(content, tmp[:n]...) } fmt.Println(string(content)) } bufio读取文件 bufio是在file的基础上封装了一层API，支持更多的功能。 package main import ( \"bufio\" \"fmt\" \"io\" \"os\" ) // bufio按行读取示例 func main() { file, err := os.Open(\"./xx.txt\") if err != nil { fmt.Println(\"open file failed, err:\", err) return } defer file.Close() reader := bufio.NewReader(file) for { line, err := reader.ReadString('\\n') //注意是字符 if err == io.EOF { if len(line) != 0 { fmt.Println(line) } fmt.Println(\"文件读完了\") break } if err != nil { fmt.Println(\"read file failed, err:\", err) return } fmt.Print(line) } } ioutil读取整个文件 io/ioutil包的ReadFile方法能够读取完整的文件，只需要将文件名作为参数传入。 package main import ( \"fmt\" \"io/ioutil\" ) // ioutil.ReadFile读取整个文件 func main() { content, err := ioutil.ReadFile(\"./main.go\") if err != nil { fmt.Println(\"read file failed, err:\", err) return } fmt.Println(string(content)) } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:3","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"文件写入 os.OpenFile()函数能够以指定模式打开文件，从而实现文件写入相关功能。 func OpenFile(name string, flag int, perm FileMode) (*File, error) { ... } 其中： name：要打开的文件名 flag：打开文件的模式。 模式有以下几种： 模式 含义 os.O_WRONLY 只写 os.O_CREATE 创建文件 os.O_RDONLY 只读 os.O_RDWR 读写 os.O_TRUNC 清空 os.O_APPEND 追加 perm：文件权限，一个八进制数。r（读）4，w（写）2，x（执行）1。 Write和WriteString func main() { file, err := os.OpenFile(\"xx.txt\", os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0666) if err != nil { fmt.Println(\"open file failed, err:\", err) return } defer file.Close() str := \"hello 沙河\" file.Write([]byte(str)) //写入字节切片数据 file.WriteString(\"hello 小王子\") //直接写入字符串数据 } bufio.NewWriter func main() { file, err := os.OpenFile(\"xx.txt\", os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0666) if err != nil { fmt.Println(\"open file failed, err:\", err) return } defer file.Close() writer := bufio.NewWriter(file) for i := 0; i \u003c 10; i++ { writer.WriteString(\"hello沙河\\n\") //将数据先写入缓存 } writer.Flush() //将缓存中的内容写入文件 } ioutil.WriteFile func main() { str := \"hello 沙河\" err := ioutil.WriteFile(\"./xx.txt\", []byte(str), 0666) if err != nil { fmt.Println(\"write file failed, err:\", err) return } } 练习： 1、实现cp命令 借助io.Copy()实现一个拷贝文件函数。 // CopyFile 拷贝文件函数 func CopyFile(dstName, srcName string) (written int64, err error) { // 以读方式打开源文件 src, err := os.Open(srcName) if err != nil { fmt.Printf(\"open %s failed, err:%v.\\n\", srcName, err) return } defer src.Close() // 以写|创建的方式打开目标文件 dst, err := os.OpenFile(dstName, os.O_WRONLY|os.O_CREATE, 0644) if err != nil { fmt.Printf(\"open %s failed, err:%v.\\n\", dstName, err) return } defer dst.Close() return io.Copy(dst, src) //调用io.Copy()拷贝内容 } func main() { _, err := CopyFile(\"dst.txt\", \"src.txt\") if err != nil { fmt.Println(\"copy file failed, err:\", err) return } fmt.Println(\"copy done!\") } 2、实现cat命令 使用文件操作相关知识，模拟实现linux平台cat命令的功能 package main import ( \"bufio\" \"flag\" \"fmt\" \"io\" \"os\" ) // cat命令实现 func cat(r *bufio.Reader) { for { buf, err := r.ReadBytes('\\n') //注意是字符 if err == io.EOF { // 退出之前将已读到的内容输出 fmt.Fprintf(os.Stdout, \"%s\", buf) break } fmt.Fprintf(os.Stdout, \"%s\", buf) } } func main() { flag.Parse() // 解析命令行参数 if flag.NArg() == 0 { // 如果没有参数默认从标准输入读取内容 cat(bufio.NewReader(os.Stdin)) } // 依次读取每个指定文件的内容并打印到终端 for i := 0; i \u003c flag.NArg(); i++ { f, err := os.Open(flag.Arg(i)) if err != nil { fmt.Fprintf(os.Stdout, \"reading from %s failed, err:%v\\n\", flag.Arg(i), err) continue } cat(bufio.NewReader(f)) } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-file/:1:4","tags":["Go","file"],"title":"Go file","uri":"/posts/2023-11-11-go-file/"},{"categories":["Go 库文档"],"content":"Excel库excelize 参考链接：[Go 语言读写 Excel - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/33417413#:~:text=Excelize 是 Go 语言编写的用于操作 Office Excel 文档类库，基于 ECMA-376,标准。 可以使用它来读取、写入由 Microsoft Excel™ 2007 及以上版本创建的 XLSX 文档。) Excelize 是 Go 语言编写的用于操作 Office Excel 文档类库，基于 ECMA-376 Office OpenXML 标准。可以使用它来读取、写入由 Microsoft Excel™ 2007 及以上版本创建的 XLSX 文档。相比较其他的开源类库，Excelize 支持写入原本带有图片(表)、透视表和切片器等复杂样式的文档，还支持向 Excel 文档中插入图片与图表，并且在保存后不会丢失文档原有样式，可以应用于各类报表系统中。使用本类库要求使用的 Go 语言为 1.8 或更高版本，完整的 API 使用文档请访问 godoc.org 或查看参考文档。 GitHub: excelize 官方文档：https://xuri.me/excelize ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-excelize/:1:0","tags":["Go","excelize","xls","xlsx"],"title":"Go excelize","uri":"/posts/2023-11-11-go-excelize/"},{"categories":["Go 库文档"],"content":"1、简单使用 安装 go get github.com/xuri/excelize/v2 1）创建XLSX package main import \"github.com/360EntSecGroup-Skylar/excelize\" func main() { f := excelize.NewFile() // 创建一个工作表 index := f.NewSheet(\"Sheet2\") // 设置单元格的值 f.SetCellValue(\"Sheet1\", \"A2\", \"Hello world.\") f.SetCellValue(\"Sheet1\", \"B2\", 100) f.SetCellValue(\"Sheet1\", \"B3\", \"github\") // 设置工作簿的默认工作表 f.SetActiveSheet(index) // 根据指定路径保存文件 if err := f.SaveAs(\"Book1.xlsx\"); err != nil { println(err.Error()) } } 结果： SetCellValue函数解释 f.SetCellValue(sheet string, axis string, value interface{}) f.SetCellValue(\"Sheet1\", \"B3\", \"github\") sheet：是sheet表格的的名字。 axis：包含两部分，字母表示列，数字表示行。 value：表示值。 2）读取xlsx func ReadXlsx() { filename := \"Book1.xlsx\" f, err := excelize.OpenFile(filename) if err != nil { fmt.Printf(\"无法打开xlsx：%v 错误原因：%v\", filename, err) return } // 获取工作表中指定单元格的值 cell, err := f.GetCellValue(\"Sheet1\", \"B3\") if err != nil { fmt.Printf(\"获取 %v 的%v的 值 失败,失败原因：%v\", \"Sheet1\", \"B3\", err) } fmt.Printf(\"读取的内容为：%v\", cell) // 获取 Sheet1 上所有单元格 rows, err := f.GetRows(\"Sheet1\") if err != nil { fmt.Printf(\"获取 %v的单元格失败,失败原因：%v\", \"Sheet1\", err) } for _, row := range rows { for _, colCell := range row { print(colCell, \"\\t\") } println() } } 3）插入一行数据 func (exa *ExcelService) ParseInfoList2Excel(infoList []system.SysBaseMenu, filePath string) error { excel := excelize.NewFile() excel.SetSheetRow(\"Sheet1\", \"A1\", \u0026[]string{\"ID\", \"路由Name\", \"路由Path\", \"是否隐藏\", \"父节点\", \"排序\", \"文件名称\"}) for i, menu := range infoList { axis := fmt.Sprintf(\"A%d\", i+2) excel.SetSheetRow(\"Sheet1\", axis, \u0026[]interface{}{ menu.ID, menu.Name, menu.Path, menu.Hidden, menu.ParentId, menu.Sort, menu.Component, }) } err := excel.SaveAs(filePath) return err } 4）从表格中导入数据 func PasreExcel2List(filepath string, fileHeader []string, skipHeader bool) (data [][]string, err error) { file, err := excelize.OpenFile(filepath) if err != nil { return } defer file.Close() rows, err := file.GetRows(\"Sheet1\") if err != nil { return } if skipHeader { if ForEqualStringSlice(rows[0], fileHeader) { rows = rows[1:] } else { err = errors.New(\"FileHeader not Equal.\") return } } data = rows return } func (exa *ExcelService) ParseExcel2InfoList() ([]system.SysBaseMenu, error) { skipHeader := true fixedHeader := []string{\"ID\", \"路由Name\", \"路由Path\", \"是否隐藏\", \"父节点\", \"排序\", \"文件名称\"} file, err := excelize.OpenFile(global.GVA_CONFIG.Excel.Dir + \"ExcelImport.xlsx\") if err != nil { return nil, err } menus := make([]system.SysBaseMenu, 0) rows, err := file.Rows(\"Sheet1\") if err != nil { return nil, err } for rows.Next() { row, err := rows.Columns() if err != nil { return nil, err } if skipHeader { if exa.compareStrSlice(row, fixedHeader) { skipHeader = false continue } else { return nil, errors.New(\"Excel格式错误\") } } if len(row) != len(fixedHeader) { continue } id, _ := strconv.Atoi(row[0]) hidden, _ := strconv.ParseBool(row[3]) sort, _ := strconv.Atoi(row[5]) menu := system.SysBaseMenu{ GVA_MODEL: global.GVA_MODEL{ ID: uint(id), }, Name: row[1], Path: row[2], Hidden: hidden, ParentId: row[4], Sort: sort, Component: row[6], } menus = append(menus, menu) } return menus, nil } func (exa *ExcelService) compareStrSlice(a, b []string) bool { if len(a) != len(b) { return false } if (b == nil) != (a == nil) { return false } for key, value := range a { if value != b[key] { return false } } return true } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-excelize/:1:1","tags":["Go","excelize","xls","xlsx"],"title":"Go excelize","uri":"/posts/2023-11-11-go-excelize/"},{"categories":["Go 库文档"],"content":"cron定时任务 参考链接：https://segmentfault.com/a/1190000023029219 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:0","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"简介 cron一个用于管理定时任务的库，用 Go 实现 Linux 中crontab这个命令的效果。之前我们也介绍过一个类似的 Go 库——gron。gron代码小巧，用于学习是比较好的。但是它功能相对简单些，并且已经不维护了。如果有定时任务需求，还是建议使用cron。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:1","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"快速使用 安装cron，目前最新稳定版本为 v3： $ go get github.com/robfig/cron/v3 使用 package main import ( \"fmt\" \"time\" \"github.com/robfig/cron/v3\" ) func main() { c := cron.New() c.AddFunc(\"@every 1s\", func() { fmt.Println(\"tick every 1 second\") }) c.Start() time.Sleep(time.Second * 5) } 使用非常简单，创建cron对象，这个对象用于管理定时任务。 调用cron对象的AddFunc()方法向管理器中添加定时任务。AddFunc()接受两个参数，参数 1 以字符串形式指定触发时间规则，参数 2 是一个无参的函数，每次触发时调用。@every 1s表示每秒触发一次，@every后加一个时间间隔，表示每隔多长时间触发一次。例如@every 1h表示每小时触发一次，@every 1m2s表示每隔 1 分 2 秒触发一次。time.ParseDuration()支持的格式都可以用在这里。 调用c.Start()启动定时循环。 注意一点，因为c.Start()启动一个新的 goroutine 做循环检测，我们在代码最后加了一行time.Sleep(time.Second * 5)防止主 goroutine 退出。 运行效果，每隔 1s 输出一行字符串： $ go run main.go tick every 1 second tick every 1 second tick every 1 second tick every 1 second tick every 1 second ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:2","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"时间格式 与Linux 中crontab命令相似，cron库支持用 5 个空格分隔的域来表示时间。这 5 个域含义依次为： Minutes：分钟，取值范围[0-59]，支持特殊字符* / , -； Hours：小时，取值范围[0-23]，支持特殊字符* / , -； Day of month：每月的第几天，取值范围[1-31]，支持特殊字符* / , - ?； Month：月，取值范围[1-12]或者使用月份名字缩写[JAN-DEC]，支持特殊字符* / , -； Day of week：周历，取值范围[0-6]或名字缩写[JUN-SAT]，支持特殊字符* / , - ?。 注意，月份和周历名称都是不区分大小写的，也就是说SUN/Sun/sun表示同样的含义（都是周日）。 特殊字符含义如下： *：使用*的域可以匹配任何值，例如将月份域（第 4 个）设置为*，表示每个月； /：用来指定范围的步长，例如将小时域（第 2 个）设置为3-59/15表示第 3 分钟触发，以后每隔 15 分钟触发一次，因此第 2 次触发为第 18 分钟，第 3 次为 33 分钟。。。直到分钟大于 59； ,：用来列举一些离散的值和多个范围，例如将周历的域（第 5 个）设置为MON,WED,FRI表示周一、三和五； -：用来表示范围，例如将小时的域（第 1 个）设置为9-17表示上午 9 点到下午 17 点（包括 9 和 17）； ?：只能用在月历和周历的域中，用来代替*，表示每月/周的任意一天。 了解规则之后，我们可以定义任意时间： 30 * * * *：分钟域为 30，其他域都是*表示任意。每小时的 30 分触发； 30 3-6,20-23 * * *：分钟域为 30，小时域的3-6,20-23表示 3 点到 6 点和 20 点到 23 点。3,4,5,6,20,21,22,23 时的 30 分触发； 0 0 1 1 *：1（第 4 个） 月 1（第 3 个） 号的 0（第 2 个） 时 0（第 1 个） 分触发。 记熟了这几个域的顺序，再多练习几次很容易就能掌握格式。熟悉规则了之后，就能熟练使用crontab命令了。 func main() { c := cron.New() c.AddFunc(\"30 * * * *\", func() { fmt.Println(\"Every hour on the half hour\") }) c.AddFunc(\"30 3-6,20-23 * * *\", func() { fmt.Println(\"On the half hour of 3-6am, 8-11pm\") }) c.AddFunc(\"0 0 1 1 *\", func() { fmt.Println(\"Jun 1 every year\") }) c.Start() for { time.Sleep(time.Second) } } 预定义时间规则 为了方便使用，cron预定义了一些时间规则： @yearly：也可以写作@annually，表示每年第一天的 0 点。等价于0 0 1 1 *； @monthly：表示每月第一天的 0 点。等价于0 0 1 * *； @weekly：表示每周第一天的 0 点，注意第一天为周日，即周六结束，周日开始的那个 0 点。等价于0 0 * * 0； @daily：也可以写作@midnight，表示每天 0 点。等价于0 0 * * *； @hourly：表示每小时的开始。等价于0 * * * *。 例如： func main() { c := cron.New() c.AddFunc(\"@hourly\", func() { fmt.Println(\"Every hour\") }) c.AddFunc(\"@daily\", func() { fmt.Println(\"Every day on midnight\") }) c.AddFunc(\"@weekly\", func() { fmt.Println(\"Every week\") }) c.Start() for { time.Sleep(time.Second) } } 上面代码只是演示用法，实际运行可能要等待非常长的时间才能有输出。 固定时间间隔 cron支持固定时间间隔，格式为： @every \u003cduration\u003e 含义为每隔duration触发一次。``会调用time.ParseDuration()函数解析，所以ParseDuration支持的格式都可以。例如1h30m10s。在快速开始部分，我们已经演示了@every的用法了，这里就不赘述了。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:3","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"时区 默认情况下，所有时间都是基于当前时区的。当然我们也可以指定时区，有 2 两种方式： 在时间字符串前面添加一个CRON_TZ= + 具体时区，具体时区的格式在之前carbon的文章中有详细介绍。东京时区为Asia/Tokyo，纽约时区为America/New_York； 创建cron对象时增加一个时区选项cron.WithLocation(location)，location为time.LoadLocation(zone)加载的时区对象，zone为具体的时区格式。或者调用已创建好的cron对象的SetLocation()方法设置时区。 示例： func main() { nyc, _ := time.LoadLocation(\"America/New_York\") c := cron.New(cron.WithLocation(nyc)) c.AddFunc(\"0 6 * * ?\", func() { fmt.Println(\"Every 6 o'clock at New York\") }) c.AddFunc(\"CRON_TZ=Asia/Tokyo 0 6 * * ?\", func() { fmt.Println(\"Every 6 o'clock at Tokyo\") }) c.Start() for { time.Sleep(time.Second) } } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:4","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"Job接口 除了直接将无参函数作为回调外，cron还支持Job接口： // cron.go type Job interface { Run() } 我们定义一个实现接口Job的结构： type GreetingJob struct { Name string } func (g GreetingJob) Run() { fmt.Println(\"Hello \", g.Name) } 调用cron对象的AddJob()方法将GreetingJob对象添加到定时管理器中： func main() { c := cron.New() c.AddJob(\"@every 1s\", GreetingJob{\"dj\"}) c.Start() time.Sleep(5 * time.Second) } 运行效果： $ go run main.go Hello dj Hello dj Hello dj Hello dj Hello dj 使用自定义的结构可以让任务携带状态（Name字段）。 实际上AddFunc()方法内部也调用了AddJob()方法。首先，cron基于func()类型定义一个新的类型FuncJob： // cron.go type FuncJob func() 然后让FuncJob实现Job接口： // cron.go func (f FuncJob) Run() { f() } 在AddFunc()方法中，将传入的回调转为FuncJob类型，然后调用AddJob()方法： func (c *Cron) AddFunc(spec string, cmd func()) (EntryID, error) { return c.AddJob(spec, FuncJob(cmd)) } ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:5","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"线程安全 cron会创建一个新的 goroutine 来执行触发回调。如果这些回调需要并发访问一些资源、数据，我们需要显式地做同步。 ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:6","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"自定义时间格式 cron支持灵活的时间格式，如果默认的格式不能满足要求，我们可以自己定义时间格式。时间规则字符串需要cron.Parser对象来解析。我们先来看看默认的解析器是如何工作的。 首先定义各个域： // parser.go const ( Second ParseOption = 1 \u003c\u003c iota SecondOptional Minute Hour Dom Month Dow DowOptional Descriptor ) 除了Minute/Hour/Dom(Day of month)/Month/Dow(Day of week)外，还可以支持Second。相对顺序都是固定的： // parser.go var places = []ParseOption{ Second, Minute, Hour, Dom, Month, Dow, } var defaults = []string{ \"0\", \"0\", \"0\", \"*\", \"*\", \"*\", } 默认的时间格式使用 5 个域。 我们可以调用cron.NewParser()创建自己的Parser对象，以位格式传入使用哪些域，例如下面的Parser使用 6 个域，支持Second（秒）： parser := cron.NewParser( cron.Second | cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.Dow | cron.Descriptor, ) 调用cron.WithParser(parser)创建一个选项传入构造函数cron.New()，使用时就可以指定秒了： c := cron.New(cron.WithParser(parser)) c.AddFunc(\"1 * * * * *\", func () { fmt.Println(\"every 1 second\") }) c.Start() 这里时间格式必须使用 6 个域，顺序与上面的const定义一致。 因为上面的时间格式太常见了，cron定义了一个便捷的函数： // option.go func WithSeconds() Option { return WithParser(NewParser( Second | Minute | Hour | Dom | Month | Dow | Descriptor, )) } 注意Descriptor表示对@every/@hour等的支持。有了WithSeconds()，我们不用手动创建Parser对象了： c := cron.New(cron.WithSeconds()) ","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:7","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"选项 cron对象创建使用了选项模式，我们前面已经介绍了 3 个选项： WithLocation：指定时区； WithParser：使用自定义的解析器； WithSeconds：让时间格式支持秒，实际上内部调用了WithParser。 cron还提供了另外两种选项： WithLogger：自定义Logger； WithChain：Job 包装器。 WithLogger WithLogger可以设置cron内部使用我们自定义的Logger： func main() { c := cron.New( cron.WithLogger( cron.VerbosePrintfLogger(log.New(os.Stdout, \"cron: \", log.LstdFlags)))) c.AddFunc(\"@every 1s\", func() { fmt.Println(\"hello world\") }) c.Start() time.Sleep(5 * time.Second) } 上面调用cron.VerbosPrintfLogger()包装log.Logger，这个logger会详细记录cron内部的调度过程： $ go run main.go cron: 2020/06/26 07:09:14 start cron: 2020/06/26 07:09:14 schedule, now=2020-06-26T07:09:14+08:00, entry=1, next=2020-06-26T07:09:15+08:00 cron: 2020/06/26 07:09:15 wake, now=2020-06-26T07:09:15+08:00 cron: 2020/06/26 07:09:15 run, now=2020-06-26T07:09:15+08:00, entry=1, next=2020-06-26T07:09:16+08:00 hello world cron: 2020/06/26 07:09:16 wake, now=2020-06-26T07:09:16+08:00 cron: 2020/06/26 07:09:16 run, now=2020-06-26T07:09:16+08:00, entry=1, next=2020-06-26T07:09:17+08:00 hello world cron: 2020/06/26 07:09:17 wake, now=2020-06-26T07:09:17+08:00 cron: 2020/06/26 07:09:17 run, now=2020-06-26T07:09:17+08:00, entry=1, next=2020-06-26T07:09:18+08:00 hello world cron: 2020/06/26 07:09:18 wake, now=2020-06-26T07:09:18+08:00 hello world cron: 2020/06/26 07:09:18 run, now=2020-06-26T07:09:18+08:00, entry=1, next=2020-06-26T07:09:19+08:00 cron: 2020/06/26 07:09:19 wake, now=2020-06-26T07:09:19+08:00 hello world cron: 2020/06/26 07:09:19 run, now=2020-06-26T07:09:19+08:00, entry=1, next=2020-06-26T07:09:20+08:0 我们看看默认的Logger是什么样的： // logger.go var DefaultLogger Logger = PrintfLogger(log.New(os.Stdout, \"cron: \", log.LstdFlags)) func PrintfLogger(l interface{ Printf(string, ...interface{}) }) Logger { return printfLogger{l, false} } func VerbosePrintfLogger(l interface{ Printf(string, ...interface{}) }) Logger { return printfLogger{l, true} } type printfLogger struct { logger interface{ Printf(string, ...interface{}) } logInfo bool } WithChain Job 包装器可以在执行实际的Job前后添加一些逻辑： 捕获panic； 如果Job上次运行还未结束，推迟本次执行; 如果Job上次运行还未介绍，跳过本次执行； 记录每个Job的执行情况。 我们可以将Chain类比为 Web 处理器的中间件。实际上就是在Job的执行逻辑外在封装一层逻辑。我们的封装逻辑需要写成一个函数，传入一个Job类型，返回封装后的Job。cron为这种函数定义了一个类型JobWrapper： // chain.go type JobWrapper func(Job) Job 然后使用一个Chain对象将这些JobWrapper组合到一起： type Chain struct { wrappers []JobWrapper } func NewChain(c ...JobWrapper) Chain { return Chain{c} } 调用Chain对象的Then(job)方法应用这些JobWrapper，返回最终的`Job： func (c Chain) Then(j Job) Job { for i := range c.wrappers { j = c.wrappers[len(c.wrappers)-i-1](j) } return j } 注意应用JobWrapper的顺序。 内置JobWrapper cron内置了 3 个用得比较多的JobWrapper： Recover：捕获内部Job产生的 panic； DelayIfStillRunning：触发时，如果上一次任务还未执行完成（耗时太长），则等待上一次任务完成之后再执行； SkipIfStillRunning：触发时，如果上一次任务还未完成，则跳过此次执行。 下面分别介绍。 Recover 先看看如何使用： type panicJob struct { count int } func (p *panicJob) Run() { p.count++ if p.count == 1 { panic(\"oooooooooooooops!!!\") } fmt.Println(\"hello world\") } func main() { c := cron.New() c.AddJob(\"@every 1s\", cron.NewChain(cron.Recover(cron.DefaultLogger)).Then(\u0026panicJob{})) c.Start() time.Sleep(5 * time.Second) } panicJob在第一次触发时，触发了panic。因为有cron.Recover()保护，后续任务还能执行： go run main.go cron: 2020/06/27 14:02:00 panic, error=oooooooooooooops!!!, stack=... goroutine 18 [running]: github.com/robfig/cron/v3.Recover.func1.1.1(0x514ee0, 0xc0000044a0) D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/chain.go:45 +0xbc panic(0x4cf380, 0x513280) C:/Go/src/runtime/panic.go:969 +0x174 main.(*panicJob).Run(0xc0000140e8) D:/code/golang/src/github.com/darjun/go-daily-lib/cron/recover/main.go:17 +0xba github.com/robfig/cron/v3.Recover.func1.1() D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/chain.go:53 +0x6f github.com/robfig/cron/v3.FuncJob.Run(0xc000070390) D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/cron.go:136 +0x2c github.com/robfig/cron/v3.(*Cron).startJob.func1(0xc00005c0a0, 0x514d20, 0xc000070390) D:/code/golang/pkg/mod/github.com/robfig/cron/v3@v3.0.1/cron.go:312 +0x68 created by github.com/robfig/cron/v3.(*Cron).startJob D:","date":"2023-11-11","objectID":"/posts/2023-11-11-go-cron/:1:8","tags":["Go","cron"],"title":"Go cron","uri":"/posts/2023-11-11-go-cron/"},{"categories":["Go 库文档"],"content":"Go goph库 链接地址： github.com/melbahja/goph github.com/serialt/goph (方便指定端口) ","date":"2023-11-10","objectID":"/posts/go-goth/:0:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"特性 易于使用，简化 ssh api。 支持ssh 密码、私钥，带密码的私钥。 支持从本地上传文件和从远程下载文件。 支持 ssh 使用 ssh-agent 连接会话。 支持增加主机到 known_hosts 文件。 ","date":"2023-11-10","objectID":"/posts/go-goth/:1:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"安装 go get github.com/serialt/goph ","date":"2023-11-10","objectID":"/posts/go-goth/:2:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"使用示例 ","date":"2023-11-10","objectID":"/posts/go-goth/:3:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"1、使用执行命令 package main import ( \"fmt\" \"log\" \"github.com/serialt/goph\" ) var Client *goph.Client func init() { auth, err := goph.Key(os.Getenv(\"HOME\")+\"/.ssh/id_rsa\", \"\") if err != nil { log.Fatalf(\"cat read the ssh private key: %v\", err) } client, err := goph.New(\"root\", \"10.10.16.10\", 22, auth) if err != nil { log.Fatalf(\"ssh link faild: %v\", err) } Client = client } func main() { result, err := Client.Run(\"date\") fmt.Printf(\"result: %v\\nerr: %v\", string(result), err) defer Client.Close() } ","date":"2023-11-10","objectID":"/posts/go-goth/:3:1","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"2、从字符串中读取私钥 package main import ( \"fmt\" \"log\" \"github.com/serialt/goph\" ) var Client *goph.Client var sshkey = ` -----BEGIN OPENSSH PRIVATE KEY----- NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID AAAECptYaTKFA2Omsb67+FN2SPr3daBAA0IxpVwv5KYJ1QKWR98JYVP7/WAqffRO NeY6rItzuvwtiPa5etNiAAAAGnNlcmlhbHQgdHNlcmlhbHRAZ21haWwuY29tAQID -----END OPENSSH PRIVATE KEY----- ` func init() { auth, err := goph.RawKey(sshkey, \"\") if err != nil { log.Fatalf(\"cat read the ssh private key: %v\", err) } client, err := goph.New(\"root\", \"10.10.16.10\", 22, auth) if err != nil { log.Fatalf(\"ssh link faild: %v\", err) } Client = client } func main() { result, err := Client.Run(\"date\") fmt.Printf(\"result: %v\\nerr: %v\", string(result), err) defer Client.Close() } ","date":"2023-11-10","objectID":"/posts/go-goth/:3:2","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"3、密钥带密码 auth, err := goph.Key(os.Getenv(\"HOME\")+\"/.ssh/id_rsa\", \"you_passphrase_here\") if err != nil { // handle error } client, err := goph.New(\"root\", \"192.1.1.3\", auth) ","date":"2023-11-10","objectID":"/posts/go-goth/:3:3","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"4、使用密码 auth, err := goph.UseAgent() if err != nil { // handle error } client, err := goph.New(\"root\", \"192.1.1.1\", auth) ","date":"2023-11-10","objectID":"/posts/go-goth/:3:4","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"5、上传和下载文件 // upload local file to remote err := client.Upload(\"/path/to/local/file\", \"/path/to/remote/file\") // download remote file to local err := client.Download(\"/path/to/remote/file\", \"/path/to/local/file\") ","date":"2023-11-10","objectID":"/posts/go-goth/:3:5","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"6、执行shell命令 // execute bash commands out, err := client.Run(\"bash -c 'printenv'\") // execute bash command whith timeout context, cancel := context.WithTimeout(ctx, time.Second) defer cancel() // will send SIGINT and return error after 1 second out, err := client.RunContext(ctx, \"sleep 5\") // execute bash command whith env variables out, err := client.Run(`env MYVAR=\"MY VALUE\" bash -c 'echo $MYVAR;'`) ","date":"2023-11-10","objectID":"/posts/go-goth/:3:6","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"7、使用goph cmd Goph.Cmd struct is like the Go standard os/exec.Cmd. // Get new `Goph.Cmd` cmd, err := client.Command(\"ls\", \"-alh\", \"/tmp\") // or with context: // cmd, err := client.CommandContext(ctx, \"ls\", \"-alh\", \"/tmp\") if err != nil { // handle the error! } // You can set env vars, but the server must be configured to `AcceptEnv line`. cmd.Env = []string{\"MY_VAR=MYVALUE\"} // Run you command. err = cmd.Run() ust like os/exec.Cmd you can run CombinedOutput, Output, Start, Wait, and ssh.Session methods like Signal… ","date":"2023-11-10","objectID":"/posts/go-goth/:3:7","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"8、使用sftp操作文件系统 sftp, err := client.NewSftp() if err != nil { // handle the error! } file, err := sftp.Create(\"/tmp/remote_file\") file.Write([]byte(`Hello world`)) file.Close() For more file operations see SFTP Docs. ","date":"2023-11-10","objectID":"/posts/go-goth/:3:8","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["Go 库文档"],"content":"官方示例 package main import ( \"bufio\" \"context\" \"errors\" \"flag\" \"fmt\" \"log\" \"net\" \"os\" osuser \"os/user\" \"path/filepath\" \"strings\" \"time\" \"github.com/pkg/sftp\" \"github.com/serialt/goph\" \"golang.org/x/crypto/ssh\" \"golang.org/x/crypto/ssh/terminal\" ) // // Run command and auth via password: // \u003e go run main.go --ip 192.168.122.102 --pass --cmd ls // // Run command and auth via private key: // \u003e go run main.go --ip 192.168.122.102 --cmd ls // Or: // \u003e go run main.go --ip 192.168.122.102 --key /path/to/private_key --cmd ls // // Run command and auth with private key and passphrase: // \u003e go run main.go --ip 192.168.122.102 --passphrase --cmd ls // // Run a command and interrupt it after 1 second: // \u003e go run main.go --ip 192.168.122.102 --cmd \"sleep 10\" --timeout=1s // // You can test with the interactive mode without passing --cmd flag. // var ( err error auth goph.Auth client *goph.Client addr string user string port uint key string cmd string pass bool passphrase bool timeout time.Duration agent bool sftpc *sftp.Client ) func init() { usr, err := osuser.Current() if err != nil { fmt.Println(\"couldn't determine current user. defaulting to 'root'\") usr.Username = \"root\" } flag.StringVar(\u0026addr, \"ip\", \"127.0.0.1\", \"machine ip address.\") flag.StringVar(\u0026user, \"user\", usr.Username, \"ssh user.\") flag.UintVar(\u0026port, \"port\", 22, \"ssh port number.\") flag.StringVar(\u0026key, \"key\", filepath.Join(os.Getenv(\"HOME\"), \".ssh\", \"id_rsa\"), \"private key path.\") flag.StringVar(\u0026cmd, \"cmd\", \"\", \"command to run.\") flag.BoolVar(\u0026pass, \"pass\", false, \"ask for ssh password instead of private key.\") flag.BoolVar(\u0026agent, \"agent\", false, \"use ssh agent for authentication (unix systems only).\") flag.BoolVar(\u0026passphrase, \"passphrase\", false, \"ask for private key passphrase.\") flag.DurationVar(\u0026timeout, \"timeout\", 0, \"interrupt a command with SIGINT after a given timeout (0 means no timeout)\") } func VerifyHost(host string, remote net.Addr, key ssh.PublicKey) error { // // If you want to connect to new hosts. // here your should check new connections public keys // if the key not trusted you shuld return an error // // hostFound: is host in known hosts file. // err: error if key not in known hosts file OR host in known hosts file but key changed! hostFound, err := goph.CheckKnownHost(host, remote, key, \"\") // Host in known hosts but key mismatch! // Maybe because of MAN IN THE MIDDLE ATTACK! if hostFound \u0026\u0026 err != nil { return err } // handshake because public key already exists. if hostFound \u0026\u0026 err == nil { return nil } // Ask user to check if he trust the host public key. if askIsHostTrusted(host, key) == false { // Make sure to return error on non trusted keys. return errors.New(\"you typed no, aborted!\") } // Add the new host to known hosts file. return goph.AddKnownHost(host, remote, key, \"\") } func main() { flag.Parse() var err error if agent || goph.HasAgent() { auth, err = goph.UseAgent() } else if pass { auth = goph.Password(askPass(\"Enter SSH Password: \")) } else { auth, err = goph.Key(key, getPassphrase(passphrase)) } if err != nil { panic(err) } client, err = goph.NewConn(\u0026goph.Config{ User: user, Addr: addr, Port: port, Auth: auth, Callback: VerifyHost, }) if err != nil { panic(err) } // Close client net connection defer client.Close() // If the cmd flag exists if cmd != \"\" { ctx := context.Background() // create a context with timeout, if supplied in the argumetns if timeout \u003e 0 { var cancel context.CancelFunc ctx, cancel = context.WithTimeout(ctx, timeout) defer cancel() } out, err := client.RunContext(ctx, cmd) fmt.Println(string(out), err) return } // else open interactive mode. playWithSSHJustForTestingThisProgram(client) } func askPass(msg string) string { fmt.Print(msg) pass, err := terminal.ReadPassword(0) if err != nil { panic(err) } fmt.Println(\"\") return strings.TrimSpace(string(pass)) } func getPassphrase(ask bool) string { if ask { return askPass(\"Enter Private Key Passphrase: \") } return \"\" } func askIsHostTrusted(host string, key ssh.Public","date":"2023-11-10","objectID":"/posts/go-goth/:4:0","tags":["Go","goph","ssh","sftp"],"title":"Go goph","uri":"/posts/go-goth/"},{"categories":["morse编码"],"content":"Morse Code 二叉树记忆法 start E T I A N M S U R W D K G O H V F L P J B X C Y Z Q . - E T .. .- -. -- I A N M ... ..- .-. ..- -.. -.- --. --- S U R W D K G O .... ...- ..-. .-.. .--. .--- -... -..- -.-. -.-- --.. --.- H v F L P J B X C Y Z Q ","date":"2023-11-08","objectID":"/posts/morse-code/:1:0","tags":["morse","morse-code"],"title":"Morse Code","uri":"/posts/morse-code/"},{"categories":["Go req 库文档"],"content":"req Go语言人性化HTTP请求库 特性 轻量级 简单 容易操作JSON和XML 容易调试和日志记录 容易上传和下载文件 容易管理Cookie 容易设置代理 容易设置超时 容易自定义HTTP客户端 安装 go get github.com/serialt/req 概要 req 基于标准库 net/http 实现了一个友好的API. Req 和 Resp 是两个最重要的结构体, 你可以把 Req 看作客户端， 把Resp 看作存放请求及其响应的容器，它们都提供许多简洁方便的API，让你可以很轻松做很多很多事情。 func (r *Req) Post(url string, v ...interface{}) (*Resp, error) 大多情况下，发起请求只有url是必选参数，其它都可选，比如请求头、请求参数、文件或请求体等。 包中含一个默认的 Req 对象, 它所有的公有方法都被req包对应的公有方法包装了，所以大多数情况下，你直接可以把req包看作一个Req对象来使用。 // 创建Req对象来发起请求 r := req.New() r.Get(url) // 直接使用req包发起请求 req.Get(url) 你可以使用 req.New() 方法来创建 *Req 作为一个单独的客户端 例子 基础用法 设置请求头 设置请求参数 设置请求体 调试 输出格式 ToJSON \u0026 ToXML 获取 *http.Response 上传 下载 Cookie 设置超时 设置代理 自定义 http.Client ","date":"2023-10-09","objectID":"/posts/req/:0:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"基础用法 header := req.Header{ \"Accept\": \"application/json\", \"Authorization\": \"Basic YWRtaW46YWRtaW4=\", } param := req.Param{ \"name\": \"imroc\", \"cmd\": \"add\", } // 只有url必选，其它参数都是可选 r, err = req.Post(\"http://foo.bar/api\", header, param) if err != nil { log.Fatal(err) } r.ToJSON(\u0026foo) // 响应体转成对象 log.Printf(\"%+v\", r) // 打印详细信息 ","date":"2023-10-09","objectID":"/posts/req/:1:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置请求头 使用 req.Header (它实际上是一个 map[string]string) authHeader := req.Header{ \"Accept\": \"application/json\", \"Authorization\": \"Basic YWRtaW46YWRtaW4=\", } req.Get(\"https://www.baidu.com\", authHeader, req.Header{\"User-Agent\": \"V1.1\"}) 使用 http.Header header := make(http.Header) header.Set(\"Accept\", \"application/json\") req.Get(\"https://www.baidu.com\", header) 你可以使用 struct 来设置请求头，用 HeaderFromStruct 这个函数来解析你的 struct type HeaderStruct struct { UserAgent string `json:\"User-Agent\"` Authorization string `json:\"Authorization\"` } func main(){ h := HeaderStruct{ \"V1.0.0\", \"roc\", } authHeader := req.HeaderFromStruct(h) req.Get(\"https://www.baidu.com\", authHeader, req.Header{\"User-Agent\": \"V1.1\"}) } 注：请给你的 struct 加上 json tag. ","date":"2023-10-09","objectID":"/posts/req/:2:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置请求参数 Use req.Param (它实际上是一个 map[string]interface{}) param := req.Param{ \"id\": \"imroc\", \"pwd\": \"roc\", } req.Get(\"http://foo.bar/api\", param) // http://foo.bar/api?id=imroc\u0026pwd=roc req.Post(url, param) // 请求体 =\u003e id=imroc\u0026pwd=roc 使用 req.QueryParam 强制将请求参数拼在url后面 (它实际上也是一个 map[string]interface{}) req.Post(\"http://foo.bar/api\", req.Param{\"name\": \"roc\", \"age\": \"22\"}, req.QueryParam{\"access_token\": \"fedledGF9Hg9ehTU\"}) /* POST /api?access_token=fedledGF9Hg9ehTU HTTP/1.1 Host: foo.bar User-Agent: Go-http-client/1.1 Content-Length: 15 Content-Type: application/x-www-form-urlencoded;charset=UTF-8 Accept-Encoding: gzip age=22\u0026name=roc */ ","date":"2023-10-09","objectID":"/posts/req/:3:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置请求体 Put string, []byte and io.Reader as body directly. req.Post(url, \"id=roc\u0026cmd=query\") 将对象作为JSON或XML请求体（自动添加 Content-Type 请求头） req.Post(url, req.BodyJSON(\u0026foo)) req.Post(url, req.BodyXML(\u0026bar)) ","date":"2023-10-09","objectID":"/posts/req/:4:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"调试 将全局变量 req.Debug 设置为true，将会把所有请求的详细信息打印在标准输出。 req.Debug = true req.Post(\"http://localhost/test\" \"hi\") ","date":"2023-10-09","objectID":"/posts/req/:5:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"输出格式 您可以使用指定类型的输出格式在日志文件中记录请求和响应的信息。例如，在开发阶段使用％+v格式，可以让你观察请求和响应的细节信息。 在生产阶段使用％v或％-v输出格式，只记录所需要的信息。 ","date":"2023-10-09","objectID":"/posts/req/:6:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"%+v 或 %+s 详细输出 r, _ := req.Post(url, header, param) log.Printf(\"%+v\", r) // 输出格式和Debug开启时的格式一样 ","date":"2023-10-09","objectID":"/posts/req/:6:1","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"%v 或 %s 简单输出（默认格式） r, _ := req.Get(url, param) log.Printf(\"%v\\n\", r) // GET http://foo.bar/api?name=roc\u0026cmd=add {\"code\":\"0\",\"msg\":\"success\"} log.Prinln(r) // 和上面一样 ","date":"2023-10-09","objectID":"/posts/req/:6:2","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"%-v 或 %-s 简单输出并保持所有内容在一行内（请求体或响应体可能包含多行，这种格式会将所有换行、回车替换成\" \", 这在会让你在查日志的时候非常有用） ","date":"2023-10-09","objectID":"/posts/req/:6:3","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"Flag 你可以调用 SetFlags 控制输出内容，决定哪些部分能够被输出。 const ( LreqHead = 1 \u003c\u003c iota // 输出请求首部（包含请求行和请求头） LreqBody // 输出请求体 LrespHead // 输出响应首部（包含响应行和响应头） LrespBody // 输出响应体 Lcost // 输出请求所消耗掉时长 LstdFlags = LreqHead | LreqBody | LrespHead | LrespBody ) req.SetFlags(req.LreqHead | req.LreqBody | req.LrespHead) ","date":"2023-10-09","objectID":"/posts/req/:6:4","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"监控请求耗时 req.SetFlags(req.LstdFlags | req.Lcost) // 输出格式显示请求耗时 r,_ := req.Get(url) log.Println(r) // http://foo.bar/api 3.260802ms {\"code\":0 \"msg\":\"success\"} if r.Cost() \u003e 3 * time.Second { // 检查耗时 log.Println(\"WARN: slow request:\", r) } ","date":"2023-10-09","objectID":"/posts/req/:6:5","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"ToJSON \u0026 ToXML r, _ := req.Get(url) r.ToJSON(\u0026foo) r, _ = req.Post(url, req.BodyXML(\u0026bar)) r.ToXML(\u0026baz) ","date":"2023-10-09","objectID":"/posts/req/:7:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"获取 *http.Response // func (r *Req) Response() *http.Response r, _ := req.Get(url) resp := r.Response() fmt.Println(resp.StatusCode) ","date":"2023-10-09","objectID":"/posts/req/:8:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"上传 使用 req.File 匹配文件 req.Post(url, req.File(\"imroc.png\"), req.File(\"/Users/roc/Pictures/*.png\")) 使用 req.FileUpload 细粒度控制上传 file, _ := os.Open(\"imroc.png\") req.Post(url, req.FileUpload{ File: file, FieldName: \"file\", // FieldName 是表单字段名 FileName: \"avatar.png\", // Filename 是要上传的文件的名称，我们使用它来猜测mimetype，并将其上传到服务器上 }) 使用req.UploadProgress监听上传进度 progress := func(current, total int64) { fmt.Println(float32(current)/float32(total)*100, \"%\") } req.Post(url, req.File(\"/Users/roc/Pictures/*.png\"), req.UploadProgress(progress)) fmt.Println(\"upload complete\") ","date":"2023-10-09","objectID":"/posts/req/:9:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"下载 r, _ := req.Get(url) r.ToFile(\"imroc.png\") 使用req.DownloadProgress监听下载进度 progress := func(current, total int64) { fmt.Println(float32(current)/float32(total)*100, \"%\") } r, _ := req.Get(url, req.DownloadProgress(progress)) r.ToFile(\"hello.mp4\") fmt.Println(\"download complete\") ","date":"2023-10-09","objectID":"/posts/req/:10:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"Cookie 默认情况下，底层的 *http.Client 会自动管理你的cookie（如果服务器给你发了cookie，之后的请求它会自动带上cookie请求头给服务器）, 你可以调用这个方法取消自动管理： req.EnableCookie(false) 你还可以在发送请求的时候自己传入 *http.Cookie cookie := new(http.Cookie) // ...... req.Get(url, cookie) ","date":"2023-10-09","objectID":"/posts/req/:11:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置超时 req.SetTimeout(50 * time.Second) ","date":"2023-10-09","objectID":"/posts/req/:12:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"设置代理 默认情况下，如果系统环境变量有 http_proxy 或 https_proxy ，req会讲对应的地址作为对应协议的代理，你也可以自定义设置代理，或者将其置为nil，即取消代理。 req.SetProxy(func(r *http.Request) (*url.URL, error) { if strings.Contains(r.URL.Hostname(), \"google\") { return url.Parse(\"http://my.vpn.com:23456\") } return nil, nil }) 设置简单代理（将所有请求都转发到指定代理url地址上） req.SetProxyUrl(\"http://my.proxy.com:23456\") ","date":"2023-10-09","objectID":"/posts/req/:13:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go req 库文档"],"content":"自定义HTTP客户端 使用 SetClient 改变底层的 *http.Client req.SetClient(client) 给某个请求制定特定的 *http.Client client := \u0026http.Client{Timeout: 30 * time.Second} req.Get(url, client) 改变底层 *http.Client 的某些属性 req.Client().Jar, _ = cookiejar.New(nil) trans, _ := req.Client().Transport.(*http.Transport) trans.MaxIdleConns = 20 trans.TLSHandshakeTimeout = 20 * time.Second trans.DisableKeepAlives = true trans.TLSClientConfig = \u0026tls.Config{InsecureSkipVerify: true} ","date":"2023-10-09","objectID":"/posts/req/:14:0","tags":["Go","http","req"],"title":"Go Http Client","uri":"/posts/req/"},{"categories":["Go 库文档"],"content":"Go 原生http库 Go语言内置的net/http包十分的优秀，提供了HTTP客户端和服务端的实现。 ","date":"2023-10-09","objectID":"/posts/go-http/:0:0","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"一、net/http介绍 Go语言内置的net/http包提供了HTTP客户端和服务端的实现。 HTTP协议 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络传输协议，所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。 ","date":"2023-10-09","objectID":"/posts/go-http/:1:0","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"二、HTTP客户端 Get、Head、Post和PostForm函数发出HTTP/HTTPS请求。 resp, err := http.Get(\"http://example.com/\") ... resp, err := http.Post(\"http://example.com/upload\", \"image/jpeg\", \u0026buf) ... resp, err := http.PostForm(\"http://example.com/form\", url.Values{\"key\": {\"Value\"}, \"id\": {\"123\"}}) 程序在使用完response后必须关闭回复的主体。 resp, err := http.Get(\"http://example.com/\") if err != nil { // handle error } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) // ... ","date":"2023-10-09","objectID":"/posts/go-http/:2:0","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"GET请求示例 package main import ( \"fmt\" \"io\" \"net/http\" ) func main() { resp, err := http.Get(\"https://httpbin.org/uuid\") if err != nil { fmt.Printf(\"get failed, err:%v\\n\", err) return } defer resp.Body.Close() body, err := io.ReadAll(resp.Body) if err != nil { fmt.Printf(\"read from resp.Body failed, err:%v\\n\", err) return } fmt.Print(string(body)) } 自定义请求 package main import ( \"encoding/json\" \"fmt\" \"io\" \"net/http\" \"net/url\" ) type UUID struct { Uuid string `json:\"uuid\"` } func main() { apiURL := \"https://httpbin.org/uuid\" query := url.Values{} query.Add(\"q\", \"golang\") query.Add(\"page\", \"1\") ApiURL, _ := url.ParseRequestURI(apiURL) ApiURL.RawQuery = query.Encode() req, _ := http.NewRequest(\"GET\", ApiURL.String(), nil) req.Header.Add(\"Accept\", \"*/*\") client := \u0026http.Client{} resp, err := client.Do(req) if err != nil { return } defer resp.Body.Close() var uuid UUID body, err := io.ReadAll(resp.Body) if err != nil { fmt.Printf(\"read from resp.Body failed, err:%v\\n\", err) return } json.Unmarshal(body, \u0026uuid) fmt.Println(uuid.Uuid) } ","date":"2023-10-09","objectID":"/posts/go-http/:2:1","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Go 库文档"],"content":"POST 请求示例 package main import ( \"encoding/json\" \"io\" \"net/http\" \"net/url\" ) type dockerToken struct { Token string `json:\"token\"` } func main() { apiUrl := \"https://hub.docker.com/v2/users/login\" data := url.Values{} data.Set(\"username\", \"username\") data.Set(\"password\", \"password\") resp, err := http.PostForm(apiUrl, data) if err != nil { return } defer resp.Body.Close() _data, _ := io.ReadAll(resp.Body) var tmpT dockerToken json.Unmarshal(_data, \u0026tmpT) } package main import ( \"bytes\" \"io\" \"net/http\" \"net/url\" \"strings\" \"log/slog\" ) func POST1() { apiURL := \"https://httpbin.org/post\" form := url.Values{} form.Add(\"ln\", \"ln222\") form.Add(\"ip\", \"1.1.1.1\") form.Add(\"ua\", \"ua123\") client := \u0026http.Client{} req, _ := http.NewRequest(\"POST\", apiURL, strings.NewReader(form.Encode())) req.Header.Set(\"User-Agent\", \"test\") req.Header.Set(\"Content-Type\", \"application/x-www-form-urlencoded\") // 发送请求 resp, err := client.Do(req) if err != nil { slog.Error(\"POST request failed\", \"err\", err) return } defer resp.Body.Close() // 读取内容 body, err := io.ReadAll(resp.Body) if err != nil { slog.Error(\"POST request\", \"err\", err) } else { slog.Info(string(body)) } } func POSTJson() { apiURL := \"https://httpbin.org/post\" var jsonStr = []byte(`{\"title\":\"this is a title\", \"cate\": 1}`) client := \u0026http.Client{} req, _ := http.NewRequest(\"POST\", apiURL, bytes.NewBuffer(jsonStr)) req.Header.Set(\"User-Agent\", \"test\") req.Header.Set(\"Content-Type\", \"application/x-www-form-urlencoded\") // 发送请求 resp, err := client.Do(req) if err != nil { slog.Error(\"POST request failed\", \"err\", err) return } defer resp.Body.Close() // 读取内容 body, err := io.ReadAll(resp.Body) if err != nil { slog.Error(\"POST request\", \"err\", err) } else { slog.Info(string(body)) } } func main() { // POST1() POSTJson() } ","date":"2023-10-09","objectID":"/posts/go-http/:2:2","tags":["Go","http"],"title":"Go Http","uri":"/posts/go-http/"},{"categories":["Kubernetes","DevOps"],"content":"Dev in kubernetes ​ 传统的开发模式中，是代码存放在本地，使用 IDE 进行编辑和 debug 。但随着容器化火了之后，很多单一服务都进行了拆分，微服务化。在开发阶段，需要本地同时启动多个服务，这使得本地开发调试变得越来越困难。Okteto 是一个通过在 Kubernetes 中来开发和测试代码的应用程序开发工具。可以通过 Okteto 在 Kubernetes 中一键为我们启动一个开发环境，非常简单方便。Google 推出的 Skaffold 只是把 CICD 集成到本地，使用起来也比较困难。Okteto 的工作原理是在 kubernetes 中启动一个服务，把本地代码同步到 pod 中，然后执行命令让服务运行起来，Okteto 可以进行端口的转发，转发pod里服务的端口到本地，在进行 debug 的时候，pod里启动的端口可以被 kubernetes 内的其他服务所访问，本地转发的端口可以被本地的工具（例如 postman ）访问。 okteto官网文档：https://www.okteto.com/docs Go 配置文档：https://www.okteto.com/docs/samples/golang/ 示例环境： vscode 1.82.1(需要安装 Remote - Kubernetes 插件，插件code：okteto.remote-kubernetes) k3d mac ","date":"2023-09-26","objectID":"/posts/okteto/:0:0","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"安装与配置 下载okteto：https://github.com/okteto/okteto/releases [crab@Sugar ~]🐳 wget https://ghproxy.com/https://github.com/okteto/okteto/releases/download/2.20.0/okteto-Darwin-arm64 [crab@Sugar ~]🐳 chmod +x okteto-Darwin-arm64 [crab@Sugar ~]🐳 sudo mv okteto-Darwin-arm64 /usr/local/bin/okteto ","date":"2023-09-26","objectID":"/posts/okteto/:1:0","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"下载示例代码 [crab@Sugar ~]🐳 git clone https://github.com/okteto/go-getting-started go-okteto [crab@Sugar ~]🐳 cd go-okteto ","date":"2023-09-26","objectID":"/posts/okteto/:1:1","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"配置port-forward端口 需要转发两个，一个是服务的端口，另一个是debug使用的端口 okteto.yaml build: hello-world: image: serialt/go-hello-world:1.0.0 context: . deploy: - kubectl apply -f k8s.yml dev: hello-world: # 被替换的服务名 image: okteto/golang:1 command: bash sync: - .:/usr/src/app volumes: - /go - /root/.cache securityContext: capabilities: add: - SYS_PTRACE forward: - 2345:2345 - 8080:8080 # \u003c---- 增加8080服务端口转发 设置okteto context，okteto 默认会优先使用KUBECONFIG环境变量的配置文件，如果没有设置，则使用 ~/.kube/config文件 [crab@Sugar go-okteto]🐳 okteto context ✓ Context 'k3d-mycluster' selected ✓ Using dev @ k3d-mycluster ","date":"2023-09-26","objectID":"/posts/okteto/:1:2","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"启动服务 [crab@Sugar go-okteto]🐳 okteto up i Using dev @ k3d-mycluster as context i 'go-getting-started' was already deployed. To redeploy run 'okteto deploy' or 'okteto up --deploy' i Images were already built. To rebuild your images run 'okteto build' or 'okteto deploy --build' ✓ Images successfully pulled ✓ Files synchronized Context: k3d-mycluster Namespace: dev Name: hello-world Forward: 2345 -\u003e 2345 8080 -\u003e 8080 Welcome to your development container. Happy coding! dev:hello-world app\u003e dev:hello-world app\u003e ls Dockerfile LICENSE Makefile README.md bashrc go.mod k8s.yml main.go okteto.yml ","date":"2023-09-26","objectID":"/posts/okteto/:1:3","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"远程开发 # okteto终端 dev:hello-world app\u003e go run main.go Starting hello-world server... # 终端测试 [crab@Sugar ~]🐳 curl 127.0.0.1:8080 Hello world! ","date":"2023-09-26","objectID":"/posts/okteto/:1:4","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["Kubernetes","DevOps"],"content":"远程调试 # okteto终端, 执行dlv命令 dev:hello-world app\u003e dlv debug --headless --listen=:2345 --log --api-version=2 API server listening at: [::]:2345 2023-09-26T13:40:51Z warning layer=rpc Listening for remote connections (connections are not authenticated nor encrypted) 2023-09-26T13:40:51Z info layer=debugger launching process with args: [./__debug_bin3213431902] 2023-09-26T13:40:51Z debug layer=debugger Adding target 575 \"/usr/src/app/__debug_bin3213431902\" # main.go 打上debug标记 func helloServer(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \"Hello world from Okteto!, k3d is great! \") fmt.Println(\"okteto ccccccc\") # 标记此行 } 在vscode debug中点击开始debug 使用命令请求 http://127.0.0.1:8080，即可debug到标记点 [sugar@Sugar go-okteto]🐳 curl http://127.0.0.1:8080 Hello world from Okteto!, k3d is great! ","date":"2023-09-26","objectID":"/posts/okteto/:1:5","tags":["okteto","kubernetes","vscode","dev"],"title":"Okteto","uri":"/posts/okteto/"},{"categories":["vscode","DevOps"],"content":"Debug shell 1、安装插件 安装bashdb插件 rogalmic.bash-debug 2、增加一个vscode launch.json配置文件 Select Debug -\u003e Add Configuration to add custom debug configuration 示例： { \"configurations\": [ { \"type\": \"bashdb\", \"request\": \"launch\", \"name\": \"Bash-Debug\", \"cwd\": \"${workspaceFolder}\", \"program\": \"${workspaceFolder}/ccc.sh\", \"args\": [] }, ] } 就可以像debug其他语言一样进行调试shell脚本 ","date":"2023-09-24","objectID":"/posts/debug-shell-in-vscode/:0:0","tags":["shell"],"title":"Debug Shell in VSCode","uri":"/posts/debug-shell-in-vscode/"},{"categories":["DevOps"],"content":"清华镜像网页搭建镜像站 tuna mirror-web地址：https://github.com/tuna/mirror-web.git tuna mirror-web基于jekyll开发，由于ruby环境安装复杂，因此采用docker编译，但在build镜像的时候，出现安装包依赖安装失败，在多次测试后，无法build成镜像。前段时间，在查看mirror-web段issues时，有人询问mirror-web段README.md文档的下一步，官方给了一点提示，有关于基于nginx的第三方模块来实现目录第渲染的提示说明，再次尝试后，经历各种困难和折磨，终于摸索出。 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:0","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"1、下载mirror-web的jekyll编译环境 tuna的编译镜像：tunathu/mirror-web 在下载tunathu/mirror-web时发生了一个小问题，由于在国内使用的docker镜像加速，下载的镜像是旧版本的，但境外的服务器下载的镜像是最新的，在踩坑后果断推到自己的dockerhub上，新的下载地址：serialt/tuna-mirror-web。 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:1","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"2、下载github仓库 git clone https://github.com/tuna/mirror-web.git /opt/mirror-web ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:2","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"3、下载额外资源和编译 cd /opt/mirror-web wget https://mirrors.tuna.tsinghua.edu.cn/static/tunasync.json -O static/tunasync.json wget https://mirrors.tuna.tsinghua.edu.cn/static/tunet.json -O static/tunet.json mkdir -p static/status wget https://mirrors.tuna.tsinghua.edu.cn/static/status/isoinfo.json -O static/status/isoinfo.json docker run -it -v /opt/mirror-web/:/data serialt/tuna-mirror-web:20211006 编译的后静态文件在_site里 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:3","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"4、编译nginx 需要安装第三方模块 modules/ngx_http_js_module.so modules/ngx_http_fancyindex_module.so [root@serialt nginx]# ll 总用量 1068 drwxr-xr-x 9 sonar sonar 186 10月 5 22:27 nginx-1.20.1 -rw-r--r-- 1 root root 1061461 5月 25 23:34 nginx-1.20.1.tar.gz drwxrwxr-x 3 root root 217 10月 27 2020 ngx-fancyindex-0.5.1 -rw-r--r-- 1 root root 25148 10月 27 2020 ngx-fancyindex-0.5.1.tar.xz drwxr-xr-x 10 root root 228 10月 6 15:49 njs # njs下载 git clone https://github.com/nginx/njs # ngx-fancyindex 下载 wget https://github.com/aperezdc/ngx-fancyindex/releases/download/v0.5.1/ngx-fancyindex-0.5.1.tar.xz 编译： [root@serialt nginx]# ls nginx-1.20.1 nginx-1.20.1.tar.gz ngx-fancyindex-0.5.1 ngx-fancyindex-0.5.1.tar.xz njs [root@serialt nginx]# cd nginx-1.20.1/ [root@serialt nginx-1.20.1]# ./configure --prefix=/usr/local/nginx --with-pcre --with-http_auth_request_module --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-mail --with-mail_ssl_module --with-stream --with-stream_ssl_module --with-stream_realip_module --add-dynamic-module=/root/nginx/ngx-fancyindex-0.5.1 --add-dynamic-module=/root/nginx/njs/nginx # add m 3997 [2022-02-25 00:49:21] [root] [10.5.0.10] ./configure --with-compat --add-dynamic-module=/root/github/tuna-mirror-web/njs-0.6.2/nginx 3998 [2022-02-25 00:49:31] [root] [10.5.0.10] make modules nginx配置文件内容 [root@serialt mirrors]# cat /usr/local/nginx/conf/nginx.conf #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; load_module modules/ngx_http_js_module.so; load_module modules/ngx_http_fancyindex_module.so; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; map $http_user_agent $isbrowser { default 0; \"~*validation server\" 0; \"~*mozilla\" 1; } js_path /opt/mirror-web/_site/static/njs; js_include /opt/mirror-web/_site/static/njs/all.njs; #js_path /opt/mirror-web/static/njs; #js_include /opt/mirror-web/static/njs/all.njs; server { listen 8007; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; #root /opt/mirror-web/_site; fancyindex_header /fancy-index/before; fancyindex_footer /fancy-index/after; fancyindex_exact_size off; fancyindex_time_format \"%d %b %Y %H:%M:%S +0000\"; fancyindex_name_length 256; error_page 404 /404.html; location /fancy-index { internal; root /opt/mirror-web/_site; subrequest_output_buffer_size 100k; location = /fancy-index/before { js_content fancyIndexBeforeRender; } location = /fancy-index/after { js_content fancyIndexAfterRender; } } location / { root /opt/mirror-web/_site; index index.html index.htm; #try_files /_site/$uri $uri/ /_site/$uri; fancyindex on; } # location / { # root html; # index index.html index.htm; # } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } [root@serialt mirrors]# ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:4","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"5、镜像资源暴露 方法1：以软链接形式存放在/opt/mirror-web/_site中 [root@serialt _site]# pwd /opt/mirror-web/_site [root@serialt _site]# ll 总用量 160 -rw-r--r-- 1 root root 16415 10月 6 15:37 404.html drwxr-xr-x 2 root root 6 10月 6 17:14 cc drwxr-xr-x 2 root root 19 10月 6 17:14 centos drwxr-xr-x 2 root root 94 10月 6 09:25 fancy-index -rw-r--r-- 1 root root 36650 10月 6 15:37 feed.xml drwxr-xr-x 103 root root 4096 10月 6 09:25 help -rw-r--r-- 1 root root 27679 10月 6 15:37 index.html -rw-r--r-- 1 root root 20728 10月 6 15:37 legacy_index.html -rw-r--r-- 1 root root 18092 10月 6 15:37 LICENSE drwxr-xr-x 47 root root 4096 10月 6 09:25 news -rw-r--r-- 1 root root 58 10月 6 15:37 robots.txt -rw-r--r-- 1 root root 19134 10月 6 15:37 sitemap.xml drwxr-xr-x 8 root root 115 10月 6 15:37 static drwxr-xr-x 2 root root 24 10月 6 09:25 status 方法二：把/opt/mirror-web/_site里的文件以软链接的方式链接到镜像的跟目录（建议使用） ln -snf /opt/mirror-web/_site/* /opt/imau 目录描述文件：_data/options.yml 站点资源显示控制：static/tunasync.json tunasync.json [ { \"name\": \"ant\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"book\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"centos\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"dev\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"frp\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"git\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"go\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"grafana\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"iso\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"jdk\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"jmeter\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"kubernetes\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"mac\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"monitor\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"node\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"root-ca\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"other\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"printer\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"prometheus\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"pycharm\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"python\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"repo\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"script\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"test\", \"is_master\": true, \"status\": \"success\" }, { \"name\": \"tool\", \"is_master\": true, \"status\": \"success\" } ] \"last_update\": \"2022-01-11 16:39:37 +0800\", \"last_update_ts\": 1641890377, \"last_started\": \"2022-01-11 16:39:21 +0800\", \"last_started_ts\": 1641890361, \"last_ended\": \"2022-01-11 16:39:37 +0800\", \"last_ended_ts\": 1641890377, \"next_schedule\": \"2022-01-11 22:39:37 +0800\", \"next_schedule_ts\": 1641911977, \"upstream\": \"rsync://msync.centos.org/CentOS/\", - status: 'success' last_update: '-' name: \"AUR\" url: 'https://aur.tuna.tsinghua.edu.cn/' upstream: 'https://aur.archlinux.org/' is_master: true options.yml # Content Related mirror_desc: - name: git desc: git 二进制编译版本 - name: go desc: golang 开发环境 - name: grafana desc: grafana 的安装包 - name: helm desc: helm 的二进制发行包 - name: ios desc: 镜像文件，如centos, ubuntu, rocky等 - name: jdk desc: java 开发环境安装包 new_mirrors: - hugging-face-models - endeavouros - ubuntukylin - putty - postmarketOS - postmarketOS-images - obs-studio - stellarium unlisted_mirrors: - status: 'success' last_update: '-' name: \"AUR\" url: 'https://aur.tuna.tsinghua.edu.cn/' upstream: 'https://aur.archlinux.org/' is_master: true - link_to: 'osdn' name: \"manjaro-cd\" url: '/osdn/storage/g/m/ma/manjaro/' - link_to: 'osdn' name: \"manjaro-arm-cd\" url: '/osdn/storage/g/m/ma/manjaro-arm/' - link_to: 'osdn' name: \"mxlinux-isos\" url: '/osdn/storage/g/m/mx/mx-linux/ISOs/' - link_to: 'osdn' name: \"garuda-linux\" url: '/osdn/storage/g/g/ga/garuda-linux/' - link_to: 'osdn' name: \"linuxlite-cd\" url: '/osdn/storage/g/l/li/linuxlite/' - link_to: 'github-release' name: \"prometheus\" url: '/github-rele","date":"2023-09-24","objectID":"/posts/tuna-web/:1:5","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"6、docker镜像使用 静态文件编译 构建 Jekyll 的 docker 镜像环境复杂，建议直接使用官方或者已经存在的镜像tunathu/mirror-web或者serialt/tuna-mirror-web [root@tc ~]# docker run -it -v /path/to/mirror-web/:/data serialt/tuna-mirror-web 一些动态数据已经下载，若需要最新的，可以就行以下操作,然后在构建 下载最新的动态数据文件 wget https://mirrors.tuna.tsinghua.edu.cn/static/tunasync.json -O static/tunasync.json wget https://mirrors.tuna.tsinghua.edu.cn/static/tunet.json -O static/tunet.json mkdir -p static/status wget https://mirrors.tuna.tsinghua.edu.cn/static/status/isoinfo.json -O static/status/isoinfo.json 运行服务 docker镜像网页根目录: /opt/mirror-web 镜像站资源根目录: /opt/mirror 启动服务 docker run -tid -v /opt/tuna-mirror-web/_site:/opt/mirror-web -v /opt/mirror:/opt/mirror -p 8099:80 --name=tuna-mirror-nginx serialt/tuna-mirror-web-nginx:7b0c89d version: \"3\" networks: tuna-mirror-nginx: external: false services: tuna-mirror-nginx: image: serialt/tuna-mirror-web-nginx:latest container_name: mirror-nginx hostname: mirror-nginx restart: always networks: - tuna-mirror-nginx volumes: - \"/etc/localtime:/etc/localtime:ro\" - \"/opt/mirror-web/_site:/opt/mirror-web\" - \"/opt/mirror:/opt/mirror\" ports: - \"80:80\" dns: - 223.5.5.5 - 223.6.6.6 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:6","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"新镜像站版本发布 docker run -it --rm -v /opt/tuna-mirror-web:/data serialt/tuna-mirror-web docker restart tuna-mirror-nginx ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:7","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"编写说明 _data/options.yml: 是显示在镜像站主页对各个目录的说明 static/tunasync.json: 是对当前repo的同步信息的描述，可以自行编辑，也可以从tuna上下载 help: help目录里存有各个repo的帮助信息，在主页上会显示有个\"?\" news: 镜像站的新闻信息 ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:8","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["DevOps"],"content":"help 说明 permalink 是表示help的首页的路径，必须要有 --- layout: help category: help mirrorid: app permalink: /help/app/ --- ","date":"2023-09-24","objectID":"/posts/tuna-web/:1:9","tags":["mirrors"],"title":"Tuna Web","uri":"/posts/tuna-web/"},{"categories":["Kubernetes","DevOps"],"content":"helm oci ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:0","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"},{"categories":["Kubernetes","DevOps"],"content":"缘由 Helm 3.8 版本开始，支持使用oci进行存储chart。镜像存储常用的Harbor在v1.6版本开始支持Helm Chart仓库功能， chart仓库由chartmuseum以插件的方式提供。随着兼容OCI规范的Helm Chart在社区上被更广泛地接受，Helm Chart能以Artifact的形式在Harbor中存储和管理，不再依赖ChartMuseum，因此Harbor在v2.8.0版本中，移除对ChartMuseum的支持。 ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:1","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"},{"categories":["Kubernetes","DevOps"],"content":"registry 仓库使用 基本使用 ### registry # 登录 helm registry login -u serialt docker.io # 注销 helm registry logout docker.io # pull chart helm fetch oci://docker.io/serialt/loki-stack --version=2.9.11 # push chart helm push loki-stack-2.9.11.tgz oci://docker.io/serialt oci支持的其他命令 helm pull helm show helm template helm install helm upgrade $ helm pull oci://localhost:5000/helm-charts/mychart --version 0.1.0 Pulled: localhost:5000/helm-charts/mychart:0.1.0 Digest: sha256:0be7ec9fb7b962b46d81e4bb74fdcdb7089d965d3baca9f85d64948b05b402ff $ helm show all oci://localhost:5000/helm-charts/mychart --version 0.1.0 apiVersion: v2 appVersion: 1.16.0 description: A Helm chart for Kubernetes name: mychart ... $ helm template myrelease oci://localhost:5000/helm-charts/mychart --version 0.1.0 --- # Source: mychart/templates/serviceaccount.yaml apiVersion: v1 kind: ServiceAccount ... $ helm install myrelease oci://localhost:5000/helm-charts/mychart --version 0.1.0 NAME: myrelease LAST DEPLOYED: Wed Oct 27 15:11:40 2021 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: ... $ helm upgrade myrelease oci://localhost:5000/helm-charts/mychart --version 0.2.0 Release \"myrelease\" has been upgraded. Happy Helming! NAME: myrelease LAST DEPLOYED: Wed Oct 27 15:12:05 2021 NAMESPACE: default STATUS: deployed REVISION: 2 NOTES: ... ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:2","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"},{"categories":["Kubernetes","DevOps"],"content":"迁移 chart repo 到 oci 仓库 基于 github action 镜像 helm repo 仓库到 docker hub，以加速 helm repo 到访问。 migrate-chart ","date":"2023-09-24","objectID":"/posts/helm-migrate-oci/:1:3","tags":["helm"],"title":"Helm Migrate OCI","uri":"/posts/helm-migrate-oci/"},{"categories":null,"content":"ccd ip 使用 openvpn配置客户端静态IP 1）在配置文件中添加一个目录 cd /etc/openvpn # server.conf client-config-dir ccd 2）创建目录 mkdir -p /etc/openvpn/ccd 3）创建文件配置客户端IP 这里需要注意，创建的这个文件就是用你的用户名，比如这里我的用户名是liao，那么创建的文件也是liao touch /etc/openvpn/ccd/liao 内容写入，ifconfig-push中的每一对IP地址表示虚拟客户端和服务器的IP端点 echo “ifconfig-push 10.8.0.5 10.8.0.6” \u003e /etc/openvpn/ccd/liao 注意：这里分配的IP规则如下 # ifconfig-push中的每一对IP地址表示虚拟客户端和服务器的IP端点 # 它们必须从连续的/30子网网段中获取(这里是/30表示xxx.xxx.xxx.xxx/30，即子网掩码位数为30) # 以便于与Windows客户端和TAP-Windows驱动兼容。明确地说，每个端点的IP地址对的最后8位字节必须取自下面的集合： [ 1, 2] [ 5, 6] [ 9, 10] [ 13, 14] [ 17, 18] [ 21, 22] [ 25, 26] [ 29, 30] [ 33, 34] [ 37, 38] [ 41, 42] [ 45, 46] [ 49, 50] [ 53, 54] [ 57, 58] [ 61, 62] [ 65, 66] [ 69, 70] [ 73, 74] [ 77, 78] [ 81, 82] [ 85, 86] [ 89, 90] [ 93, 94] [ 97, 98] [101,102] [105,106] [109,110] [113,114] [117,118] [121,122] [125,126] [129,130] [133,134] [137,138] [141,142] [145,146] [149,150] [153,154] [157,158] [161,162] [165,166] [169,170] [173,174] [177,178] [181,182] [185,186] [189,190] [193,194] [197,198] [201,202] [205,206] [209,210] [213,214] [217,218] [221,222] [225,226] [229,230] [233,234] [237,238] [241,242] [245,246] [249,250] [253,254] 4）重启生效 systemctl restart openvpn@server 总结：这里需要注意的是分配静态IP的时候需要参考文章中的注意点，按对应分配否则会出现兼容问题或者连接不上情况 ","date":"0001-01-01","objectID":"/posts/2024-06-13-openvpn/:0:1","tags":null,"title":"","uri":"/posts/2024-06-13-openvpn/"},{"categories":null,"content":"Task 是一个任务运行器/构建工具，旨在比 GNU Make 等更简单易用。 由于它是用 Go 编写的，Task 只是一个二进制文件，没有其他依赖项，这意味着您不需要为了使用构建工具而烦恼任何复杂的安装设置。 安装 后，您只需在名为 Taskfile.yml 的文件中使用简单的 YAML 规则描述您的构建任务： task 支持发文件名称 Taskfile.yml taskfile.yml Taskfile.yaml taskfile.yaml Taskfile.dist.yml taskfile.dist.yml Taskfile.dist.yaml taskfile.dist.yaml 示例： version: '3' vars: PROJECT_NAME: cli BRANCH: sh: git symbolic-ref HEAD 2\u003e/dev/null | cut -d\"/\" -f 3 VERSION: \"{{ .BRANCH }}\" # 获取最新的tag # sh: git fetch --tags \u0026\u0026 git tag | sort -V | tail -1 APP_NAME: \"{{ .PROJECT_NAME }}\" GIT_COMMIT: # 短hash # sh: git log -n 1 --format=%h # 长hash sh: git rev-parse HEAD GoVersion: sh: go version | cut -d \" \" -f 3 BuildTime: '{{now | date \"Mon Jan 02 15:04:05 SGT 2006\"}}' Maintainer: tserialt@gmail.com PKGFLAGS: \" -s -w -X 'main.APPVersion={{ .VERSION }}' -X 'main.GoVersion={{ .GoVersion }}' -X 'main.BuildTime={{ .BuildTime }}' -X 'main.GitCommit={{ .GIT_COMMIT }}' \" tasks: clean: cmds: - rm -rf dist/{{ .PROJECT_NAME }}* run: cmds: - go run . build: cmds: - go build -trimpath -ldflags \"{{ .PKGFLAGS }}\" -o \"dist/{{ .APP_NAME }}\" build-linux: vars: OS_TYPE: linux cmds: - GOOS=\"{{ .OS_TYPE }}\" GOARCH=\"amd64\" go build -trimpath -ldflags \"{{ .PKGFLAGS }}\" -v -o \"dist/{{ .APP_NAME }}-{{ .OS_TYPE }}-amd64\" - GOOS=\"{{ .OS_TYPE }}\" GOARCH=\"arm64\" go build -trimpath -ldflags \"{{ .PKGFLAGS }}\" -v -o \"dist/{{ .APP_NAME }}-{{ .OS_TYPE }}-arm64\" build-mac: vars: OS_TYPE: darwin cmds: - GOOS=\"{{ .OS_TYPE }}\" GOARCH=\"amd64\" go build -trimpath -ldflags \"{{ .PKGFLAGS }}\" -v -o \"dist/{{ .APP_NAME }}-{{ .OS_TYPE }}-amd64\" - GOOS=\"{{ .OS_TYPE }}\" GOARCH=\"arm64\" go build -trimpath -ldflags \"{{ .PKGFLAGS }}\" -v -o \"dist/{{ .APP_NAME }}-{{ .OS_TYPE }}-arm64\" build-win: vars: OS_TYPE: windows cmds: - GOOS=\"{{ .OS_TYPE }}\" GOARCH=\"amd64\" go build -trimpath -ldflags \"{{ .PKGFLAGS }}\" -v -o \"dist/{{ .APP_NAME }}-{{ .OS_TYPE }}-amd64.exe\" release: cmds: - task: build-linux - task: build-mac - task: build-win - task: banner banner: cmds: - cmd: echo -e \"\\n******************************\\n\\n build succeed \\n\\n******************************\\n\" silent: true default: deps: [clean] cmds: - task: build - task: banner ","date":"0001-01-01","objectID":"/posts/2024-06-14-taskfile/:0:0","tags":null,"title":"","uri":"/posts/2024-06-14-taskfile/"}]